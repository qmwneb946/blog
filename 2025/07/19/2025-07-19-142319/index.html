<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>跨越语言的藩篱：深入探索跨语言信息检索技术 | qmwneb946 的博客</title><meta name="author" content="qmwneb946"><meta name="copyright" content="qmwneb946"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="作者：qmwneb946  引言：语言的壁垒与全球知识的渴望 在数字时代，信息爆炸式增长，知识以前所未有的速度传播。然而，一个根本性的挑战依然存在：语言的壁垒。全球拥有数千种语言，每一种语言都承载着独特的文化、历史和知识。当我们试图从互联网、文献库或其他信息源中获取信息时，往往会被限制在自己所理解的语言范围内。想象一下，一篇关于量子计算的突破性论文以日语发表，一篇关于古代历史的珍贵文献仅存西班牙语">
<meta property="og:type" content="article">
<meta property="og:title" content="跨越语言的藩篱：深入探索跨语言信息检索技术">
<meta property="og:url" content="https://qmwneb946.dpdns.org/2025/07/19/2025-07-19-142319/index.html">
<meta property="og:site_name" content="qmwneb946 的博客">
<meta property="og:description" content="作者：qmwneb946  引言：语言的壁垒与全球知识的渴望 在数字时代，信息爆炸式增长，知识以前所未有的速度传播。然而，一个根本性的挑战依然存在：语言的壁垒。全球拥有数千种语言，每一种语言都承载着独特的文化、历史和知识。当我们试图从互联网、文献库或其他信息源中获取信息时，往往会被限制在自己所理解的语言范围内。想象一下，一篇关于量子计算的突破性论文以日语发表，一篇关于古代历史的珍贵文献仅存西班牙语">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://qmwneb946.dpdns.org/img/icon.png">
<meta property="article:published_time" content="2025-07-19T06:23:19.000Z">
<meta property="article:modified_time" content="2025-07-22T07:56:20.561Z">
<meta property="article:author" content="qmwneb946">
<meta property="article:tag" content="2025">
<meta property="article:tag" content="数学">
<meta property="article:tag" content="跨语言信息检索技术">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://qmwneb946.dpdns.org/img/icon.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "跨越语言的藩篱：深入探索跨语言信息检索技术",
  "url": "https://qmwneb946.dpdns.org/2025/07/19/2025-07-19-142319/",
  "image": "https://qmwneb946.dpdns.org/img/icon.png",
  "datePublished": "2025-07-19T06:23:19.000Z",
  "dateModified": "2025-07-22T07:56:20.561Z",
  "author": [
    {
      "@type": "Person",
      "name": "qmwneb946",
      "url": "https://github.com/qmwneb946"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://qmwneb946.dpdns.org/2025/07/19/2025-07-19-142319/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '跨越语言的藩篱：深入探索跨语言信息检索技术',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2845632165165414" crossorigin="anonymous"></script><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="qmwneb946 的博客" type="application/atom+xml">
</head><body><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">qmwneb946 的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">跨越语言的藩篱：深入探索跨语言信息检索技术</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">跨越语言的藩篱：深入探索跨语言信息检索技术<a class="post-edit-link" href="https://github.com/qmwneb946/blog/edit/main/source/_posts/2025-07-19-142319.md" title="编辑" target="_blank"><i class="fas fa-pencil-alt"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-07-19T06:23:19.000Z" title="发表于 2025-07-19 14:23:19">2025-07-19</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-07-22T07:56:20.561Z" title="更新于 2025-07-22 15:56:20">2025-07-22</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%95%B0%E5%AD%A6/">数学</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><p><strong>作者：qmwneb946</strong></p>
<hr>
<h3 id="引言：语言的壁垒与全球知识的渴望">引言：语言的壁垒与全球知识的渴望</h3>
<p>在数字时代，信息爆炸式增长，知识以前所未有的速度传播。然而，一个根本性的挑战依然存在：语言的壁垒。全球拥有数千种语言，每一种语言都承载着独特的文化、历史和知识。当我们试图从互联网、文献库或其他信息源中获取信息时，往往会被限制在自己所理解的语言范围内。想象一下，一篇关于量子计算的突破性论文以日语发表，一篇关于古代历史的珍贵文献仅存西班牙语版本，或者一个特定疾病的最新治疗方案只在德语论坛中被讨论。如果我们的信息检索系统无法跨越这些语言障碍，那么我们所能获取的知识就仅仅是全球知识海洋中的一小部分——一个巨大的信息鸿沟由此产生。</p>
<p>这种信息不对称不仅阻碍了个人学习和研究，更可能影响科学发现、商业决策乃至全球合作。如何打破这种语言壁垒，让不同语言的信息能够被不同语言的用户检索并理解，正是“跨语言信息检索”（Cross-Lingual Information Retrieval, CLIR）技术的核心目标。</p>
<p>CLIR不仅仅是将一种语言的文本简单地翻译成另一种语言，它更深层次的挑战在于如何理解不同语言表达背后的语义，如何在语义层面进行匹配，从而实现用户以其母语查询，却能获取到任何语言的、相关的信息。这项技术融合了自然语言处理（NLP）、机器学习、信息检索（IR）以及计算语言学等多个领域的智慧，是构建真正全球化知识图谱的关键一环。</p>
<p>作为一位技术爱好者，你可能会好奇：这项技术是如何实现的？它面临着哪些挑战？最新的深度学习技术又如何赋能CLIR？在本文中，我将带领大家深入探讨CLIR的世界，从基础概念、核心方法到前沿进展，共同揭开跨语言信息检索的神秘面纱。</p>
<h3 id="跨语言信息检索-CLIR-的挑战与核心概念">跨语言信息检索 (CLIR) 的挑战与核心概念</h3>
<p>要理解CLIR，我们首先需要明确它所面临的独特挑战和核心的运作模式。与单语言信息检索（Monolingual IR）不同，CLIR在查询和文档之间增加了一个“语言转换”的维度。</p>
<h4 id="语言多样性：表征的鸿沟">语言多样性：表征的鸿沟</h4>
<p>语言是人类思想的载体，但不同语言在词汇、语法、句法和语义表达上存在巨大差异。</p>
<ul>
<li><strong>词汇差异：</strong> 词语的意义在不同语言中可能存在一对多（多义词）、多对一（同义词）或无对应（特定文化概念）的关系。例如，一个英语单词可能需要用多个中文词才能准确表达其含义，反之亦然。</li>
<li><strong>句法差异：</strong> 句子结构、语序在不同语言中千差万别。例如，英语是SVO（主谓宾），日语是SOV（主宾谓）。</li>
<li><strong>语义差异：</strong> 即使表面上能找到对应词，其隐含的文化背景、语用含义也可能大相径庭。例如，“hot dog”在中文中直接翻译是“热狗”，但其作为一种食物的概念远不止字面意义。</li>
<li><strong>形态差异：</strong> 许多语言有丰富的词形变化（屈折变化），这使得词干提取和词形还原在不同语言中具有不同的复杂性。</li>
</ul>
<p>这些差异使得简单地将查询或文档进行“词对词”的翻译变得不可靠，甚至会引入歧义，导致检索结果的质量下降。</p>
<h4 id="CLIR-的基本范式">CLIR 的基本范式</h4>
<p>CLIR通常可以归结为以下几种基本范式：</p>
<ol>
<li><strong>查询翻译 (Query Translation, QT)：</strong> 将用户用源语言输入的查询翻译成目标语言，然后在目标语言的文档集合上进行单语检索。这是最常见也最直观的方法。</li>
<li><strong>文档翻译 (Document Translation, DT)：</strong> 将整个目标语言的文档集合翻译成源语言，然后将用户查询直接在翻译后的文档集合上进行单语检索。</li>
<li><strong>混合方法 (Hybrid Methods)：</strong> 结合QT和DT的优点，例如先对查询进行翻译，再利用文档的元数据或部分内容进行辅助判断。</li>
<li><strong>跨语言表示 (Cross-Lingual Representation)：</strong> 不进行显式翻译，而是将查询和文档都映射到一个共同的、语言无关的语义空间中，在这个空间中计算它们的相似度。这是当前深度学习领域研究的热点。</li>
</ol>
<h4 id="评测指标">评测指标</h4>
<p>衡量CLIR系统性能的标准与单语IR类似，但需要考虑跨语言的复杂性。常用的指标包括：</p>
<ul>
<li><strong>准确率 (Precision):</strong> 检索到的相关文档数量占所有检索到文档数量的比例。<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∣</mi><mtext>相关并检索到</mtext><mi mathvariant="normal">∣</mi></mrow><mrow><mi mathvariant="normal">∣</mi><mtext>检索到</mtext><mi mathvariant="normal">∣</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">P = \frac{|\text{相关并检索到}|}{|\text{检索到}|} 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣</span><span class="mord text"><span class="mord cjk_fallback">检索到</span></span><span class="mord">∣</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣</span><span class="mord text"><span class="mord cjk_fallback">相关并检索到</span></span><span class="mord">∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
</li>
<li><strong>召回率 (Recall):</strong> 检索到的相关文档数量占所有相关文档数量的比例。<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>R</mi><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∣</mi><mtext>相关并检索到</mtext><mi mathvariant="normal">∣</mi></mrow><mrow><mi mathvariant="normal">∣</mi><mtext>所有相关</mtext><mi mathvariant="normal">∣</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">R = \frac{|\text{相关并检索到}|}{|\text{所有相关}|} 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣</span><span class="mord text"><span class="mord cjk_fallback">所有相关</span></span><span class="mord">∣</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣</span><span class="mord text"><span class="mord cjk_fallback">相关并检索到</span></span><span class="mord">∣</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
</li>
<li><strong>F1分数 (F1-score):</strong> 准确率和召回率的调和平均值。<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>F</mi><mn>1</mn><mo>=</mo><mn>2</mn><mo>×</mo><mfrac><mrow><mi>P</mi><mo>×</mo><mi>R</mi></mrow><mrow><mi>P</mi><mo>+</mo><mi>R</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">F1 = 2 \times \frac{P \times R}{P + R} 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:2.1297em;vertical-align:-0.7693em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3603em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
</li>
<li><strong>平均准确率 (Mean Average Precision, MAP):</strong> 衡量排序质量，对每个查询计算其平均准确率，然后对所有查询取平均。</li>
<li><strong>归一化折损累计增益 (Normalized Discounted Cumulative Gain, NDCG):</strong> 更精细地考虑了检索结果的排序，并对相关性高的结果赋予更高的权重，对排名靠前的结果赋予更高的折扣。<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>D</mi><mi>C</mi><msub><mi>G</mi><mi>p</mi></msub><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>p</mi></munderover><mfrac><mrow><mi>r</mi><mi>e</mi><msub><mi>l</mi><mi>i</mi></msub></mrow><mrow><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><mi>i</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">DCG_p = \sum_{i=1}^{p} \frac{rel_i}{\log_2(i+1)} 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.9762em;vertical-align:-1.2777em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6985em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3471em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.207em;"><span style="top:-2.4559em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2441em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">re</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0197em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>I</mi><mi>D</mi><mi>C</mi><msub><mi>G</mi><mi>p</mi></msub><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>p</mi></munderover><mfrac><mrow><mi>r</mi><mi>e</mi><msubsup><mi>l</mi><mi>i</mi><mrow><mi>i</mi><mi>d</mi><mi>e</mi><mi>a</mi><mi>l</mi></mrow></msubsup></mrow><mrow><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mn>2</mn></msub><mo stretchy="false">(</mo><mi>i</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">IDCG_p = \sum_{i=1}^{p} \frac{rel_i^{ideal}}{\log_2(i+1)} 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.9762em;vertical-align:-1.2777em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6985em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3471em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5261em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.207em;"><span style="top:-2.4559em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2441em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">re</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-2.4413em;margin-left:-0.0197em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2587em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>N</mi><mi>D</mi><mi>C</mi><msub><mi>G</mi><mi>p</mi></msub><mo>=</mo><mfrac><mrow><mi>D</mi><mi>C</mi><msub><mi>G</mi><mi>p</mi></msub></mrow><mrow><mi>I</mi><mi>D</mi><mi>C</mi><msub><mi>G</mi><mi>p</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">NDCG_p = \frac{DCG_p}{IDCG_p} 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.3324em;vertical-align:-0.9721em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3603em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9721em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mi>e</mi><msub><mi>l</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">rel_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord mathnormal">re</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0197em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 个结果的相关性得分。</li>
</ul>
<p>这些指标帮助我们量化不同CLIR方法的有效性，并指导我们优化系统。</p>
<h3 id="CLIR-的主要方法：从传统到深度学习">CLIR 的主要方法：从传统到深度学习</h3>
<p>CLIR的发展历程可以看作是对“如何有效跨越语言鸿沟”的不断探索。早期方法多依赖于词典和统计模型，而近年来，随着深度学习的崛起，基于表示学习的方法成为主流。</p>
<h4 id="基于翻译的方法-Translation-Based-CLIR">基于翻译的方法 (Translation-Based CLIR)</h4>
<p>这是最直观的CLIR方法，其核心思想是利用机器翻译（Machine Translation, MT）将查询或文档从一种语言转换到另一种。</p>
<h5 id="查询翻译-Query-Translation-QT">查询翻译 (Query Translation, QT)</h5>
<p>将用户用源语言输入的查询翻译成目标语言，然后在目标语言的文档集合上进行单语检索。</p>
<ul>
<li>
<p><strong>词典翻译 (Dictionary-based Query Translation):</strong></p>
<ul>
<li><strong>原理：</strong> 依赖双语词典或多语词典，将查询中的每个词语翻译成目标语言的一个或多个对应词。</li>
<li><strong>优点：</strong> 简单，易于实现，对于特定领域或术语有较高精度（如果词典构建得好）。</li>
<li><strong>缺点：</strong> 无法处理词典中不存在的词（OOV问题），无法处理多词短语、短语歧义和上下文依赖，容易造成查询失真或过度扩展（一个词翻译成多个词）。</li>
<li><strong>改进：</strong> 利用词语的权重（例如IDF值）来选择最佳翻译，或者结合统计信息来选择最可能的翻译。</li>
</ul>
</li>
<li>
<p><strong>统计机器翻译 (Statistical Machine Translation, SMT):</strong></p>
<ul>
<li><strong>原理：</strong> 基于大规模并行语料库（同一内容在两种语言中的对照翻译），通过统计模型学习源语言句子到目标语言句子的映射规则。核心模型包括基于词的模型（如IBM Models）和基于短语的模型（Phrase-Based SMT, PBSMT）。PBSMT通过学习短语对的翻译概率和重排序模型来生成翻译。</li>
<li><strong>优点：</strong> 能够处理短语和上下文，翻译质量通常优于单纯的词典翻译。</li>
<li><strong>缺点：</strong> 依赖高质量的并行语料，对语料的规模和领域有较高要求；模型复杂，训练耗时。</li>
</ul>
</li>
<li>
<p><strong>神经网络机器翻译 (Neural Machine Translation, NMT):</strong></p>
<ul>
<li><strong>原理：</strong> 利用深度神经网络（特别是循环神经网络RNN、卷积神经网络CNN和Transformer模型）直接学习从源语言句子到目标语言句子的端到端映射。NMT模型能够捕捉长距离依赖关系，生成更流畅、更符合语法规则的翻译。Transformer架构（基于自注意力机制）在NMT中取得了巨大成功，成为当前主流。</li>
<li><strong>优点：</strong> 翻译质量显著提升，尤其在处理复杂句式和语境方面表现优异；泛化能力强。</li>
<li><strong>缺点：</strong> 需要海量的并行语料进行训练；计算资源需求大；对于低资源语言（数据稀缺的语言）效果可能不佳。</li>
</ul>
</li>
<li>
<p><strong>跨语言词嵌入 (Cross-lingual Word Embeddings) 用于查询翻译：</strong></p>
<ul>
<li><strong>原理：</strong> 不直接生成句子翻译，而是将源语言的查询词语或整个查询表示为向量，然后通过预训练的跨语言词嵌入模型将其映射到目标语言的向量空间中。在这个共享空间中，可以找到与查询向量最接近的目标语言词语或短语。</li>
<li><strong>方法：</strong>
<ul>
<li><strong>监督对齐：</strong> 利用少量双语词典（Anchor Pairs），通过线性变换（如Procrustes Analysis）将一种语言的词向量空间对齐到另一种语言的词向量空间。</li>
<li><strong>无监督对齐：</strong> 在没有并行词典的情况下，通过对抗训练（如GANs）、迭代最近邻搜索等方法，利用两种语言词向量分布的相似性进行对齐（例如VecMap, MUSE）。</li>
</ul>
</li>
<li><strong>优点：</strong> 能够捕捉词语的语义相似性，即使是未见过的词，如果语义相似，也可能找到好的映射。对于OOV问题有一定缓解作用。</li>
<li><strong>缺点：</strong> 对齐效果受词向量质量和对齐算法影响。</li>
</ul>
</li>
</ul>
<p><strong>示例：使用Python进行简单的查询翻译（以Transformer模型为例）</strong></p>
<p>这里我们使用Hugging Face的<code>transformers</code>库，它封装了许多预训练的NMT模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 首先，确保你安装了transformers库</span></span><br><span class="line"><span class="comment"># pip install transformers sentencepiece accelerate</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载一个多语言翻译模型，例如&#x27;Helsinki-NLP/opus-mt-zh-en&#x27; (中文到英文)</span></span><br><span class="line"><span class="comment"># 更多模型可以在Hugging Face模型中心查找：https://huggingface.co/Helsinki-NLP</span></span><br><span class="line">translator = pipeline(<span class="string">&quot;translation&quot;</span>, model=<span class="string">&quot;Helsinki-NLP/opus-mt-zh-en&quot;</span>)</span><br><span class="line"></span><br><span class="line">chinese_query = <span class="string">&quot;量子计算的最新进展&quot;</span></span><br><span class="line">english_query = translator(chinese_query)[<span class="number">0</span>][<span class="string">&#x27;translation_text&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;原始中文查询: <span class="subst">&#123;chinese_query&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;翻译后的英文查询: <span class="subst">&#123;english_query&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可以加载一个英文到中文的模型 &#x27;Helsinki-NLP/opus-mt-en-zh&#x27;</span></span><br><span class="line">translator_en_zh = pipeline(<span class="string">&quot;translation&quot;</span>, model=<span class="string">&quot;Helsinki-NLP/opus-mt-en-zh&quot;</span>)</span><br><span class="line">english_text = <span class="string">&quot;The latest advancements in artificial intelligence.&quot;</span></span><br><span class="line">chinese_text = translator_en_zh(english_text)[<span class="number">0</span>][<span class="string">&#x27;translation_text&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;原始英文查询: <span class="subst">&#123;english_text&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;翻译后的中文查询: <span class="subst">&#123;chinese_text&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意：这些Helsinki-NLP模型是基于opus数据集训练的，对于通用领域表现较好。</span></span><br><span class="line"><span class="comment"># 对于特定领域的翻译，可能需要微调或使用更专业的模型。</span></span><br></pre></td></tr></table></figure>
<h5 id="文档翻译-Document-Translation-DT">文档翻译 (Document Translation, DT)</h5>
<p>将目标语言的整个文档集合翻译成源语言，然后进行单语检索。</p>
<ul>
<li><strong>原理：</strong> 预先将所有待检索的文档翻译成用户查询的语言（或某种公共语言），然后进行标准的单语检索。</li>
<li><strong>优点：</strong> 检索阶段是标准的单语IR，可以利用成熟的单语IR技术和工具；翻译过程可以在离线进行，不影响实时检索性能。</li>
<li><strong>缺点：</strong> 计算成本和存储成本巨大，特别是对于大规模文档集合和多种目标语言；翻译错误会在文档层面传播，可能导致大量噪音或信息丢失，影响检索精度；翻译质量难以保证，尤其是对于长文档和不同领域。</li>
</ul>
<h5 id="混合翻译-Hybrid-Translation">混合翻译 (Hybrid Translation)</h5>
<p>结合QT和DT的优点，或者在翻译过程中引入更多的上下文信息。例如，可以通过查询翻译得到候选文档，然后对候选文档进行部分翻译或摘要翻译，再进行更精细的匹配。</p>
<h4 id="基于跨语言表示的方法-Cross-Lingual-Representation-Based-CLIR">基于跨语言表示的方法 (Cross-Lingual Representation-Based CLIR)</h4>
<p>这类方法不进行显式的语言转换（翻译），而是将不同语言的文本映射到同一个“语义空间”中，在这个共享空间中，可以计算查询和文档之间的语义相似度。这是当前CLIR领域的研究前沿，尤其是在深度学习时代得到了长足发展。</p>
<h5 id="跨语言主题模型-Cross-Lingual-Topic-Models">跨语言主题模型 (Cross-Lingual Topic Models)</h5>
<ul>
<li><strong>原理：</strong> 假设不同语言的文档都围绕着一组共同的潜在主题。通过分析不同语言文本的词语分布，学习这些共享的主题，并将文档表示为主题的混合。如果查询和文档在这些潜在主题上的分布相似，则认为它们是相关的。</li>
<li><strong>代表模型：</strong>
<ul>
<li><strong>Parallel Latent Semantic Analysis (PLSA) / Latent Dirichlet Allocation (LDA) 的扩展：</strong> 将LSA或LDA应用于并行语料或可比语料，使其能够学习跨语言的主题分布。例如，CL-LDA（Cross-Lingual LDA）可以在给定一些对齐文档的情况下，学习共享的主题。</li>
<li><strong>Biterm Topic Models (BTM) 的跨语言扩展：</strong> 关注词对（biterms）而不是文档，可以更好地处理短文本。</li>
</ul>
</li>
<li><strong>优点：</strong> 能够捕捉文档的宏观语义主题；对词汇差异不敏感。</li>
<li><strong>缺点：</strong> 主题模型对语料质量和规模有要求；对主题的解释性有时不明确；难以捕捉细粒度的语义信息。</li>
</ul>
<h5 id="跨语言词嵌入-Cross-Lingual-Word-Embeddings">跨语言词嵌入 (Cross-Lingual Word Embeddings)</h5>
<p>在“查询翻译”部分我们简单提到了跨语言词嵌入，这里我们进行更深入的探讨。它在CLIR中的应用不仅仅是翻译查询词，更重要的是将查询和文档都表示为语义向量，并在共同的向量空间中进行相似度计算。</p>
<ul>
<li><strong>基本思想：</strong> 训练不同语言的词嵌入，然后通过某种方式（监督或无监督）将这些独立的词向量空间对齐，使得在不同语言中具有相同或相似语义的词语，在对齐后的空间中也具有相近的向量表示。</li>
<li><strong>监督对齐方法：</strong>
<ul>
<li><strong>Procrustes Analysis：</strong> 给定少量双语词典作为“锚点”，通过学习一个线性变换矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span></span></span>，使得源语言词向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> 经过 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mi>W</mi></mrow><annotation encoding="application/x-tex">XW</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span></span></span> 变换后，与目标语言词向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span> 的对应部分尽可能接近。即最小化 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi>X</mi><mi>W</mi><mo>−</mo><mi>Y</mi><mi mathvariant="normal">∣</mi><msubsup><mi mathvariant="normal">∣</mi><mi>F</mi><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">||XW - Y||_F^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣∣</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0894em;vertical-align:-0.2753em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mord">∣</span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-2.4247em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">F</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2753em;"><span></span></span></span></span></span></span></span></span></span>。</li>
<li><strong><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mi>W</mi><mo>≈</mo><mi>Y</mi></mrow><annotation encoding="application/x-tex">XW \approx Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span></strong></li>
<li><strong>缺点：</strong> 依赖于高质量的双语词典，且线性变换可能不足以捕捉复杂的跨语言语义关系。</li>
</ul>
</li>
<li><strong>无监督对齐方法：</strong>
<ul>
<li><strong>对抗训练 (Adversarial Training)：</strong> 灵感来源于GANs。一个生成器试图将源语言向量映射到目标语言向量空间，一个判别器试图区分这些映射后的向量是来自真实的目标语言向量还是来自生成器。通过这种对抗训练，生成器被迫学习一个能使得源语言和目标语言向量分布难以区分的映射。代表模型有MUSE (Multilingual Unsupervised and Supervised Embeddings)。</li>
<li><strong>迭代最近邻搜索 (Iterative Closest Point, ICP) 变体：</strong> 迭代地寻找两种语言中最接近的向量对作为新的锚点，然后重新计算对齐矩阵，直至收敛。</li>
<li><strong>优点：</strong> 不需要并行语料或双语词典，适用于低资源语言；能够发现更复杂的非线性对齐关系。</li>
<li><strong>缺点：</strong> 对齐效果受词向量质量、初始化和迭代策略影响，可能存在概念漂移。</li>
</ul>
</li>
</ul>
<p>一旦获得对齐的跨语言词嵌入，就可以用它们来构建句子或文档的跨语言表示（例如通过平均词向量），然后计算查询和文档向量之间的余弦相似度。</p>
<p><strong>余弦相似度 (Cosine Similarity):</strong><br>
对于两个向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf{A}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6861em;"></span><span class="mord mathbf">A</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">B</mi></mrow><annotation encoding="application/x-tex">\mathbf{B}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6861em;"></span><span class="mord mathbf">B</span></span></span></span>，其余弦相似度定义为：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>similarity</mtext><mo>=</mo><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi mathvariant="bold">A</mi><mo>⋅</mo><mi mathvariant="bold">B</mi></mrow><mrow><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi mathvariant="bold">A</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mo>⋅</mo><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi mathvariant="bold">B</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>A</mi><mi>i</mi></msub><msub><mi>B</mi><mi>i</mi></msub></mrow><mrow><msqrt><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msubsup><mi>A</mi><mi>i</mi><mn>2</mn></msubsup></mrow></msqrt><msqrt><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msubsup><mi>B</mi><mi>i</mi><mn>2</mn></msubsup></mrow></msqrt></mrow></mfrac></mrow><annotation encoding="application/x-tex">\text{similarity} = \cos(\theta) = \frac{\mathbf{A} \cdot \mathbf{B}}{||\mathbf{A}|| \cdot ||\mathbf{B}||} = \frac{\sum_{i=1}^n A_i B_i}{\sqrt{\sum_{i=1}^n A_i^2} \sqrt{\sum_{i=1}^n B_i^2}} 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord text"><span class="mord">similarity</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">cos</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.2991em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3631em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣∣</span><span class="mord mathbf">A</span><span class="mord">∣∣</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">∣∣</span><span class="mord mathbf">B</span><span class="mord">∣∣</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathbf">A</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathbf">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.624em;vertical-align:-1.13em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.494em;"><span style="top:-2.1727em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9373em;"><span class="svg-align" style="top:-3.2em;"><span class="pstrut" style="height:3.2em;"></span><span class="mord" style="padding-left:1em;"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8043em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7959em;"><span style="top:-2.4231em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.0448em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2769em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8973em;"><span class="pstrut" style="height:3.2em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.28em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.28em" viewBox="0 0 400000 1296" preserveAspectRatio="xMinYMin slice"><path d="M263,681c0.7,0,18,39.7,52,119
c34,79.3,68.167,158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120
c340,-704.7,510.7,-1060.3,512,-1067
l0 -0
c4.7,-7.3,11,-11,19,-11
H40000v40H1012.3
s-271.3,567,-271.3,567c-38.7,80.7,-84,175,-136,283c-52,108,-89.167,185.3,-111.5,232
c-22.3,46.7,-33.8,70.3,-34.5,71c-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1
s-109,-253,-109,-253c-72.7,-168,-109.3,-252,-110,-252c-10.7,8,-22,16.7,-34,26
c-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26s76,-59,76,-59s76,-60,76,-60z
M1001 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3027em;"><span></span></span></span></span></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9373em;"><span class="svg-align" style="top:-3.2em;"><span class="pstrut" style="height:3.2em;"></span><span class="mord" style="padding-left:1em;"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8043em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7959em;"><span style="top:-2.4231em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.0448em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2769em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8973em;"><span class="pstrut" style="height:3.2em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.28em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.28em" viewBox="0 0 400000 1296" preserveAspectRatio="xMinYMin slice"><path d="M263,681c0.7,0,18,39.7,52,119
c34,79.3,68.167,158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120
c340,-704.7,510.7,-1060.3,512,-1067
l0 -0
c4.7,-7.3,11,-11,19,-11
H40000v40H1012.3
s-271.3,567,-271.3,567c-38.7,80.7,-84,175,-136,283c-52,108,-89.167,185.3,-111.5,232
c-22.3,46.7,-33.8,70.3,-34.5,71c-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1
s-109,-253,-109,-253c-72.7,-168,-109.3,-252,-110,-252c-10.7,8,-22,16.7,-34,26
c-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26s76,-59,76,-59s76,-60,76,-60z
M1001 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3027em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.6897em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8043em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0502em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.13em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>余弦相似度的值域为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mo>−</mo><mn>1</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[-1, 1]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">−</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose">]</span></span></span></span>，值越大表示两个向量的夹角越小，方向越接近，语义相似度越高。</p>
<h5 id="多语言预训练模型-Multilingual-Pre-trained-Models">多语言预训练模型 (Multilingual Pre-trained Models)</h5>
<p>这是当前最强大的跨语言表示学习方法，它们在海量的多语言文本数据上进行预训练，学习能够捕捉多种语言共享和独有特征的通用语言表示。</p>
<ul>
<li>
<p><strong>代表模型：</strong></p>
<ul>
<li><strong>mBERT (Multilingual BERT):</strong> 在超过100种语言的维基百科语料上训练的BERT模型。尽管没有显式的跨语言对齐任务，但由于其共享的词汇表（或字符级分词器）和在多语言数据上的联合训练，它表现出了惊人的跨语言零样本迁移能力。</li>
<li><strong>XLM (Cross-lingual Language Model):</strong> 通过语言建模和翻译语言建模（TLM）等目标进行预训练，更强调跨语言对齐。</li>
<li><strong>XLM-R (XLM-RoBERTa):</strong> 在更大规模（2.5TB）的CommonCrawl多语言数据集上训练的XLM模型，拥有更强的跨语言能力。</li>
<li><strong>LaBSE (Language-agnostic BERT Sentence Embedding):</strong> 专门为句子嵌入任务设计，通过大规模多语言并行数据（例如，使用Tatoeba语料库）和对比学习（Contrastive Learning）策略，学习得到高质量的跨语言句子向量，使得不同语言的语义相似句子在向量空间中距离很近。</li>
<li><strong>mT5 (Multilingual Text-to-Text Transfer Transformer):</strong> 基于T5架构，在多语言Colossal Clean Crawled Corpus (mC4) 上进行预训练，可以应用于多种文本到文本任务，包括跨语言检索的表示学习。</li>
</ul>
</li>
<li>
<p><strong>CLIR中的应用：</strong></p>
<ol>
<li><strong>编码器 (Encoder):</strong> 将查询和文档分别输入到预训练的多语言模型中，提取它们的语义向量（例如，取<code>[CLS]</code> token的输出向量作为句向量，或对所有token向量进行平均池化）。</li>
<li><strong>相似度计算:</strong> 在共同的向量空间中，计算查询向量和文档向量之间的余弦相似度或欧氏距离，作为相关性得分。</li>
<li><strong>排序 (Ranking):</strong> 根据相似度得分对文档进行排序，返回最相关的文档。</li>
</ol>
</li>
</ul>
<p><strong>示例：使用LaBSE进行跨语言文本相似度计算</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModel</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> scipy.spatial.distance <span class="keyword">import</span> cosine</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载LaBSE模型和分词器</span></span><br><span class="line"><span class="comment"># LaBSE在跨语言句子嵌入方面表现出色</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">&quot;sentence-transformers/LaBSE&quot;</span>)</span><br><span class="line">model = AutoModel.from_pretrained(<span class="string">&quot;sentence-transformers/LaBSE&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_sentence_embedding</span>(<span class="params">text, tokenizer, model</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    获取文本的LaBSE嵌入向量</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 对文本进行分词</span></span><br><span class="line">    encoded_input = tokenizer(text, return_tensors=<span class="string">&#x27;pt&#x27;</span>, padding=<span class="literal">True</span>, truncation=<span class="literal">True</span>, max_length=<span class="number">128</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 禁用梯度计算以节省内存和加速</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        model_output = model(**encoded_input)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 取 [CLS] token 的输出作为句子嵌入，并进行归一化</span></span><br><span class="line">    <span class="comment"># LaBSE通常使用 mean pooling 或 [CLS] token 的向量作为句嵌入</span></span><br><span class="line">    <span class="comment"># 这里我们使用 [CLS] token 的输出</span></span><br><span class="line">    sentence_embedding = model_output.last_hidden_state[:, <span class="number">0</span>, :]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># L2 归一化，这是计算余弦相似度的前提</span></span><br><span class="line">    sentence_embedding = torch.nn.functional.normalize(sentence_embedding, p=<span class="number">2</span>, dim=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> sentence_embedding.squeeze().numpy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文查询</span></span><br><span class="line">query_cn = <span class="string">&quot;人工智能的最新突破&quot;</span></span><br><span class="line"><span class="comment"># 英文文档</span></span><br><span class="line">doc_en_related = <span class="string">&quot;Recent breakthroughs in artificial intelligence.&quot;</span></span><br><span class="line">doc_en_unrelated = <span class="string">&quot;The history of ancient Roman architecture.&quot;</span></span><br><span class="line"><span class="comment"># 日文文档</span></span><br><span class="line">doc_jp_related = <span class="string">&quot;人工知能の最新のブレイクスルー&quot;</span> <span class="comment"># 人工智能的最新突破</span></span><br><span class="line">doc_jp_unrelated = <span class="string">&quot;日本の伝統的なお祭り&quot;</span> <span class="comment"># 日本的传统节日</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取嵌入向量</span></span><br><span class="line">query_embedding = get_sentence_embedding(query_cn, tokenizer, model)</span><br><span class="line">doc_en_related_embedding = get_sentence_embedding(doc_en_related, tokenizer, model)</span><br><span class="line">doc_en_unrelated_embedding = get_sentence_embedding(doc_en_unrelated, tokenizer, model)</span><br><span class="line">doc_jp_related_embedding = get_sentence_embedding(doc_jp_related, tokenizer, model)</span><br><span class="line">doc_jp_unrelated_embedding = get_sentence_embedding(doc_jp_unrelated, tokenizer, model)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算余弦相似度</span></span><br><span class="line">sim_cn_en_related = <span class="number">1</span> - cosine(query_embedding, doc_en_related_embedding)</span><br><span class="line">sim_cn_en_unrelated = <span class="number">1</span> - cosine(query_embedding, doc_en_unrelated_embedding)</span><br><span class="line">sim_cn_jp_related = <span class="number">1</span> - cosine(query_embedding, doc_jp_related_embedding)</span><br><span class="line">sim_cn_jp_unrelated = <span class="number">1</span> - cosine(query_embedding, doc_jp_unrelated_embedding)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;查询 (中文): \&quot;<span class="subst">&#123;query_cn&#125;</span>\&quot;&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;文档 (英文相关): \&quot;<span class="subst">&#123;doc_en_related&#125;</span>\&quot;&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;相似度 (中文查询 vs 英文相关文档): <span class="subst">&#123;sim_cn_en_related:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;文档 (英文不相关): \&quot;<span class="subst">&#123;doc_en_unrelated&#125;</span>\&quot;&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;相似度 (中文查询 vs 英文不相关文档): <span class="subst">&#123;sim_cn_en_unrelated:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;文档 (日文相关): \&quot;<span class="subst">&#123;doc_jp_related&#125;</span>\&quot;&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;相似度 (中文查询 vs 日文相关文档): <span class="subst">&#123;sim_cn_jp_related:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;文档 (日文不相关): \&quot;<span class="subst">&#123;doc_jp_unrelated&#125;</span>\&quot;&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;相似度 (中文查询 vs 日文不相关文档): <span class="subst">&#123;sim_cn_jp_unrelated:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以观察到，相关文档的相似度分数显著高于不相关文档，</span></span><br><span class="line"><span class="comment"># 即使是不同语言之间，LaBSE也能很好地捕捉语义相似性。</span></span><br></pre></td></tr></table></figure>
<h4 id="基于并行语料和可比语料的方法">基于并行语料和可比语料的方法</h4>
<p>无论是统计机器翻译还是多语言预训练模型，都离不开大规模的多语言语料库。</p>
<ul>
<li>
<p><strong>并行语料库 (Parallel Corpora):</strong></p>
<ul>
<li><strong>定义：</strong> 包含相同内容在两种或多种语言中的对照翻译的文本集合。例如，联合国文件、法律文本、软件本地化文件等。</li>
<li><strong>作用：</strong> 是训练机器翻译系统（尤其是SMT和NMT）以及学习跨语言词对齐和短语对齐的核心资源。它们提供了语言之间直接的“映射”知识。</li>
<li><strong>构建：</strong> 往往通过人工翻译、众包或从多语言网站（如维基百科、新闻机构）中挖掘获得。</li>
</ul>
</li>
<li>
<p><strong>可比语料库 (Comparable Corpora):</strong></p>
<ul>
<li><strong>定义：</strong> 包含相同主题或领域，但在不同语言中独立生成、内容相似而非直接翻译的文本集合。例如，不同语言的新闻报道同一事件，或不同语言的百科全书条目。</li>
<li><strong>作用：</strong> 虽然没有直接的句子级或短语级对齐，但可以通过统计分析（例如，共同出现的命名实体、主题词）来推断跨语言的词语或概念对应关系。可用于构建领域特定的双语词典，或辅助训练跨语言表示模型。</li>
<li><strong>构建：</strong> 通常通过爬取、筛选和过滤大量特定领域或主题的多语言网络文本获得。</li>
</ul>
</li>
</ul>
<p>这些语料库是CLIR技术进步的基石，为模型提供了学习跨语言语义对应关系的“数据营养”。</p>
<h3 id="深度学习在CLIR中的崛起">深度学习在CLIR中的崛起</h3>
<p>在过去几年中，深度学习，特别是预训练语言模型（如BERT、GPT系列），极大地推动了CLIR领域的发展。它们改变了传统CLIR范式，使得基于跨语言表示的方法成为主流。</p>
<h4 id="神经信息检索-Neural-IR-的兴起">神经信息检索 (Neural IR) 的兴起</h4>
<p>传统信息检索方法（如TF-IDF、BM25）依赖于词语的统计共现和稀有性，而神经信息检索则专注于学习文本的语义表示，并基于这些表示进行匹配。</p>
<ul>
<li><strong>表示学习 (Representation Learning):</strong>
<ul>
<li>深度学习模型能够将文本（词、短语、句子、文档）映射到高维连续向量空间，这些向量被称为嵌入（embeddings）。在这个空间中，语义相似的文本具有相近的向量。</li>
<li>对于CLIR，目标是学习一个“语言无关”的语义空间，使得不同语言中表达相同意义的文本，在嵌入空间中也彼此靠近。</li>
</ul>
</li>
<li><strong>匹配模型 (Matching Models):</strong>
<ul>
<li><strong>Siamese Networks (孪生网络):</strong> 两个共享权重的神经网络并行处理查询和文档，然后计算它们输出向量之间的相似度。在CLIR中，查询和文档可以是不同语言。</li>
<li><strong>BERT-style Re-rankers (BERT风格的重排序器):</strong> 首先使用传统的检索方法（如BM25）或简单的向量检索（如Faiss）获取一个粗略的候选集，然后使用多语言BERT或其变体对查询和候选文档进行更深度的交互式编码，计算更精确的相关性得分进行重新排序。这种方法可以捕捉更复杂的语义交互。例如，将查询和文档拼接后输入BERT，让模型直接预测它们的相似度。</li>
</ul>
</li>
</ul>
<h4 id="跨语言问答-Cross-Lingual-Question-Answering-CLQA">跨语言问答 (Cross-Lingual Question Answering, CLQA)</h4>
<p>CLQA可以看作是CLIR的一种高级和特定形式，用户用一种语言提问，系统则在另一种语言的文档中寻找答案。这不仅要求检索到相关文档，还需要从文档中精确抽取出答案。</p>
<ul>
<li><strong>挑战：</strong> 除了CLIR固有的语言障碍，CLQA还需要精确的答案抽取能力，这通常涉及对语义的更深层理解和推理。</li>
<li><strong>方法：</strong>
<ul>
<li><strong>翻译-问答：</strong> 将问题翻译成文档语言，然后进行单语QA。</li>
<li><strong>问答-翻译：</strong> 在文档语言中找到答案，然后将答案翻译成问题语言。</li>
<li><strong>跨语言表示学习：</strong> 训练模型直接在跨语言的语义空间中进行问答，例如，使用多语言预训练模型对问题和文档上下文进行编码，然后通过一个答案预测层来识别答案跨度。</li>
</ul>
</li>
<li><strong>多语言QA数据集：</strong> XQuAD, MLQA, TyDi QA等数据集的出现，极大地推动了CLQA的研究和模型开发。这些数据集提供了多语言的问题-文档-答案对，用于训练和评估跨语言QA系统。</li>
</ul>
<p>深度学习的强大之处在于其从大规模数据中自动学习复杂特征的能力，这使得它能够有效地捕捉不同语言之间微妙的语义关系，从而显著提升CLIR系统的性能。</p>
<h3 id="挑战与未来方向">挑战与未来方向</h3>
<p>尽管CLIR技术取得了显著进展，但它仍然面临诸多挑战，同时也有许多令人兴奋的未来发展方向。</p>
<h4 id="当前挑战">当前挑战</h4>
<ol>
<li><strong>低资源语言 (Low-resource languages)：</strong> 全球有数千种语言，但大多数语言缺乏足够的数据（并行语料、单语语料）来训练高性能的机器翻译模型或多语言表示模型。CLIR在这些语言上的表现仍然是瓶颈。</li>
<li><strong>领域适应 (Domain Adaptation)：</strong> 即使对于高资源语言，在一个领域（如新闻）训练的模型，在另一个领域（如医疗、法律）的表现可能会下降，因为不同领域有其独特的术语和表达方式。领域适应和知识迁移是重要的研究方向。</li>
<li><strong>翻译质量与歧义处理：</strong> 机器翻译并非完美，翻译错误、语义歧义（特别是短语或多义词）会直接影响检索结果。如何识别并减轻这些错误的影响，仍然是一个难题。</li>
<li><strong>计算效率与可扩展性：</strong> 对于大规模文档集合和高并发查询，实时的跨语言检索需要巨大的计算资源。如何优化模型的推理速度，以及构建高效的跨语言索引结构，是工程实现上的挑战。</li>
<li><strong>文化和语用差异：</strong> 语言不仅仅是词汇和语法，更深层次的是其所承载的文化和语用信息。一个在某种文化背景下被认为是相关的概念，在另一种文化中可能完全不同。CLIR系统需要更好地理解这些非语言的、语境相关的因素。</li>
<li><strong>查询意图的跨语言理解：</strong> 用户在不同语言中表达相同意图的方式可能大相径庭。如何深入理解跨语言的查询意图，而不仅仅是字面翻译，是提升检索质量的关键。</li>
</ol>
<h4 id="未来方向">未来方向</h4>
<ol>
<li><strong>更强大的多语言表示学习：</strong>
<ul>
<li><strong>统一多语言模型：</strong> 开发能够处理更多语言、在更多任务上表现卓越的通用多语言预训练模型，并研究其内部机制。</li>
<li><strong>轻量级与高效模型：</strong> 探索模型压缩、量化和蒸馏等技术，使大型多语言模型能在资源受限的环境中运行。</li>
<li><strong>多模态跨语言表示：</strong> 将文本、图像、语音等多种模态的信息融合到统一的跨语言表示中，实现跨语言、跨模态的信息检索（例如，用中文图片搜索英文图片描述）。</li>
</ul>
</li>
<li><strong>少样本/零样本学习 (Few-shot/Zero-shot CLIR)：</strong> 针对低资源语言，研究如何在只有极少量甚至没有并行数据的情况下，通过知识蒸馏、元学习或跨任务迁移学习来提升CLIR性能。</li>
<li><strong>交互式CLIR：</strong>
<ul>
<li>不仅仅是提供一次性检索结果，而是允许用户与系统进行多轮交互，通过反馈（如相关性判断、修正查询）来逐步细化检索结果，提升用户体验。</li>
<li>引入可解释性，让用户了解为什么某些文档被检索出来，从而建立信任。</li>
</ul>
</li>
<li><strong>知识图谱与语义网络融合：</strong> 结合跨语言知识图谱，利用结构化知识来增强跨语言语义匹配的准确性，解决词语歧义和概念对齐问题。</li>
<li><strong>伦理与偏见：</strong> 预训练模型可能继承训练数据中的语言偏见、文化偏见甚至刻板印象，这可能导致检索结果带有偏见。未来的研究需要关注如何识别、量化和减轻CLIR系统中的偏见。</li>
<li><strong>领域与任务特定的CLIR：</strong> 针对垂直领域（如医疗、金融、科技文献）或特定任务（如专利检索、法律咨询），开发定制化的CLIR解决方案，结合领域知识和专业术语，提升精度。</li>
</ol>
<h3 id="结论">结论</h3>
<p>跨语言信息检索是连接全球知识、打破语言壁垒的关键技术。从最初的词典翻译，到统计机器翻译的兴起，再到当前深度学习和大规模多语言预训练模型的革命，CLIR技术已经取得了长足进步。我们已经能够将不同语言的文本映射到共享的语义空间中，实现了前所未有的跨语言理解和检索能力。</p>
<p>然而，CLIR的旅程远未结束。低资源语言的挑战、领域适应的复杂性、机器翻译的局限性以及效率和可扩展性的需求，都为未来的研究和工程实践提供了广阔的空间。随着多模态学习、更强大的语言模型以及更智能的交互方式的发展，我们可以预见，未来的CLIR系统将能够更加无缝、准确、高效地为全球用户提供跨越语言界限的知识服务。</p>
<p>作为技术爱好者，我们有幸见证并参与到这一激动人心的领域发展中。每一次算法的优化，每一次模型的创新，都让我们离一个真正“语言无障碍”的全球信息共享世界更近一步。让我们持续探索，不断创新，共同为人类知识的无界流动贡献力量！</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a target="_blank" rel="noopener" href="https://github.com/qmwneb946">qmwneb946</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://qmwneb946.dpdns.org/2025/07/19/2025-07-19-142319/">https://qmwneb946.dpdns.org/2025/07/19/2025-07-19-142319/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://opensource.org/licenses/MIT" target="_blank">MIT License</a> 许可协议。转载请注明来源 <a href="https://qmwneb946.dpdns.org" target="_blank">qmwneb946 的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/2025/">2025</a><a class="post-meta__tags" href="/tags/%E6%95%B0%E5%AD%A6/">数学</a><a class="post-meta__tags" href="/tags/%E8%B7%A8%E8%AF%AD%E8%A8%80%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2%E6%8A%80%E6%9C%AF/">跨语言信息检索技术</a></div><div class="post-share"><div class="social-share" data-image="/img/icon.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/07/19/2025-07-19-142412/" title="卫星互联网的星座设计与部署：连接世界的下一代网络"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">卫星互联网的星座设计与部署：连接世界的下一代网络</div></div><div class="info-2"><div class="info-item-1"> 引言：超越光纤的连接梦想 在21世纪的今天，互联网已经深入到我们生活的每一个角落。然而，即便光纤网络如毛细血管般在全球蔓延，地球上仍有广袤的区域——从偏远的农村、海上的航船、翱翔的飞机到灾难现场——处于数字鸿沟的边缘，无法享受到稳定、高速的网络服务。传统的基础设施建设成本高昂，铺设难度大，对于这些区域而言，连接的梦想似乎遥不可及。 正是在这样的背景下，卫星互联网，尤其是基于低地球轨道（LEO）卫星的星座网络，正以惊人的速度崛起，有望成为解决全球连接挑战的颠覆性力量。它承诺将高速、低延迟的宽带服务带到地球的每一个角落，无论是繁华都市还是无人荒漠。但，要实现这一宏伟目标，绝非易事。它需要我们深入理解轨道力学、无线电通信、网络拓扑、大规模制造和部署等一系列复杂的技术挑战。 作为一名热衷于探索技术深度的博主qmwneb946，我将在这篇文章中，带领大家踏上一段激动人心的旅程，深入剖析卫星互联网的星座设计与部署背后的科学与工程，揭示这一“连接世界”梦想如何从蓝图变为现实。我们将从卫星轨道的基础知识出发，逐步探讨星座设计的核心原则、关键技术突破，以及面临的挑战与未来的展望。 第一部分：从地...</div></div></div></a><a class="pagination-related" href="/2025/07/19/2025-07-19-142226/" title="逐像素洞察万物：深度学习语义分割模型的奥秘与实践"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">逐像素洞察万物：深度学习语义分割模型的奥秘与实践</div></div><div class="info-2"><div class="info-item-1">大家好，我是qmwneb946。在我的博客中，我们总是致力于探索人工智能领域最前沿、最核心的技术。今天，我们将把目光聚焦于计算机视觉领域的一个迷人且极具挑战性的任务——语义分割（Semantic Segmentation）。这不仅仅是将图像中的物体框选出来，而是要对图像中的每一个像素点进行分类，赋予它们特定的语义标签，从而让机器真正“理解”图像的每一个角落。从自动驾驶到医疗诊断，从虚拟现实到智能安防，语义分割正在以前所未有的深度和广度改变着我们的世界。 那么，究竟是什么让深度学习在语义分割领域大放异彩？它又经历了怎样的发展历程？各种经典模型又有着怎样的巧妙设计？今天，就让我们一同踏上这段深度探索之旅，从理论到实践，全面揭示深度学习语义分割模型的强大力量。 什么是语义分割？ 在深入探讨模型之前，我们首先要明确语义分割的定义及其在计算机视觉任务中的位置。 定义与目标 语义分割，顾名思义，是对图像中的每一个像素点进行分类，将其归属于预定义的类别之一（例如，天空、道路、汽车、行人、树木等）。它的最终输出通常是一张与原图大小相同的“分割图”，其中每个像素的颜色代表了其所属的类别。这与我们平...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/07/18/2025-07-18-082519/" title="增强现实与工业维修：一场效率革命"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">增强现实与工业维修：一场效率革命</div></div><div class="info-2"><div class="info-item-1">增强现实 (AR) 技术正以前所未有的速度改变着我们的生活，而其在工业维修领域的应用更是展现出了巨大的潜力。不再局限于科幻电影中的场景，AR 如今已成为提升维修效率、降低维护成本、提高安全性的强大工具。本文将深入探讨 AR 如何与工业维修相结合，并分析其背后的技术和未来发展趋势。 引言：传统工业维修的挑战 传统的工业维修往往面临着诸多挑战：  信息获取困难: 维修人员需要查阅大量的纸质文档、图纸和视频，耗时费力，容易出错。 培训成本高昂:  熟练技工的培养需要漫长的学习过程和大量的实践经验，成本高昂。 安全风险较高:  一些复杂的设备维修存在高风险，例如高压电、高温部件等，容易发生意外事故。 维修效率低下:  由于缺乏实时信息和有效的指导，维修时间往往较长，导致生产停机时间增加，损失巨大。  AR 如何改变工业维修的游戏规则 AR 技术通过将数字信息叠加到现实世界中，为工业维修提供了全新的解决方案： 远程专家指导 通过 AR 眼镜或平板电脑，现场维修人员可以与远程专家实时互动。专家可以通过 AR 系统看到现场设备的实时图像，并利用虚拟标注、3D 模型等工具进行远程指导，大大缩短了...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082652/" title="纳米材料在靶向药物中的革命性应用"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">纳米材料在靶向药物中的革命性应用</div></div><div class="info-2"><div class="info-item-1">近年来，癌症等重大疾病的治疗面临着巨大的挑战，传统的化疗药物往往毒性大、副作用强，难以实现精准治疗。而纳米技术的兴起为解决这一难题提供了新的思路，特别是纳米材料在靶向药物递送系统中的应用，正引发一场医学革命。本文将深入探讨纳米材料如何提升靶向药物的疗效，降低其毒副作用。 纳米材料的特性及其在药物递送中的优势 纳米材料，是指至少在一个维度上尺寸小于100纳米的材料。这种极小的尺寸赋予了它们许多独特的物理和化学性质，使其在药物递送领域具有显著优势： 增强的药物溶解度和稳定性 许多药物具有较低的溶解度，限制了其在体内的吸收和生物利用度。纳米载体，例如脂质体、聚合物纳米颗粒和无机纳米颗粒（如金纳米颗粒、氧化铁纳米颗粒），可以显著提高药物的溶解度和稳定性，延长其在体内的循环时间。例如，将抗癌药物负载在聚合物纳米颗粒中，可以保护药物免受降解，并提高其在肿瘤组织中的积累。 靶向药物递送 纳米材料可以通过表面修饰，例如结合特异性配体（如抗体、肽或小分子），实现对特定细胞或组织的靶向递送。这种靶向递送可以最大限度地减少药物对健康组织的毒性，并提高药物在靶标部位的浓度，从而增强治疗效果。例如，修饰有...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082925/" title="生物化学中的蛋白质折叠问题：一个复杂而迷人的计算挑战"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">生物化学中的蛋白质折叠问题：一个复杂而迷人的计算挑战</div></div><div class="info-2"><div class="info-item-1">生命，这奇妙的现象，其本质很大程度上取决于蛋白质的精确三维结构。蛋白质是由氨基酸链组成的长链分子，但仅仅是氨基酸序列并不能完全决定其功能。蛋白质必须折叠成特定的三维结构（构象），才能发挥其生物学功能，例如催化酶促反应、运输分子或构建细胞结构。  而这个折叠过程，就是著名的“蛋白质折叠问题”。 蛋白质折叠：从线性序列到三维结构 蛋白质的氨基酸序列由基因编码决定，这是一个线性的一维结构。然而，这些氨基酸链并非随机地盘踞在一起，而是会遵循特定的物理和化学原理，自发地折叠成独特的、功能性的三维结构。这个折叠过程涉及到多种相互作用，包括： 疏水相互作用 蛋白质内部的疏水氨基酸残基倾向于聚集在一起，远离水性环境，形成蛋白质的核心区域。而亲水性氨基酸残基则倾向于暴露在蛋白质的表面，与水分子相互作用。 静电相互作用 带电荷的氨基酸残基之间会发生静电吸引或排斥作用，影响蛋白质的折叠。 氢键 氢键在维持蛋白质二级结构（例如α螺旋和β折叠）中起着关键作用。 二硫键 某些氨基酸残基（例如半胱氨酸）之间可以形成二硫键，进一步稳定蛋白质的三维结构。 这些相互作用共同决定了蛋白质的最终构象，这是一个极其复杂的...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-092536/" title="CRISPR基因编辑：技术的奇迹与伦理的挑战"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">CRISPR基因编辑：技术的奇迹与伦理的挑战</div></div><div class="info-2"><div class="info-item-1">大家好！我是你们的技术和数学博主，今天我们要深入探讨一个既令人兴奋又充满争议的话题：CRISPR-Cas9基因编辑技术及其伦理挑战。CRISPR技术以其精准性和效率，为治疗遗传疾病、改良作物等领域带来了革命性的变革，但与此同时，它也引发了诸多伦理难题，需要我们认真思考和谨慎应对。 CRISPR技术：一把双刃剑 CRISPR-Cas9系统，简单来说，就是一种可以精确地“剪切和粘贴”DNA的工具。它源自细菌的天然防御机制，利用向导RNA（gRNA）引导Cas9酶到基因组中的特定位置，从而进行基因的敲除、插入或替换。其操作简便、成本低廉、效率高，使其成为基因编辑领域的“明星”技术。 CRISPR的工作原理 CRISPR系统的工作机制可以概括为以下几个步骤：  设计gRNA:  根据目标基因序列设计相应的gRNA，使其能够特异性地结合目标DNA序列。 Cas9酶的结合: gRNA引导Cas9酶到目标DNA序列。 DNA双链断裂: Cas9酶在目标位点切割DNA双链，形成双链断裂（DSB）。 DNA修复: 细胞利用非同源末端连接（NHEJ）或同源定向修复（HDR）机制修复DSB。NHEJ修...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-094115/" title="免疫学与癌症免疫疗法：一场人体内部的战争与和平"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">免疫学与癌症免疫疗法：一场人体内部的战争与和平</div></div><div class="info-2"><div class="info-item-1">免疫系统，人体精妙的防御机制，日夜不停地抵御着病毒、细菌和其他有害物质的入侵。然而，当这套系统出现故障，对自身细胞发起攻击，或者无法有效清除癌细胞时，疾病便会发生，其中最可怕的莫过于癌症。近年来，癌症免疫疗法异军突起，为癌症治疗带来了新的希望，让我们深入探索这场人体内部的战争与和平。 免疫系统：人体精妙的防御网络 我们的免疫系统由先天免疫和适应性免疫两大支柱组成。 先天免疫：第一道防线 先天免疫是人体抵御病原体的第一道防线，它包含物理屏障（例如皮肤和黏膜）、化学屏障（例如胃酸和酶）以及细胞介导的免疫反应，例如巨噬细胞和自然杀伤细胞（NK细胞）的吞噬和杀伤作用。这些细胞能够识别并清除被感染的细胞或癌细胞，但其特异性较低。 适应性免疫：精准打击 适应性免疫系统则更为精细，它具有特异性和记忆性。T细胞和B细胞是适应性免疫的主角。T细胞负责细胞介导的免疫，其中细胞毒性T细胞（CTL）能够特异性识别并杀死靶细胞，例如被病毒感染的细胞或癌细胞。B细胞则负责体液免疫，产生抗体，中和病原体或标记癌细胞以便清除。  抗原呈递细胞（APC），例如树突状细胞，在将抗原信息呈递给T细胞，启动适应性免疫反...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-094141/" title="生态学中的生物多样性保护：一个复杂系统工程的视角"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">生态学中的生物多样性保护：一个复杂系统工程的视角</div></div><div class="info-2"><div class="info-item-1">大家好！今天我们要深入探讨一个既充满挑战又至关重要的话题：生态学中的生物多样性保护。  这不仅是环境保护的基石，也与我们人类的福祉息息相关。对技术爱好者来说，这更像是一个巨大的、复杂的系统工程，充满了需要解决的优化问题和值得探索的算法。 生物多样性的价值：超越简单的物种数量 我们通常将生物多样性理解为物种数量的多样性。但实际上，它是一个多层次的概念，包括：  遗传多样性 (Genetic Diversity):  同一物种内基因组的差异性，这决定了物种的适应性和进化潜力。  想象一下，一个抗旱基因的缺失可能导致整个小麦品种在干旱年份面临灭绝的风险。 物种多样性 (Species Diversity):  不同物种的数量及其相对丰度。 这通常用Shannon多样性指数 (H=−∑i=1Spilog⁡2piH = -\sum_{i=1}^{S} p_i \log_2 p_iH=−∑i=1S​pi​log2​pi​) 来衡量，其中 pip_ipi​ 是第 iii 个物种的比例，SSS 是物种总数。  更高的Shannon指数表示更高的物种多样性。 生态系统多样性 (Ecosystem ...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">qmwneb946</div><div class="author-info-description">一个专注于技术分享的个人博客，涵盖编程、算法、系统设计等内容</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">418</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">422</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/qmwneb946"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/qmwneb946" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:qmwneb946@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">代码与远方，技术与生活交织的篇章。</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%95%E8%A8%80%EF%BC%9A%E8%AF%AD%E8%A8%80%E7%9A%84%E5%A3%81%E5%9E%92%E4%B8%8E%E5%85%A8%E7%90%83%E7%9F%A5%E8%AF%86%E7%9A%84%E6%B8%B4%E6%9C%9B"><span class="toc-number">1.</span> <span class="toc-text">引言：语言的壁垒与全球知识的渴望</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B7%A8%E8%AF%AD%E8%A8%80%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2-CLIR-%E7%9A%84%E6%8C%91%E6%88%98%E4%B8%8E%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5"><span class="toc-number">2.</span> <span class="toc-text">跨语言信息检索 (CLIR) 的挑战与核心概念</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AF%AD%E8%A8%80%E5%A4%9A%E6%A0%B7%E6%80%A7%EF%BC%9A%E8%A1%A8%E5%BE%81%E7%9A%84%E9%B8%BF%E6%B2%9F"><span class="toc-number">2.1.</span> <span class="toc-text">语言多样性：表征的鸿沟</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#CLIR-%E7%9A%84%E5%9F%BA%E6%9C%AC%E8%8C%83%E5%BC%8F"><span class="toc-number">2.2.</span> <span class="toc-text">CLIR 的基本范式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AF%84%E6%B5%8B%E6%8C%87%E6%A0%87"><span class="toc-number">2.3.</span> <span class="toc-text">评测指标</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CLIR-%E7%9A%84%E4%B8%BB%E8%A6%81%E6%96%B9%E6%B3%95%EF%BC%9A%E4%BB%8E%E4%BC%A0%E7%BB%9F%E5%88%B0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0"><span class="toc-number">3.</span> <span class="toc-text">CLIR 的主要方法：从传统到深度学习</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E7%BF%BB%E8%AF%91%E7%9A%84%E6%96%B9%E6%B3%95-Translation-Based-CLIR"><span class="toc-number">3.1.</span> <span class="toc-text">基于翻译的方法 (Translation-Based CLIR)</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%9F%A5%E8%AF%A2%E7%BF%BB%E8%AF%91-Query-Translation-QT"><span class="toc-number">3.1.1.</span> <span class="toc-text">查询翻译 (Query Translation, QT)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%96%87%E6%A1%A3%E7%BF%BB%E8%AF%91-Document-Translation-DT"><span class="toc-number">3.1.2.</span> <span class="toc-text">文档翻译 (Document Translation, DT)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%B7%B7%E5%90%88%E7%BF%BB%E8%AF%91-Hybrid-Translation"><span class="toc-number">3.1.3.</span> <span class="toc-text">混合翻译 (Hybrid Translation)</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E8%B7%A8%E8%AF%AD%E8%A8%80%E8%A1%A8%E7%A4%BA%E7%9A%84%E6%96%B9%E6%B3%95-Cross-Lingual-Representation-Based-CLIR"><span class="toc-number">3.2.</span> <span class="toc-text">基于跨语言表示的方法 (Cross-Lingual Representation-Based CLIR)</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%B7%A8%E8%AF%AD%E8%A8%80%E4%B8%BB%E9%A2%98%E6%A8%A1%E5%9E%8B-Cross-Lingual-Topic-Models"><span class="toc-number">3.2.1.</span> <span class="toc-text">跨语言主题模型 (Cross-Lingual Topic Models)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%B7%A8%E8%AF%AD%E8%A8%80%E8%AF%8D%E5%B5%8C%E5%85%A5-Cross-Lingual-Word-Embeddings"><span class="toc-number">3.2.2.</span> <span class="toc-text">跨语言词嵌入 (Cross-Lingual Word Embeddings)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%A4%9A%E8%AF%AD%E8%A8%80%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B-Multilingual-Pre-trained-Models"><span class="toc-number">3.2.3.</span> <span class="toc-text">多语言预训练模型 (Multilingual Pre-trained Models)</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%B9%B6%E8%A1%8C%E8%AF%AD%E6%96%99%E5%92%8C%E5%8F%AF%E6%AF%94%E8%AF%AD%E6%96%99%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">3.3.</span> <span class="toc-text">基于并行语料和可比语料的方法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9C%A8CLIR%E4%B8%AD%E7%9A%84%E5%B4%9B%E8%B5%B7"><span class="toc-number">4.</span> <span class="toc-text">深度学习在CLIR中的崛起</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%A5%9E%E7%BB%8F%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2-Neural-IR-%E7%9A%84%E5%85%B4%E8%B5%B7"><span class="toc-number">4.1.</span> <span class="toc-text">神经信息检索 (Neural IR) 的兴起</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B7%A8%E8%AF%AD%E8%A8%80%E9%97%AE%E7%AD%94-Cross-Lingual-Question-Answering-CLQA"><span class="toc-number">4.2.</span> <span class="toc-text">跨语言问答 (Cross-Lingual Question Answering, CLQA)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%91%E6%88%98%E4%B8%8E%E6%9C%AA%E6%9D%A5%E6%96%B9%E5%90%91"><span class="toc-number">5.</span> <span class="toc-text">挑战与未来方向</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BD%93%E5%89%8D%E6%8C%91%E6%88%98"><span class="toc-number">5.1.</span> <span class="toc-text">当前挑战</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%AA%E6%9D%A5%E6%96%B9%E5%90%91"><span class="toc-number">5.2.</span> <span class="toc-text">未来方向</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA"><span class="toc-number">6.</span> <span class="toc-text">结论</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/22/hello-world/" title="Hello World">Hello World</a><time datetime="2025-07-22T07:56:20.604Z" title="发表于 2025-07-22 15:56:20">2025-07-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/22/%E5%8D%9A%E5%BC%88%E8%AE%BA%E5%9F%BA%E7%A1%80/" title="博弈论基础">博弈论基础</a><time datetime="2025-07-22T07:56:20.604Z" title="发表于 2025-07-22 15:56:20">2025-07-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/21/2025-07-22-075445/" title="光的旋律，数据的交响：深入探索可见光通信（VLC）技术">光的旋律，数据的交响：深入探索可见光通信（VLC）技术</a><time datetime="2025-07-21T23:54:45.000Z" title="发表于 2025-07-22 07:54:45">2025-07-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/21/2025-07-22-075356/" title="对话的温度：深入探索对话系统的个性化与情感化">对话的温度：深入探索对话系统的个性化与情感化</a><time datetime="2025-07-21T23:53:56.000Z" title="发表于 2025-07-22 07:53:56">2025-07-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/21/2025-07-22-075257/" title="少样本图像分类：从元学习到前沿范式，探寻小数据下的智能之路">少样本图像分类：从元学习到前沿范式，探寻小数据下的智能之路</a><time datetime="2025-07-21T23:52:57.000Z" title="发表于 2025-07-22 07:52:57">2025-07-22</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;2025 By qmwneb946</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.2</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css')
    if (true) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const getGiscusTheme = theme => theme === 'dark' ? 'dark' : 'light'

  const createScriptElement = config => {
    const ele = document.createElement('script')
    Object.entries(config).forEach(([key, value]) => {
      ele.setAttribute(key, value)
    })
    return ele
  }

  const loadGiscus = (el = document, key) => {
    const mappingConfig = isShuoshuo
      ? { 'data-mapping': 'specific', 'data-term': key }
      : { 'data-mapping': (option && option['data-mapping']) || 'pathname' }

    const giscusConfig = {
      src: 'https://giscus.app/client.js',
      'data-repo': 'qmwneb946/blog',
      'data-repo-id': 'R_kgDOPM6cWw',
      'data-category-id': 'DIC_kwDOPM6cW84CtEzo',
      'data-theme': getGiscusTheme(document.documentElement.getAttribute('data-theme')),
      'data-reactions-enabled': '1',
      crossorigin: 'anonymous',
      async: true,
      ...option,
      ...mappingConfig
    }

    const scriptElement = createScriptElement(giscusConfig)

    el.querySelector('#giscus-wrap').appendChild(scriptElement)

    if (isShuoshuo) {
      window.shuoshuoComment.destroyGiscus = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }
  }

  const changeGiscusTheme = theme => {
    const iframe = document.querySelector('#giscus-wrap iframe')
    if (iframe) {
      const message = {
        giscus: {
          setConfig: {
            theme: getGiscusTheme(theme)
          }
        }
      }
      iframe.contentWindow.postMessage(message, 'https://giscus.app')
    }
  }

  btf.addGlobalFn('themeChange', changeGiscusTheme, 'giscus')

  if (isShuoshuo) {
    'Giscus' === 'Giscus'
      ? window.shuoshuoComment = { loadComment: loadGiscus }
      : window.loadOtherComment = loadGiscus
    return
  }

  if ('Giscus' === 'Giscus' || !false) {
    if (false) btf.loadComment(document.getElementById('giscus-wrap'), loadGiscus)
    else loadGiscus()
  } else {
    window.loadOtherComment = loadGiscus
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>