<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>神经形态计算与类脑芯片：揭秘大脑启发的下一代计算范式 | qmwneb946 的博客</title><meta name="author" content="qmwneb946"><meta name="copyright" content="qmwneb946"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="大家好，我是 qmwneb946，你们的老朋友。今天，我们将一同踏上一段激动人心的旅程，深入探索一个有望彻底改变我们计算方式的领域——神经形态计算（Neuromorphic Computing）与类脑芯片（Brain-Inspired Chips）。在人工智能浪潮席卷全球的当下，我们正面临着一个严峻的挑战：当前的计算架构，尤其是冯·诺依曼（Von Neumann）架构，在处理海量数据和复杂智能任务">
<meta property="og:type" content="article">
<meta property="og:title" content="神经形态计算与类脑芯片：揭秘大脑启发的下一代计算范式">
<meta property="og:url" content="https://qmwneb946.dpdns.org/2025/07/19/2025-07-19-103025/index.html">
<meta property="og:site_name" content="qmwneb946 的博客">
<meta property="og:description" content="大家好，我是 qmwneb946，你们的老朋友。今天，我们将一同踏上一段激动人心的旅程，深入探索一个有望彻底改变我们计算方式的领域——神经形态计算（Neuromorphic Computing）与类脑芯片（Brain-Inspired Chips）。在人工智能浪潮席卷全球的当下，我们正面临着一个严峻的挑战：当前的计算架构，尤其是冯·诺依曼（Von Neumann）架构，在处理海量数据和复杂智能任务">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://qmwneb946.dpdns.org/img/icon.png">
<meta property="article:published_time" content="2025-07-19T02:30:25.000Z">
<meta property="article:modified_time" content="2025-07-21T20:33:29.945Z">
<meta property="article:author" content="qmwneb946">
<meta property="article:tag" content="2025">
<meta property="article:tag" content="计算机科学">
<meta property="article:tag" content="神经形态计算与类脑芯片">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://qmwneb946.dpdns.org/img/icon.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "神经形态计算与类脑芯片：揭秘大脑启发的下一代计算范式",
  "url": "https://qmwneb946.dpdns.org/2025/07/19/2025-07-19-103025/",
  "image": "https://qmwneb946.dpdns.org/img/icon.png",
  "datePublished": "2025-07-19T02:30:25.000Z",
  "dateModified": "2025-07-21T20:33:29.945Z",
  "author": [
    {
      "@type": "Person",
      "name": "qmwneb946",
      "url": "https://github.com/qmwneb946"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://qmwneb946.dpdns.org/2025/07/19/2025-07-19-103025/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '神经形态计算与类脑芯片：揭秘大脑启发的下一代计算范式',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2845632165165414" crossorigin="anonymous"></script><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="qmwneb946 的博客" type="application/atom+xml">
</head><body><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">qmwneb946 的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">神经形态计算与类脑芯片：揭秘大脑启发的下一代计算范式</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">神经形态计算与类脑芯片：揭秘大脑启发的下一代计算范式<a class="post-edit-link" href="https://github.com/qmwneb946/blog/edit/main/source/_posts/2025-07-19-103025.md" title="编辑" target="_blank"><i class="fas fa-pencil-alt"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-07-19T02:30:25.000Z" title="发表于 2025-07-19 10:30:25">2025-07-19</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-07-21T20:33:29.945Z" title="更新于 2025-07-22 04:33:29">2025-07-22</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/">计算机科学</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><p>大家好，我是 qmwneb946，你们的老朋友。今天，我们将一同踏上一段激动人心的旅程，深入探索一个有望彻底改变我们计算方式的领域——神经形态计算（Neuromorphic Computing）与类脑芯片（Brain-Inspired Chips）。在人工智能浪潮席卷全球的当下，我们正面临着一个严峻的挑战：当前的计算架构，尤其是冯·诺依曼（Von Neumann）架构，在处理海量数据和复杂智能任务时，其固有的瓶颈正日益凸显。那么，人类最伟大的“处理器”——我们的大脑，能否为我们提供新的灵感，指引我们走向未来计算的新范式呢？答案是肯定的。</p>
<h3 id="引言：AI时代的能耗危机与冯·诺依曼瓶颈">引言：AI时代的能耗危机与冯·诺依曼瓶颈</h3>
<p>想象一下，你正在用最新的AI模型处理大量图像数据，或者训练一个参数数百亿的大语言模型。你的电脑风扇狂转，机箱发热，电表指针也飞速跳动。这正是我们当前计算模式面临的现实：功耗爆炸式增长。</p>
<p>传统的计算机，无论是最强大的超级计算机还是你手中的智能手机，都基于约翰·冯·诺依曼在20世纪40年代提出的架构。这种架构的核心思想是将程序和数据存储在同一个内存中，中央处理器（CPU）通过总线不断地从内存中读取指令和数据，执行运算，再将结果写回内存。</p>
<p>冯·诺依曼架构的伟大毋庸置疑，它奠定了现代计算机的基础，并推动了信息技术的高速发展。然而，随着我们进入大数据和人工智能时代，它的局限性也变得越来越明显，这便是著名的“冯·诺依曼瓶颈”或“内存墙”问题。</p>
<p><strong>冯·诺依曼瓶颈：数据移动的困境</strong></p>
<p>在冯·诺依曼架构中，处理器和内存是分离的。这意味着，每次处理器需要数据时，都必须通过总线从内存中获取，处理完毕后再送回。数据在处理器和内存之间来回传输需要时间，也消耗大量的能量。当处理器的计算速度远超数据传输速度时，处理器就会“等待”数据，造成性能浪费。对于当前流行的深度学习模型而言，其核心是大量的矩阵乘法和累加运算，这需要频繁地访问内存中的权重和激活值。据统计，在许多AI任务中，数据移动所消耗的能量可能占到总能耗的90%以上。</p>
<p>以著名的AlphaGo为例，它在击败围棋世界冠军李世石时，消耗的电能高达数十千瓦，而人类大脑在完成同样任务时，功耗仅为20瓦左右。这种巨大的能效差距，促使科学家们开始思考：有没有一种计算方式，能够像大脑一样，在低功耗下高效地处理复杂信息？神经形态计算应运而生。</p>
<h3 id="第一章：从生物大脑汲取灵感——自然界的计算奇迹">第一章：从生物大脑汲取灵感——自然界的计算奇迹</h3>
<p>要理解神经形态计算，我们首先要回归其最根本的灵感来源——生物大脑。大脑是自然界最复杂的“计算设备”，它以惊人的能效比处理着世界上最复杂的信息。</p>
<h4 id="神经元与突触：大脑的基本构建块">神经元与突触：大脑的基本构建块</h4>
<p>我们的大脑由大约860亿个神经元组成，每个神经元又通过数千个突触与其他神经元相连，形成一个极其复杂的网络。</p>
<ul>
<li><strong>神经元 (Neuron)</strong>：神经元是信息处理的基本单元。它接收来自其他神经元的输入信号，整合这些信号，当达到某个阈值时，就会产生一个电脉冲（称为“动作电位”或“尖峰”，Spike），并将这个尖冲沿着轴突传递出去。</li>
<li><strong>突触 (Synapse)</strong>：突触是神经元之间连接的桥梁，也是信息传递和学习发生的地方。当一个神经元发出尖峰时，它会通过突触向下一个神经元传递信号。突触的强度（权重）决定了信号传递的效率。</li>
</ul>
<h4 id="大脑的运行机制：并行、事件驱动、可塑性">大脑的运行机制：并行、事件驱动、可塑性</h4>
<p>大脑与冯·诺依曼计算机的工作方式截然不同：</p>
<ol>
<li><strong>大规模并行处理 (Massively Parallel Processing)</strong>：大脑中的所有神经元几乎同时并行工作，而不是像传统CPU那样按顺序执行指令。这种高度并行的特性使其能够同时处理多个输入，并快速响应复杂的环境。</li>
<li><strong>事件驱动 (Event-Driven)</strong>：神经元只有在接收到足够强的输入信号并达到阈值时才发放尖峰，否则保持静默。这种“按需计算”的模式大大降低了能量消耗。相比之下，传统芯片即使没有有效数据输入，其时钟也在持续运行，不断进行计算，消耗大量能量。</li>
<li><strong>内存与计算一体 (In-Memory Computing)</strong>：大脑中，存储（突触权重）和计算（神经元活动）紧密结合在一起。数据（尖峰）在网络中传输，并在传输过程中进行计算，没有明显的“数据移动”瓶颈。突触本身就是存储单元，而且它们就在神经元旁边。</li>
<li><strong>可塑性与学习 (Plasticity and Learning)</strong>：突触的连接强度不是固定不变的，而是可以根据神经元的活动模式进行调整。这种突触可塑性是大脑学习和记忆的基础，例如著名的赫布学习规则（Hebbian Learning）和脉冲时间依赖可塑性（Spike-Timing Dependent Plasticity, STDP）。</li>
<li><strong>模拟与数字混合 (Mixed-Signal)</strong>：生物神经元内部的信号处理是模拟的（膜电位、离子通道），而尖峰的传递则是数字的（全或无的电脉冲）。这种混合信号的特性使其在能效和鲁棒性之间取得了平衡。</li>
</ol>
<h4 id="生物效率的启示">生物效率的启示</h4>
<p>大脑的这些特性，使其在处理模糊、不精确、时变的数据时表现出色，并且能耗极低。这种通过并行、事件驱动和内存计算一体化来实现的超高能效，正是神经形态计算所追求的目标。</p>
<h3 id="第二章：神经形态计算的核心概念">第二章：神经形态计算的核心概念</h3>
<p>神经形态计算旨在借鉴大脑的结构和工作原理，设计出全新的硬件和软件系统。这不仅仅是模拟大脑，更是从大脑中汲取计算范式的灵感。</p>
<h4 id="脉冲神经网络-Spiking-Neural-Networks-SNN-：第三代神经网络">脉冲神经网络 (Spiking Neural Networks, SNN)：第三代神经网络</h4>
<p>如果我们把感知机、多层感知机视为第一代神经网络，反向传播（Backpropagation, BP）训练的深度学习网络视为第二代，那么脉冲神经网络（SNNs）则被认为是第三代神经网络。</p>
<p>与传统的神经网络（ANNs）不同，SNNs中的神经元不传递连续的激活值，而是传递离散的“尖峰”（Spike）。这些尖峰是二进制的事件信号，只在神经元膜电位达到阈值时才发生。</p>
<p><strong>基本工作原理：整合-发放模型 (Integrate-and-Fire Model)</strong></p>
<p>最简单的SNN神经元模型是整合-发放模型（Integrate-and-Fire, IF），或其更常见的变体——漏整合-发放模型（Leaky Integrate-and-Fire, LIF）。</p>
<p>在一个LIF神经元中：</p>
<ol>
<li><strong>整合 (Integrate)</strong>：神经元持续累积来自其输入突触的信号。每个输入尖峰都会导致神经元膜电位增加一定量。</li>
<li><strong>泄露 (Leaky)</strong>：膜电位会随时间衰减，模拟离子通道的泄漏。</li>
<li><strong>发放 (Fire)</strong>：当膜电位达到预设的阈值 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mrow><mi>t</mi><mi>h</mi></mrow></msub></mrow><annotation encoding="application/x-tex">V_{th}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 时，神经元发放一个尖峰，其膜电位立即重置到静息电位 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mrow><mi>r</mi><mi>e</mi><mi>s</mi><mi>e</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">V_{reset}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">rese</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>（通常低于阈值），并进入一个短暂的不应期（Refractory Period），在此期间不能发放新的尖峰。</li>
</ol>
<p>数学上，一个LIF神经元的膜电位 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">V(t)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mclose">)</span></span></span></span> 变化可以简化表示为：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>τ</mi><mfrac><mrow><mi>d</mi><mi>V</mi></mrow><mrow><mi>d</mi><mi>t</mi></mrow></mfrac><mo>=</mo><mo>−</mo><mo stretchy="false">(</mo><mi>V</mi><mo>−</mo><msub><mi>V</mi><mrow><mi>r</mi><mi>e</mi><mi>s</mi><mi>t</mi></mrow></msub><mo stretchy="false">)</mo><mo>+</mo><mi>R</mi><mi>I</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\tau \frac{dV}{dt} = -(V - V_{rest}) + RI(t) 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.0574em;vertical-align:-0.686em;"></span><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="mord mathnormal">t</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">res</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mclose">)</span></span></span></span></span></p>
<p>其中：</p>
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">V(t)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mclose">)</span></span></span></span> 是膜电位</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi></mrow><annotation encoding="application/x-tex">\tau</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span></span></span></span> 是膜时间常数，表示电位衰减的速度</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mrow><mi>r</mi><mi>e</mi><mi>s</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">V_{rest}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">res</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是静息电位</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span> 是膜电阻</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">I(t)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mclose">)</span></span></span></span> 是输入电流，由所有输入尖峰产生。</li>
</ul>
<p>当 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo><mo>≥</mo><msub><mi>V</mi><mrow><mi>t</mi><mi>h</mi></mrow></msub></mrow><annotation encoding="application/x-tex">V(t) \ge V_{th}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 时，神经元发放一个尖峰，并重置 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi>V</mi><mrow><mi>r</mi><mi>e</mi><mi>s</mi><mi>e</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">V(t) = V_{reset}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">rese</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。</p>
<p><strong>时间编码与事件驱动</strong></p>
<p>SNNs的独特之处在于其利用“时间”进行信息编码。信息不是通过神经元的激活强度，而是通过尖峰的精确时间、尖峰的频率或者尖峰的相对顺序来编码。这种时间维度上的信息处理，使得SNNs非常适合处理时序数据，如音频、视频和传感器数据。</p>
<p>因为只在事件（尖峰）发生时才进行计算，SNNs天生就是事件驱动的。这与生物大脑高度相似，也是其实现低功耗的关键。</p>
<h4 id="突触可塑性与学习规则-STDP">突触可塑性与学习规则 (STDP)</h4>
<p>SNNs的学习机制与传统神经网络的反向传播大相径庭。由于尖峰信号的非连续性和不可微性，直接应用反向传播算法非常困难。相反，SNNs更倾向于使用受生物启发的局部学习规则，其中最著名的是脉冲时间依赖可塑性（Spike-Timing Dependent Plasticity, STDP）。</p>
<p>STDP规则基于这样一个生物学观察：</p>
<ul>
<li>如果一个突触前神经元在突触后神经元发放尖峰<strong>之前</strong>很快地发放尖峰，那么该突触的强度会增强（“Fire together, wire together”）。</li>
<li>如果一个突触前神经元在突触后神经元发放尖峰<strong>之后</strong>才发放尖峰，那么该突触的强度会减弱。</li>
</ul>
<p>用数学形式来表示，突触权重 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi><mi>w</mi></mrow><annotation encoding="application/x-tex">\Delta w</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Δ</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span></span></span></span> 的变化量取决于突触前尖峰时间和突触后尖峰时间之差 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi><mi>t</mi><mo>=</mo><msub><mi>t</mi><mrow><mi>p</mi><mi>o</mi><mi>s</mi><mi>t</mi></mrow></msub><mo>−</mo><msub><mi>t</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\Delta t = t_{post} - t_{pre}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Δ</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.9012em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">os</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.9012em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">re</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="normal">Δ</mi><mi>w</mi><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.36em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>A</mi><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow></msub><mo>⋅</mo><msup><mi>e</mi><mfrac><mrow><mi mathvariant="normal">Δ</mi><mi>t</mi></mrow><msub><mi>τ</mi><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow></msub></mfrac></msup></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if </mtext><mi mathvariant="normal">Δ</mi><mi>t</mi><mo>&gt;</mo><mn>0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><msub><mi>A</mi><mrow><mi>n</mi><mi>e</mi><mi>g</mi></mrow></msub><mo>⋅</mo><msup><mi>e</mi><mfrac><mrow><mi mathvariant="normal">Δ</mi><mi>t</mi></mrow><msub><mi>τ</mi><mrow><mi>n</mi><mi>e</mi><mi>g</mi></mrow></msub></mfrac></msup></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>if </mtext><mi mathvariant="normal">Δ</mi><mi>t</mi><mo>&lt;</mo><mn>0</mn></mrow></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">\Delta w = \begin{cases} A_{pos} \cdot e^{\frac{\Delta t}{\tau_{pos}}} &amp; \text{if } \Delta t &gt; 0 \\ A_{neg} \cdot e^{\frac{\Delta t}{\tau_{neg}}} &amp; \text{if } \Delta t &lt; 0 \end{cases} 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Δ</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.1765em;vertical-align:-1.3382em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size4">{</span></span><span class="mord"><span class="mtable"><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8382em;"><span style="top:-3.8382em;"><span class="pstrut" style="height:3.1562em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">os</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.1562em;"><span style="top:-3.5458em;margin-right:0.05em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8721em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.1132em;">τ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2306em;"><span style="top:-2.3em;margin-left:-0.1132em;margin-right:0.1em;"><span class="pstrut" style="height:2.5em;"></span><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">os</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3944em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.2255em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">Δ</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6257em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:3.1562em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.1562em;"><span style="top:-3.5458em;margin-right:0.05em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8721em;"><span style="top:-2.656em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.1132em;">τ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2306em;"><span style="top:-2.3em;margin-left:-0.1132em;margin-right:0.1em;"><span class="pstrut" style="height:2.5em;"></span><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3944em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.2255em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line mtight" style="border-bottom-width:0.049em;"></span></span><span style="top:-3.384em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">Δ</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6257em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3382em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:1em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8382em;"><span style="top:-3.8382em;"><span class="pstrut" style="height:3.1562em;"></span><span class="mord"><span class="mord text"><span class="mord">if </span></span><span class="mord">Δ</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord">0</span></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:3.1562em;"></span><span class="mord"><span class="mord text"><span class="mord">if </span></span><span class="mord">Δ</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3382em;"><span></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow></msub><mo separator="true">,</mo><msub><mi>A</mi><mrow><mi>n</mi><mi>e</mi><mi>g</mi></mrow></msub><mo separator="true">,</mo><msub><mi>τ</mi><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow></msub><mo separator="true">,</mo><msub><mi>τ</mi><mrow><mi>n</mi><mi>e</mi><mi>g</mi></mrow></msub></mrow><annotation encoding="application/x-tex">A_{pos}, A_{neg}, \tau_{pos}, \tau_{neg}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">os</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1132em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">os</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1132em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 是常数。</p>
<p>STDP是一种无监督的局部学习规则，它允许SNNs在没有明确监督信号的情况下，通过神经元间的时序相关性自主学习特征和模式。这使其在处理流式数据和在线学习场景中具有巨大潜力。</p>
<h4 id="内存计算-In-Memory-Computing-与数据移动瓶颈">内存计算 (In-Memory Computing) 与数据移动瓶颈</h4>
<p>为了克服冯·诺依曼瓶颈，神经形态芯片的一个核心设计理念是将计算能力尽可能地与存储单元紧密集成，甚至在存储单元内部进行计算。这被称为“内存计算”（In-Memory Computing, IMC）或“近内存计算”（Processing-in-Memory, PIM）。</p>
<p>在神经形态芯片中，突触权重通常直接存储在交叉点阵列（Crossbar Array）或电阻式随机存取存储器（RRAM）等非易失性存储器中。当尖峰信号（电流或电压）通过这些存储单元时，会与存储的权重（电阻或电导）相乘，直接实现权重-激活的乘法累加运算。这种方式极大地减少了数据在处理器和内存之间来回传输的需要，从而大幅降低了能耗和延迟。</p>
<h4 id="模拟与数字：实现路径的选择">模拟与数字：实现路径的选择</h4>
<p>神经形态芯片的实现可以大致分为模拟、数字和混合信号三种路径：</p>
<ul>
<li>
<p><strong>模拟神经形态芯片</strong>：</p>
<ul>
<li>直接利用物理特性（如电压、电流、电阻）来模拟神经元和突触的行为。</li>
<li>优点：能效极高，面积小，能更自然地模拟生物过程。</li>
<li>缺点：精度较低，易受噪声和工艺变化影响，难以编程和扩展。</li>
<li>典型代表：BrainScaleS。</li>
</ul>
</li>
<li>
<p><strong>数字神经形态芯片</strong>：</p>
<ul>
<li>用数字电路精确地模拟神经元和突触的数学模型。</li>
<li>优点：精度高，可编程性强，易于扩展和调试，与现有数字设计工具兼容。</li>
<li>缺点：能耗相对较高，面积较大。</li>
<li>典型代表：IBM TrueNorth, Intel Loihi, SpiNNaker。</li>
</ul>
</li>
<li>
<p><strong>混合信号神经形态芯片</strong>：</p>
<ul>
<li>结合了模拟和数字的优点，例如，突触部分采用模拟电路以实现高能效和高密度，而神经元或路由器部分采用数字电路以提高精度和可控性。</li>
<li>旨在平衡能效、精度和可编程性。</li>
</ul>
</li>
</ul>
<p>选择哪种实现路径，取决于具体的应用场景和设计目标。</p>
<h3 id="第三章：类脑芯片的先行者与实践">第三章：类脑芯片的先行者与实践</h3>
<p>神经形态计算并非空中楼阁，全球各大研究机构和科技巨头都在投入巨资进行研发，并取得了令人瞩目的成果。</p>
<h4 id="IBM-TrueNorth：脉冲的先驱">IBM TrueNorth：脉冲的先驱</h4>
<p><strong>特点：</strong></p>
<ul>
<li><strong>时间：</strong> 2014年发布。</li>
<li><strong>架构：</strong> 纯数字设计，包含4096个“神经形态核”，每个核模拟256个可编程的神经元和它们对应的突触。</li>
<li><strong>规模：</strong> 单芯片拥有100万个神经元和2.56亿个突触。</li>
<li><strong>能效：</strong> 功耗仅为70毫瓦，但每秒能处理460亿个突触操作，能效比传统GPU高出数千倍。</li>
<li><strong>核心理念：</strong> 事件驱动，异步通信，大规模并行。它没有全局时钟，所有计算都是在收到尖峰事件时触发。</li>
<li><strong>应用：</strong> 主要面向低功耗、实时的模式识别任务，如图像识别、音频处理等。</li>
</ul>
<p><strong>洞察：</strong> TrueNorth是首个将神经形态架构扩展到百万级神经元规模的芯片，它证明了这种架构在能效上的巨大潜力。然而，其固定、不可训练的突触权重使其在灵活性和通用性上有所欠缺，更像是一个“可配置的SNN加速器”。</p>
<h4 id="Intel-Loihi-Loihi-2：通用的神经形态处理器">Intel Loihi/Loihi 2：通用的神经形态处理器</h4>
<p><strong>特点：</strong></p>
<ul>
<li><strong>时间：</strong> Loihi于2017年发布，Loihi 2于2021年发布。</li>
<li><strong>架构：</strong> 数字SNN处理器，Loihi包含128个神经形态核，每个核有1024个LIF神经元和128K个突触。Loihi 2在工艺、性能和连接密度上都有显著提升。</li>
<li><strong>规模：</strong> 单芯片拥有13万个神经元和1.3亿个突触。Loihi 2使用Intel 4工艺，性能更强。</li>
<li><strong>能效：</strong> 专注于低功耗和实时处理，能效远超通用CPU/GPU。</li>
<li><strong>核心理念：</strong> 可编程性强，支持各种SNN模型和学习规则（包括STDP），旨在成为一个通用的神经形态研究平台。Intel还提供了Loihi的软件开发套件（SDK）——Lava，以促进算法开发。</li>
<li><strong>应用：</strong> 边缘AI、自主系统、机器人、优化问题、甚至部分神经科学研究。</li>
</ul>
<p><strong>洞察：</strong> Loihi系列是通用性最强的神经形态芯片之一，它试图构建一个完整的软硬件生态系统，让研究人员能够方便地探索各种SNN算法。Loihi 2的发布，标志着Intel在该领域的持续投入和领先地位。</p>
<h4 id="SpiNNaker-Spiking-Neural-Network-Architecture-：大规模神经元模拟平台">SpiNNaker (Spiking Neural Network Architecture)：大规模神经元模拟平台</h4>
<p><strong>特点：</strong></p>
<ul>
<li><strong>时间：</strong> 2011年开始开发，由英国曼彻斯特大学主导。</li>
<li><strong>架构：</strong> 基于ARM处理器的数字多核芯片，每个芯片集成18个ARM968处理器核，每个核可以模拟数千个神经元。</li>
<li><strong>规模：</strong> “百万核机器”——SpiNNaker系统最终由超过100万个ARM核组成，能够模拟高达数亿个神经元和数万亿个突触，是目前世界上最大的神经形态系统之一。</li>
<li><strong>核心理念：</strong> 主要用于神经科学研究，模拟生物大脑的大规模神经网络行为。它强调大规模并行通信，所有ARM核之间通过一个专用的路由网络进行数据包通信。</li>
<li><strong>能效：</strong> 虽然每个ARM核本身的能效不如专门的SNN加速器，但其超大规模的并行能力使得总功耗相对可控。</li>
</ul>
<p><strong>洞察：</strong> SpiNNaker更像是一个超大规模的并行计算平台，其设计目标是精确模拟生物神经网络，帮助神经科学家理解大脑的工作原理。它通过软件模拟神经元和突触，牺牲了一部分硬件加速的极致能效，换取了极大的灵活性和规模。</p>
<h4 id="BrainScaleS：混合信号的魅力">BrainScaleS：混合信号的魅力</h4>
<p><strong>特点：</strong></p>
<ul>
<li><strong>时间：</strong> 德国海德堡大学自2005年起开发的欧洲人类大脑计划（Human Brain Project）的一部分。</li>
<li><strong>架构：</strong> 混合信号设计，神经元和突触的动力学在模拟域中实现，而学习规则和通信则在数字域中处理。</li>
<li><strong>规模：</strong> 系统包含20块wafer-scale集成电路，每块wafer上有384个核心，每个核心模拟768个神经元。整个系统能够模拟数百万个神经元。</li>
<li><strong>核心理念：</strong> 加速模拟，其模拟速度比生物大脑快100万倍。这使得研究人员可以在几分钟内模拟几个月甚至几年的大脑活动。</li>
<li><strong>能效：</strong> 模拟部分能耗极低，是其一大优势。</li>
</ul>
<p><strong>洞察：</strong> BrainScaleS代表了神经形态计算的另一条重要路线——混合信号模拟。通过将耗能部分（如尖峰传输）数字化，而将计算密集型部分（如膜电位动力学）模拟化，它在能效和模拟速度上取得了突破。</p>
<h4 id="中国力量：天机芯片等">中国力量：天机芯片等</h4>
<p>中国在神经形态计算领域也取得了显著进展：</p>
<ul>
<li><strong>清华大学天机芯片 (Tianjic Chip)</strong>：2019年发表于《自然》杂志，是中国首款异构融合的类脑芯片。它在同一芯片上集成了SNN和ANN功能，可以在多种神经网络模型之间切换，甚至能同时运行。它在自动驾驶小车和机器臂控制等任务上展示了其灵活性和性能优势。天机芯片的意义在于，它试图将AI的优势与神经形态计算的能效结合起来。</li>
<li><strong>中科院计算所“悟道”系列芯片</strong>：也在积极研发面向深度学习和SNN的专用芯片。</li>
<li><strong>浙江大学“达尔文”芯片</strong>：早期研究成果，专注于SNN的实现。</li>
</ul>
<p><strong>洞察：</strong> 中国在神经形态计算领域正迎头赶上，并逐渐形成自己的特色。特别是天机芯片的异构融合设计，为未来AI芯片的发展提供了新的思路，即在通用性和专用性之间寻求最佳平衡。</p>
<h3 id="第四章：类脑芯片的应用前景与挑战">第四章：类脑芯片的应用前景与挑战</h3>
<p>神经形态计算描绘了一个激动人心的未来，但其发展也面临着诸多挑战。</p>
<h4 id="应用前景：智能边缘，极致能效">应用前景：智能边缘，极致能效</h4>
<ol>
<li>
<p><strong>边缘智能与物联网 (Edge AI &amp; IoT)</strong>：</p>
<ul>
<li>在智能手机、智能手表、传感器等边缘设备上实现复杂的AI功能，而无需将数据上传到云端，保护隐私，降低延迟。</li>
<li>例如，低功耗的语音识别、手势识别、异常检测等。</li>
<li>SNNs的事件驱动特性和低功耗使其成为边缘AI的理想选择。</li>
</ul>
</li>
<li>
<p><strong>实时感知与决策 (Real-time Perception &amp; Decision-making)</strong>：</p>
<ul>
<li>自动驾驶：车辆需要毫秒级地处理传感器数据并做出决策。神经形态芯片的低延迟特性使其具有独特优势。</li>
<li>工业机器人：在复杂、动态的环境中进行实时交互和控制。</li>
<li>医疗健康：可穿戴设备进行生理信号监测和早期疾病预警。</li>
</ul>
</li>
<li>
<p><strong>智能机器人与自主系统 (Robotics &amp; Autonomous Systems)</strong>：</p>
<ul>
<li>赋予机器人更像生物的感知、学习和适应能力。</li>
<li>例如，机器人可以通过模仿学习、强化学习在未知环境中自主探索和学习技能。</li>
</ul>
</li>
<li>
<p><strong>能源效率优化 (Energy Efficiency Optimization)</strong>：</p>
<ul>
<li>在数据中心、云计算领域，虽然目前AI加速器以GPU为主，但未来神经形态芯片有望在特定任务上提供更低的TCO（总拥有成本），降低巨型AI模型的能耗。</li>
</ul>
</li>
<li>
<p><strong>神经科学研究 (Neuroscience Research)</strong>：</p>
<ul>
<li>作为模拟大脑的平台，帮助神经科学家深入理解大脑的运作机制、疾病发生机理等。</li>
</ul>
</li>
</ol>
<h4 id="挑战：软件生态，算法创新">挑战：软件生态，算法创新</h4>
<ol>
<li>
<p><strong>编程模型与软件生态</strong>：</p>
<ul>
<li>这是当前神经形态计算最大的挑战之一。SNN的编程范式与传统的命令式编程和深度学习框架（如TensorFlow, PyTorch）大相径庭。</li>
<li>如何将现有的ANN模型高效地转换或映射到SNN上？如何开发新的、原生的SNN算法和训练方法？</li>
<li>目前缺乏统一的编程语言、开发工具和调试器，这限制了其广泛应用。</li>
</ul>
</li>
<li>
<p><strong>算法开发与学习规则</strong>：</p>
<ul>
<li>SNN的学习方法不像BP算法那样成熟和通用。STDP等局部学习规则虽然生物学上合理，但在解决复杂大规模任务上的性能仍需提升。</li>
<li>将监督学习（如分类）与SNN的事件驱动特性相结合，仍是一个活跃的研究方向（例如，利用代理梯度或STDP与反向传播结合）。</li>
</ul>
</li>
<li>
<p><strong>通用性与规模化</strong>：</p>
<ul>
<li>现有的类脑芯片往往针对特定任务或神经元模型进行了优化，通用性不足。</li>
<li>如何大规模生产这些芯片，并确保其可靠性和一致性，也是一个工程挑战。模拟芯片尤其面临精度和良率问题。</li>
</ul>
</li>
<li>
<p><strong>软硬件协同设计</strong>：</p>
<ul>
<li>神经形态系统需要硬件、软件、算法、应用层面的紧密协同。</li>
<li>开发新的评估基准（benchmarks）来衡量神经形态芯片的实际性能和能效，也是当前的重要任务。</li>
</ul>
</li>
<li>
<p><strong>与传统计算的融合</strong>：</p>
<ul>
<li>未来的计算系统很可能不是纯粹的神经形态，而是混合架构，将神经形态加速器作为通用计算平台的一部分。如何有效地集成和调度这些异构资源，也是一个重要课题。</li>
</ul>
</li>
</ol>
<h3 id="结论：迈向计算的“新常态”">结论：迈向计算的“新常态”</h3>
<p>神经形态计算与类脑芯片不仅仅是硬件技术的一次迭代，更是一场关于计算范式的深刻变革。它挑战了我们对“计算”的固有理解，从传统的指令-数据分离模式，转向更接近生物智能的内存-计算一体、事件驱动、大规模并行处理。</p>
<p>虽然前方仍有诸多挑战，但我们已经看到了它在能效、实时性以及处理模糊、不精确信息方面的巨大潜力。未来，类脑芯片有望在边缘智能、机器人、自动驾驶等对功耗和延迟有严苛要求的领域大放异彩。它也将继续推动我们对人类大脑的理解，反过来指导更高效、更智能的计算系统设计。</p>
<p>从长远来看，神经形态计算可能不会完全取代传统的冯·诺依曼架构，而更有可能以加速器或异构计算单元的形式，融入我们未来的计算系统，共同构建一个更加智能、更加节能的数字世界。</p>
<p>这场计算的“新常态”正在悄然来临，我们有幸成为这一历史进程的见证者和参与者。作为技术爱好者，让我们一起期待神经形态计算的未来，因为它不仅关乎芯片，更关乎我们理解智能、创造智能的边界。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a target="_blank" rel="noopener" href="https://github.com/qmwneb946">qmwneb946</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://qmwneb946.dpdns.org/2025/07/19/2025-07-19-103025/">https://qmwneb946.dpdns.org/2025/07/19/2025-07-19-103025/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://opensource.org/licenses/MIT" target="_blank">MIT License</a> 许可协议。转载请注明来源 <a href="https://qmwneb946.dpdns.org" target="_blank">qmwneb946 的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/2025/">2025</a><a class="post-meta__tags" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/">计算机科学</a><a class="post-meta__tags" href="/tags/%E7%A5%9E%E7%BB%8F%E5%BD%A2%E6%80%81%E8%AE%A1%E7%AE%97%E4%B8%8E%E7%B1%BB%E8%84%91%E8%8A%AF%E7%89%87/">神经形态计算与类脑芯片</a></div><div class="post-share"><div class="social-share" data-image="/img/icon.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/07/19/2025-07-19-111605/" title="记忆B细胞与长期免疫的奥秘：从分子机制到疫苗策略"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">记忆B细胞与长期免疫的奥秘：从分子机制到疫苗策略</div></div><div class="info-2"><div class="info-item-1">作为qmwneb946，一名技术与数学爱好者，我始终着迷于自然界中最精妙的“算法”——生命科学。今天，我们将一同深入探讨一个与我们健康息息相关的宏大主题：免疫系统的记忆，特别是记忆B细胞在构建长期免疫防御中的核心作用。 我们每天暴露在无数病原体之下，但为何大多数感染仅发生一次，我们便能对它“免疫”？这并非偶然，而是生命演化出的最伟大的安全机制之一。它涉及复杂而精密的分子识别、细胞分化以及群体选择过程。理解记忆B细胞的运作，不仅能揭示我们自身防御的奥秘，更能指导我们开发出更有效、更持久的疫苗策略，从而抵御未来的流行病威胁。 本文将从免疫系统的基本记忆原理出发，逐步深入B细胞的生命旅程，探讨它们如何从“幼稚”状态演变为高效的记忆细胞。我们将揭示生发中心（Germinal Center）这一免疫“熔炉”中的惊人化学反应，并尝试引入一些数学视角来理解其中的选择压力。最终，我们将把这些基础知识与当前疫苗开发的挑战和前沿进展联系起来，希望能为你带来一场关于生命智能的深度思考。  免疫系统的记忆：为何我们不会反复生病？ 我们都知道，一旦得了水痘，通常就不会再得了。这种现象被称为“免疫记忆”。它...</div></div></div></a><a class="pagination-related" href="/2025/07/19/2025-07-19-102941/" title="碳基硅基共舞：DNA存储技术的研究进展与未来图景"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">碳基硅基共舞：DNA存储技术的研究进展与未来图景</div></div><div class="info-2"><div class="info-item-1"> 引言 在数字时代波澜壮阔的浪潮中，我们正以前所未有的速度生成、收集并分析着海量数据。从全球互联网流量，到科学研究的海量数据集，再到个人生活的数字轨迹，数据洪流已经成为我们文明的基石。然而，硅基存储介质——硬盘、固态硬盘、磁带——正面临着严峻的挑战：它们不仅有固定的寿命（通常在几年到几十年之间），消耗大量能源，而且在存储密度上也逐渐触及物理极限。我们迫切需要一种更高效、更持久、更绿色的存储方案。 正是在这样的背景下，生物界最古老、最强大的信息载体——脱氧核糖核酸（DNA），作为一种颠覆性的存储介质，走进了科学家和工程师的视野。DNA，这个承载了地球生命亿万年演化奥秘的双螺旋分子，以其无与伦比的存储密度、惊人的稳定性以及极低的能耗，为解决未来数据存储危机描绘了一幅激动人心的蓝图。 想象一下：您电脑硬盘中的所有数据，甚至全球互联网的数据总和，最终可以被压缩并存储在一个指甲盖大小的DNA样本中，并且能保存数万甚至数十万年，几乎不需要电力维持。这听起来像是科幻小说，但科学家们正一步步将其变为现实。作为一名常年游走于技术与数学边界的博主，我（qmwneb946）将带领大家深入探索DNA存储...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/07/18/2025-07-18-082418/" title="机器学习算法的公平性问题：技术挑战与伦理困境"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">机器学习算法的公平性问题：技术挑战与伦理困境</div></div><div class="info-2"><div class="info-item-1">引言 机器学习 (ML) 正在迅速改变我们的世界，从医疗保健到金融，再到刑事司法系统，它的应用几乎无处不在。然而，随着 ML 系统的广泛部署，一个越来越令人担忧的问题浮出水面：公平性。  算法的输出可能反映并放大现有的社会偏见，导致对某些群体的不公平待遇。本文将深入探讨机器学习算法中的公平性问题，分析其技术根源和伦理困境，并探讨一些可能的解决方案。 偏见是如何进入机器学习模型的？ 机器学习模型的公平性问题并非源于算法本身的恶意，而是源于其训练数据的偏见。  这些偏见可能来自多种来源： 数据收集与标注  样本选择偏差 (Sampling Bias):  如果训练数据未能充分代表所有群体，模型就会学习到一个有偏的表示。例如，如果一个用于预测贷款偿还能力的模型主要基于白人申请人的数据，它可能会对少数族裔申请人产生不公平的负面预测。 测量偏差 (Measurement Bias):  数据收集过程中的错误或不一致也会引入偏见。例如，在犯罪预测模型中，如果某些社区的执法力度更大，导致该社区的犯罪数据被过度记录，模型就会对该社区产生负面偏见。 标注偏差 (Label Bias):  人工标注...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082429/" title="区块链技术与数字版权保护：一场技术与法律的博弈"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">区块链技术与数字版权保护：一场技术与法律的博弈</div></div><div class="info-2"><div class="info-item-1">大家好，我是你们的技术博主X，今天我们来聊一个非常热门的话题：区块链技术如何应用于数字版权保护。在数字内容飞速发展的时代，版权侵权问题日益严峻，传统的版权保护机制显得力不从心。而区块链技术，凭借其去中心化、不可篡改、透明等特性，为解决这一难题提供了新的思路。 区块链技术概述 首先，让我们简单回顾一下区块链技术的基本原理。区块链是一个由多个区块组成的链式数据库，每个区块包含一系列经过加密验证的交易记录。这些交易记录一旦被写入区块链，就无法被篡改或删除，保证了数据的完整性和安全性。  其核心技术包括：  密码学:  确保数据的安全性和完整性，例如哈希算法和数字签名。 共识机制:  例如工作量证明（PoW）和权益证明（PoS），用于维护区块链的统一性和安全性，防止恶意攻击。 分布式账本: 数据分布在多个节点上，提高了系统的容错性和安全性。  区块链如何保护数字版权 区块链技术可以为数字版权保护提供多种方案，主要体现在以下几个方面： 版权登记与确权 传统的版权登记流程繁琐且耗时，而区块链可以提供一个快速、透明的版权登记平台。创作者可以将作品的哈希值（作品的数字指纹）记录到区块链上，以此证...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082438/" title="云计算中的数据安全与隐私：挑战与应对"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">云计算中的数据安全与隐私：挑战与应对</div></div><div class="info-2"><div class="info-item-1">云计算为企业和个人提供了强大的计算资源和数据存储能力，但也带来了新的安全与隐私挑战。本文将深入探讨云计算环境下的数据安全与隐私问题，分析其背后的技术机制，并提出一些有效的应对策略。 云计算安全风险剖析 云计算环境中，数据安全与隐私面临着多种威胁，主要包括： 数据泄露与丢失 这是最常见的风险之一。  数据可能由于云提供商的内部安全漏洞、恶意攻击（例如SQL注入、DDoS攻击）、员工失误或意外事件（例如硬件故障）而泄露或丢失。  对于敏感数据，例如医疗记录、金融信息和个人身份信息，这种风险尤为严重。 数据违规 数据违规是指未经授权访问或使用数据的情况。这可能导致数据被篡改、删除或用于非法目的。  法规遵从性（例如 GDPR, CCPA）的压力也使得数据违规的代价越来越高。 权限管理不足 缺乏细粒度的访问控制机制可能导致数据被未授权的个人或应用程序访问。  复杂的云环境中，权限的管理和审核是一个极大的挑战。 数据完整性问题 云环境中的数据完整性需要得到保障，确保数据没有被未经授权的修改或破坏。  这需要使用诸如哈希算法和数字签名等技术来验证数据的完整性。 数据合规性 不同国家和地区对数...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082500/" title="物联网设备的网络安全协议：挑战与解决方案"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">物联网设备的网络安全协议：挑战与解决方案</div></div><div class="info-2"><div class="info-item-1">物联网 (IoT) 设备正以前所未有的速度渗透到我们生活的方方面面，从智能家居到工业自动化，再到医疗保健。然而，这种广泛的连接也带来了巨大的安全风险。由于物联网设备通常资源受限，安全性设计常常被忽视，导致它们成为网络攻击的理想目标。本文将深入探讨物联网设备面临的网络安全挑战，以及用于增强其安全性的各种协议和技术。 物联网安全面临的挑战 物联网设备的安全挑战与传统IT系统大相径庭，主要体现在以下几个方面： 资源受限 许多物联网设备具有有限的处理能力、内存和存储空间。这使得部署复杂的加密算法和安全协议变得困难，同时也增加了运行时开销。  运行资源消耗较大的安全软件可能会影响设备的性能甚至导致其崩溃。 设备异构性 物联网生态系统由各种各样的设备组成，这些设备运行不同的操作系统，使用不同的编程语言，并具有不同的安全特性。这种异构性使得实施统一的安全策略变得极其复杂。  很难找到一个适用于所有设备的通用安全解决方案。 数据隐私与安全 物联网设备通常会收集大量敏感数据，例如个人健康信息、位置数据和财务信息。保护这些数据的隐私和安全至关重要，但由于设备自身的安全缺陷和数据传输过程中的漏洞，这成...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082528/" title="量子计算对现代密码学的威胁：后量子密码学的挑战与机遇"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">量子计算对现代密码学的威胁：后量子密码学的挑战与机遇</div></div><div class="info-2"><div class="info-item-1">量子计算的飞速发展为许多领域带来了革命性的变革，但也对现有的密码体系构成了前所未有的挑战。本文将深入探讨量子计算如何威胁现代密码学，以及我们如何应对这一挑战。 量子计算的优势与密码学的困境 经典计算机基于比特，其值只能是 0 或 1。而量子计算机利用量子比特，可以同时表示 0 和 1 的叠加态，这使得它们能够进行并行计算，处理能力远超经典计算机。  这种巨大的计算能力为解决某些目前被认为是“不可解”的问题提供了可能性，其中就包括许多现代密码学的基石。 例如，RSA 算法，广泛应用于电子商务和安全通信，其安全性依赖于大数分解的困难性。经典计算机分解一个很大的数需要指数级的时间，因此被认为是安全的。然而，Shor 算法，一个在量子计算机上运行的算法，能够以多项式时间分解大数。这意味着，一台足够强大的量子计算机能够轻易破解 RSA 加密，从而威胁到大量的在线交易、数据安全以及国家安全。 同样，椭圆曲线密码学 (ECC)，另一种广泛使用的密码算法，其安全性也依赖于某些数学问题的复杂性。然而，量子计算机也能够有效地解决这些问题，例如离散对数问题。 Shor 算法与 Grover 算法：量子...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082537/" title="图论算法在社交网络分析中的应用"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">图论算法在社交网络分析中的应用</div></div><div class="info-2"><div class="info-item-1">社交网络已经成为我们生活中不可或缺的一部分。从Facebook和Twitter到微信和微博，这些平台连接着数十亿用户，产生着海量的数据。而理解这些数据，挖掘其背后的规律和价值，就需要借助强大的数学工具——图论。本文将深入探讨图论算法在社交网络分析中的多种应用。 社交网络的图表示 在图论中，社交网络可以被自然地表示为图 G=(V,E)G = (V, E)G=(V,E)，其中 VVV 代表用户集合（节点），EEE 代表用户之间的关系集合（边）。例如，在Facebook中，每个用户是一个节点，如果两个用户是朋友，则在他们之间存在一条无向边；在Twitter中，如果用户A关注用户B，则存在一条从A指向B的有向边。边的权重可以表示关系的强度（例如，朋友关系的亲密度，或者互动频率）。  这种图表示为我们分析社交网络提供了坚实的基础。 核心图论算法及其应用 社区发现 社区发现旨在将社交网络划分成多个紧密连接的社区（也称为集群）。这对于理解用户群体、推荐系统以及病毒式营销等都至关重要。常用的算法包括：  Louvain算法:  一种贪婪的启发式算法，通过迭代优化模块度来寻找最佳社区结构。模块度 ...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">qmwneb946</div><div class="author-info-description">一个专注于技术分享的个人博客，涵盖编程、算法、系统设计等内容</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">352</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">356</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/qmwneb946"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/qmwneb946" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:qmwneb946@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">代码与远方，技术与生活交织的篇章。</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%95%E8%A8%80%EF%BC%9AAI%E6%97%B6%E4%BB%A3%E7%9A%84%E8%83%BD%E8%80%97%E5%8D%B1%E6%9C%BA%E4%B8%8E%E5%86%AF%C2%B7%E8%AF%BA%E4%BE%9D%E6%9B%BC%E7%93%B6%E9%A2%88"><span class="toc-number">1.</span> <span class="toc-text">引言：AI时代的能耗危机与冯·诺依曼瓶颈</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%9A%E4%BB%8E%E7%94%9F%E7%89%A9%E5%A4%A7%E8%84%91%E6%B1%B2%E5%8F%96%E7%81%B5%E6%84%9F%E2%80%94%E2%80%94%E8%87%AA%E7%84%B6%E7%95%8C%E7%9A%84%E8%AE%A1%E7%AE%97%E5%A5%87%E8%BF%B9"><span class="toc-number">2.</span> <span class="toc-text">第一章：从生物大脑汲取灵感——自然界的计算奇迹</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%A5%9E%E7%BB%8F%E5%85%83%E4%B8%8E%E7%AA%81%E8%A7%A6%EF%BC%9A%E5%A4%A7%E8%84%91%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%9E%84%E5%BB%BA%E5%9D%97"><span class="toc-number">2.1.</span> <span class="toc-text">神经元与突触：大脑的基本构建块</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%A7%E8%84%91%E7%9A%84%E8%BF%90%E8%A1%8C%E6%9C%BA%E5%88%B6%EF%BC%9A%E5%B9%B6%E8%A1%8C%E3%80%81%E4%BA%8B%E4%BB%B6%E9%A9%B1%E5%8A%A8%E3%80%81%E5%8F%AF%E5%A1%91%E6%80%A7"><span class="toc-number">2.2.</span> <span class="toc-text">大脑的运行机制：并行、事件驱动、可塑性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%94%9F%E7%89%A9%E6%95%88%E7%8E%87%E7%9A%84%E5%90%AF%E7%A4%BA"><span class="toc-number">2.3.</span> <span class="toc-text">生物效率的启示</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E7%AB%A0%EF%BC%9A%E7%A5%9E%E7%BB%8F%E5%BD%A2%E6%80%81%E8%AE%A1%E7%AE%97%E7%9A%84%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5"><span class="toc-number">3.</span> <span class="toc-text">第二章：神经形态计算的核心概念</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%84%89%E5%86%B2%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-Spiking-Neural-Networks-SNN-%EF%BC%9A%E7%AC%AC%E4%B8%89%E4%BB%A3%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">3.1.</span> <span class="toc-text">脉冲神经网络 (Spiking Neural Networks, SNN)：第三代神经网络</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AA%81%E8%A7%A6%E5%8F%AF%E5%A1%91%E6%80%A7%E4%B8%8E%E5%AD%A6%E4%B9%A0%E8%A7%84%E5%88%99-STDP"><span class="toc-number">3.2.</span> <span class="toc-text">突触可塑性与学习规则 (STDP)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E8%AE%A1%E7%AE%97-In-Memory-Computing-%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%A7%BB%E5%8A%A8%E7%93%B6%E9%A2%88"><span class="toc-number">3.3.</span> <span class="toc-text">内存计算 (In-Memory Computing) 与数据移动瓶颈</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A8%A1%E6%8B%9F%E4%B8%8E%E6%95%B0%E5%AD%97%EF%BC%9A%E5%AE%9E%E7%8E%B0%E8%B7%AF%E5%BE%84%E7%9A%84%E9%80%89%E6%8B%A9"><span class="toc-number">3.4.</span> <span class="toc-text">模拟与数字：实现路径的选择</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E7%AB%A0%EF%BC%9A%E7%B1%BB%E8%84%91%E8%8A%AF%E7%89%87%E7%9A%84%E5%85%88%E8%A1%8C%E8%80%85%E4%B8%8E%E5%AE%9E%E8%B7%B5"><span class="toc-number">4.</span> <span class="toc-text">第三章：类脑芯片的先行者与实践</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#IBM-TrueNorth%EF%BC%9A%E8%84%89%E5%86%B2%E7%9A%84%E5%85%88%E9%A9%B1"><span class="toc-number">4.1.</span> <span class="toc-text">IBM TrueNorth：脉冲的先驱</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Intel-Loihi-Loihi-2%EF%BC%9A%E9%80%9A%E7%94%A8%E7%9A%84%E7%A5%9E%E7%BB%8F%E5%BD%A2%E6%80%81%E5%A4%84%E7%90%86%E5%99%A8"><span class="toc-number">4.2.</span> <span class="toc-text">Intel Loihi&#x2F;Loihi 2：通用的神经形态处理器</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#SpiNNaker-Spiking-Neural-Network-Architecture-%EF%BC%9A%E5%A4%A7%E8%A7%84%E6%A8%A1%E7%A5%9E%E7%BB%8F%E5%85%83%E6%A8%A1%E6%8B%9F%E5%B9%B3%E5%8F%B0"><span class="toc-number">4.3.</span> <span class="toc-text">SpiNNaker (Spiking Neural Network Architecture)：大规模神经元模拟平台</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#BrainScaleS%EF%BC%9A%E6%B7%B7%E5%90%88%E4%BF%A1%E5%8F%B7%E7%9A%84%E9%AD%85%E5%8A%9B"><span class="toc-number">4.4.</span> <span class="toc-text">BrainScaleS：混合信号的魅力</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%AD%E5%9B%BD%E5%8A%9B%E9%87%8F%EF%BC%9A%E5%A4%A9%E6%9C%BA%E8%8A%AF%E7%89%87%E7%AD%89"><span class="toc-number">4.5.</span> <span class="toc-text">中国力量：天机芯片等</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E5%9B%9B%E7%AB%A0%EF%BC%9A%E7%B1%BB%E8%84%91%E8%8A%AF%E7%89%87%E7%9A%84%E5%BA%94%E7%94%A8%E5%89%8D%E6%99%AF%E4%B8%8E%E6%8C%91%E6%88%98"><span class="toc-number">5.</span> <span class="toc-text">第四章：类脑芯片的应用前景与挑战</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%E5%89%8D%E6%99%AF%EF%BC%9A%E6%99%BA%E8%83%BD%E8%BE%B9%E7%BC%98%EF%BC%8C%E6%9E%81%E8%87%B4%E8%83%BD%E6%95%88"><span class="toc-number">5.1.</span> <span class="toc-text">应用前景：智能边缘，极致能效</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8C%91%E6%88%98%EF%BC%9A%E8%BD%AF%E4%BB%B6%E7%94%9F%E6%80%81%EF%BC%8C%E7%AE%97%E6%B3%95%E5%88%9B%E6%96%B0"><span class="toc-number">5.2.</span> <span class="toc-text">挑战：软件生态，算法创新</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA%EF%BC%9A%E8%BF%88%E5%90%91%E8%AE%A1%E7%AE%97%E7%9A%84%E2%80%9C%E6%96%B0%E5%B8%B8%E6%80%81%E2%80%9D"><span class="toc-number">6.</span> <span class="toc-text">结论：迈向计算的“新常态”</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/21/hello-world/" title="Hello World">Hello World</a><time datetime="2025-07-21T20:33:29.985Z" title="发表于 2025-07-22 04:33:29">2025-07-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/21/2025-07-21-203212/" title="量子退火算法及其应用：开启优化计算的未来篇章">量子退火算法及其应用：开启优化计算的未来篇章</a><time datetime="2025-07-21T12:32:12.000Z" title="发表于 2025-07-21 20:32:12">2025-07-21</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/21/2025-07-21-195648/" title="VR/AR内容：从沉浸式创作到无界分发的技术深度解析">VR/AR内容：从沉浸式创作到无界分发的技术深度解析</a><time datetime="2025-07-21T11:56:48.000Z" title="发表于 2025-07-21 19:56:48">2025-07-21</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/21/2025-07-21-194427/" title="深度剖析5G切片技术：赋能垂直行业数字化转型的核心动力">深度剖析5G切片技术：赋能垂直行业数字化转型的核心动力</a><time datetime="2025-07-21T11:44:27.000Z" title="发表于 2025-07-21 19:44:27">2025-07-21</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/21/2025-07-21-192802/" title="揭秘 EDR：从端点数据到安全响应的智慧之眼">揭秘 EDR：从端点数据到安全响应的智慧之眼</a><time datetime="2025-07-21T11:28:02.000Z" title="发表于 2025-07-21 19:28:02">2025-07-21</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;2025 By qmwneb946</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.2</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css')
    if (true) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const getGiscusTheme = theme => theme === 'dark' ? 'dark' : 'light'

  const createScriptElement = config => {
    const ele = document.createElement('script')
    Object.entries(config).forEach(([key, value]) => {
      ele.setAttribute(key, value)
    })
    return ele
  }

  const loadGiscus = (el = document, key) => {
    const mappingConfig = isShuoshuo
      ? { 'data-mapping': 'specific', 'data-term': key }
      : { 'data-mapping': (option && option['data-mapping']) || 'pathname' }

    const giscusConfig = {
      src: 'https://giscus.app/client.js',
      'data-repo': 'qmwneb946/blog',
      'data-repo-id': 'R_kgDOPM6cWw',
      'data-category-id': 'DIC_kwDOPM6cW84CtEzo',
      'data-theme': getGiscusTheme(document.documentElement.getAttribute('data-theme')),
      'data-reactions-enabled': '1',
      crossorigin: 'anonymous',
      async: true,
      ...option,
      ...mappingConfig
    }

    const scriptElement = createScriptElement(giscusConfig)

    el.querySelector('#giscus-wrap').appendChild(scriptElement)

    if (isShuoshuo) {
      window.shuoshuoComment.destroyGiscus = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }
  }

  const changeGiscusTheme = theme => {
    const iframe = document.querySelector('#giscus-wrap iframe')
    if (iframe) {
      const message = {
        giscus: {
          setConfig: {
            theme: getGiscusTheme(theme)
          }
        }
      }
      iframe.contentWindow.postMessage(message, 'https://giscus.app')
    }
  }

  btf.addGlobalFn('themeChange', changeGiscusTheme, 'giscus')

  if (isShuoshuo) {
    'Giscus' === 'Giscus'
      ? window.shuoshuoComment = { loadComment: loadGiscus }
      : window.loadOtherComment = loadGiscus
    return
  }

  if ('Giscus' === 'Giscus' || !false) {
    if (false) btf.loadComment(document.getElementById('giscus-wrap'), loadGiscus)
    else loadGiscus()
  } else {
    window.loadOtherComment = loadGiscus
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>