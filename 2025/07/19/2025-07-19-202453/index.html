<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>预训练语言模型的压缩与蒸馏：从理论到实践的深度探索 | qmwneb946 的博客</title><meta name="author" content="qmwneb946"><meta name="copyright" content="qmwneb946"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="你好，技术爱好者们！我是 qmwneb946，今天我们将一同踏上一段关于人工智能前沿的深度探索之旅。在过去几年中，预训练语言模型（PLMs）如BERT、GPT系列、T5等，凭借其惊人的性能，在自然语言处理（NLP）领域掀起了一场革命。它们能够理解、生成并处理复杂的文本信息，并在诸多下游任务中取得了突破性的进展，从文本分类、命名实体识别到机器翻译、问答系统，无所不能。 然而，伴随其强大能力而来的是一">
<meta property="og:type" content="article">
<meta property="og:title" content="预训练语言模型的压缩与蒸馏：从理论到实践的深度探索">
<meta property="og:url" content="https://qmwneb946.dpdns.org/2025/07/19/2025-07-19-202453/index.html">
<meta property="og:site_name" content="qmwneb946 的博客">
<meta property="og:description" content="你好，技术爱好者们！我是 qmwneb946，今天我们将一同踏上一段关于人工智能前沿的深度探索之旅。在过去几年中，预训练语言模型（PLMs）如BERT、GPT系列、T5等，凭借其惊人的性能，在自然语言处理（NLP）领域掀起了一场革命。它们能够理解、生成并处理复杂的文本信息，并在诸多下游任务中取得了突破性的进展，从文本分类、命名实体识别到机器翻译、问答系统，无所不能。 然而，伴随其强大能力而来的是一">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://qmwneb946.dpdns.org/img/icon.png">
<meta property="article:published_time" content="2025-07-19T12:24:53.000Z">
<meta property="article:modified_time" content="2025-07-20T15:19:26.993Z">
<meta property="article:author" content="qmwneb946">
<meta property="article:tag" content="2025">
<meta property="article:tag" content="数学">
<meta property="article:tag" content="预训练语言模型的压缩与蒸馏">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://qmwneb946.dpdns.org/img/icon.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "预训练语言模型的压缩与蒸馏：从理论到实践的深度探索",
  "url": "https://qmwneb946.dpdns.org/2025/07/19/2025-07-19-202453/",
  "image": "https://qmwneb946.dpdns.org/img/icon.png",
  "datePublished": "2025-07-19T12:24:53.000Z",
  "dateModified": "2025-07-20T15:19:26.993Z",
  "author": [
    {
      "@type": "Person",
      "name": "qmwneb946",
      "url": "https://github.com/qmwneb946"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://qmwneb946.dpdns.org/2025/07/19/2025-07-19-202453/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '预训练语言模型的压缩与蒸馏：从理论到实践的深度探索',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2845632165165414" crossorigin="anonymous"></script><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="qmwneb946 的博客" type="application/atom+xml">
</head><body><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">qmwneb946 的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">预训练语言模型的压缩与蒸馏：从理论到实践的深度探索</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">预训练语言模型的压缩与蒸馏：从理论到实践的深度探索<a class="post-edit-link" href="https://github.com/qmwneb946/blog/edit/main/source/_posts/2025-07-19-202453.md" title="编辑" target="_blank"><i class="fas fa-pencil-alt"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-07-19T12:24:53.000Z" title="发表于 2025-07-19 20:24:53">2025-07-19</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-07-20T15:19:26.993Z" title="更新于 2025-07-20 23:19:26">2025-07-20</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%95%B0%E5%AD%A6/">数学</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><p>你好，技术爱好者们！我是 qmwneb946，今天我们将一同踏上一段关于人工智能前沿的深度探索之旅。在过去几年中，预训练语言模型（PLMs）如BERT、GPT系列、T5等，凭借其惊人的性能，在自然语言处理（NLP）领域掀起了一场革命。它们能够理解、生成并处理复杂的文本信息，并在诸多下游任务中取得了突破性的进展，从文本分类、命名实体识别到机器翻译、问答系统，无所不能。</p>
<p>然而，伴随其强大能力而来的是一个日益突出的问题：这些模型往往规模庞大，参数量动辄数亿乃至数万亿，导致其对计算资源的需求极高，推理速度缓慢，且部署成本昂贵。这使得PLMs在资源受限的边缘设备、移动应用，以及需要低延迟响应的实时系统中面临巨大挑战。</p>
<p>因此，“如何让这些庞大而强大的模型变得更小、更快、更高效？”成为了当前AI领域的一个核心研究方向。今天，我们的主题正是围绕这一核心问题展开，深入探讨预训练语言模型的<strong>压缩</strong>与<strong>蒸馏</strong>技术。我们将从理论基础出发，逐步揭示各种方法的原理、优势、劣势，并通过一些概念性的代码和数学公式，帮助你构建一个清晰而深刻的理解。</p>
<hr>
<h2 id="PLM压缩的必要性与挑战">PLM压缩的必要性与挑战</h2>
<p>在深入具体技术之前，我们首先需要理解为什么模型压缩变得如此紧迫，以及我们在尝试压缩时会遇到哪些难题。</p>
<h3 id="为什么需要压缩？">为什么需要压缩？</h3>
<ol>
<li><strong>计算资源限制</strong>: 训练和部署大型PLM需要海量的计算资源，包括高性能GPU和高带宽内存。这对于普通研究者、中小型企业或个人开发者而言是巨大的负担。即使是大型公司，也需要优化资源利用率。</li>
<li><strong>推理延迟</strong>: 在线服务、对话系统、实时翻译等应用对延迟有严格要求。一个推理耗时数百毫秒的模型，在很多场景下是不可接受的。压缩可以显著降低推理时间。</li>
<li><strong>能耗与环境影响</strong>: 巨大的模型意味着巨大的能耗。AI模型的“碳足迹”日益受到关注。通过压缩，我们可以减少能源消耗，使AI更加“绿色”和可持续。</li>
<li><strong>部署限制</strong>:
<ul>
<li><strong>移动设备与边缘计算</strong>: 智能手机、IoT设备、嵌入式系统等，其计算能力、内存和电池寿命都非常有限。部署未经压缩的PLM几乎不可能。</li>
<li><strong>本地部署与隐私</strong>: 某些应用场景出于数据隐私或网络条件限制，需要将模型部署在本地设备上，而非云端。</li>
<li><strong>模型分发</strong>: 更小的模型文件更容易分发、更新和管理。</li>
</ul>
</li>
</ol>
<h3 id="压缩的挑战">压缩的挑战</h3>
<p>虽然压缩的好处显而易见，但实现它并非易事：</p>
<ol>
<li><strong>性能下降</strong>: 这是最大的挑战。压缩往往意味着去除冗余或降低精度，这很容易导致模型性能（如准确率、F1分数等）的下降。如何在保持甚至提升性能的同时进行大幅压缩，是核心难题。</li>
<li><strong>通用性问题</strong>: 某些压缩方法可能在特定任务上表现良好，但在其他任务上可能效果不佳。我们需要寻找具有良好通用性的压缩策略。</li>
<li><strong>工程复杂性</strong>: 引入压缩技术（尤其是量化感知训练、结构化剪枝等）会增加训练和部署流程的复杂性，需要专门的工具和框架支持。</li>
<li><strong>新架构与方法论的探索</strong>: 传统的压缩技术可能无法完全适应PLM的Transformer架构。我们需要不断探索针对Transformer特性的新型压缩方法。</li>
</ol>
<hr>
<h2 id="核心压缩技术">核心压缩技术</h2>
<p>现在，让我们深入探讨几种主流的PLM压缩技术。</p>
<h3 id="1-模型剪枝-Pruning">1. 模型剪枝 (Pruning)</h3>
<p>模型剪枝是一种通过移除模型中不重要或冗余的连接、神经元或层来减小模型大小和计算量的方法。它的灵感来源于生物学中大脑发育过程中的突触修剪。</p>
<h4 id="原理">原理</h4>
<p>剪枝的核心思想是识别并消除模型中的“不活跃”或“不重要”的部分，因为它们对模型的最终输出贡献甚微，甚至可能引入噪声。</p>
<h4 id="类型">类型</h4>
<p>根据剪枝的粒度，剪枝可以分为两类：</p>
<ol>
<li>
<p><strong>非结构化剪枝 (Unstructured Pruning)</strong>:</p>
<ul>
<li><strong>原理</strong>: 移除模型中单个的权重。例如，将权重矩阵中绝对值小于某个阈值的元素设为零。</li>
<li><strong>优点</strong>: 压缩比高，理论上可以达到最大的稀疏度。</li>
<li><strong>缺点</strong>: 导致模型参数稀疏不规则，难以被通用硬件（如GPU）高效加速，需要特殊的稀疏矩阵运算库支持，实际推理加速效果不明显。</li>
</ul>
</li>
<li>
<p><strong>结构化剪枝 (Structured Pruning)</strong>:</p>
<ul>
<li><strong>原理</strong>: 移除整个神经元、通道、注意力头、甚至整个Transformer层。</li>
<li><strong>优点</strong>: 移除的是完整的结构，模型变得更小且更规则，可以直接在现有硬件上获得实际的推理加速。</li>
<li><strong>缺点</strong>: 相比非结构化剪枝，通常难以达到同等高的压缩比，且可能对模型性能影响更大，因为移除的是“一整块”。</li>
</ul>
</li>
</ol>
<h4 id="剪枝策略">剪枝策略</h4>
<p>如何决定哪些部分是“不重要”的？这是剪枝策略的关键：</p>
<ol>
<li>
<p><strong>基于幅度剪枝 (Magnitude-based Pruning)</strong>:</p>
<ul>
<li><strong>原理</strong>: 最简单直观的方法。认为绝对值较小的权重对模型输出影响小，可以移除。</li>
<li><strong>流程</strong>: 训练模型 -&gt; 设定阈值 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>τ</mi></mrow><annotation encoding="application/x-tex">\tau</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span></span></span></span> -&gt; 将所有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∣</mi><msub><mi>w</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><mo>&lt;</mo><mi>τ</mi></mrow><annotation encoding="application/x-tex">|w_i| &lt; \tau</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span></span></span></span> 的权重 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">w_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 设为0。</li>
<li><strong>简单但有效</strong>，是很多高级剪枝方法的基石。</li>
</ul>
</li>
<li>
<p><strong>基于敏感度剪枝 (Sensitivity-based Pruning)</strong>:</p>
<ul>
<li><strong>原理</strong>: 评估移除某个权重或结构对模型性能的影响。影响越小，该部分越不重要。</li>
<li><strong>流程</strong>: 训练模型 -&gt; 移除某个部分 -&gt; 评估性能下降 -&gt; 恢复 -&gt; 尝试移除下一个部分… 这是一个非常耗时的过程。</li>
</ul>
</li>
<li>
<p><strong>基于重要性分数剪枝 (Importance-score based Pruning)</strong>:</p>
<ul>
<li><strong>原理</strong>: 通过计算一个“重要性分数”来衡量每个参数或结构的贡献。</li>
<li><strong>示例</strong>:
<ul>
<li><strong>SNIP/GraSP</strong>: 基于一次性梯度信息。</li>
<li><strong>IMP (Iterative Magnitude Pruning)</strong>: 迭代地剪枝和微调。</li>
<li><strong>Lottery Ticket Hypothesis (彩票假说)</strong>: 认为在随机初始化的网络中，存在一个“彩票”（即稀疏子网络），如果单独训练它，能达到与原始网络相同甚至更好的性能。其发现了一个剪枝-回溯-重训练的流程，证明了这种“彩票”的存在。
<ul>
<li>流程: 随机初始化 -&gt; 训练网络 -&gt; 剪枝 -&gt; 将剩余权重回溯到初始值 -&gt; 重新训练。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<h4 id="剪枝流程">剪枝流程</h4>
<p>典型的剪枝流程包括以下步骤：</p>
<ol>
<li><strong>预训练/训练</strong>: 首先训练一个完整的、大型的模型（教师模型，或待剪枝模型）。</li>
<li><strong>剪枝</strong>: 根据选定的策略（如基于幅度、结构化等）移除模型中的冗余部分。</li>
<li><strong>微调 (Fine-tuning)</strong>: 剪枝后的模型性能可能会下降，需要在一个小数据集上进行微调（或重新训练），以恢复甚至提升性能。</li>
</ol>
<p>对于Transformer模型，剪枝可以应用于：</p>
<ul>
<li><strong>注意力头剪枝</strong>: 移除整个注意力头。研究表明，某些注意力头是冗余的。</li>
<li><strong>隐藏层神经元剪枝</strong>: 移除全连接层中的特定神经元。</li>
<li><strong>层剪枝</strong>: 移除整个Transformer编码器或解码器层。</li>
</ul>
<h4 id="数学表示">数学表示</h4>
<p>剪枝可以被看作是对模型参数应用一个二值掩码 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span>，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>M</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>∈</mo><mo stretchy="false">{</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">M_{ij} \in \{0, 1\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose">}</span></span></span></span>。</p>
<p>原始模型的损失函数为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>o</mi><mi>r</mi><mi>i</mi><mi>g</mi><mi>i</mi><mi>n</mi><mi>a</mi><mi>l</mi></mrow></msub><mo stretchy="false">(</mo><mi>W</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L_{original}(W)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">or</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span><span class="mord mathnormal mtight">ina</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mclose">)</span></span></span></span>，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span></span></span> 是模型权重。剪枝后的模型损失函数可以表示为：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>L</mi><mrow><mi>p</mi><mi>r</mi><mi>u</mi><mi>n</mi><mi>e</mi></mrow></msub><mo stretchy="false">(</mo><mi>W</mi><mo separator="true">,</mo><mi>M</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi>L</mi><mrow><mi>o</mi><mi>r</mi><mi>i</mi><mi>g</mi><mi>i</mi><mi>n</mi><mi>a</mi><mi>l</mi></mrow></msub><mo stretchy="false">(</mo><mi>W</mi><mo>⊙</mo><mi>M</mi><mo stretchy="false">)</mo><mo>+</mo><mi>λ</mi><munder><mo>∑</mo><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></munder><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msub><mi>M</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L_{prune}(W, M) = L_{original}(W \odot M) + \lambda \sum_{i,j} (1 - M_{ij}) 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">or</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span><span class="mord mathnormal mtight">ina</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⊙</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:2.4638em;vertical-align:-1.4138em;"></span><span class="mord mathnormal">λ</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4138em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
<p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⊙</mo></mrow><annotation encoding="application/x-tex">\odot</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord">⊙</span></span></span></span> 表示逐元素乘法，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msub><mi>M</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(1 - M_{ij})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 表示被剪枝的参数，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">λ</span></span></span></span> 是正则化项，鼓励更多的参数被剪枝。在实际应用中，通常是通过阈值设定来直接修改 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span></span></span>。</p>
<h4 id="概念性代码示例-PyTorch-风格">概念性代码示例 (PyTorch 风格)</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.utils.prune <span class="keyword">as</span> prune</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设这是一个简单的线性层</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.linear1 = nn.Linear(<span class="number">10</span>, <span class="number">5</span>)</span><br><span class="line">        <span class="variable language_">self</span>.relu = nn.ReLU()</span><br><span class="line">        <span class="variable language_">self</span>.linear2 = nn.Linear(<span class="number">5</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.linear2(<span class="variable language_">self</span>.relu(<span class="variable language_">self</span>.linear1(x)))</span><br><span class="line"></span><br><span class="line">model = SimpleModel()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;原始模型参数:&quot;</span>, <span class="built_in">sum</span>(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters()))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对linear1层进行非结构化剪枝，剪掉50%的权重</span></span><br><span class="line"><span class="comment"># prune.random_unstructured 也可以换成 prune.L1Unstructured (基于L1范数)</span></span><br><span class="line">prune.random_unstructured(model.linear1, name=<span class="string">&quot;weight&quot;</span>, amount=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以查看剪枝后的模块</span></span><br><span class="line"><span class="comment"># model.linear1.weight_mask 是剪枝操作生成的掩码</span></span><br><span class="line"><span class="comment"># model.linear1.weight_orig 是原始权重</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;剪枝后的linear1层:&quot;</span>, model.linear1.weight)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;剪枝掩码:&quot;</span>, model.linear1.weight_mask)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 永久移除剪枝操作创建的参数和缓冲区</span></span><br><span class="line"><span class="comment"># 否则模型仍然占用原始空间，只是计算时零值不参与</span></span><br><span class="line">prune.remove(model.linear1, <span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;永久移除剪枝参数后的linear1层:&quot;</span>, model.linear1.weight)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;剪枝后的模型参数 (仅统计非零权重，但实际上内存未立即释放):&quot;</span>, <span class="built_in">sum</span>(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters()))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意：实际内存和计算量减少需要硬件和框架支持稀疏计算，或者进行结构化剪枝。</span></span><br><span class="line"><span class="comment"># 结构化剪枝示例：</span></span><br><span class="line"><span class="comment"># prune.remove(model.linear1, &#x27;weight&#x27;) # 移除之前的剪枝</span></span><br><span class="line"><span class="comment"># prune.ln_structured(model.linear1, name=&quot;weight&quot;, amount=0.5, n=2, dim=0) # 按行剪枝50%</span></span><br><span class="line"><span class="comment"># print(&quot;结构化剪枝后的linear1层:&quot;, model.linear1.weight)</span></span><br></pre></td></tr></table></figure>
<h3 id="2-量化-Quantization">2. 量化 (Quantization)</h3>
<p>量化是一种将模型参数和/或激活值的浮点数表示转换为低比特（如8位、4位甚至1位）整数表示的技术。</p>
<h4 id="原理-2">原理</h4>
<p>现代神经网络通常使用32位浮点数（FP32）来表示权重和激活值。量化的核心思想是：在很多情况下，这种高精度是不必要的，我们可以用更少的比特来近似表示这些数值，同时保持模型性能。这不仅可以显著减少模型大小，还能利用整数运算的效率，从而加速推理。</p>
<h4 id="优点">优点</h4>
<ul>
<li><strong>模型大小显著减小</strong>: 例如，从FP32到INT8，模型大小可以减少4倍。</li>
<li><strong>推理速度提升</strong>: 整数运算比浮点运算更快，且消耗更少能量。许多硬件（如CPU、NPU、DSP）都针对INT8运算进行了优化。</li>
<li><strong>能耗降低</strong>: 更少的内存访问和更快的计算意味着更低的能耗。</li>
</ul>
<h4 id="类型-2">类型</h4>
<ol>
<li>
<p><strong>训练后量化 (Post-Training Quantization, PTQ)</strong>:</p>
<ul>
<li><strong>原理</strong>: 模型在训练完成后，直接将FP32参数转换为低比特整数。</li>
<li><strong>优点</strong>: 实现简单，不需要重新训练或微调。</li>
<li><strong>缺点</strong>: 转换过程可能导致较大的性能下降，尤其是在对精度敏感的任务上。需要使用校准数据集来确定量化范围和缩放因子。</li>
<li><strong>子类型</strong>:
<ul>
<li><strong>动态量化</strong>: 权重在推理前被量化，但激活值在运行时根据其动态范围进行量化。适合CPU。</li>
<li><strong>静态量化</strong>: 权重和激活值都被提前量化，需要一个代表性数据集来校准激活值的范围。性能通常优于动态量化，适合GPU/NPU。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>量化感知训练 (Quantization-Aware Training, QAT)</strong>:</p>
<ul>
<li><strong>原理</strong>: 在训练过程中模拟量化操作的影响，使模型“感知”到量化的存在。通过在前向传播中插入伪量化操作，并在反向传播中应用特殊的梯度处理（如直通估计器 Straight-Through Estimator, STE），使模型在训练时就适应量化误差。</li>
<li><strong>优点</strong>: 性能通常显著优于PTQ，能够最大限度地减少量化造成的精度损失。</li>
<li><strong>缺点</strong>: 需要修改训练流程，增加训练复杂性，训练时间可能延长。</li>
</ul>
</li>
</ol>
<h4 id="量化策略">量化策略</h4>
<ul>
<li><strong>对称量化 vs. 非对称量化</strong>:
<ul>
<li><strong>对称量化</strong>: 将浮点范围 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mo>−</mo><mtext>abs_max</mtext><mo separator="true">,</mo><mtext>abs_max</mtext><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[-\text{abs\_max}, \text{abs\_max}]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mopen">[</span><span class="mord">−</span><span class="mord text"><span class="mord">abs_max</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord text"><span class="mord">abs_max</span></span><span class="mclose">]</span></span></span></span> 映射到整数范围 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mo>−</mo><msup><mn>2</mn><mrow><mi>B</mi><mo>−</mo><mn>1</mn></mrow></msup><mo>+</mo><mn>1</mn><mo separator="true">,</mo><msup><mn>2</mn><mrow><mi>B</mi><mo>−</mo><mn>1</mn></mrow></msup><mo>−</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[-2^{B-1}+1, 2^{B-1}-1]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0913em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">−</span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0358em;vertical-align:-0.1944em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">]</span></span></span></span>（或 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mo>−</mo><msup><mn>2</mn><mrow><mi>B</mi><mo>−</mo><mn>1</mn></mrow></msup><mo separator="true">,</mo><msup><mn>2</mn><mrow><mi>B</mi><mo>−</mo><mn>1</mn></mrow></msup><mo>−</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[-2^{B-1}, 2^{B-1}-1]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0913em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">−</span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">]</span></span></span></span>），零点始终为0。</li>
<li><strong>非对称量化</strong>: 将浮点范围 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mtext>min_val</mtext><mo separator="true">,</mo><mtext>max_val</mtext><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[\text{min\_val}, \text{max\_val}]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mopen">[</span><span class="mord text"><span class="mord">min_val</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord text"><span class="mord">max_val</span></span><span class="mclose">]</span></span></span></span> 映射到整数范围 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><msup><mn>2</mn><mi>B</mi></msup><mo>−</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[0, 2^B-1]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0913em;vertical-align:-0.25em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">]</span></span></span></span>，需要计算一个零点。非对称量化通常更灵活，能够更好地覆盖非对称的浮点数分布。</li>
</ul>
</li>
<li><strong>逐层量化 vs. 逐通道量化</strong>:
<ul>
<li><strong>逐层量化</strong>: 对整个层的权重使用相同的量化参数。</li>
<li><strong>逐通道量化</strong>: 对每个输出通道的权重使用独立的量化参数。通常性能更好，但需要更多存储空间来存储量化参数。</li>
</ul>
</li>
</ul>
<h4 id="数学表示-2">数学表示</h4>
<p>量化过程通常涉及一个缩放因子 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span> 和一个零点 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span></span></span></span>（用于非对称量化）。</p>
<p>浮点数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span></span></span></span> 量化为整数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span></span></span></span> 的公式：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>q</mi><mo>=</mo><mtext>round</mtext><mo stretchy="false">(</mo><mi>r</mi><mi mathvariant="normal">/</mi><mi>S</mi><mo>+</mo><mi>Z</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">q = \text{round}(r/S + Z) 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">round</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mclose">)</span></span></span></span></span></p>
<p>反量化（将整数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi></mrow><annotation encoding="application/x-tex">q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span></span></span></span> 转换为近似的浮点数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mrow><mi>q</mi><mi>u</mi><mi>a</mi><mi>n</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">r_{quant}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">an</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>）：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>r</mi><mrow><mi>q</mi><mi>u</mi><mi>a</mi><mi>n</mi><mi>t</mi></mrow></msub><mo>=</mo><mo stretchy="false">(</mo><mi>q</mi><mo>−</mo><mi>Z</mi><mo stretchy="false">)</mo><mo>⋅</mo><mi>S</mi></mrow><annotation encoding="application/x-tex">r_{quant} = (q - Z) \cdot S 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">an</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span></span></p>
<p>对于INT8量化，通常 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>=</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">B=8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">8</span></span></span></span>。<br>
缩放因子 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span> 的计算方式：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>S</mi><mo>=</mo><mfrac><mrow><mtext>max_val</mtext><mo>−</mo><mtext>min_val</mtext></mrow><mrow><msup><mn>2</mn><mi>B</mi></msup><mo>−</mo><mn>1</mn></mrow></mfrac></mrow><annotation encoding="application/x-tex">S = \frac{\text{max\_val} - \text{min\_val}}{2^B - 1} 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.1638em;vertical-align:-0.7693em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3944em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7673em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">1</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.7em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">max_val</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord text"><span class="mord">min_val</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>零点 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi></mrow><annotation encoding="application/x-tex">Z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span></span></span></span> 的计算方式：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>Z</mi><mo>=</mo><mtext>round</mtext><mo stretchy="false">(</mo><mo>−</mo><mtext>min_val</mtext><mi mathvariant="normal">/</mi><mi>S</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Z = \text{round}(-\text{min\_val} / S) 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord text"><span class="mord">round</span></span><span class="mopen">(</span><span class="mord">−</span><span class="mord text"><span class="mord">min_val</span></span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mclose">)</span></span></span></span></span></p>
<p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>max_val</mtext></mrow><annotation encoding="application/x-tex">\text{max\_val}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-0.31em;"></span><span class="mord text"><span class="mord">max_val</span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>min_val</mtext></mrow><annotation encoding="application/x-tex">\text{min\_val}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-0.31em;"></span><span class="mord text"><span class="mord">min_val</span></span></span></span></span> 是浮点数的最大值和最小值。</p>
<h4 id="概念性代码示例-PyTorch-Quantization-Aware-Training-风格">概念性代码示例 (PyTorch Quantization-Aware Training 风格)</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.quantization <span class="keyword">import</span> get_default_qconfig, quantize_jit_script, prepare, convert</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设一个简单的Conv-ReLU-Linear模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleQuantModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv = nn.Conv2d(<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">        <span class="variable language_">self</span>.relu = nn.ReLU()</span><br><span class="line">        <span class="variable language_">self</span>.fc = nn.Linear(<span class="number">3</span>*<span class="number">3</span>, <span class="number">2</span>) <span class="comment"># 假设输入是5x5，经过conv后是3x3</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.conv(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.relu(x)</span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">3</span>*<span class="number">3</span>) <span class="comment"># 展平</span></span><br><span class="line">        x = <span class="variable language_">self</span>.fc(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 创建模型实例</span></span><br><span class="line">model_fp32 = SimpleQuantModel()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 设置量化配置 (通常是QAT)</span></span><br><span class="line"><span class="comment"># &#x27;fbgemm&#x27; 用于服务器端CPU (x86), &#x27;qnnpack&#x27; 用于移动端CPU (ARM)</span></span><br><span class="line">qconfig = get_default_qconfig(<span class="string">&#x27;fbgemm&#x27;</span>)</span><br><span class="line">model_fp32.qconfig = qconfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 准备模型进行QAT: 插入观察器 (Observers) 和伪量化模块 (FakeQuantization)</span></span><br><span class="line"><span class="comment"># Observers 会在训练过程中收集激活值的统计信息 (min/max)</span></span><br><span class="line"><span class="comment"># FakeQuantization 模块会在训练时模拟量化和反量化操作</span></span><br><span class="line">model_prepared = prepare(model_fp32, inplace=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 模拟训练/校准过程</span></span><br><span class="line"><span class="comment"># 在真实场景中，这里会进行模型训练或在校准数据集上进行前向传播</span></span><br><span class="line"><span class="comment"># 伪代码：</span></span><br><span class="line"><span class="comment"># for inputs, labels in calibration_dataloader:</span></span><br><span class="line"><span class="comment">#     model_prepared(inputs)</span></span><br><span class="line"><span class="comment"># for epoch in range(num_qat_epochs):</span></span><br><span class="line"><span class="comment">#     for inputs, labels in training_dataloader:</span></span><br><span class="line"><span class="comment">#         outputs = model_prepared(inputs)</span></span><br><span class="line"><span class="comment">#         loss = criterion(outputs, labels)</span></span><br><span class="line"><span class="comment">#         loss.backward()</span></span><br><span class="line"><span class="comment">#         optimizer.step()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里我们简单地进行一次前向传播来收集统计信息</span></span><br><span class="line">dummy_input = torch.randn(<span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>)</span><br><span class="line">model_prepared(dummy_input)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;量化准备后的模型:&quot;</span>, model_prepared)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 转换模型: 将FP32模块替换为量化后的INT8模块</span></span><br><span class="line">model_int8 = convert(model_prepared)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;量化后的模型:&quot;</span>, model_int8)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以看到 Conv2d 被替换成了 QuantizedConv2d, Linear 被替换成了 QuantizedLinear</span></span><br><span class="line"><span class="comment"># 模型的实际大小和推理速度会有显著提升</span></span><br></pre></td></tr></table></figure>
<h3 id="3-知识蒸馏-Knowledge-Distillation">3. 知识蒸馏 (Knowledge Distillation)</h3>
<p>知识蒸馏是一种模型压缩技术，它通过让一个小型模型（学生模型）从一个大型、高性能的模型（教师模型）那里学习“知识”，从而在保持较小尺寸的同时，达到接近教师模型的性能。</p>
<h4 id="核心思想">核心思想</h4>
<p>传统的模型训练是让模型直接拟合真实标签（硬目标）。知识蒸馏则引入了一个额外的监督信号：教师模型的输出。教师模型的输出通常是Softmax层之后的概率分布（软目标），或者中间层的特征表示。这些软目标包含了比硬标签更丰富的类别间关系和不确定性信息，学生模型通过学习这些信息，能够更好地泛化。</p>
<h4 id="蒸馏类型">蒸馏类型</h4>
<ol>
<li>
<p><strong>基于软目标蒸馏 (Soft Target Distillation)</strong>:</p>
<ul>
<li><strong>原理</strong>: 这是Hinton等人2015年提出的经典蒸馏方法。学生模型不仅学习真实标签，还学习教师模型Softmax层输出的概率分布。</li>
<li><strong>软标签温度参数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span></strong>: 为了从教师模型的输出中提取更多信息，通常会引入一个“温度”参数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span>。当 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span> 增大时，Softmax输出的概率分布会变得更加“平滑”，即使是小概率的类别也会获得更高的概率值，从而暴露更多的类别间关系。
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mi>i</mi></msub><mo>=</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>z</mi><mi>i</mi></msub><mi mathvariant="normal">/</mi><mi>T</mi><mo stretchy="false">)</mo></mrow><mrow><msub><mo>∑</mo><mi>j</mi></msub><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>z</mi><mi>j</mi></msub><mi mathvariant="normal">/</mi><mi>T</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">P_i = \frac{\exp(z_i/T)}{\sum_j \exp(z_j/T)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.6772em;vertical-align:-0.6672em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1496em;"><span style="top:-2.1786em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4603em;"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.1952em;"></span><span class="mop mtight"><span class="mtight">e</span><span class="mtight">x</span><span class="mtight">p</span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.044em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em;"><span></span></span></span></span></span></span><span class="mord mtight">/</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mtight">e</span><span class="mtight">x</span><span class="mtight">p</span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.044em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mord mtight">/</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6672em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><br>
其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>z</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">z_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.044em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是Logits（Softmax输入）。</li>
</ul>
</li>
<li><strong>损失函数</strong>: 通常是真实标签的交叉熵损失与学生模型和教师模型软目标之间的KL散度损失的加权和。<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>L</mi><mrow><mi>t</mi><mi>o</mi><mi>t</mi><mi>a</mi><mi>l</mi></mrow></msub><mo>=</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>α</mi><mo stretchy="false">)</mo><msub><mi>L</mi><mrow><mi>C</mi><mi>E</mi></mrow></msub><mo stretchy="false">(</mo><mi>y</mi><mo separator="true">,</mo><msub><mi>S</mi><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mi>i</mi><mi>t</mi><mi>s</mi></mrow></msub><mo stretchy="false">)</mo><mo>+</mo><mi>α</mi><msub><mi>L</mi><mrow><mi>K</mi><mi>L</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>T</mi><mrow><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi></mrow></msub><mo separator="true">,</mo><msub><mi>S</mi><mrow><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L_{total} = (1-\alpha) L_{CE}(y, S_{logits}) + \alpha L_{KL}(T_{soft}, S_{soft}) 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">CE</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">so</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">so</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>
其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span> 是真实标签，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mi>i</mi><mi>t</mi><mi>s</mi></mrow></msub></mrow><annotation encoding="application/x-tex">S_{logits}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 是学生模型的Logits，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mrow><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">S_{soft}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">so</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mrow><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">T_{soft}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">so</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 分别是学生模型和教师模型经过温度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span> 处理后的Softmax输出。<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span> 是平衡两个损失项的超参数。KL散度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>D</mi><mrow><mi>K</mi><mi>L</mi></mrow></msub><mo stretchy="false">(</mo><mi>P</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi>Q</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mo>∑</mo><mi>i</mi></msub><mi>P</mi><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo><mi>log</mi><mo>⁡</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">D_{KL}(P||Q) = \sum_i P(i) \log \frac{P(i)}{Q(i)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mord">∣∣</span><span class="mord mathnormal">Q</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.53em;vertical-align:-0.52em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.162em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">Q</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">i</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>。</li>
</ul>
</li>
<li>
<p><strong>基于特征蒸馏 (Feature Distillation)</strong>:</p>
<ul>
<li><strong>原理</strong>: 学生模型通过学习教师模型的中间层特征表示来获得知识。这有助于学生模型学习到教师模型在不同抽象层次上的信息。</li>
<li><strong>损失函数</strong>: 通常是教师模型和学生模型相应中间层特征之间的L1或L2距离。<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>L</mi><mrow><mi>f</mi><mi>e</mi><mi>a</mi><mi>t</mi><mi>u</mi><mi>r</mi><mi>e</mi></mrow></msub><mo>=</mo><mi mathvariant="normal">∥</mi><msub><mi>F</mi><mi>T</mi></msub><mo>−</mo><msub><mi>F</mi><mi>S</mi></msub><msup><mi mathvariant="normal">∥</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">L_{feature} = \|F_T - F_S\|^2 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">re</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∥</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord">∥</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></p>
其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F</mi><mi>T</mi></msub></mrow><annotation encoding="application/x-tex">F_T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F</mi><mi>S</mi></msub></mrow><annotation encoding="application/x-tex">F_S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 分别是教师模型和学生模型的特征表示。可能需要引入线性变换来对齐特征维度。</li>
</ul>
</li>
<li>
<p><strong>基于关系蒸馏 (Relation Distillation)</strong>:</p>
<ul>
<li><strong>原理</strong>: 学习教师模型内部的关系知识，例如不同样本之间的相似性关系，或不同层/注意力头之间的关系。</li>
<li><strong>示例</strong>:
<ul>
<li><strong>CRD (Contrastive Representation Distillation)</strong>: 通过对比学习，使学生模型的特征表示与教师模型在正样本对上更相似，在负样本对上更不相似。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>基于注意力蒸馏 (Attention Distillation)</strong>:</p>
<ul>
<li><strong>原理</strong>: 尤其适用于Transformer模型。学生模型学习教师模型的注意力矩阵，因为注意力机制是Transformer捕捉词语间关系的关键。</li>
<li><strong>损失函数</strong>: 比较学生和教师模型在不同注意力头上的注意力权重。</li>
</ul>
</li>
</ol>
<h4 id="典型模型">典型模型</h4>
<ul>
<li><strong>DistilBERT</strong>: 最早将知识蒸馏应用于BERT，通过在预训练阶段对BERT进行蒸馏，训练出了一个更小、更快的模型，性能接近原始BERT。主要使用软目标蒸馏。</li>
<li><strong>TinyBERT</strong>: 更进一步，它将知识蒸馏应用于预训练和任务特定微调两个阶段，并且不仅蒸馏软目标，还蒸馏了Transformer层中的隐藏状态和注意力矩阵。</li>
<li><strong>MobileBERT</strong>: 针对移动设备优化，通过设计一种更窄但更深的Transformer架构，并在蒸馏时使用一个更大、更宽的教师模型进行多层、多粒度的蒸馏。</li>
</ul>
<h4 id="蒸馏的优势">蒸馏的优势</h4>
<ul>
<li><strong>性能接近</strong>: 学生模型通常能达到教师模型大部分的性能。</li>
<li><strong>灵活性</strong>: 可以与剪枝、量化等其他压缩技术结合使用，进一步提升压缩效果。</li>
<li><strong>适用于各种任务</strong>: 无论是预训练还是下游任务微调，蒸馏都可应用。</li>
</ul>
<h4 id="概念性代码示例-PyTorch-风格-2">概念性代码示例 (PyTorch 风格)</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设一个简单的教师模型和学生模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TeacherModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.linear1 = nn.Linear(<span class="number">10</span>, <span class="number">20</span>)</span><br><span class="line">        <span class="variable language_">self</span>.relu = nn.ReLU()</span><br><span class="line">        <span class="variable language_">self</span>.linear2 = nn.Linear(<span class="number">20</span>, <span class="number">5</span>) <span class="comment"># 5个类别</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.linear2(<span class="variable language_">self</span>.relu(<span class="variable language_">self</span>.linear1(x)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">StudentModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.linear1 = nn.Linear(<span class="number">10</span>, <span class="number">10</span>) <span class="comment"># 学生模型更小</span></span><br><span class="line">        <span class="variable language_">self</span>.relu = nn.ReLU()</span><br><span class="line">        <span class="variable language_">self</span>.linear2 = nn.Linear(<span class="number">10</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.linear2(<span class="variable language_">self</span>.relu(<span class="variable language_">self</span>.linear1(x)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例化模型</span></span><br><span class="line">teacher_model = TeacherModel()</span><br><span class="line">student_model = StudentModel()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设已经加载了预训练好的教师模型权重</span></span><br><span class="line"><span class="comment"># teacher_model.load_state_dict(torch.load(&#x27;teacher_weights.pth&#x27;))</span></span><br><span class="line">teacher_model.<span class="built_in">eval</span>() <span class="comment"># 教师模型在蒸馏时通常设置为评估模式</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义损失函数和优化器</span></span><br><span class="line">criterion_ce = nn.CrossEntropyLoss() <span class="comment"># 硬目标损失</span></span><br><span class="line">optimizer = torch.optim.Adam(student_model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 超参数</span></span><br><span class="line">temperature = <span class="number">2.0</span> <span class="comment"># 温度参数T</span></span><br><span class="line">alpha = <span class="number">0.5</span>       <span class="comment"># 硬目标损失和软目标损失的权重</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟训练循环</span></span><br><span class="line">num_epochs = <span class="number">10</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="comment"># 模拟数据批次 (input_data, true_labels)</span></span><br><span class="line">    <span class="comment"># 在实际中，input_data 和 true_labels 会来自 DataLoader</span></span><br><span class="line">    input_data = torch.randn(<span class="number">64</span>, <span class="number">10</span>) <span class="comment"># 批大小64，特征维度10</span></span><br><span class="line">    true_labels = torch.randint(<span class="number">0</span>, <span class="number">5</span>, (<span class="number">64</span>,)) <span class="comment"># 0-4之间的随机标签</span></span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 学生模型前向传播</span></span><br><span class="line">    student_logits = student_model(input_data)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 教师模型前向传播 (不计算梯度)</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        teacher_logits = teacher_model(input_data)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算硬目标损失 (标准交叉熵)</span></span><br><span class="line">    loss_hard = criterion_ce(student_logits, true_labels)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算软目标损失 (KL散度)</span></span><br><span class="line">    <span class="comment"># 学生模型和教师模型的软概率分布</span></span><br><span class="line">    student_soft_probs = F.softmax(student_logits / temperature, dim=<span class="number">1</span>)</span><br><span class="line">    teacher_soft_probs = F.softmax(teacher_logits / temperature, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># KL散度：D_KL(P || Q) = sum(P * log(P / Q))</span></span><br><span class="line">    <span class="comment"># PyTorch的kl_div函数接受log_softmax输入，因此我们需要对log_softmax(Q)进行处理</span></span><br><span class="line">    <span class="comment"># 或者直接使用 log_softmax + softmax + kl_div</span></span><br><span class="line">    <span class="comment"># F.kl_div 默认是平均每个元素的损失，我们希望是批次平均，所以用 reduce=&#x27;batchmean&#x27;</span></span><br><span class="line">    loss_soft = F.kl_div(F.log_softmax(student_logits / temperature, dim=<span class="number">1</span>),</span><br><span class="line">                         teacher_soft_probs,</span><br><span class="line">                         reduction=<span class="string">&#x27;batchmean&#x27;</span>) * (temperature ** <span class="number">2</span>)</span><br><span class="line">    <span class="comment"># 注意：根据Hinton的论文，KL散度需要乘以 T^2</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 总损失</span></span><br><span class="line">    total_loss = alpha * loss_soft + (<span class="number">1.</span> - alpha) * loss_hard</span><br><span class="line"></span><br><span class="line">    total_loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (epoch + <span class="number">1</span>) % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Epoch [<span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>], Total Loss: <span class="subst">&#123;total_loss.item():<span class="number">.4</span>f&#125;</span>, &quot;</span></span><br><span class="line">              <span class="string">f&quot;Hard Loss: <span class="subst">&#123;loss_hard.item():<span class="number">.4</span>f&#125;</span>, Soft Loss: <span class="subst">&#123;loss_soft.item():<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n蒸馏训练完成！学生模型已从教师模型中学习。&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="4-参数共享与矩阵分解-Parameter-Sharing-Matrix-Factorization">4. 参数共享与矩阵分解 (Parameter Sharing &amp; Matrix Factorization)</h3>
<p>这两种方法旨在从根本上减少模型中的独立参数数量。</p>
<h4 id="参数共享-Parameter-Sharing">参数共享 (Parameter Sharing)</h4>
<ul>
<li>
<p><strong>原理</strong>: 强制模型中的不同层或模块共享相同的参数。这显著减少了模型的总参数量，同时鼓励模型学习更通用的表示。</p>
</li>
<li>
<p><strong>典型应用</strong>:</p>
<ul>
<li><strong>ALBERT (A Lite BERT)</strong>: BERT的轻量级版本。它在Transformer编码器层之间共享参数，特别是所有层都共享相同的注意力参数和前馈网络参数。这使得ALBERT的参数量远小于BERT，但在一些任务上性能接近。</li>
<li><strong>Transformer-XL</strong>: 引入了循环机制，使得模型在处理长序列时可以重用过去计算的隐藏状态，并一定程度上共享参数。</li>
</ul>
</li>
<li>
<p><strong>优点</strong>: 极大减少模型参数，降低内存占用和过拟合风险。</p>
</li>
<li>
<p><strong>缺点</strong>: 可能导致模型表达能力下降，收敛速度变慢，训练难度增加。</p>
</li>
</ul>
<h4 id="矩阵分解-Matrix-Factorization-Low-Rank-Approximation">矩阵分解 (Matrix Factorization / Low-Rank Approximation)</h4>
<ul>
<li><strong>原理</strong>: 将大型权重矩阵分解为两个或更多个较小的矩阵的乘积，从而减少参数总量。</li>
<li><strong>数学表示</strong>: 假设我们有一个权重矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>m</mi><mo>×</mo><mi>n</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W \in \mathbb{R}^{m \times n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7713em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7713em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span></span></span></span></span>。我们可以将其近似分解为两个低秩矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>U</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>m</mi><mo>×</mo><mi>k</mi></mrow></msup></mrow><annotation encoding="application/x-tex">U \in \mathbb{R}^{m \times k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8491em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>k</mi><mo>×</mo><mi>n</mi></mrow></msup></mrow><annotation encoding="application/x-tex">V \in \mathbb{R}^{k \times n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8491em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span></span></span></span></span> 的乘积，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>≪</mo><mi>min</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>m</mi><mo separator="true">,</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">k \ll \min(m, n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≪</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">min</span><span class="mopen">(</span><span class="mord mathnormal">m</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">n</span><span class="mclose">)</span></span></span></span>。<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>W</mi><mo>≈</mo><mi>U</mi><msup><mi>V</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">W \approx U V^T 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8913em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span></span></p>
这样，原始矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span></span></span></span> 有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>×</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">m \times n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span> 个参数，而分解后只有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>×</mo><mi>k</mi><mo>+</mo><mi>k</mi><mo>×</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">m \times k + k \times n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span> 个参数。当 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> 远小于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo separator="true">,</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">m, n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">m</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">n</span></span></span></span> 时，参数量显著减少。</li>
<li><strong>应用</strong>:
<ul>
<li>可以将Transformer中的全连接层（如前馈网络中的大矩阵）替换为低秩近似。</li>
<li>在Adapter或LoRA等参数高效微调方法中，新引入的参数矩阵通常采用低秩分解来进一步减少参数量。</li>
</ul>
</li>
<li><strong>优点</strong>: 减少参数量，降低计算成本。</li>
<li><strong>缺点</strong>: 分解的秩 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> 需要仔细选择，过低的秩可能导致性能下降。</li>
</ul>
<h3 id="5-紧凑型架构设计-Efficient-Architecture-Design">5. 紧凑型架构设计 (Efficient Architecture Design)</h3>
<p>与上述在现有模型上进行压缩的方法不同，紧凑型架构设计是从零开始构建一个本身就更小、更高效的模型。</p>
<h4 id="原理-3">原理</h4>
<p>通过创新的网络结构设计，在保证性能的同时，从根本上减少模型的参数量和计算复杂度。这通常涉及到对传统神经网络模块的重新思考。</p>
<h4 id="代表性工作">代表性工作</h4>
<ol>
<li>
<p><strong>MobileNet / EfficientNet (计算机视觉领域启发)</strong>:</p>
<ul>
<li><strong>深度可分离卷积 (Depthwise Separable Convolution)</strong>: 将标准卷积分解为深度卷积（spatial filtering）和点卷积（pointwise convolution，1x1卷积用于通道混合）。显著减少了参数和计算量。</li>
<li>这些概念虽然源自CV，但其“模块化设计以提高效率”的思想对NLP的Transformer架构设计有启发。</li>
</ul>
</li>
<li>
<p><strong>Transformer架构的改进</strong>:</p>
<ul>
<li><strong>稀疏注意力 (Sparse Attention)</strong>: 传统Transformer的自注意力机制是二次复杂度的，即序列长度的平方 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>N</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>。稀疏注意力通过限制每个词只关注其局部上下文或特定的全局词，将复杂度降低到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>N</mi><mi>log</mi><mo>⁡</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N \log N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span> 或 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span>。
<ul>
<li><strong>Longformer</strong>: 采用滑动窗口注意力与全局注意力相结合。</li>
<li><strong>Reformer</strong>: 使用局部敏感哈希 (LSH) 来近似注意力计算。</li>
<li><strong>BigBird</strong>: 结合了局部、全局和随机注意力。</li>
</ul>
</li>
<li><strong>线性注意力 (Linear Attention)</strong>: 将注意力机制的复杂度从二次降低到线性，例如Performer模型。通过核函数方法近似Attention。
<ul>
<li><strong>公式</strong>: 传统的注意力是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>softmax</mtext><mo stretchy="false">(</mo><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup><mi mathvariant="normal">/</mi><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt><mo stretchy="false">)</mo><mi>V</mi></mrow><annotation encoding="application/x-tex">Attention(Q, K, V) = \text{softmax}(QK^T/\sqrt{d_k})V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">A</span><span class="mord mathnormal">tt</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1072em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord">/</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8572em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8172em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1828em;"><span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span>。线性注意力可以被表示为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mi>ϕ</mi><mo stretchy="false">(</mo><mi>Q</mi><mo stretchy="false">)</mo><mi>ϕ</mi><mo stretchy="false">(</mo><mi>K</mi><msup><mo stretchy="false">)</mo><mi>T</mi></msup><mi>V</mi></mrow><annotation encoding="application/x-tex">Attention(Q, K, V) = \phi(Q)\phi(K)^T V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">A</span><span class="mord mathnormal">tt</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0913em;vertical-align:-0.25em;"></span><span class="mord mathnormal">ϕ</span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mclose">)</span><span class="mord mathnormal">ϕ</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span>，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϕ</mi></mrow><annotation encoding="application/x-tex">\phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">ϕ</span></span></span></span> 是一个非线性映射，使得 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(QK^T)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0913em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 的显式计算可以避免，从而将计算复杂度从 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>N</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 降到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span>。</li>
</ul>
</li>
<li><strong>轻量级FFN</strong>: 改进Transformer块中的前馈网络。</li>
<li><strong>参数量更少的Transformer变体</strong>: 例如早期的一些轻量级BERT变体。</li>
</ul>
</li>
</ol>
<h4 id="优势">优势</h4>
<ul>
<li><strong>原生高效</strong>: 模型从一开始就设计为高效，可能比后期压缩更优。</li>
<li><strong>更强的泛化性</strong>: 设计合理的紧凑模型可能在不同任务上表现更稳定。</li>
</ul>
<h4 id="劣势">劣势</h4>
<ul>
<li><strong>设计难度</strong>: 寻找新的高效架构需要大量的实验和领域知识。</li>
<li><strong>研究阶段</strong>: 许多高效架构仍处于研究和探索阶段，尚未像标准Transformer那样广泛验证和普及。</li>
</ul>
<hr>
<h2 id="实践中的挑战与展望">实践中的挑战与展望</h2>
<p>尽管模型压缩技术取得了显著进展，但将这些技术应用于实际生产环境，并实现其最大潜力，仍面临诸多挑战。</p>
<h3 id="挑战">挑战</h3>
<ol>
<li><strong>性能下降与权衡</strong>: 这是一个永恒的矛盾。过度压缩几乎总会导致性能下降。如何在压缩比、推理速度和模型性能之间找到最佳平衡点，是工程师和研究人员需要反复权衡的问题。不同的应用场景对这些指标有不同的容忍度。</li>
<li><strong>硬件兼容性与生态</strong>: 某些压缩技术（尤其是量化）对底层硬件的指令集和加速器支持有严格要求。例如，INT8量化需要在支持INT8运算的芯片（如某些NPU、DSP、或特定的GPU核心）上才能发挥最大优势。缺乏统一的、易于使用的硬件-软件协同优化生态系统，使得部署变得复杂。</li>
<li><strong>通用性问题</strong>: 很多压缩方法可能在特定的任务或数据集上表现出色，但在其他任务上效果不佳。例如，在机器翻译上剪枝掉的某些注意力头，可能在问答任务中却是关键。这要求我们为每个具体应用场景定制压缩方案。</li>
<li><strong>自动化与工具链缺乏</strong>: 尽管有一些开源工具和库（如PyTorch Quantization, Hugging Face Optimum），但缺乏一个端到端、高度自动化、能够智能选择并组合不同压缩技术的通用工具链，这使得模型压缩的门槛依然较高。</li>
<li><strong>理论理解不足</strong>: 为什么某些剪枝策略有效？量化过程中信息是如何丢失和保留的？知识蒸馏的本质是什么？我们对这些现象的理论理解仍不够深入，这限制了我们设计更普适、更有效的压缩方法。</li>
</ol>
<h3 id="展望">展望</h3>
<p>面向未来，模型压缩与蒸馏领域将继续发展，以下几个方向值得关注：</p>
<ol>
<li><strong>更智能的自动化压缩</strong>: 结合AutoML的思想，开发能够自动探索、评估和组合不同压缩策略的框架。这包括自动决定剪枝比例、量化方案、蒸馏策略，甚至自动生成紧凑型架构。这将大大降低模型压缩的门槛。</li>
<li><strong>硬件-软件协同优化</strong>: 随着AI芯片的快速发展，针对特定硬件（如NPU、FPGA、甚至定制ASIC）进行深度定制的压缩算法和框架将成为趋势。未来的模型训练和部署将更加注重硬件的特性。</li>
<li><strong>多任务/多模态压缩</strong>: 现有研究多关注单任务PLM的压缩。未来将探索如何高效压缩能够处理多任务、多模态信息（如文本、图像、语音结合）的通用大型模型，这将面临更大的复杂性。</li>
<li><strong>可解释性与鲁棒性</strong>: 压缩模型在减小尺寸的同时，能否保持其原始模型的可解释性和鲁棒性？这是一个重要的研究方向。例如，剪枝是否会移除模型中对对抗攻击防御关键的神经元？</li>
<li><strong>Green AI与可持续发展</strong>: 模型压缩是实现“绿色AI”的关键路径之一。随着AI模型规模的不断膨胀，减少其能耗和碳排放将越来越重要。压缩技术将作为核心工具，推动AI技术向更加可持续的方向发展。</li>
<li><strong>与参数高效微调 (PEFT) 结合</strong>: PEFT技术（如LoRA, Adapter等）在微调阶段只更新模型参数的一小部分，极大地减少了存储和计算成本。将压缩（如剪枝、量化）与PEFT技术结合，有望在微调和推理阶段都实现极致的效率。</li>
</ol>
<hr>
<h2 id="结论">结论</h2>
<p>预训练语言模型的压缩与蒸馏，是当前人工智能领域一个充满活力且至关重要的研究方向。它不仅关系到AI技术能否更广泛地落地应用，触及移动设备、边缘计算等资源受限场景，更关乎AI技术的可持续发展。</p>
<p>从剪枝、量化、知识蒸馏到参数共享和紧凑型架构设计，我们看到了各种精妙的数学和工程方法，它们各有所长，也各有挑战。理解这些技术的核心原理，掌握它们的适用场景和局限性，是每一位希望深入AI领域的工程师和研究人员的必备技能。</p>
<p>未来，我们期待看到更加智能、通用、易用的压缩工具链，以及硬件与软件更紧密协同的优化方案。随着这些技术的不断成熟，大型预训练语言模型将不再是高高在上的“巨无霸”，而是能够普惠大众，服务于千行百业的“智能引擎”，让AI的星火，真正燎原。</p>
<p>感谢你与我一同完成这次深度探索。如果你有任何疑问或想分享你的见解，欢迎在评论区交流！我们下次再见！</p>
<hr>
<p>博主: qmwneb946</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a target="_blank" rel="noopener" href="https://github.com/qmwneb946">qmwneb946</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://qmwneb946.dpdns.org/2025/07/19/2025-07-19-202453/">https://qmwneb946.dpdns.org/2025/07/19/2025-07-19-202453/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://opensource.org/licenses/MIT" target="_blank">MIT License</a> 许可协议。转载请注明来源 <a href="https://qmwneb946.dpdns.org" target="_blank">qmwneb946 的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/2025/">2025</a><a class="post-meta__tags" href="/tags/%E6%95%B0%E5%AD%A6/">数学</a><a class="post-meta__tags" href="/tags/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8E%8B%E7%BC%A9%E4%B8%8E%E8%92%B8%E9%A6%8F/">预训练语言模型的压缩与蒸馏</a></div><div class="post-share"><div class="social-share" data-image="/img/icon.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/07/19/2025-07-19-202536/" title="毫米波通信：解密5G与未来网络的极速脉搏"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">毫米波通信：解密5G与未来网络的极速脉搏</div></div><div class="info-2"><div class="info-item-1">大家好，我是你们的老朋友qmwneb946，今天我们来聊一个既炙手可热又充满挑战的话题——毫米波通信。如果你对5G的“极速”和“超低时延”抱有无限憧憬，那么毫米波技术就是实现这些愿景的核心引擎之一。它不仅仅是通信技术的一次演进，更是一场突破物理极限的冒险，充满了工程师的智慧与辛劳。 在5G商用化的浪潮中，毫米波（mmWave）频段的利用是其区别于前代技术、实现Gbps甚至Tbps级传输速率的关键路径。然而，这条通往“光速”的道路并非坦途，它伴随着一系列严峻的物理与工程挑战。今天，就让我们一起深入探索毫米波通信的奥秘、优势、挑战，以及如何通过技术创新来克服这些挑战，最终勾勒出它在未来通信网络中的宏伟蓝图。 毫米波技术概述 要理解毫米波通信，我们首先得搞清楚它究竟是什么。 什么是毫米波？ 在电磁波谱中，频率范围在30 GHz到300 GHz之间的电磁波被称为毫米波。这个频率段对应的波长在1毫米到10毫米之间，因此得名“毫米波”。 与我们日常使用的2G、3G、4G以及部分5G Sub-6 GHz频段（低于6 GHz）相比，毫米波的频率要高得多。频率越高，波长越短，这带来了一系列独特的传...</div></div></div></a><a class="pagination-related" href="/2025/07/19/2025-07-19-202352/" title="穿越数据稀缺的迷雾：计算机视觉中的小样本学习方法"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">穿越数据稀缺的迷雾：计算机视觉中的小样本学习方法</div></div><div class="info-2"><div class="info-item-1">引言：当数据不再唾手可得 在深度学习的黄金时代，我们见证了人工智能在计算机视觉领域取得的里程碑式成就。从图像分类到目标检测，再到语义分割，每一次突破的背后，都离不开一个至关重要的因素：海量标注数据的支撑。ImageNet、COCO、Open Images等大型数据集的出现，为深度神经网络的“学习”提供了充足的养料，使得模型能够从数百万甚至上亿张图像中提炼出普适的特征表示。 然而，现实世界并非总是如此慷慨。在许多实际应用场景中，我们往往面临数据稀缺的困境：  医疗影像诊断： 某些罕见疾病的病例数据极为稀少，且标注需要专业医生耗费大量时间和精力。 工业缺陷检测： 新产品上市或生产线调整后，合格品和缺陷品的样本往往极不平衡，缺陷样本更是凤毛麟角。 机器人与自动化： 机器人需要快速适应全新的环境或物体，仅凭少量交互就能掌握新技能。 生物多样性保护： 对新发现物种的识别、追踪，往往只有少量照片或视频可供学习。 军事与安全： 针对特定威胁的识别，可能只有有限的样本甚至没有样本。  在这些场景下，传统深度学习模型因其“数据饥渴”的本质而显得束手无策。当每个类别只有几张甚至一张图片时，模型无法充...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/07/18/2025-07-18-082519/" title="增强现实与工业维修：一场效率革命"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">增强现实与工业维修：一场效率革命</div></div><div class="info-2"><div class="info-item-1">增强现实 (AR) 技术正以前所未有的速度改变着我们的生活，而其在工业维修领域的应用更是展现出了巨大的潜力。不再局限于科幻电影中的场景，AR 如今已成为提升维修效率、降低维护成本、提高安全性的强大工具。本文将深入探讨 AR 如何与工业维修相结合，并分析其背后的技术和未来发展趋势。 引言：传统工业维修的挑战 传统的工业维修往往面临着诸多挑战：  信息获取困难: 维修人员需要查阅大量的纸质文档、图纸和视频，耗时费力，容易出错。 培训成本高昂:  熟练技工的培养需要漫长的学习过程和大量的实践经验，成本高昂。 安全风险较高:  一些复杂的设备维修存在高风险，例如高压电、高温部件等，容易发生意外事故。 维修效率低下:  由于缺乏实时信息和有效的指导，维修时间往往较长，导致生产停机时间增加，损失巨大。  AR 如何改变工业维修的游戏规则 AR 技术通过将数字信息叠加到现实世界中，为工业维修提供了全新的解决方案： 远程专家指导 通过 AR 眼镜或平板电脑，现场维修人员可以与远程专家实时互动。专家可以通过 AR 系统看到现场设备的实时图像，并利用虚拟标注、3D 模型等工具进行远程指导，大大缩短了...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082652/" title="纳米材料在靶向药物中的革命性应用"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">纳米材料在靶向药物中的革命性应用</div></div><div class="info-2"><div class="info-item-1">近年来，癌症等重大疾病的治疗面临着巨大的挑战，传统的化疗药物往往毒性大、副作用强，难以实现精准治疗。而纳米技术的兴起为解决这一难题提供了新的思路，特别是纳米材料在靶向药物递送系统中的应用，正引发一场医学革命。本文将深入探讨纳米材料如何提升靶向药物的疗效，降低其毒副作用。 纳米材料的特性及其在药物递送中的优势 纳米材料，是指至少在一个维度上尺寸小于100纳米的材料。这种极小的尺寸赋予了它们许多独特的物理和化学性质，使其在药物递送领域具有显著优势： 增强的药物溶解度和稳定性 许多药物具有较低的溶解度，限制了其在体内的吸收和生物利用度。纳米载体，例如脂质体、聚合物纳米颗粒和无机纳米颗粒（如金纳米颗粒、氧化铁纳米颗粒），可以显著提高药物的溶解度和稳定性，延长其在体内的循环时间。例如，将抗癌药物负载在聚合物纳米颗粒中，可以保护药物免受降解，并提高其在肿瘤组织中的积累。 靶向药物递送 纳米材料可以通过表面修饰，例如结合特异性配体（如抗体、肽或小分子），实现对特定细胞或组织的靶向递送。这种靶向递送可以最大限度地减少药物对健康组织的毒性，并提高药物在靶标部位的浓度，从而增强治疗效果。例如，修饰有...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082925/" title="生物化学中的蛋白质折叠问题：一个复杂而迷人的计算挑战"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">生物化学中的蛋白质折叠问题：一个复杂而迷人的计算挑战</div></div><div class="info-2"><div class="info-item-1">生命，这奇妙的现象，其本质很大程度上取决于蛋白质的精确三维结构。蛋白质是由氨基酸链组成的长链分子，但仅仅是氨基酸序列并不能完全决定其功能。蛋白质必须折叠成特定的三维结构（构象），才能发挥其生物学功能，例如催化酶促反应、运输分子或构建细胞结构。  而这个折叠过程，就是著名的“蛋白质折叠问题”。 蛋白质折叠：从线性序列到三维结构 蛋白质的氨基酸序列由基因编码决定，这是一个线性的一维结构。然而，这些氨基酸链并非随机地盘踞在一起，而是会遵循特定的物理和化学原理，自发地折叠成独特的、功能性的三维结构。这个折叠过程涉及到多种相互作用，包括： 疏水相互作用 蛋白质内部的疏水氨基酸残基倾向于聚集在一起，远离水性环境，形成蛋白质的核心区域。而亲水性氨基酸残基则倾向于暴露在蛋白质的表面，与水分子相互作用。 静电相互作用 带电荷的氨基酸残基之间会发生静电吸引或排斥作用，影响蛋白质的折叠。 氢键 氢键在维持蛋白质二级结构（例如α螺旋和β折叠）中起着关键作用。 二硫键 某些氨基酸残基（例如半胱氨酸）之间可以形成二硫键，进一步稳定蛋白质的三维结构。 这些相互作用共同决定了蛋白质的最终构象，这是一个极其复杂的...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-092536/" title="CRISPR基因编辑：技术的奇迹与伦理的挑战"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">CRISPR基因编辑：技术的奇迹与伦理的挑战</div></div><div class="info-2"><div class="info-item-1">大家好！我是你们的技术和数学博主，今天我们要深入探讨一个既令人兴奋又充满争议的话题：CRISPR-Cas9基因编辑技术及其伦理挑战。CRISPR技术以其精准性和效率，为治疗遗传疾病、改良作物等领域带来了革命性的变革，但与此同时，它也引发了诸多伦理难题，需要我们认真思考和谨慎应对。 CRISPR技术：一把双刃剑 CRISPR-Cas9系统，简单来说，就是一种可以精确地“剪切和粘贴”DNA的工具。它源自细菌的天然防御机制，利用向导RNA（gRNA）引导Cas9酶到基因组中的特定位置，从而进行基因的敲除、插入或替换。其操作简便、成本低廉、效率高，使其成为基因编辑领域的“明星”技术。 CRISPR的工作原理 CRISPR系统的工作机制可以概括为以下几个步骤：  设计gRNA:  根据目标基因序列设计相应的gRNA，使其能够特异性地结合目标DNA序列。 Cas9酶的结合: gRNA引导Cas9酶到目标DNA序列。 DNA双链断裂: Cas9酶在目标位点切割DNA双链，形成双链断裂（DSB）。 DNA修复: 细胞利用非同源末端连接（NHEJ）或同源定向修复（HDR）机制修复DSB。NHEJ修...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-094115/" title="免疫学与癌症免疫疗法：一场人体内部的战争与和平"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">免疫学与癌症免疫疗法：一场人体内部的战争与和平</div></div><div class="info-2"><div class="info-item-1">免疫系统，人体精妙的防御机制，日夜不停地抵御着病毒、细菌和其他有害物质的入侵。然而，当这套系统出现故障，对自身细胞发起攻击，或者无法有效清除癌细胞时，疾病便会发生，其中最可怕的莫过于癌症。近年来，癌症免疫疗法异军突起，为癌症治疗带来了新的希望，让我们深入探索这场人体内部的战争与和平。 免疫系统：人体精妙的防御网络 我们的免疫系统由先天免疫和适应性免疫两大支柱组成。 先天免疫：第一道防线 先天免疫是人体抵御病原体的第一道防线，它包含物理屏障（例如皮肤和黏膜）、化学屏障（例如胃酸和酶）以及细胞介导的免疫反应，例如巨噬细胞和自然杀伤细胞（NK细胞）的吞噬和杀伤作用。这些细胞能够识别并清除被感染的细胞或癌细胞，但其特异性较低。 适应性免疫：精准打击 适应性免疫系统则更为精细，它具有特异性和记忆性。T细胞和B细胞是适应性免疫的主角。T细胞负责细胞介导的免疫，其中细胞毒性T细胞（CTL）能够特异性识别并杀死靶细胞，例如被病毒感染的细胞或癌细胞。B细胞则负责体液免疫，产生抗体，中和病原体或标记癌细胞以便清除。  抗原呈递细胞（APC），例如树突状细胞，在将抗原信息呈递给T细胞，启动适应性免疫反...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-094141/" title="生态学中的生物多样性保护：一个复杂系统工程的视角"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">生态学中的生物多样性保护：一个复杂系统工程的视角</div></div><div class="info-2"><div class="info-item-1">大家好！今天我们要深入探讨一个既充满挑战又至关重要的话题：生态学中的生物多样性保护。  这不仅是环境保护的基石，也与我们人类的福祉息息相关。对技术爱好者来说，这更像是一个巨大的、复杂的系统工程，充满了需要解决的优化问题和值得探索的算法。 生物多样性的价值：超越简单的物种数量 我们通常将生物多样性理解为物种数量的多样性。但实际上，它是一个多层次的概念，包括：  遗传多样性 (Genetic Diversity):  同一物种内基因组的差异性，这决定了物种的适应性和进化潜力。  想象一下，一个抗旱基因的缺失可能导致整个小麦品种在干旱年份面临灭绝的风险。 物种多样性 (Species Diversity):  不同物种的数量及其相对丰度。 这通常用Shannon多样性指数 (H=−∑i=1Spilog⁡2piH = -\sum_{i=1}^{S} p_i \log_2 p_iH=−∑i=1S​pi​log2​pi​) 来衡量，其中 pip_ipi​ 是第 iii 个物种的比例，SSS 是物种总数。  更高的Shannon指数表示更高的物种多样性。 生态系统多样性 (Ecosystem ...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">qmwneb946</div><div class="author-info-description">一个专注于技术分享的个人博客，涵盖编程、算法、系统设计等内容</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">290</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">294</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/qmwneb946"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/qmwneb946" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:qmwneb946@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">代码与远方，技术与生活交织的篇章。</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#PLM%E5%8E%8B%E7%BC%A9%E7%9A%84%E5%BF%85%E8%A6%81%E6%80%A7%E4%B8%8E%E6%8C%91%E6%88%98"><span class="toc-number">1.</span> <span class="toc-text">PLM压缩的必要性与挑战</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E5%8E%8B%E7%BC%A9%EF%BC%9F"><span class="toc-number">1.1.</span> <span class="toc-text">为什么需要压缩？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8E%8B%E7%BC%A9%E7%9A%84%E6%8C%91%E6%88%98"><span class="toc-number">1.2.</span> <span class="toc-text">压缩的挑战</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E5%8E%8B%E7%BC%A9%E6%8A%80%E6%9C%AF"><span class="toc-number">2.</span> <span class="toc-text">核心压缩技术</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D-Pruning"><span class="toc-number">2.1.</span> <span class="toc-text">1. 模型剪枝 (Pruning)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8E%9F%E7%90%86"><span class="toc-number">2.1.1.</span> <span class="toc-text">原理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%B1%BB%E5%9E%8B"><span class="toc-number">2.1.2.</span> <span class="toc-text">类型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%89%AA%E6%9E%9D%E7%AD%96%E7%95%A5"><span class="toc-number">2.1.3.</span> <span class="toc-text">剪枝策略</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%89%AA%E6%9E%9D%E6%B5%81%E7%A8%8B"><span class="toc-number">2.1.4.</span> <span class="toc-text">剪枝流程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E5%AD%A6%E8%A1%A8%E7%A4%BA"><span class="toc-number">2.1.5.</span> <span class="toc-text">数学表示</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A6%82%E5%BF%B5%E6%80%A7%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B-PyTorch-%E9%A3%8E%E6%A0%BC"><span class="toc-number">2.1.6.</span> <span class="toc-text">概念性代码示例 (PyTorch 风格)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E9%87%8F%E5%8C%96-Quantization"><span class="toc-number">2.2.</span> <span class="toc-text">2. 量化 (Quantization)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8E%9F%E7%90%86-2"><span class="toc-number">2.2.1.</span> <span class="toc-text">原理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%98%E7%82%B9"><span class="toc-number">2.2.2.</span> <span class="toc-text">优点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%B1%BB%E5%9E%8B-2"><span class="toc-number">2.2.3.</span> <span class="toc-text">类型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%87%8F%E5%8C%96%E7%AD%96%E7%95%A5"><span class="toc-number">2.2.4.</span> <span class="toc-text">量化策略</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E5%AD%A6%E8%A1%A8%E7%A4%BA-2"><span class="toc-number">2.2.5.</span> <span class="toc-text">数学表示</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A6%82%E5%BF%B5%E6%80%A7%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B-PyTorch-Quantization-Aware-Training-%E9%A3%8E%E6%A0%BC"><span class="toc-number">2.2.6.</span> <span class="toc-text">概念性代码示例 (PyTorch Quantization-Aware Training 风格)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F-Knowledge-Distillation"><span class="toc-number">2.3.</span> <span class="toc-text">3. 知识蒸馏 (Knowledge Distillation)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3"><span class="toc-number">2.3.1.</span> <span class="toc-text">核心思想</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%92%B8%E9%A6%8F%E7%B1%BB%E5%9E%8B"><span class="toc-number">2.3.2.</span> <span class="toc-text">蒸馏类型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B8%E5%9E%8B%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.3.3.</span> <span class="toc-text">典型模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%92%B8%E9%A6%8F%E7%9A%84%E4%BC%98%E5%8A%BF"><span class="toc-number">2.3.4.</span> <span class="toc-text">蒸馏的优势</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A6%82%E5%BF%B5%E6%80%A7%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B-PyTorch-%E9%A3%8E%E6%A0%BC-2"><span class="toc-number">2.3.5.</span> <span class="toc-text">概念性代码示例 (PyTorch 风格)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%8F%82%E6%95%B0%E5%85%B1%E4%BA%AB%E4%B8%8E%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3-Parameter-Sharing-Matrix-Factorization"><span class="toc-number">2.4.</span> <span class="toc-text">4. 参数共享与矩阵分解 (Parameter Sharing &amp; Matrix Factorization)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E5%85%B1%E4%BA%AB-Parameter-Sharing"><span class="toc-number">2.4.1.</span> <span class="toc-text">参数共享 (Parameter Sharing)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3-Matrix-Factorization-Low-Rank-Approximation"><span class="toc-number">2.4.2.</span> <span class="toc-text">矩阵分解 (Matrix Factorization &#x2F; Low-Rank Approximation)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E7%B4%A7%E5%87%91%E5%9E%8B%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1-Efficient-Architecture-Design"><span class="toc-number">2.5.</span> <span class="toc-text">5. 紧凑型架构设计 (Efficient Architecture Design)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8E%9F%E7%90%86-3"><span class="toc-number">2.5.1.</span> <span class="toc-text">原理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E8%A1%A8%E6%80%A7%E5%B7%A5%E4%BD%9C"><span class="toc-number">2.5.2.</span> <span class="toc-text">代表性工作</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%98%E5%8A%BF"><span class="toc-number">2.5.3.</span> <span class="toc-text">优势</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8A%A3%E5%8A%BF"><span class="toc-number">2.5.4.</span> <span class="toc-text">劣势</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E8%B7%B5%E4%B8%AD%E7%9A%84%E6%8C%91%E6%88%98%E4%B8%8E%E5%B1%95%E6%9C%9B"><span class="toc-number">3.</span> <span class="toc-text">实践中的挑战与展望</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%91%E6%88%98"><span class="toc-number">3.1.</span> <span class="toc-text">挑战</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B1%95%E6%9C%9B"><span class="toc-number">3.2.</span> <span class="toc-text">展望</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA"><span class="toc-number">4.</span> <span class="toc-text">结论</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/20/hello-world/" title="Hello World">Hello World</a><time datetime="2025-07-20T15:19:27.002Z" title="发表于 2025-07-20 23:19:27">2025-07-20</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/20/2025-07-20-151852/" title="构建混合云管理平台：驾驭多云复杂性的核心利器">构建混合云管理平台：驾驭多云复杂性的核心利器</a><time datetime="2025-07-20T07:18:52.000Z" title="发表于 2025-07-20 15:18:52">2025-07-20</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/20/2025-07-20-145307/" title="区块链与供应链金融的交响曲：一次深度技术与商业的融合之旅">区块链与供应链金融的交响曲：一次深度技术与商业的融合之旅</a><time datetime="2025-07-20T06:53:07.000Z" title="发表于 2025-07-20 14:53:07">2025-07-20</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/20/2025-07-20-141645/" title="可信人工智能的评估标准：构建人机协作的信任基石">可信人工智能的评估标准：构建人机协作的信任基石</a><time datetime="2025-07-20T06:16:45.000Z" title="发表于 2025-07-20 14:16:45">2025-07-20</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/20/2025-07-20-135441/" title="深度学习在推荐系统中的应用：从理论到实践的深度探索">深度学习在推荐系统中的应用：从理论到实践的深度探索</a><time datetime="2025-07-20T05:54:41.000Z" title="发表于 2025-07-20 13:54:41">2025-07-20</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;2025 By qmwneb946</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.2</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css')
    if (true) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const getGiscusTheme = theme => theme === 'dark' ? 'dark' : 'light'

  const createScriptElement = config => {
    const ele = document.createElement('script')
    Object.entries(config).forEach(([key, value]) => {
      ele.setAttribute(key, value)
    })
    return ele
  }

  const loadGiscus = (el = document, key) => {
    const mappingConfig = isShuoshuo
      ? { 'data-mapping': 'specific', 'data-term': key }
      : { 'data-mapping': (option && option['data-mapping']) || 'pathname' }

    const giscusConfig = {
      src: 'https://giscus.app/client.js',
      'data-repo': 'qmwneb946/blog',
      'data-repo-id': 'R_kgDOPM6cWw',
      'data-category-id': 'DIC_kwDOPM6cW84CtEzo',
      'data-theme': getGiscusTheme(document.documentElement.getAttribute('data-theme')),
      'data-reactions-enabled': '1',
      crossorigin: 'anonymous',
      async: true,
      ...option,
      ...mappingConfig
    }

    const scriptElement = createScriptElement(giscusConfig)

    el.querySelector('#giscus-wrap').appendChild(scriptElement)

    if (isShuoshuo) {
      window.shuoshuoComment.destroyGiscus = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }
  }

  const changeGiscusTheme = theme => {
    const iframe = document.querySelector('#giscus-wrap iframe')
    if (iframe) {
      const message = {
        giscus: {
          setConfig: {
            theme: getGiscusTheme(theme)
          }
        }
      }
      iframe.contentWindow.postMessage(message, 'https://giscus.app')
    }
  }

  btf.addGlobalFn('themeChange', changeGiscusTheme, 'giscus')

  if (isShuoshuo) {
    'Giscus' === 'Giscus'
      ? window.shuoshuoComment = { loadComment: loadGiscus }
      : window.loadOtherComment = loadGiscus
    return
  }

  if ('Giscus' === 'Giscus' || !false) {
    if (false) btf.loadComment(document.getElementById('giscus-wrap'), loadGiscus)
    else loadGiscus()
  } else {
    window.loadOtherComment = loadGiscus
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>