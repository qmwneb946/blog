<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>重复博弈中的策略与均衡：时间如何改变决策的逻辑 | qmwneb946 的博客</title><meta name="author" content="qmwneb946"><meta name="copyright" content="qmwneb946"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="博主：qmwneb946  引言：超越一锤子买卖的智慧 在我们的日常生活中，无论是商业合作、国际关系、人际交往，乃至生物进化，很多时候我们都不是在与一个陌生人进行“一锤子买卖”。相反，我们常常会与相同的参与者反复互动，形成一种持续的、动态的关系。这种重复的互动，彻底改变了我们做决策的逻辑。一次性的背叛可能带来短期利益，但长期的声誉损失、潜在的惩罚，以及失去未来合作机会的代价，往往远超短期的诱惑。">
<meta property="og:type" content="article">
<meta property="og:title" content="重复博弈中的策略与均衡：时间如何改变决策的逻辑">
<meta property="og:url" content="https://qmwneb946.dpdns.org/2025/07/19/2025-07-19-124557/index.html">
<meta property="og:site_name" content="qmwneb946 的博客">
<meta property="og:description" content="博主：qmwneb946  引言：超越一锤子买卖的智慧 在我们的日常生活中，无论是商业合作、国际关系、人际交往，乃至生物进化，很多时候我们都不是在与一个陌生人进行“一锤子买卖”。相反，我们常常会与相同的参与者反复互动，形成一种持续的、动态的关系。这种重复的互动，彻底改变了我们做决策的逻辑。一次性的背叛可能带来短期利益，但长期的声誉损失、潜在的惩罚，以及失去未来合作机会的代价，往往远超短期的诱惑。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://qmwneb946.dpdns.org/img/icon.png">
<meta property="article:published_time" content="2025-07-19T04:45:57.000Z">
<meta property="article:modified_time" content="2025-07-23T15:28:31.411Z">
<meta property="article:author" content="qmwneb946">
<meta property="article:tag" content="科技前沿">
<meta property="article:tag" content="2025">
<meta property="article:tag" content="重复博弈中的策略与均衡">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://qmwneb946.dpdns.org/img/icon.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "重复博弈中的策略与均衡：时间如何改变决策的逻辑",
  "url": "https://qmwneb946.dpdns.org/2025/07/19/2025-07-19-124557/",
  "image": "https://qmwneb946.dpdns.org/img/icon.png",
  "datePublished": "2025-07-19T04:45:57.000Z",
  "dateModified": "2025-07-23T15:28:31.411Z",
  "author": [
    {
      "@type": "Person",
      "name": "qmwneb946",
      "url": "https://github.com/qmwneb946"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://qmwneb946.dpdns.org/2025/07/19/2025-07-19-124557/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '重复博弈中的策略与均衡：时间如何改变决策的逻辑',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2845632165165414" crossorigin="anonymous"></script><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="qmwneb946 的博客" type="application/atom+xml">
</head><body><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">qmwneb946 的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">重复博弈中的策略与均衡：时间如何改变决策的逻辑</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">重复博弈中的策略与均衡：时间如何改变决策的逻辑<a class="post-edit-link" href="https://github.com/qmwneb946/blog/edit/main/source/_posts/2025-07-19-124557.md" title="编辑" target="_blank"><i class="fas fa-pencil-alt"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-07-19T04:45:57.000Z" title="发表于 2025-07-19 12:45:57">2025-07-19</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-07-23T15:28:31.411Z" title="更新于 2025-07-23 23:28:31">2025-07-23</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%A7%91%E6%8A%80%E5%89%8D%E6%B2%BF/">科技前沿</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><p><strong>博主：qmwneb946</strong></p>
<hr>
<h3 id="引言：超越一锤子买卖的智慧">引言：超越一锤子买卖的智慧</h3>
<p>在我们的日常生活中，无论是商业合作、国际关系、人际交往，乃至生物进化，很多时候我们都不是在与一个陌生人进行“一锤子买卖”。相反，我们常常会与相同的参与者反复互动，形成一种持续的、动态的关系。这种重复的互动，彻底改变了我们做决策的逻辑。一次性的背叛可能带来短期利益，但长期的声誉损失、潜在的惩罚，以及失去未来合作机会的代价，往往远超短期的诱惑。</p>
<p>这里，我们将深入探讨一个迷人而又深刻的博弈论分支：<strong>重复博弈 (Repeated Games)</strong>。它不仅仅是关于如何在重复情境中玩游戏，更是关于时间、信任、惩罚、声誉以及未来对当下决策的影响。在重复博弈中，“未来之影”（the shadow of the future）是核心驱动力，它使得合作成为可能，即使在单次博弈中合作是不理性的。</p>
<p>作为一位对技术和数学充满热情的博主，我希望通过这篇文章，不仅能带你领略重复博弈的理论美感，更能窥见其在经济学、社会学、计算机科学乃至人工智能领域的广泛应用。我们将从基础概念出发，逐步深入到复杂的策略、核心定理，并辅以具体的案例分析和代码示例，力求为你呈现一个既严谨又生动的知识全景。</p>
<p>准备好了吗？让我们一起探索重复博弈的智慧世界。</p>
<hr>
<h3 id="第一部分：基础回顾与单次博弈的困境">第一部分：基础回顾与单次博弈的困境</h3>
<p>在深入重复博弈之前，我们有必要先回顾一下博弈论的基础，尤其是单次博弈中的核心概念，因为正是单次博弈的局限性，才催生了对重复博弈的研究需求。</p>
<h4 id="什么是博弈论？">什么是博弈论？</h4>
<p>博弈论 (Game Theory) 是研究在决策者之间互动过程中如何进行理性决策的数学工具。它假设所有参与者都是理性的，并且旨在最大化自身的收益。一个博弈通常由以下几个要素构成：</p>
<ul>
<li><strong>参与者 (Players)</strong>：参与决策的个体或实体。</li>
<li><strong>策略 (Strategies)</strong>：每个参与者在特定情境下可能采取的行动方案。</li>
<li><strong>收益 (Payoffs)</strong>：参与者在采取特定策略组合后所获得的结果或价值。</li>
<li><strong>信息 (Information)</strong>：参与者对博弈规则、其他参与者策略和收益的了解程度。</li>
</ul>
<p>根据博弈的特征，可以将其分为多种类型，例如：</p>
<ul>
<li><strong>合作博弈 (Cooperative Games)</strong> vs. <strong>非合作博弈 (Non-cooperative Games)</strong></li>
<li><strong>完全信息博弈 (Complete Information Games)</strong> vs. <strong>不完全信息博弈 (Incomplete Information Games)</strong></li>
<li><strong>静态博弈 (Static Games)</strong> vs. <strong>动态博弈 (Dynamic Games)</strong></li>
</ul>
<p>本文主要关注非合作、完全信息且动态的重复博弈。</p>
<h4 id="单次博弈的核心：纳什均衡">单次博弈的核心：纳什均衡</h4>
<p>在单次博弈中，最核心的均衡概念是<strong>纳什均衡 (Nash Equilibrium)</strong>。</p>
<p><strong>定义：</strong> 一组策略构成纳什均衡，当且仅当在给定其他参与者策略的情况下，没有任何一个参与者可以通过单方面改变自己的策略来提高自己的收益。换句话说，每个参与者的策略都是对其余参与者策略的最佳响应 (Best Response)。</p>
<p>让我们通过一个经典的例子来理解纳什均衡及其在单次博弈中的局限性：<strong>囚徒困境 (Prisoner’s Dilemma)</strong>。</p>
<p>假设两名嫌疑犯（A和B）因一项重罪被捕，分别关押审讯，无法交流。警方提供以下交易：</p>
<ul>
<li>如果A和B都选择<strong>坦白 (Confess, C)</strong>，则两人各判5年。</li>
<li>如果A坦白，B抵赖 (Defect, D)，A无罪释放（0年），B判10年。</li>
<li>如果A抵赖，B坦白，A判10年，B无罪释放（0年）。</li>
<li>如果A和B都选择<strong>抵赖 (Defess, D)</strong>，则两人各判1年（因证据不足，判轻罪）。</li>
</ul>
<p>我们可以将这个博弈的收益矩阵表示如下（收益为负，表示刑期）：</p>
<table>
<thead>
<tr>
<th style="text-align:left">A \ B</th>
<th style="text-align:left">坦白 ©</th>
<th style="text-align:left">抵赖 (D)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>坦白 ©</strong></td>
<td style="text-align:left">(-5, -5)</td>
<td style="text-align:left">(0, -10)</td>
</tr>
<tr>
<td style="text-align:left"><strong>抵赖 (D)</strong></td>
<td style="text-align:left">(-10, 0)</td>
<td style="text-align:left">(-1, -1)</td>
</tr>
</tbody>
</table>
<p>现在，让我们分析每个囚徒的理性选择：</p>
<ul>
<li><strong>对于囚徒A：</strong>
<ul>
<li>如果B坦白，A坦白判5年，A抵赖判10年。A会选择坦白。</li>
<li>如果B抵赖，A坦白判0年，A抵赖判1年。A会选择坦白。</li>
<li>因此，无论B选择什么，A的最佳策略都是坦白。坦白是A的<strong>严格优势策略 (Strictly Dominant Strategy)</strong>。</li>
</ul>
</li>
<li><strong>对于囚徒B：</strong>
<ul>
<li>同理，无论A选择什么，B的最佳策略也是坦白。坦白是B的严格优势策略。</li>
</ul>
</li>
</ul>
<p>所以，这个囚徒困境的唯一纳什均衡是**（坦白，坦白）**，两人都判5年。</p>
<p>然而，显而易见的是，如果A和B都选择<strong>抵赖</strong>，他们各判1年，这是一个对双方都更好的结果（帕累托最优）。但由于缺乏信任和沟通，且博弈只进行一次，理性的个体决策却导致了一个集体非最优的结果。这就是单次囚徒困境的困境所在。</p>
<p>那么，如果这个博弈不是一次性的，而是反复进行的呢？如果囚徒们知道他们未来还会相遇，他们的决策会发生改变吗？答案是肯定的，这就是重复博弈的魅力所在。</p>
<hr>
<h3 id="第二部分：重复博弈的魔力：“未来之影”">第二部分：重复博弈的魔力：“未来之影”</h3>
<p>重复博弈将单次博弈的思想延伸到多轮次互动中。它引入了时间维度，使得参与者能够通过建立声誉、实施惩罚或给予奖励来影响未来的互动，从而可能实现单次博弈中无法达到的合作。</p>
<h4 id="重复博弈的定义与分类">重复博弈的定义与分类</h4>
<p><strong>定义：</strong> 一个重复博弈是由一个被称为“阶段博弈 (Stage Game)”的静态博弈在多个时期（或轮次）内重复进行而形成的动态博弈。在每一轮结束后，参与者会观察到之前的行动结果，并根据这些信息决定下一轮的行动。</p>
<p>根据重复的次数，重复博弈主要分为两类：</p>
<ol>
<li><strong>有限次重复博弈 (Finitely Repeated Games)</strong>：阶段博弈重复特定次数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span> 次。例如，重复进行100次的囚徒困境。</li>
<li><strong>无限次重复博弈 (Infinitely Repeated Games)</strong>：阶段博弈重复无限次。虽然在现实中博弈不可能真正无限进行，但“无限”可以理解为参与者不知道博弈何时结束，或者结束的概率非常小，以至于未来收益的重要性远超短期收益。许多现实世界的长期关系（如国家间的贸易关系、企业间的长期合作）更适合用无限次重复博弈来建模。</li>
</ol>
<h4 id="“未来之影”：为什么重复很重要？">“未来之影”：为什么重复很重要？</h4>
<p>重复博弈的核心思想是“未来之影”——当前决策对未来结果的影响。正是因为这种影响，参与者有了动机去考虑长期利益，而不是仅仅追求眼前的短期最大化。</p>
<ul>
<li>
<p><strong>声誉与信任 (Reputation and Trust)</strong>：在重复博弈中，参与者可以通过持续的合作行为建立良好的声誉，从而赢得他人的信任，促成更多互利合作。反之，一次背叛可能会永久损害声誉。</p>
</li>
<li>
<p><strong>惩罚与奖励机制 (Punishment and Reward Mechanisms)</strong>：如果一名参与者在某一轮背叛，另一名参与者可以在未来的轮次中对其进行惩罚（如也选择背叛），从而降低背叛的吸引力。同样，持续的合作可以获得持续的奖励。</p>
</li>
<li>
<p><strong>贴现因子 (Discount Factor, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span></span></span></span>)</strong>：在重复博弈中，未来的收益往往不如现在的收益有价值。我们用<strong>贴现因子 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span></span></span></span></strong> (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>≤</mo><mi>δ</mi><mo>&lt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">0 \le \delta &lt; 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7804em;vertical-align:-0.136em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7335em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span>) 来衡量参与者对未来收益的重视程度。</p>
<ul>
<li>一个未来收益 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> 在当前时刻的价值是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi><mi>X</mi></mrow><annotation encoding="application/x-tex">\delta X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>。</li>
<li>更远的未来收益会被进一步贴现：下一轮是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span></span></span></span>，下两轮是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>δ</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\delta^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>，以此类推。</li>
<li>当 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span></span></span></span> 接近1时，参与者非常重视未来收益，这意味着未来之影很长。</li>
<li>当 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span></span></span></span> 接近0时，参与者几乎不重视未来收益，未来之影很短，博弈接近单次博弈。</li>
<li>无限次重复博弈中的总收益通常表示为未来各轮收益的加权和：<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>总收益</mtext><mo>=</mo><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>0</mn></mrow><mi mathvariant="normal">∞</mi></munderover><msup><mi>δ</mi><mi>t</mi></msup><msub><mi>P</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\text{总收益} = \sum_{t=0}^{\infty} \delta^t P_t 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord text"><span class="mord cjk_fallback">总收益</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.9185em;vertical-align:-1.2671em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6514em;"><span style="top:-1.8829em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∞</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8436em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>
其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">P_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em;"></span><span class="mord mathnormal">t</span></span></span></span> 轮的收益。</li>
</ul>
</li>
</ul>
<p>理解贴现因子对于分析重复博弈中的策略至关重要。一个策略是否是均衡，往往取决于参与者对未来收益的耐心程度（即 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span></span></span></span> 的大小）。</p>
<h4 id="均衡概念的扩展：子博弈完美纳什均衡">均衡概念的扩展：子博弈完美纳什均衡</h4>
<p>在动态博弈中，纳什均衡可能不够“强”，因为它允许包含“不可置信的威胁 (Non-credible Threats)”。例如，A威胁说如果B不合作，A会自残，这显然不是一个可信的威胁。为了剔除这些不可置信的威胁，我们需要一个更强的均衡概念：<strong>子博弈完美纳什均衡 (Subgame Perfect Nash Equilibrium, SPNE)</strong>。</p>
<p><strong>定义：</strong> 一组策略构成子博弈完美纳什均衡，当且仅当它在博弈的每一个子博弈中都构成纳什均衡。</p>
<p>在重复博弈中，每一次重复阶段博弈后的决策点都开启了一个新的子博弈。SPNE要求参与者的策略在博弈的任何一个可能的历史路径上，都始终是理性的。这意味着，无论之前发生了什么，参与者在当前决策点仍会选择对自己最有利的行动。</p>
<hr>
<h3 id="第三部分：合作策略：从朴素到复杂">第三部分：合作策略：从朴素到复杂</h3>
<p>重复博弈的精髓在于，即使在单次博弈中合作不是均衡，通过精心设计的策略，合作也能成为稳定的均衡结果。本节将介绍几种经典的重复博弈策略，并重点分析它们的逻辑和有效性。</p>
<h4 id="朴素策略">朴素策略</h4>
<p>在理解更复杂的策略之前，我们可以先看看几种最简单的策略：</p>
<ul>
<li><strong>永远合作 (Always Cooperate, AC)</strong>：无论对手做什么，我永远选择合作。这种策略在理想情况下能带来高收益，但在面对背叛者时非常脆弱。</li>
<li><strong>永远背叛 (Always Defect, AD)</strong>：无论对手做什么，我永远选择背叛。这种策略在单次博弈中是优势策略，但在重复博弈中可能导致双方都陷入低收益的循环。</li>
<li><strong>随机策略 (Random Strategy)</strong>：每一轮随机选择合作或背叛。这通常不是一个好的理性策略，因为它无法利用博弈的重复性。</li>
</ul>
<p>这些朴素策略通常无法在长期重复博弈中维持合作。为了实现并维持合作，我们需要能对对手行为做出响应的策略，尤其是那些能够惩罚背叛行为的策略。</p>
<h4 id="触发策略-Trigger-Strategies">触发策略 (Trigger Strategies)</h4>
<p>触发策略是一类关键的重复博弈策略。它们的共同特点是：在合作持续时保持合作，一旦观察到对手背叛，则“触发”某种惩罚机制。</p>
<h5 id="古板策略-Grim-Trigger-Strategy">古板策略 (Grim Trigger Strategy)</h5>
<p>古板策略是最严厉的触发策略之一，其逻辑简单粗暴但异常有效。</p>
<p><strong>定义：</strong></p>
<ol>
<li>在第一轮，选择合作。</li>
<li>在后续轮次，如果所有之前的轮次中，所有参与者都选择了合作，那么本轮继续选择合作。</li>
<li>如果之前任何一轮中，有任何一个参与者选择了背叛，那么本轮以及之后的所有轮次，永远选择背叛。</li>
</ol>
<p>古板策略的有效性在于其“一触即发，永不宽恕”的惩罚机制，这使得任何背叛的短期诱惑都显得微不足道。</p>
<p><strong>古板策略作为SPNE的条件分析</strong></p>
<p>我们以囚徒困境为例，来分析古板策略在何种条件下构成SPNE。<br>
假设囚徒困境的收益如下：</p>
<ul>
<li>R (Reward): 双方合作收益 (例如：3)</li>
<li>S (Sucker): 我方合作对方背叛的收益 (例如：0)</li>
<li>T (Temptation): 我方背叛对方合作的收益 (例如：5)</li>
<li>P (Punishment): 双方背叛收益 (例如：1)<br>
并且满足 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>&gt;</mo><mi>R</mi><mo>&gt;</mo><mi>P</mi><mo>&gt;</mo><mi>S</mi></mrow><annotation encoding="application/x-tex">T &gt; R &gt; P &gt; S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>R</mi><mo>&gt;</mo><mi>T</mi><mo>+</mo><mi>S</mi></mrow><annotation encoding="application/x-tex">2R &gt; T+S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord">2</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span> (使合作帕累托最优)。</li>
</ul>
<p>现在考虑一个参与者（比如玩家A）是否会从古板策略中偏离。</p>
<p><strong>情况1：当前处于合作路径上 (即双方一直合作)</strong></p>
<ul>
<li><strong>如果A继续合作：</strong> A将获得永久的合作收益流。<br>
A的总收益为：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>+</mo><mi>δ</mi><mi>R</mi><mo>+</mo><msup><mi>δ</mi><mn>2</mn></msup><mi>R</mi><mo>+</mo><mo>⋯</mo><mo>=</mo><mfrac><mi>R</mi><mrow><mn>1</mn><mo>−</mo><mi>δ</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">R + \delta R + \delta^2 R + \dots = \frac{R}{1-\delta}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8974em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.3669em;"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2757em;vertical-align:-0.4033em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.03785em;">δ</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></li>
<li><strong>如果A选择背叛：</strong> A在当前轮获得诱惑收益 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span>，但由于古板策略的触发，从下一轮开始，对手会永远背叛，双方都将获得惩罚收益 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span>。<br>
A的总收益为：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>+</mo><mi>δ</mi><mi>P</mi><mo>+</mo><msup><mi>δ</mi><mn>2</mn></msup><mi>P</mi><mo>+</mo><mo>⋯</mo><mo>=</mo><mi>T</mi><mo>+</mo><mfrac><mrow><mi>δ</mi><mi>P</mi></mrow><mrow><mn>1</mn><mo>−</mo><mi>δ</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">T + \delta P + \delta^2 P + \dots = T + \frac{\delta P}{1-\delta}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8974em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.3669em;"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.2834em;vertical-align:-0.4033em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.03785em;">δ</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03785em;">δ</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></li>
</ul>
<p>为了使古板策略是SPNE，A必须没有动机偏离，即合作的收益不小于背叛的收益：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mi>R</mi><mrow><mn>1</mn><mo>−</mo><mi>δ</mi></mrow></mfrac><mo>≥</mo><mi>T</mi><mo>+</mo><mfrac><mrow><mi>δ</mi><mi>P</mi></mrow><mrow><mn>1</mn><mo>−</mo><mi>δ</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{R}{1-\delta} \ge T + \frac{\delta P}{1-\delta} 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.1297em;vertical-align:-0.7693em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3603em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:2.1408em;vertical-align:-0.7693em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>移项整理，我们可以得到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span></span></span></span> 的临界值：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>R</mi><mo>≥</mo><mi>T</mi><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>δ</mi><mo stretchy="false">)</mo><mo>+</mo><mi>δ</mi><mi>P</mi></mrow><annotation encoding="application/x-tex">R \ge T(1-\delta) + \delta P 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8193em;vertical-align:-0.136em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>R</mi><mo>−</mo><mi>P</mi><mo>≥</mo><mi>T</mi><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>δ</mi><mo stretchy="false">)</mo><mo>−</mo><mi>δ</mi><mi>P</mi><mo>+</mo><mi>P</mi><mo>−</mo><mi>P</mi></mrow><annotation encoding="application/x-tex">R - P \ge T(1-\delta) - \delta P + P - P 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8193em;vertical-align:-0.136em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>R</mi><mo>−</mo><mi>P</mi><mo>≥</mo><mi>T</mi><mo>−</mo><mi>T</mi><mi>δ</mi><mo>+</mo><mi>δ</mi><mi>P</mi></mrow><annotation encoding="application/x-tex">R - P \ge T - T\delta + \delta P 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8193em;vertical-align:-0.136em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>T</mi><mi>δ</mi><mo>−</mo><mi>δ</mi><mi>P</mi><mo>≥</mo><mi>T</mi><mo>−</mo><mi>R</mi></mrow><annotation encoding="application/x-tex">T\delta - \delta P \ge T - R 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8304em;vertical-align:-0.136em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>δ</mi><mo stretchy="false">(</mo><mi>T</mi><mo>−</mo><mi>P</mi><mo stretchy="false">)</mo><mo>≥</mo><mi>T</mi><mo>−</mo><mi>R</mi></mrow><annotation encoding="application/x-tex">\delta(T - P) \ge T - R 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>δ</mi><mo>≥</mo><mfrac><mrow><mi>T</mi><mo>−</mo><mi>R</mi></mrow><mrow><mi>T</mi><mo>−</mo><mi>P</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\delta \ge \frac{T - R}{T - P} 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8304em;vertical-align:-0.136em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.1297em;vertical-align:-0.7693em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3603em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>这个条件表明，当贴现因子 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span></span></span></span> 足够大时（即未来足够重要），古板策略才能维持合作。如果 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span></span></span></span> 太小，短期背叛的诱惑 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>−</mo><mi>R</mi></mrow><annotation encoding="application/x-tex">T-R</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span> 就会超过未来惩罚 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>−</mo><mi>P</mi></mrow><annotation encoding="application/x-tex">T-P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> 的威慑力。</p>
<p><strong>情况2：当前处于惩罚路径上 (即之前有背叛发生，双方都选择背叛)</strong></p>
<p>在这种情况下，双方的策略都是永远背叛。</p>
<ul>
<li>如果A继续背叛：A获得 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo>+</mo><mi>δ</mi><mi>P</mi><mo>+</mo><msup><mi>δ</mi><mn>2</mn></msup><mi>P</mi><mo>+</mo><mo>⋯</mo><mo>=</mo><mfrac><mi>P</mi><mrow><mn>1</mn><mo>−</mo><mi>δ</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">P + \delta P + \delta^2 P + \dots = \frac{P}{1-\delta}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8974em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.3669em;"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2757em;vertical-align:-0.4033em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.03785em;">δ</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></li>
<li>如果A选择合作（偏离）：在当前轮，A获得 S (Sucker’s payoff)，而对手会继续背叛。从下一轮开始，双方仍然会背叛，因为对手的古板策略已经触发。<br>
A的总收益为：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo>+</mo><mi>δ</mi><mi>P</mi><mo>+</mo><msup><mi>δ</mi><mn>2</mn></msup><mi>P</mi><mo>+</mo><mo>⋯</mo><mo>=</mo><mi>S</mi><mo>+</mo><mfrac><mrow><mi>δ</mi><mi>P</mi></mrow><mrow><mn>1</mn><mo>−</mo><mi>δ</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">S + \delta P + \delta^2 P + \dots = S + \frac{\delta P}{1-\delta}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8974em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.3669em;"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.2834em;vertical-align:-0.4033em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.03785em;">δ</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03785em;">δ</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></li>
</ul>
<p>由于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo>&gt;</mo><mi>S</mi></mrow><annotation encoding="application/x-tex">P &gt; S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span></span></span></span>，A没有动机从背叛偏离到合作。因此，古板策略在惩罚路径上也是子博弈完美的。</p>
<p><strong>总结：</strong> 当 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi><mo>≥</mo><mfrac><mrow><mi>T</mi><mo>−</mo><mi>R</mi></mrow><mrow><mi>T</mi><mo>−</mo><mi>P</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\delta \ge \frac{T - R}{T - P}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8304em;vertical-align:-0.136em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2757em;vertical-align:-0.4033em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> 时，古板策略是囚徒困境的子博弈完美纳什均衡，可以维持合作。</p>
<h5 id="宽恕策略-Tit-for-Tat-TFT">宽恕策略 (Tit-for-Tat, TFT)</h5>
<p>相较于古板策略的严厉，宽恕策略 (或称“以牙还牙”策略) 则显得更为灵活和人性化。它是由阿纳托尔·拉波波特（Anatol Rapoport）提出，并在罗伯特·阿克塞尔罗德（Robert Axelrod）著名的计算机博弈竞赛中脱颖而出。</p>
<p><strong>定义：</strong></p>
<ol>
<li>在第一轮，选择合作。</li>
<li>在后续轮次，复制对手在上一轮的选择。如果对手上一轮合作，我本轮也合作；如果对手上一轮背叛，我本轮也背叛。</li>
</ol>
<p><strong>TFT的特点：</strong></p>
<ul>
<li><strong>善良 (Nice)</strong>：从不首先背叛。</li>
<li><strong>报复 (Retaliatory)</strong>：一旦被背叛，立即反击。</li>
<li><strong>宽恕 (Forgiving)</strong>：一旦对手重新合作，立即恢复合作。</li>
<li><strong>清晰 (Clear)</strong>：策略简单易懂。</li>
</ul>
<p><strong>阿克塞尔罗德的竞赛 (Axelrod’s Tournament)</strong><br>
1980年代，政治学家罗伯特·阿克塞尔罗德组织了一系列计算机模拟的囚徒困境比赛。他邀请世界各地的博弈论专家提交他们在重复囚徒困境中使用的策略程序。结果令人惊讶：最简单的<strong>宽恕策略 (TFT)</strong> 取得了最好的成绩。</p>
<p>TFT的成功在于：</p>
<ul>
<li>它能促进与合作者的长期合作。</li>
<li>它能惩罚背叛者，但不会陷入无休止的惩罚循环（因为它具有宽恕性）。</li>
<li>它足够简单，易于被对手理解，从而促进对手的合作。</li>
</ul>
<p>尽管TFT在许多场景下表现出色，但它也有局限性，例如在有噪声（即可能发生误判或随机错误）的环境中，TFT可能会导致双方陷入永无止境的背叛循环。例如，如果A合作，但因噪声B错误地“被观察到”背叛，则A下一轮会背叛，然后B也会背叛，循环往复。</p>
<h4 id="更复杂的策略">更复杂的策略</h4>
<p>除了古板策略和TFT，还有许多其他策略被提出和研究，例如：</p>
<ul>
<li><strong>Win-Stay, Lose-Shift (WSLS)</strong>：如果上一轮表现良好（赢了），则保持当前策略；如果表现不好（输了），则改变策略。这种策略在有噪声的环境中可能比TFT表现更好，因为它不会对一次误判的背叛做出持续的报复。</li>
<li><strong>适应性策略 (Adaptive Strategies)</strong>：根据对手的行为模式动态调整自身策略，例如通过机器学习算法预测对手的下一步行动。</li>
</ul>
<h4 id="代码示例：囚徒困境模拟">代码示例：囚徒困境模拟</h4>
<p>为了更好地理解这些策略的运作方式，让我们用Python实现一个简单的重复囚徒困境模拟器。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 囚徒困境的收益矩阵 (Player 1, Player 2)</span></span><br><span class="line"><span class="comment"># Row Player (Player 1) chooses rows, Column Player (Player 2) chooses columns</span></span><br><span class="line"><span class="comment">#        Player 2</span></span><br><span class="line"><span class="comment">#           C      D</span></span><br><span class="line"><span class="comment"># Player 1 C (R, R) (S, T)</span></span><br><span class="line"><span class="comment">#          D (T, S) (P, P)</span></span><br><span class="line"><span class="comment"># R: Reward for mutual cooperation (双方合作)</span></span><br><span class="line"><span class="comment"># S: Sucker&#x27;s payoff (我合作，对方背叛)</span></span><br><span class="line"><span class="comment"># T: Temptation to defect (我背叛，对方合作)</span></span><br><span class="line"><span class="comment"># P: Punishment for mutual defection (双方背叛)</span></span><br><span class="line"><span class="comment"># 标准囚徒困境条件: T &gt; R &gt; P &gt; S</span></span><br><span class="line"><span class="comment"># 例如: R=3, S=0, T=5, P=1</span></span><br><span class="line"></span><br><span class="line">PAYOFFS = &#123;</span><br><span class="line">    (<span class="string">&#x27;C&#x27;</span>, <span class="string">&#x27;C&#x27;</span>): (<span class="number">3</span>, <span class="number">3</span>),  <span class="comment"># 双方合作</span></span><br><span class="line">    (<span class="string">&#x27;C&#x27;</span>, <span class="string">&#x27;D&#x27;</span>): (<span class="number">0</span>, <span class="number">5</span>),  <span class="comment"># 我方合作，对方背叛</span></span><br><span class="line">    (<span class="string">&#x27;D&#x27;</span>, <span class="string">&#x27;C&#x27;</span>): (<span class="number">5</span>, <span class="number">0</span>),  <span class="comment"># 我方背叛，对方合作</span></span><br><span class="line">    (<span class="string">&#x27;D&#x27;</span>, <span class="string">&#x27;D&#x27;</span>): (<span class="number">1</span>, <span class="number">1</span>),  <span class="comment"># 双方背叛</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 贴现因子 (衡量未来收益的重要性)</span></span><br><span class="line">DELTA = <span class="number">0.9</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">simulate_game</span>(<span class="params">player1_strategy_func, player2_strategy_func, num_rounds</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    模拟一个重复囚徒困境。</span></span><br><span class="line"><span class="string">    :param player1_strategy_func: 玩家1的策略函数</span></span><br><span class="line"><span class="string">    :param player2_strategy_func: 玩家2的策略函数</span></span><br><span class="line"><span class="string">    :param num_rounds: 模拟的回合数</span></span><br><span class="line"><span class="string">    :return: 玩家1和玩家2的总贴现收益</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    player1_history = []  <span class="comment"># 记录玩家1的历史行动</span></span><br><span class="line">    player2_history = []  <span class="comment"># 记录玩家2的历史行动</span></span><br><span class="line">    player1_total_payoff = <span class="number">0.0</span></span><br><span class="line">    player2_total_payoff = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n--- 模拟开始 (<span class="subst">&#123;num_rounds&#125;</span> 回合, Delta=<span class="subst">&#123;DELTA&#125;</span>) ---&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;<span class="string">&#x27;回合&#x27;</span>:&lt;<span class="number">6</span>&#125;</span> <span class="subst">&#123;<span class="string">&#x27;玩家1行动&#x27;</span>:&lt;<span class="number">10</span>&#125;</span> <span class="subst">&#123;<span class="string">&#x27;玩家2行动&#x27;</span>:&lt;<span class="number">10</span>&#125;</span> <span class="subst">&#123;<span class="string">&#x27;玩家1收益&#x27;</span>:&lt;<span class="number">10</span>&#125;</span> <span class="subst">&#123;<span class="string">&#x27;玩家2收益&#x27;</span>:&lt;<span class="number">10</span>&#125;</span> <span class="subst">&#123;<span class="string">&#x27;P1总收益&#x27;</span>:&lt;<span class="number">12</span>&#125;</span> <span class="subst">&#123;<span class="string">&#x27;P2总收益&#x27;</span>:&lt;<span class="number">12</span>&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-&quot;</span> * <span class="number">75</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> r <span class="keyword">in</span> <span class="built_in">range</span>(num_rounds):</span><br><span class="line">        <span class="comment"># 玩家根据各自的策略和历史选择行动</span></span><br><span class="line">        action1 = player1_strategy_func(player1_history, player2_history)</span><br><span class="line">        action2 = player2_strategy_func(player2_history, player1_history)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取当轮收益</span></span><br><span class="line">        payoff1, payoff2 = PAYOFFS[(action1, action2)]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 更新总贴现收益</span></span><br><span class="line">        <span class="comment"># (DELTA ** r) 用于计算当前收益在第一轮的现值</span></span><br><span class="line">        player1_total_payoff += (DELTA ** r) * payoff1</span><br><span class="line">        player2_total_payoff += (DELTA ** r) * payoff2</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 记录历史行动</span></span><br><span class="line">        player1_history.append(action1)</span><br><span class="line">        player2_history.append(action2)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;r+<span class="number">1</span>:&lt;<span class="number">6</span>&#125;</span> <span class="subst">&#123;action1:&lt;<span class="number">10</span>&#125;</span> <span class="subst">&#123;action2:&lt;<span class="number">10</span>&#125;</span> <span class="subst">&#123;payoff1:&lt;<span class="number">10</span>&#125;</span> <span class="subst">&#123;payoff2:&lt;<span class="number">10</span>&#125;</span> <span class="subst">&#123;player1_total_payoff:&lt;<span class="number">12.2</span>f&#125;</span> <span class="subst">&#123;player2_total_payoff:&lt;<span class="number">12.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-&quot;</span> * <span class="number">75</span>)</span><br><span class="line">    <span class="keyword">return</span> player1_total_payoff, player2_total_payoff</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- 经典策略实现 ---</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">grim_trigger_strategy</span>(<span class="params">self_history, opponent_history</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    古板策略：开始合作，一旦对手背叛过，就永远背叛。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 如果是第一轮，或者对手从未背叛过，则合作</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> opponent_history <span class="keyword">or</span> <span class="string">&#x27;D&#x27;</span> <span class="keyword">not</span> <span class="keyword">in</span> opponent_history:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;C&#x27;</span></span><br><span class="line">    <span class="comment"># 否则，永远背叛</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;D&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tit_for_tat_strategy</span>(<span class="params">self_history, opponent_history</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    宽恕策略 (TFT)：第一轮合作，之后模仿对手上一轮的行动。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 如果是第一轮，合作</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> opponent_history:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;C&#x27;</span></span><br><span class="line">    <span class="comment"># 否则，模仿对手上一轮的行动</span></span><br><span class="line">    <span class="keyword">return</span> opponent_history[-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">always_cooperate_strategy</span>(<span class="params">self_history, opponent_history</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    永远合作策略。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;C&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">always_defect_strategy</span>(<span class="params">self_history, opponent_history</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    永远背叛策略。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;D&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># --- 模拟示例 ---</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    num_rounds = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 1. 古板策略 vs 古板策略</span></span><br><span class="line">    p1_gt_payoff, p2_gt_payoff = simulate_game(grim_trigger_strategy, grim_trigger_strategy, num_rounds)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n古板策略 vs 古板策略: P1总收益=<span class="subst">&#123;p1_gt_payoff:<span class="number">.2</span>f&#125;</span>, P2总收益=<span class="subst">&#123;p2_gt_gt_payoff:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 2. 宽恕策略 vs 宽恕策略</span></span><br><span class="line">    p1_tft_payoff, p2_tft_payoff = simulate_game(tit_for_tat_strategy, tit_for_tat_strategy, num_rounds)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n宽恕策略 vs 宽恕策略: P1总收益=<span class="subst">&#123;p1_tft_payoff:<span class="number">.2</span>f&#125;</span>, P2总收益=<span class="subst">&#123;p2_tft_payoff:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 3. 古板策略 vs 永远背叛</span></span><br><span class="line">    <span class="comment"># 理论上：古板策略在第一轮合作，但对手背叛，所以从第二轮开始永远背叛。</span></span><br><span class="line">    p1_gt_ad_payoff, p2_gt_ad_payoff = simulate_game(grim_trigger_strategy, always_defect_strategy, num_rounds)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n古板策略 vs 永远背叛: P1总收益=<span class="subst">&#123;p1_gt_ad_payoff:<span class="number">.2</span>f&#125;</span>, P2总收益=<span class="subst">&#123;p2_gt_ad_payoff:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 4. 宽恕策略 vs 永远背叛</span></span><br><span class="line">    <span class="comment"># 理论上：TFT第一轮合作，对手背叛，TFT第二轮也背叛，然后一直背叛。</span></span><br><span class="line">    p1_tft_ad_payoff, p2_tft_ad_payoff = simulate_game(tit_for_tat_strategy, always_defect_strategy, num_rounds)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n宽恕策略 vs 永远背叛: P1总收益=<span class="subst">&#123;p1_tft_ad_payoff:<span class="number">.2</span>f&#125;</span>, P2总收益=<span class="subst">&#123;p2_tft_ad_payoff:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 5. 宽恕策略 vs 古板策略 (模拟其中一方“犯错”导致连锁反应)</span></span><br><span class="line">    <span class="comment"># 这是一个更复杂的场景，TFT的宽恕性在这里会凸显</span></span><br><span class="line">    <span class="comment"># 假设Player 1是TFT，Player 2是GT</span></span><br><span class="line">    <span class="comment"># 如果某个回合 Player 1意外地背叛了一次</span></span><br><span class="line">    <span class="comment"># Player 2 (GT) 看到背叛，将永远背叛</span></span><br><span class="line">    <span class="comment"># Player 1 (TFT) 看到Player 2背叛，也将永远背叛</span></span><br><span class="line">    <span class="comment"># 这种场景需要策略内部状态或者外部控制来模拟一次性的“失误”</span></span><br><span class="line">    <span class="comment"># 为了简化，我们只模拟经典策略的交互</span></span><br></pre></td></tr></table></figure>
<p>通过运行上述代码，你可以直观地看到不同策略组合在重复囚徒困境中的表现，以及贴现因子对总收益的影响。例如，在古板策略 vs 永远背叛的模拟中，古板策略的玩家在第一轮会“吃亏”，然后双方进入互相惩罚的模式。而当双方都采用合作导向的策略时（如GT vs GT 或 TFT vs TFT），他们能够维持高效的合作，从而获得更高的总收益。</p>
<hr>
<h3 id="第四部分：重复博弈的核心定理">第四部分：重复博弈的核心定理</h3>
<p>重复博弈理论中最具影响力的成果之一是“民间定理”，它为理解合作如何在理性参与者之间达成提供了理论基石。</p>
<h4 id="有限次重复博弈的“逆向归纳”问题">有限次重复博弈的“逆向归纳”问题</h4>
<p>回顾我们之前提到的有限次重复博弈。如果博弈只重复有限的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span> 次，例如重复100次囚徒困境，情况会如何呢？直观上，我们可能认为合作依然是可能的。然而，严谨的分析却得出令人沮丧的结论。</p>
<p>让我们使用<strong>逆向归纳法 (Backward Induction)</strong> 来分析：</p>
<ol>
<li>
<p><strong>最后一轮 (第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span> 轮)</strong>：<br>
在第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span> 轮，因为没有未来，这实际上就是一个单次囚徒困境。根据我们之前的分析，唯一的纳什均衡是双方都选择<strong>背叛 (D, D)</strong>。</p>
</li>
<li>
<p><strong>倒数第二轮 (第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">T-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span> 轮)</strong>：<br>
参与者知道无论他们在第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">T-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span> 轮做什么，第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span> 轮都会是（背叛，背叛）。这意味着第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">T-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span> 轮的行动不会影响第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span> 轮的结果。因此，第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">T-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span> 轮也变成了单次囚徒困境，唯一的纳什均衡是（背叛，背叛）。</p>
</li>
<li>
<p><strong>依此类推</strong>：<br>
通过逆向归纳，我们可以得出结论：在任何一轮，理性的参与者都会预期后续轮次都会选择背叛，所以当前轮次也应该选择背叛。</p>
</li>
</ol>
<p><strong>结论：</strong> 在任何有限次重复的囚徒困境中，唯一的子博弈完美纳什均衡是所有轮次双方都选择<strong>永远背叛 (D, D, …, D)</strong>。</p>
<p>这个结论听起来可能反直觉，因为它与现实世界中普遍存在的合作现象相悖。它表明，如果博弈的结束时间是明确且已知的，那么“未来之影”将完全消失，合作将无法维系。</p>
<p>为了解释现实中的合作，博弈论引入了无限次重复博弈、不确定终止时间、不完全信息、或者有限理性等假设。</p>
<h4 id="民间定理-Folk-Theorem">民间定理 (Folk Theorem)</h4>
<p>民间定理是重复博弈理论中一个极其重要的概念，它解释了为什么在长期互动中合作普遍存在。它的名字“民间”并非因为它不重要，而是因为它的基本思想在博弈论学家中口耳相传、广泛流传，直到后来才被正式严谨地表述和证明。</p>
<p><strong>核心思想：</strong> 在无限次重复博弈中，只要参与者足够“耐心”（即贴现因子 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span></span></span></span> 足够大），那么任何一个能给所有参与者带来比“最小个体理性收益”更高收益的策略组合，都可以作为某个子博弈完美纳什均衡的收益结果。</p>
<p><strong>具体阐述：</strong></p>
<ul>
<li><strong>可行收益 (Feasible Payoffs)</strong>：指通过某种混合策略组合（在所有轮次中）可以达到的平均收益。</li>
<li><strong>个体理性收益 (Individually Rational Payoffs)</strong>：指每个参与者获得的收益，必须不低于其<strong>最小个体理性收益 (Minimax Payoff)</strong>。
<ul>
<li><strong>最小个体理性收益 (Minimax Payoff)</strong>：在所有可能的对手策略中，参与者在最坏情况下（即对手试图最小化我方收益时）所能获得的最低收益。<br>
对于囚徒困境，当对手永远背叛时，我方能获得的最好收益是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span> (双方背叛的收益)。所以，囚徒困境的最小个体理性收益是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span></span></span></span>。</li>
</ul>
</li>
</ul>
<p><strong>民间定理的正式表述（简要版，Perfect Folk Theorem）：</strong><br>
假设一个阶段博弈有一个纳什均衡。在无限次重复该阶段博弈中，任何给所有参与者带来严格高于其最小个体理性收益的可行平均收益向量，都可以由某个子博弈完美纳什均衡支持，只要贴现因子 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span></span></span></span> 足够接近1。</p>
<p><strong>民间定理的意义：</strong></p>
<ol>
<li><strong>解释合作：</strong> 它提供了合作在长期关系中可能存在的理论基础。在单次囚徒困境中，合作是不可能的，但民间定理表明，如果囚徒们知道他们会无限次地相遇，并且重视未来的收益，那么他们可以通过建立一套惩罚机制（如古板策略）来维持合作，达到帕累托最优的（合作，合作）收益。</li>
<li><strong>均衡结果的多样性：</strong> 民间定理指出，在无限次重复博弈中，潜在的均衡结果非常多，而不仅仅是阶段博弈的纳什均衡的重复。这意味着在长期互动中，人们可以通过不同的协议、规范和惩罚制度来实现各种各样的合作水平。</li>
<li><strong>“未来之影”的力量：</strong> 再次强调了贴现因子 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span></span></span></span> 的重要性。只有当未来足够重要时，长期的合作才能被维持。</li>
</ol>
<p>尽管民间定理揭示了合作的无限可能性，但它并没有告诉我们哪种合作会真正出现，也没有说明在存在多个均衡时，参与者会选择哪个均衡。这是一个开放的研究领域，通常需要结合行为博弈论或实验博弈论来探讨。</p>
<hr>
<h3 id="第五部分：应用与案例分析">第五部分：应用与案例分析</h3>
<p>重复博弈理论不仅仅是抽象的数学概念，它在现实世界的许多领域都有着深远的解释力。</p>
<h4 id="经济学">经济学</h4>
<ul>
<li>
<p><strong>卡特尔与价格战 (Cartels and Price Wars)</strong>：<br>
卡特尔是厂商通过协议来限制产量、提高价格，以获取垄断利润的组织。这种协议本质上是一个重复的囚徒困境：如果所有厂商都遵守协议（合作），它们都能获得高利润；如果一个厂商偷偷提高产量或降低价格（背叛），它可以在短期内获得巨大收益，但如果所有厂商都背叛，就会导致价格战，所有厂商都会遭受损失。<br>
重复博弈理论解释了卡特尔为何能在一定时期内维持，以及为何它们最终常常崩溃。当贴现因子足够大（例如，厂商重视长期利润、监管不严、市场相对稳定时），古板策略或TFT等机制（如互相监督、对违约者进行价格战惩罚）可以维持合作。但当市场出现不确定性、监管加强或某厂商短期资金紧张急需利润时，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span></span></span></span> 值降低，背叛的诱惑可能导致卡特尔瓦解。OPEC（石油输出国组织）的产量协调就是一个典型的例子。</p>
</li>
<li>
<p><strong>劳资谈判 (Labor-Management Negotiations)</strong>：<br>
工会与管理层之间的关系往往是长期的。如果双方都能建立信任并遵守协议（例如，工会不随意罢工，管理层不随意裁员或压低工资），则能实现长期共赢。重复博弈解释了为什么尽管单次谈判中可能存在强硬立场或背叛的诱惑，但长期稳定的劳资关系往往通过相互的承诺、惩罚和奖励机制来维持。</p>
</li>
<li>
<p><strong>公共物品供给 (Provision of Public Goods)</strong>：<br>
公共物品（如清洁空气、国防）的特点是非排他性和非竞争性，容易导致“搭便车”问题。例如，每个人都希望享受公共物品，但都不愿意付出成本。然而，在社区或小型群体中，通过重复互动和声誉机制，人们可能会自愿为公共物品付费或贡献。比如，邻里之间维护公共绿地，如果一个人不贡献，他的声誉会受损，未来在其他方面的合作（如借工具）可能受阻。</p>
</li>
</ul>
<h4 id="社会学与生物学">社会学与生物学</h4>
<ul>
<li>
<p><strong>社会规范与信任 (Social Norms and Trust)</strong>：<br>
为什么人们会遵守社会规范，即使在没有外部强制的情况下？重复博弈提供了一个解释。违反规范（背叛）可能会带来短期收益，但会被社区惩罚（失去信任、被排斥）。这种预期惩罚促使人们遵守规范，从而维系了社会秩序。信任的建立本身就是一个重复博弈的过程，通过不断地合作和履行承诺来积累。</p>
</li>
<li>
<p><strong>利他行为的演化 (Evolution of Altruism)</strong>：<br>
在生物学中，利他行为（牺牲个体利益帮助他人）似乎与“适者生存”相悖。然而，通过“互惠利他主义 (Reciprocal Altruism)”的概念，重复博弈可以解释这种现象。例如，蝙蝠之间会互相分享血液，如果一只蝙蝠今天分享了，它预期未来被它分享过的蝙蝠也会在它需要时分享。如果一只蝙蝠是“骗子”，它在下次需要血液时可能就不会得到帮助。这类似于TFT策略在生物进化中的体现。</p>
</li>
</ul>
<h4 id="人工智能-Artificial-Intelligence">人工智能 (Artificial Intelligence)</h4>
<ul>
<li>
<p><strong>多智能体系统中的协作与竞争 (Cooperation and Competition in Multi-Agent Systems)</strong>：<br>
在多智能体强化学习中，智能体之间可能需要相互协作来完成复杂任务（如自动驾驶车队的协调、机器人足球队）。通过将这些交互建模为重复博弈，智能体可以学习更有效的协作策略，避免短期内的“自私”行为导致系统整体效率下降。例如，通过引入惩罚或奖励机制，可以引导智能体收敛到协作均衡。</p>
</li>
<li>
<p><strong>区块链中的共识机制 (Consensus Mechanisms in Blockchain)</strong>：<br>
在去中心化的区块链网络中，矿工或验证者需要就交易的有效性达成共识。PoW (Proof of Work) 和 PoS (Proof of Stake) 等共识机制，本质上就是设计一种重复博弈，使得参与者有动机去“合作”（诚实验证和打包交易）而不是“背叛”（双花攻击、伪造区块）。通过设计激励（挖矿奖励）和惩罚（算力浪费、资产质押被没收），使得长期合作的收益远高于短期背叛的收益，从而维持网络的安全性。</p>
</li>
<li>
<p><strong>在线平台与信誉系统 (Online Platforms and Reputation Systems)</strong>：<br>
电商平台（如淘宝、亚马逊）的商家和消费者、共享经济平台（如滴滴、Airbnb）的司机/房东和用户之间，都是重复博弈的关系。评论系统、评分机制和申诉机制等，都是为了建立和维护参与者的声誉，使得“好”的行为得到奖励，“坏”的行为受到惩罚。这促使参与者更倾向于提供高质量的服务或遵守规则，从而提高了平台的整体信任水平和效率。</p>
</li>
</ul>
<hr>
<h3 id="第六部分：挑战与局限性">第六部分：挑战与局限性</h3>
<p>尽管重复博弈理论强大且富有洞察力，但它也存在一些挑战和局限性：</p>
<h4 id="信息不对称-Information-Asymmetry">信息不对称 (Information Asymmetry)</h4>
<p>在实际情境中，参与者往往无法完全了解对手的类型（是理性还是非理性？是合作型还是背叛型？），也无法完美观察对手的每一次行动。不完全信息会极大地增加博弈的复杂性，并可能导致合作难以维持。例如，一个“好”的合作者可能会被误认为是背叛者，导致不必要的惩罚循环。</p>
<h4 id="噪声与错误-Noise-and-Errors">噪声与错误 (Noise and Errors)</h4>
<p>在真实世界中，沟通可能会出现噪声，行动可能会发生错误。例如，一个合作者可能因为疏忽而“意外”地做出了背叛的行动。在这种情况下，严格的古板策略会导致双方陷入无休止的惩罚循环，而像TFT这样具有宽恕性的策略则可能表现更好。如何在噪声环境下设计健壮的策略是重要的研究方向。</p>
<h4 id="有限理性-Bounded-Rationality">有限理性 (Bounded Rationality)</h4>
<p>重复博弈理论通常假设参与者是完全理性的，能够进行复杂的计算和无限次的逆向归纳。然而，现实中的人类往往是有限理性的，他们可能依赖启发式规则、情感或经验来做决策，而不是严格的效用最大化计算。行为博弈论 (Behavioral Game Theory) 正是研究人类实际行为与理性模型之间差异的领域。</p>
<h4 id="博弈的复杂性-Complexity-of-Games">博弈的复杂性 (Complexity of Games)</h4>
<p>当阶段博弈变得非常复杂，或参与者数量众多时，计算最优策略和分析均衡变得异常困难。多智能体系统中的高维状态空间和行动空间使得传统的重复博弈分析方法难以直接应用，需要结合机器学习等技术。</p>
<h4 id="均衡选择问题-Equilibrium-Selection-Problem">均衡选择问题 (Equilibrium Selection Problem)</h4>
<p>民间定理告诉我们，在无限次重复博弈中可能存在无数个SPNE。那么，在这些可能的均衡中，参与者会选择哪一个呢？理论本身并不能提供明确的答案，这通常需要引入额外的假设（如焦点效应、沟通、社会规范）来解决。</p>
<hr>
<h3 id="结论：时间的礼物与合作的艺术">结论：时间的礼物与合作的艺术</h3>
<p>通过对重复博弈的探索，我们看到了时间维度如何彻底改变了决策的逻辑。单次博弈中“自私”的理性选择可能导致集体困境，但在重复博弈的“未来之影”下，合作不仅成为可能，而且在很多情况下是理性的最优选择。</p>
<p>我们回顾了囚徒困境的单次困境，揭示了贴现因子如何量化未来对当下的影响力。我们深入剖析了古板策略和宽恕策略（TFT）的机制，理解了它们如何在不同条件下维持合作，并看到了阿克塞尔罗德竞赛中TFT的魅力。最重要的是，民间定理向我们展示了，只要未来足够重要，合作的艺术便有无限可能。</p>
<p>重复博弈理论不仅解释了经济组织中的卡特尔形成与瓦解、劳资关系的维系，也为社会规范的建立、生物利他行为的演化提供了深刻的洞察。在当今的AI时代，它更是构建多智能体协作系统、设计区块链共识机制以及理解在线平台信誉系统不可或缺的基石。</p>
<p>当然，现实世界比理论模型更加复杂。信息不对称、噪声、有限理性以及多方博弈的挑战，都在不断推动着重复博弈理论的边界。未来的研究将继续融合行为科学、机器学习和计算方法，以更精准地捕捉现实互动的细微之处。</p>
<p>希望这篇文章能让你对重复博弈的策略与均衡有了更深层次的理解。它不仅仅是关于如何玩“游戏”，更是关于如何理解和构建一个更具信任、更可持续的协作世界。下次当你与他人进行重复互动时，不妨想想“未来之影”的力量，它或许会悄然改变你的决策。</p>
<hr>
<p><strong>博主：qmwneb946</strong></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a target="_blank" rel="noopener" href="https://github.com/qmwneb946">qmwneb946</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://qmwneb946.dpdns.org/2025/07/19/2025-07-19-124557/">https://qmwneb946.dpdns.org/2025/07/19/2025-07-19-124557/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://opensource.org/licenses/MIT" target="_blank">MIT License</a> 许可协议。转载请注明来源 <a href="https://qmwneb946.dpdns.org" target="_blank">qmwneb946 的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%A7%91%E6%8A%80%E5%89%8D%E6%B2%BF/">科技前沿</a><a class="post-meta__tags" href="/tags/2025/">2025</a><a class="post-meta__tags" href="/tags/%E9%87%8D%E5%A4%8D%E5%8D%9A%E5%BC%88%E4%B8%AD%E7%9A%84%E7%AD%96%E7%95%A5%E4%B8%8E%E5%9D%87%E8%A1%A1/">重复博弈中的策略与均衡</a></div><div class="post-share"><div class="social-share" data-image="/img/icon.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/07/19/2025-07-19-124700/" title="探索非线性规划的奥秘：算法研究与实践"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">探索非线性规划的奥秘：算法研究与实践</div></div><div class="info-2"><div class="info-item-1">你好，我是 qmwneb946，一个对技术和数学充满热情的博主。今天，我们将一同踏上一段深度探索之旅，去揭开优化领域中一个既迷人又充满挑战的课题——非线性规划（Nonlinear Programming, NLP）的算法研究。 在工程设计、经济建模、机器学习、金融分析乃至生物医药等诸多领域，我们常常需要找到一组变量的最佳取值，以最大化或最小化某个目标。如果这个目标函数和所有约束条件都是线性的，那么恭喜你，你正在处理一个线性规划问题，它的求解相对成熟且高效。然而，现实世界往往远比线性复杂，当目标函数或任何一个约束条件呈现出非线性特性时，我们就进入了非线性规划的广阔天地。 非线性规划的复杂性在于，它的目标函数可能拥有多个局部最优解，约束条件可能形成复杂的非凸可行域，这使得寻找全局最优解变得异常困难。但正是这种复杂性，催生了无数巧妙而强大的算法。本文将带你从最基本的概念出发，逐步深入到各种经典的无约束与有约束非线性规划算法，探讨它们的原理、优缺点、适用场景，并展望这一领域的未来发展。 无论你是数据科学家、机器学习工程师、运筹学研究员，还是仅仅对优化问题抱有好奇心的技术爱好者，我都相信这...</div></div></div></a><a class="pagination-related" href="/2025/07/19/2025-07-19-124438/" title="分形天线的设计与应用：探索无线通信的未来维度"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">分形天线的设计与应用：探索无线通信的未来维度</div></div><div class="info-2"><div class="info-item-1"> 引言 在数字信息爆炸的时代，无线通信已成为我们日常生活中不可或缺的一部分。从智能手机到物联网设备，从卫星导航到深空探测，无线连接无处不在。而在这万物互联的背后，天线扮演着至关重要的角色，它是电磁波与电子信号之间的桥梁。然而，随着技术的发展，传统天线面临着前所未有的挑战：设备小型化要求天线尺寸的不断压缩，日益复杂的通信标准则呼唤天线具备多频段、宽带乃至超宽带的性能。在这样的背景下，一种源于数学与自然之美的创新性天线设计理念——分形天线——应运而生，并以前所未有的方式改变着天线设计的范式。 分形，这个词听起来既神秘又迷人。它由数学家本华·曼德博（Benoît Mandelbrot）于1975年创造，用来描述那些具有自相似性（Self-similarity）的复杂几何形状，即无论放大或缩小，其局部与整体都呈现出相似的结构。从大自然的云朵、海岸线、树叶脉络，到人体的肺部支气管，分形无处不在。当这种无限嵌套、空间填充的几何特性被引入到天线设计中时，奇迹发生了：原本需要巨大尺寸才能在低频下工作的天线，可以通过分形结构被“折叠”进更小的空间；原本只能工作在单一频段的天线，可以同时支持多个甚至...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/07/18/2025-07-18-082408/" title="人工智能在医疗诊断中的应用：机遇与挑战"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">人工智能在医疗诊断中的应用：机遇与挑战</div></div><div class="info-2"><div class="info-item-1">大家好，我是你们的技术和数学博主！今天，我们来深入探讨一个激动人心的领域：人工智能 (AI) 在医疗诊断中的应用。AI 的快速发展正在彻底改变医疗行业，为更精准、高效的诊断提供了前所未有的可能性。但同时，我们也需要审慎地看待其挑战和局限性。 引言：AI 赋能医疗诊断 医疗诊断是一个复杂的过程，需要医生具备丰富的知识、经验和判断力。然而，人类医生可能会受到主观偏差、疲劳以及信息过载的影响。AI 的介入，则为提高诊断准确性和效率提供了新的途径。通过分析大量的医学影像数据、病历记录和基因组信息，AI 算法可以学习识别疾病模式，辅助医生进行诊断，甚至在某些情况下独立完成初步诊断。 AI 在医疗诊断中的核心技术 深度学习在医学影像分析中的应用 深度学习，特别是卷积神经网络 (CNN)，在医学影像分析中取得了显著的成功。CNN 可以从大量的医学影像数据（例如 X 光片、CT 扫描、MRI 图像）中学习特征，并识别出细微的病变，例如肺癌结节、脑瘤或心血管疾病。 例如，一个训练良好的 CNN 模型可以比人类放射科医生更早地检测出肺癌，从而提高早期诊断率和治疗成功率。  这其中的关键在于大量的标注...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082643/" title="高分子化学与可降解塑料：迈向可持续未来的关键"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">高分子化学与可降解塑料：迈向可持续未来的关键</div></div><div class="info-2"><div class="info-item-1">近年来，塑料污染已成为全球性环境问题。传统塑料由于其难以降解的特性，对环境造成了巨大的压力。而可降解塑料的出现，为解决这一问题提供了一条可行的途径。本文将深入探讨高分子化学在可降解塑料研发中的关键作用，并介绍几种主要的降解机制和材料。 高分子化学：可降解塑料的基础 可降解塑料并非简单的“可被分解的塑料”，其核心在于高分子材料的分子结构设计。高分子化学为我们提供了理解和操纵聚合物结构的工具，从而设计出具有特定降解性能的材料。传统塑料通常由难以断裂的强共价键连接而成，而可降解塑料则通过引入特定的化学键或结构单元，使其在特定条件下能够断裂，从而实现降解。  这需要对聚合物的合成方法、分子量分布、链结构以及结晶度等进行精细的控制。 常见的可降解塑料聚合物 目前，市场上常见的可降解塑料主要包括以下几种：   聚乳酸 (PLA):  PLA 是一种生物基聚合物，由可再生资源（例如玉米淀粉）制成。其降解过程主要依靠水解反应，在特定条件下（例如堆肥环境）可以被微生物降解。PLA 的机械性能较好，但耐热性相对较差。   聚羟基脂肪酸酯 (PHAs): PHAs 是一类由微生物合成的聚酯。它们具有良...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082805/" title="电化学储能技术的新进展：迈向更清洁、更持久的能源未来"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">电化学储能技术的新进展：迈向更清洁、更持久的能源未来</div></div><div class="info-2"><div class="info-item-1">电化学储能技术作为解决可再生能源间歇性问题的关键技术，近年来取得了显著进展。从电动汽车到智能电网，电化学储能系统正深刻地改变着我们的生活。本文将深入探讨电化学储能技术的最新突破，涵盖不同类型的储能技术及其面临的挑战与机遇。 电化学储能技术的类型 目前，市场上主要的电化学储能技术包括： 锂离子电池 锂离子电池凭借其高能量密度、长循环寿命和相对较低的成本，占据了当前电化学储能市场的主导地位。然而，锂资源的有限性和安全性问题仍然是制约其发展的瓶颈。  近年来，研究者们致力于开发高能量密度锂离子电池，例如：  固态锂电池:  固态电解质的采用可以显著提高电池的安全性，并有望实现更高的能量密度。然而，固态电解质的离子电导率和界面接触仍然是需要克服的挑战。 锂硫电池:  锂硫电池具有极高的理论能量密度，但其循环寿命和硫的穿梭效应仍然是需要解决的关键问题。  研究者们正在探索各种改性策略来提高锂硫电池的性能。 锂空气电池:  锂空气电池拥有理论上最高的能量密度，但其反应动力学缓慢，副反应多，循环寿命短等问题限制了其商业化应用。  钠离子电池 作为锂离子的潜在替代品，钠离子电池具有成本低、资源丰...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-092352/" title="材料科学与新型半导体材料：摩尔定律的未来"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">材料科学与新型半导体材料：摩尔定律的未来</div></div><div class="info-2"><div class="info-item-1">引言 摩尔定律，即集成电路上的晶体管数量每隔两年翻一番，几十年来一直驱动着信息技术产业的飞速发展。然而，随着晶体管尺寸逼近物理极限，摩尔定律的持续性受到了挑战。为了维持这种指数级增长，我们需要探索新型半导体材料，突破硅基技术的瓶颈。本文将深入探讨材料科学在新型半导体材料研发中的关键作用，并介绍一些具有前景的候选材料。 新型半导体材料的需求 硅作为半导体材料的主力，其优势在于成本低、工艺成熟。但其固有的物理特性限制了其在更高频率、更高功率和更低功耗方面的性能提升。例如，硅的载流子迁移率相对较低，导致能量损耗增加，尤其是在高频应用中。因此，我们需要寻找具有更高载流子迁移率、更宽禁带宽度、更高饱和电子漂移速度等优异特性的材料。 性能瓶颈及解决方案 硅基技术的性能瓶颈主要体现在以下几个方面：  漏电流:  随着晶体管尺寸的缩小，漏电流问题日益严重，导致功耗增加和性能下降。 热耗散: 高频运行会导致晶体管产生大量热量，影响器件稳定性和可靠性。 开关速度: 硅的载流子迁移率限制了晶体管的开关速度，限制了处理器的运行频率。  为了解决这些问题，研究人员正在积极探索各种新型半导体材料，例如：  ...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-092411/" title="弦理论中的额外维度探索：超越我们感知的宇宙"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">弦理论中的额外维度探索：超越我们感知的宇宙</div></div><div class="info-2"><div class="info-item-1">引言 我们生活在一个看似三维的空间中，加上时间构成四维时空。然而，弦理论，这个试图统一所有基本力的优雅理论，却预言了额外维度的存在。这些额外维度并非我们日常经验所能感知，它们蜷缩在比原子尺度还要小得多的空间里。本文将深入探讨弦理论中额外维度的概念，并解释科学家们如何尝试探测这些隐藏的宇宙维度。 弦理论与额外维度：一个必要的假设 弦理论的核心思想是将基本粒子视为微小的振动弦，不同振动模式对应不同的粒子。为了使理论自洽，并消除量子场论中的一些困扰，弦理论需要引入额外空间维度。最初的弦理论版本需要 26 个维度，而超弦理论则将维度数量缩减到 10 个（或 11 个，在 M 理论中）。这多出来的 6 个（或 7 个）维度是如何隐藏起来的呢？ 卡拉比-丘空间：卷曲的维度 弦理论提出，额外维度并非不存在，而是以紧致化的形式存在，就像一根细细的管子卷曲得非常紧密，以至于在宏观尺度上无法被察觉。这些紧致化的额外维度通常被描述为卡拉比-丘空间，这是一类复杂的六维流形，具有独特的几何性质。卡拉比-丘空间的形状和大小直接影响了我们观察到的粒子物理学特性，例如粒子质量和相互作用强度。 R6R^6R6 表...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-092451/" title="粒子物理学的标准模型之外：探索宇宙未解之谜"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">粒子物理学的标准模型之外：探索宇宙未解之谜</div></div><div class="info-2"><div class="info-item-1">我们生活在一个由基本粒子及其相互作用组成的宇宙中。粒子物理学的标准模型，如同一个精妙的乐章，成功地描述了已知的基本粒子及其三种基本作用力（电磁力、弱力和强力），并准确预测了许多实验结果。然而，这个模型并非完美无缺，它留下了许多未解之谜，指引着我们向标准模型之外的更广阔领域探索。 标准模型的局限性 标准模型尽管取得了巨大的成功，但它并不能解释宇宙中的一切现象。一些关键的不足之处包括： 暗物质与暗能量 宇宙学观测表明，宇宙中存在大量的暗物质和暗能量，它们构成了宇宙质量能量的大部分，但标准模型中却无法解释它们的本质。暗物质不参与电磁相互作用，因此我们无法直接观测到它，只能通过其引力效应间接探测。暗能量则是一种神秘的能量形式，导致宇宙加速膨胀。它们的发现暗示着标准模型之外存在着新的物理学。 中微子质量 标准模型最初假设中微子是无质量的。然而，实验观测表明中微子具有微小的质量，这与标准模型的预言相矛盾。中微子的质量之谜需要新的物理机制来解释，例如 seesaw 机制。 质子衰变 标准模型预言质子是稳定的，然而，一些大统一理论（GUTs）预测质子会发生极其缓慢的衰变。虽然到目前为止还没有观测...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">qmwneb946</div><div class="author-info-description">一个专注于技术分享的个人博客，涵盖编程、算法、系统设计等内容</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">733</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">737</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/qmwneb946"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/qmwneb946" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:qmwneb946@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">代码与远方，技术与生活交织的篇章。</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%95%E8%A8%80%EF%BC%9A%E8%B6%85%E8%B6%8A%E4%B8%80%E9%94%A4%E5%AD%90%E4%B9%B0%E5%8D%96%E7%9A%84%E6%99%BA%E6%85%A7"><span class="toc-number">1.</span> <span class="toc-text">引言：超越一锤子买卖的智慧</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%EF%BC%9A%E5%9F%BA%E7%A1%80%E5%9B%9E%E9%A1%BE%E4%B8%8E%E5%8D%95%E6%AC%A1%E5%8D%9A%E5%BC%88%E7%9A%84%E5%9B%B0%E5%A2%83"><span class="toc-number">2.</span> <span class="toc-text">第一部分：基础回顾与单次博弈的困境</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%8D%9A%E5%BC%88%E8%AE%BA%EF%BC%9F"><span class="toc-number">2.1.</span> <span class="toc-text">什么是博弈论？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%95%E6%AC%A1%E5%8D%9A%E5%BC%88%E7%9A%84%E6%A0%B8%E5%BF%83%EF%BC%9A%E7%BA%B3%E4%BB%80%E5%9D%87%E8%A1%A1"><span class="toc-number">2.2.</span> <span class="toc-text">单次博弈的核心：纳什均衡</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86%EF%BC%9A%E9%87%8D%E5%A4%8D%E5%8D%9A%E5%BC%88%E7%9A%84%E9%AD%94%E5%8A%9B%EF%BC%9A%E2%80%9C%E6%9C%AA%E6%9D%A5%E4%B9%8B%E5%BD%B1%E2%80%9D"><span class="toc-number">3.</span> <span class="toc-text">第二部分：重复博弈的魔力：“未来之影”</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%87%8D%E5%A4%8D%E5%8D%9A%E5%BC%88%E7%9A%84%E5%AE%9A%E4%B9%89%E4%B8%8E%E5%88%86%E7%B1%BB"><span class="toc-number">3.1.</span> <span class="toc-text">重复博弈的定义与分类</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%80%9C%E6%9C%AA%E6%9D%A5%E4%B9%8B%E5%BD%B1%E2%80%9D%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88%E9%87%8D%E5%A4%8D%E5%BE%88%E9%87%8D%E8%A6%81%EF%BC%9F"><span class="toc-number">3.2.</span> <span class="toc-text">“未来之影”：为什么重复很重要？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9D%87%E8%A1%A1%E6%A6%82%E5%BF%B5%E7%9A%84%E6%89%A9%E5%B1%95%EF%BC%9A%E5%AD%90%E5%8D%9A%E5%BC%88%E5%AE%8C%E7%BE%8E%E7%BA%B3%E4%BB%80%E5%9D%87%E8%A1%A1"><span class="toc-number">3.3.</span> <span class="toc-text">均衡概念的扩展：子博弈完美纳什均衡</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%EF%BC%9A%E5%90%88%E4%BD%9C%E7%AD%96%E7%95%A5%EF%BC%9A%E4%BB%8E%E6%9C%B4%E7%B4%A0%E5%88%B0%E5%A4%8D%E6%9D%82"><span class="toc-number">4.</span> <span class="toc-text">第三部分：合作策略：从朴素到复杂</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%B4%E7%B4%A0%E7%AD%96%E7%95%A5"><span class="toc-number">4.1.</span> <span class="toc-text">朴素策略</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%A6%E5%8F%91%E7%AD%96%E7%95%A5-Trigger-Strategies"><span class="toc-number">4.2.</span> <span class="toc-text">触发策略 (Trigger Strategies)</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8F%A4%E6%9D%BF%E7%AD%96%E7%95%A5-Grim-Trigger-Strategy"><span class="toc-number">4.2.1.</span> <span class="toc-text">古板策略 (Grim Trigger Strategy)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AE%BD%E6%81%95%E7%AD%96%E7%95%A5-Tit-for-Tat-TFT"><span class="toc-number">4.2.2.</span> <span class="toc-text">宽恕策略 (Tit-for-Tat, TFT)</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9B%B4%E5%A4%8D%E6%9D%82%E7%9A%84%E7%AD%96%E7%95%A5"><span class="toc-number">4.3.</span> <span class="toc-text">更复杂的策略</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E7%A4%BA%E4%BE%8B%EF%BC%9A%E5%9B%9A%E5%BE%92%E5%9B%B0%E5%A2%83%E6%A8%A1%E6%8B%9F"><span class="toc-number">4.4.</span> <span class="toc-text">代码示例：囚徒困境模拟</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%EF%BC%9A%E9%87%8D%E5%A4%8D%E5%8D%9A%E5%BC%88%E7%9A%84%E6%A0%B8%E5%BF%83%E5%AE%9A%E7%90%86"><span class="toc-number">5.</span> <span class="toc-text">第四部分：重复博弈的核心定理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%89%E9%99%90%E6%AC%A1%E9%87%8D%E5%A4%8D%E5%8D%9A%E5%BC%88%E7%9A%84%E2%80%9C%E9%80%86%E5%90%91%E5%BD%92%E7%BA%B3%E2%80%9D%E9%97%AE%E9%A2%98"><span class="toc-number">5.1.</span> <span class="toc-text">有限次重复博弈的“逆向归纳”问题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B0%91%E9%97%B4%E5%AE%9A%E7%90%86-Folk-Theorem"><span class="toc-number">5.2.</span> <span class="toc-text">民间定理 (Folk Theorem)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%EF%BC%9A%E5%BA%94%E7%94%A8%E4%B8%8E%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90"><span class="toc-number">6.</span> <span class="toc-text">第五部分：应用与案例分析</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BB%8F%E6%B5%8E%E5%AD%A6"><span class="toc-number">6.1.</span> <span class="toc-text">经济学</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%A4%BE%E4%BC%9A%E5%AD%A6%E4%B8%8E%E7%94%9F%E7%89%A9%E5%AD%A6"><span class="toc-number">6.2.</span> <span class="toc-text">社会学与生物学</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD-Artificial-Intelligence"><span class="toc-number">6.3.</span> <span class="toc-text">人工智能 (Artificial Intelligence)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%EF%BC%9A%E6%8C%91%E6%88%98%E4%B8%8E%E5%B1%80%E9%99%90%E6%80%A7"><span class="toc-number">7.</span> <span class="toc-text">第六部分：挑战与局限性</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%A1%E6%81%AF%E4%B8%8D%E5%AF%B9%E7%A7%B0-Information-Asymmetry"><span class="toc-number">7.1.</span> <span class="toc-text">信息不对称 (Information Asymmetry)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%99%AA%E5%A3%B0%E4%B8%8E%E9%94%99%E8%AF%AF-Noise-and-Errors"><span class="toc-number">7.2.</span> <span class="toc-text">噪声与错误 (Noise and Errors)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%89%E9%99%90%E7%90%86%E6%80%A7-Bounded-Rationality"><span class="toc-number">7.3.</span> <span class="toc-text">有限理性 (Bounded Rationality)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%9A%E5%BC%88%E7%9A%84%E5%A4%8D%E6%9D%82%E6%80%A7-Complexity-of-Games"><span class="toc-number">7.4.</span> <span class="toc-text">博弈的复杂性 (Complexity of Games)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9D%87%E8%A1%A1%E9%80%89%E6%8B%A9%E9%97%AE%E9%A2%98-Equilibrium-Selection-Problem"><span class="toc-number">7.5.</span> <span class="toc-text">均衡选择问题 (Equilibrium Selection Problem)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA%EF%BC%9A%E6%97%B6%E9%97%B4%E7%9A%84%E7%A4%BC%E7%89%A9%E4%B8%8E%E5%90%88%E4%BD%9C%E7%9A%84%E8%89%BA%E6%9C%AF"><span class="toc-number">8.</span> <span class="toc-text">结论：时间的礼物与合作的艺术</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/23/hello-world/" title="Hello World">Hello World</a><time datetime="2025-07-23T15:28:31.522Z" title="发表于 2025-07-23 23:28:31">2025-07-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/23/%E5%8D%9A%E5%BC%88%E8%AE%BA%E5%9F%BA%E7%A1%80/" title="博弈论基础">博弈论基础</a><time datetime="2025-07-23T15:28:31.522Z" title="发表于 2025-07-23 23:28:31">2025-07-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/23/2025-07-23-152542/" title="动力系统中的熵理论：混沌、信息与秩序的深层度量">动力系统中的熵理论：混沌、信息与秩序的深层度量</a><time datetime="2025-07-23T07:25:42.000Z" title="发表于 2025-07-23 15:25:42">2025-07-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/23/2025-07-23-152441/" title="揭秘代数曲面：从意大利学派到小川维度，一场分类的史诗之旅">揭秘代数曲面：从意大利学派到小川维度，一场分类的史诗之旅</a><time datetime="2025-07-23T07:24:41.000Z" title="发表于 2025-07-23 15:24:41">2025-07-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/23/2025-07-23-152351/" title="算术丢番图几何：连接数论与代数几何的宏伟桥梁">算术丢番图几何：连接数论与代数几何的宏伟桥梁</a><time datetime="2025-07-23T07:23:51.000Z" title="发表于 2025-07-23 15:23:51">2025-07-23</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;2025 By qmwneb946</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.2</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css')
    if (true) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const getGiscusTheme = theme => theme === 'dark' ? 'dark' : 'light'

  const createScriptElement = config => {
    const ele = document.createElement('script')
    Object.entries(config).forEach(([key, value]) => {
      ele.setAttribute(key, value)
    })
    return ele
  }

  const loadGiscus = (el = document, key) => {
    const mappingConfig = isShuoshuo
      ? { 'data-mapping': 'specific', 'data-term': key }
      : { 'data-mapping': (option && option['data-mapping']) || 'pathname' }

    const giscusConfig = {
      src: 'https://giscus.app/client.js',
      'data-repo': 'qmwneb946/blog',
      'data-repo-id': 'R_kgDOPM6cWw',
      'data-category-id': 'DIC_kwDOPM6cW84CtEzo',
      'data-theme': getGiscusTheme(document.documentElement.getAttribute('data-theme')),
      'data-reactions-enabled': '1',
      crossorigin: 'anonymous',
      async: true,
      ...option,
      ...mappingConfig
    }

    const scriptElement = createScriptElement(giscusConfig)

    el.querySelector('#giscus-wrap').appendChild(scriptElement)

    if (isShuoshuo) {
      window.shuoshuoComment.destroyGiscus = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }
  }

  const changeGiscusTheme = theme => {
    const iframe = document.querySelector('#giscus-wrap iframe')
    if (iframe) {
      const message = {
        giscus: {
          setConfig: {
            theme: getGiscusTheme(theme)
          }
        }
      }
      iframe.contentWindow.postMessage(message, 'https://giscus.app')
    }
  }

  btf.addGlobalFn('themeChange', changeGiscusTheme, 'giscus')

  if (isShuoshuo) {
    'Giscus' === 'Giscus'
      ? window.shuoshuoComment = { loadComment: loadGiscus }
      : window.loadOtherComment = loadGiscus
    return
  }

  if ('Giscus' === 'Giscus' || !false) {
    if (false) btf.loadComment(document.getElementById('giscus-wrap'), loadGiscus)
    else loadGiscus()
  } else {
    window.loadOtherComment = loadGiscus
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>