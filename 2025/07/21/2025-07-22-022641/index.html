<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>机器学习力场的发展与应用：桥接量子精度与经典效率的计算利器 | qmwneb946 的博客</title><meta name="author" content="qmwneb946"><meta name="copyright" content="qmwneb946"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="大家好，我是你们的博主 qmwneb946。今天，我们要深入探讨一个在计算科学领域掀起革命性浪潮的话题：机器学习力场（Machine Learning Force Fields, MLFFs）。在原子尺度的模拟世界里，我们一直面临着一个核心矛盾：如何在保证计算精度的同时，实现足够大的系统和足够长的时间尺度模拟？机器学习力场正是为解决这一“不可能三角”而生，它巧妙地融合了量子力学的精确与经典分子动力">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习力场的发展与应用：桥接量子精度与经典效率的计算利器">
<meta property="og:url" content="https://qmwneb946.dpdns.org/2025/07/21/2025-07-22-022641/index.html">
<meta property="og:site_name" content="qmwneb946 的博客">
<meta property="og:description" content="大家好，我是你们的博主 qmwneb946。今天，我们要深入探讨一个在计算科学领域掀起革命性浪潮的话题：机器学习力场（Machine Learning Force Fields, MLFFs）。在原子尺度的模拟世界里，我们一直面临着一个核心矛盾：如何在保证计算精度的同时，实现足够大的系统和足够长的时间尺度模拟？机器学习力场正是为解决这一“不可能三角”而生，它巧妙地融合了量子力学的精确与经典分子动力">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://qmwneb946.dpdns.org/img/icon.png">
<meta property="article:published_time" content="2025-07-21T18:26:41.000Z">
<meta property="article:modified_time" content="2025-07-23T06:08:46.042Z">
<meta property="article:author" content="qmwneb946">
<meta property="article:tag" content="2025">
<meta property="article:tag" content="计算机科学">
<meta property="article:tag" content="机器学习力场的发展与应用">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://qmwneb946.dpdns.org/img/icon.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "机器学习力场的发展与应用：桥接量子精度与经典效率的计算利器",
  "url": "https://qmwneb946.dpdns.org/2025/07/21/2025-07-22-022641/",
  "image": "https://qmwneb946.dpdns.org/img/icon.png",
  "datePublished": "2025-07-21T18:26:41.000Z",
  "dateModified": "2025-07-23T06:08:46.042Z",
  "author": [
    {
      "@type": "Person",
      "name": "qmwneb946",
      "url": "https://github.com/qmwneb946"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://qmwneb946.dpdns.org/2025/07/21/2025-07-22-022641/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '机器学习力场的发展与应用：桥接量子精度与经典效率的计算利器',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2845632165165414" crossorigin="anonymous"></script><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="qmwneb946 的博客" type="application/atom+xml">
</head><body><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">qmwneb946 的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">机器学习力场的发展与应用：桥接量子精度与经典效率的计算利器</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">机器学习力场的发展与应用：桥接量子精度与经典效率的计算利器<a class="post-edit-link" href="https://github.com/qmwneb946/blog/edit/main/source/_posts/2025-07-22-022641.md" title="编辑" target="_blank"><i class="fas fa-pencil-alt"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-07-21T18:26:41.000Z" title="发表于 2025-07-22 02:26:41">2025-07-22</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-07-23T06:08:46.042Z" title="更新于 2025-07-23 14:08:46">2025-07-23</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/">计算机科学</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><p>大家好，我是你们的博主 qmwneb946。今天，我们要深入探讨一个在计算科学领域掀起革命性浪潮的话题：机器学习力场（Machine Learning Force Fields, MLFFs）。在原子尺度的模拟世界里，我们一直面临着一个核心矛盾：如何在保证计算精度的同时，实现足够大的系统和足够长的时间尺度模拟？机器学习力场正是为解决这一“不可能三角”而生，它巧妙地融合了量子力学的精确与经典分子动力学的效率，为材料科学、化学和生物学研究打开了新的大门。</p>
<h2 id="引言：计算科学的“不可能三角”">引言：计算科学的“不可能三角”</h2>
<p>想象一下，你想要预测一种新材料的特性，或者理解一种复杂酶的催化机理。这些问题都要求我们深入到原子甚至电子的层面去观察和计算它们之间的相互作用。在计算科学中，模拟原子和分子的行为主要有两大类方法：</p>
<ol>
<li>
<p><strong>第一性原理方法（Ab Initio Methods）</strong>：以量子力学为基础，从最基本的物理原理出发，不依赖任何实验参数。密度泛函理论（Density Functional Theory, DFT）是其中的主力。它们能提供极高的精度，准确捕捉电子运动和化学键的形成与断裂。但其计算成本高昂，通常与体系原子数的立方甚至更高次幂成正比（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>N</mi><mn>3</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N^3)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 或更高），这意味着它们只能应用于数百个原子以下的小体系，模拟时间也极其有限（纳秒甚至皮秒级别）。</p>
</li>
<li>
<p><strong>经典力场方法（Classical Force Fields）</strong>：这些方法基于牛顿力学，将原子视为点粒子，它们之间的相互作用通过预定义的势函数（例如，Lennard-Jones 势、键长势、键角势等）来描述。它们通常是经验性的，参数来源于实验数据或量子力学计算。经典力场的计算效率极高，通常与体系原子数呈线性或平方关系（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span> 或 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>N</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>），可以模拟百万甚至亿万个原子，时间尺度达到微秒甚至毫秒。然而，它们的精度受限于参数化的准确性和泛化能力，无法精确描述化学键的形成与断裂，对未知体系或极端条件下的行为预测能力有限。</p>
</li>
</ol>
<p>这两种方法各有优势，但也都存在显著的局限性。我们需要一种能够兼顾量子力学精度和经典力场效率的方法，来应对日益复杂的研究挑战。机器学习力场的出现，正是为了填补这一鸿沟，它如同一个巧妙的桥梁，连接了量子世界的精确细节与宏观模拟的广阔尺度。</p>
<h2 id="传统原子间相互作用势的局限性">传统原子间相互作用势的局限性</h2>
<p>在深入了解机器学习力场之前，我们有必要回顾一下传统方法的局限性，这正是 MLFFs 诞生的原因。</p>
<h3 id="量子力学方法的精度与代价">量子力学方法的精度与代价</h3>
<p>量子力学（Quantum Mechanics, QM）方法，例如密度泛函理论（DFT）、哈特里-福克（Hartree-Fock, HF）以及更高级的耦合簇（Coupled Cluster, CC）方法，旨在从电子层面精确描述原子间的相互作用。</p>
<ul>
<li>
<p><strong>优点</strong>：</p>
<ul>
<li><strong>高精度</strong>：能够准确地计算分子的能量、结构、光谱性质，并预测化学反应途径。</li>
<li><strong>普适性</strong>：基于基本物理定律，无需经验参数，理论上适用于所有原子和分子体系。</li>
<li><strong>化学键的动态描述</strong>：能够精确描述化学键的形成、断裂以及电子结构的动态变化。</li>
</ul>
</li>
<li>
<p><strong>缺点</strong>：</p>
<ul>
<li><strong>计算成本高昂</strong>：这是 QM 方法最主要的瓶颈。对于一个包含 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> 个原子的体系，DFT 的计算复杂度通常是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>N</mi><mn>3</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N^3)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>N</mi><mn>4</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N^4)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，而更精确的方法如 CC 甚至可能达到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>N</mi><mn>7</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N^7)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">7</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>。这意味着，计算数百个原子的体系可能需要数天甚至数周，而对于数千个原子，则几乎不可能在合理时间内完成。</li>
<li><strong>时间尺度限制</strong>：由于每次原子移动后都需要重新求解电子薛定谔方程，QM 分子动力学模拟（ab initio MD, AIMD）通常只能持续几皮秒（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>10</mn><mrow><mo>−</mo><mn>12</mn></mrow></msup></mrow><annotation encoding="application/x-tex">10^{-12}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">12</span></span></span></span></span></span></span></span></span></span></span></span> 秒）到几十皮秒，远低于许多物理和化学过程的真实时间尺度（微秒、毫秒甚至秒）。</li>
</ul>
</li>
</ul>
<h3 id="经典力场的效率与经验性">经典力场的效率与经验性</h3>
<p>经典力场（Classical Force Fields, CFFs）则采取了截然不同的策略。它们将原子视为点粒子，并用简单的数学函数（势函数）来描述它们之间的相互作用。</p>
<ul>
<li>
<p><strong>优点</strong>：</p>
<ul>
<li><strong>计算效率极高</strong>：通常计算复杂度为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span> 到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>N</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，使得它们能够模拟包含数百万甚至数十亿个原子的体系，并持续微秒到毫秒的模拟时间。这对于研究大分子（如蛋白质、DNA）、液体、聚合物和纳米材料至关重要。</li>
<li><strong>可解释性</strong>：势函数的各项通常对应于明确的物理意义（键长、键角、二面角、非键相互作用等）。</li>
</ul>
</li>
<li>
<p><strong>缺点</strong>：</p>
<ul>
<li><strong>经验性参数</strong>：力场的参数通常是根据大量实验数据或 QM 计算数据拟合而来的。这使得力场对训练数据覆盖的化学空间非常敏感。</li>
<li><strong>泛化能力差</strong>：针对特定分子或材料优化的力场，在应用于不同化学环境或新的体系时，其精度往往会急剧下降，甚至完全失效。例如，为蛋白质设计的力场可能不适用于无机材料。</li>
<li><strong>无法描述化学反应</strong>：经典力场中的键长、键角等参数是固定的，它们无法描述化学键的形成与断裂，因此不能用于模拟化学反应过程。少数例外如 ReaxFF 尝试通过键序来处理反应，但其精度仍远不如 QM。</li>
<li><strong>缺乏电子结构信息</strong>：经典力场无法提供电子层面的信息，因此无法预测电荷转移、极化效应等现象。</li>
</ul>
</li>
</ul>
<h3 id="力场的“精度-效率”困境">力场的“精度-效率”困境</h3>
<p>综上所述，传统的计算方法陷入了一个“精度-效率”的困境：高精度的量子力学计算成本太高，难以扩展到大尺度和长时间；而高效率的经典力场又牺牲了精度和普适性，无法准确描述复杂的化学过程。这种困境严重限制了我们对许多重要科学问题的理解和探索，尤其是在材料设计、药物研发和能源科学等前沿领域。机器学习力场的兴起，正是为了打破这一僵局。</p>
<h2 id="机器学习力场的兴起：桥接量子与经典">机器学习力场的兴起：桥接量子与经典</h2>
<p>机器学习力场（MLFFs）的核心思想在于：利用机器学习模型来学习原子核位置与体系势能（以及作用在原子上的力）之间的复杂映射关系。这个映射关系是通过大量的、高精度的量子力学计算数据来训练的。一旦模型训练完成，它就能以经典力场的计算效率来预测体系的能量和力，从而在不牺牲太多精度的前提下，大大扩展模拟的规模和时间。</p>
<h3 id="核心思想">核心思想</h3>
<p>MLFFs 的基本理念可以概括为：<strong>“教”计算机从量子力学数据中“学习”原子间相互作用的规律，然后用这个“学到”的模型进行快速预测。</strong> 这种学习的目标是构建一个高维函数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mo stretchy="false">(</mo><mi mathvariant="bold">R</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">E(\mathbf{R})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord mathbf">R</span><span class="mclose">)</span></span></span></span>，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi></mrow><annotation encoding="application/x-tex">E</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span></span></span></span> 是体系的总能量，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">R</mi></mrow><annotation encoding="application/x-tex">\mathbf{R}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6861em;"></span><span class="mord mathbf">R</span></span></span></span> 代表所有原子的三维坐标集合。一旦能量函数已知，作用在每个原子上的力 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">F</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{F}_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8361em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathbf">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 就可以通过能量对原子坐标的负梯度来计算：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="bold">F</mi><mi>i</mi></msub><mo>=</mo><mo>−</mo><msub><mi mathvariant="normal">∇</mi><mi>i</mi></msub><mi>E</mi><mo stretchy="false">(</mo><mi mathvariant="bold">R</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathbf{F}_i = -\nabla_i E(\mathbf{R}) 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8361em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathbf">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord mathbf">R</span><span class="mclose">)</span></span></span></span></span></p>
<p>传统的经典力场是用预定义的、固定形式的函数（如简谐势、Lennard-Jones 势）来表达这个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mo stretchy="false">(</mo><mi mathvariant="bold">R</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">E(\mathbf{R})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mopen">(</span><span class="mord mathbf">R</span><span class="mclose">)</span></span></span></span>。而 MLFFs 则让机器学习模型从数据中“发现”这个函数的复杂形式，它不再局限于简单的解析表达式，而是可以捕捉到更复杂、非线性的相互作用。</p>
<h3 id="为什么可行">为什么可行</h3>
<p>机器学习之所以能够胜任这项任务，是基于以下几个关键观察：</p>
<ol>
<li><strong>势能面（Potential Energy Surface, PES）的连续性与平滑性</strong>：体系的势能是原子坐标的连续且平滑函数。机器学习模型，特别是神经网络和高斯过程回归，非常擅长学习这种高维的、非线性的连续映射。</li>
<li><strong>局部性原理（Locality Principle）</strong>：原子间的相互作用主要是局部的。一个原子的势能贡献主要取决于其周围近邻原子的构型，而不是整个体系中所有原子的遥远影响。这使得我们可以将总能量分解为原子能量贡献之和，从而简化学习问题并提高可扩展性。</li>
<li><strong>数据驱动范式</strong>：量子力学计算虽然昂贵，但一旦完成，其结果（原子构型、能量、力）就成为高质量的“训练数据”。机器学习模型正是利用这些数据进行训练和泛化。</li>
</ol>
<h3 id="基本范式">基本范式</h3>
<p>构建一个机器学习力场通常遵循以下基本步骤：</p>
<ol>
<li>
<p><strong>数据生成（Data Generation）</strong>：</p>
<ul>
<li>使用高精度的第一性原理方法（通常是 DFT）计算一系列不同原子构型下的体系总能量和作用在每个原子上的力。这些构型应该尽可能多样化，覆盖体系可能经历的各种状态（如平衡态、振动态、熔融态、反应过渡态等）。</li>
<li>这一步是 MLFF 的基础，数据的质量和多样性直接决定了 MLFF 的精度和泛化能力。</li>
</ul>
</li>
<li>
<p><strong>特征表示/描述符（Feature Representation / Descriptors）</strong>：</p>
<ul>
<li>直接使用原子坐标作为机器学习模型的输入是不可行的，因为它不满足平移、旋转和原子置换对称性。</li>
<li>因此，需要设计一种原子环境的“描述符”（Descriptor），将每个原子及其周围环境编码成一个固定长度的、满足对称性的数值向量。这个描述符应该是对物理信息的高度压缩和抽象。</li>
</ul>
</li>
<li>
<p><strong>机器学习模型训练（Model Training）</strong>：</p>
<ul>
<li>选择合适的机器学习模型（如神经网络、高斯过程回归等）。</li>
<li>模型接收原子描述符作为输入，输出每个原子的能量贡献（或者整个体系的能量），以及对应的力。</li>
<li>模型通过最小化预测能量和力与 QM 计算得到的真实能量和力之间的误差来训练。</li>
</ul>
</li>
<li>
<p><strong>预测与应用（Prediction &amp; Application）</strong>：</p>
<ul>
<li>一旦模型训练完成并通过验证，就可以将其部署到分子动力学模拟或结构弛豫中。</li>
<li>在模拟的每一步，模型会快速计算当前构型下的能量和力，然后原子根据牛顿运动定律移动到新的位置，如此循环。</li>
<li>由于预测速度快，MLFFs 可以进行大规模、长时间的模拟，达到传统 QM 无法企及的尺度。</li>
</ul>
</li>
</ol>
<p>接下来的章节，我们将对这些核心组成部分进行更深入的探讨。</p>
<h2 id="核心组成部分深入解析">核心组成部分深入解析</h2>
<p>构建一个高性能的机器学习力场，每个环节都至关重要。</p>
<h3 id="数据：高质量第一性原理计算">数据：高质量第一性原理计算</h3>
<p>高质量的训练数据是 MLFF 成功的基石。正如机器学习领域的格言“Garbage in, garbage out”，如果训练数据质量不高或覆盖不全面，即使是再强大的模型也无法学到准确的物理规律。</p>
<ul>
<li><strong>数据来源</strong>：
<ul>
<li>通常来源于量子力学计算，特别是密度泛函理论（DFT）。DFT 因其在精度和计算成本之间的良好平衡，成为生成大量训练数据的首选方法。</li>
<li>对于更小的体系或需要极高精度的情况，可以使用更高级的 QM 方法，如耦合簇（Coupled Cluster）。</li>
</ul>
</li>
<li><strong>数据多样性</strong>：
<ul>
<li><strong>构型空间覆盖</strong>：训练数据应尽可能覆盖体系在模拟过程中可能遇到的所有构型，包括平衡结构、弛豫结构、振动模式、高能量的非平衡态、熔融态、相变中间态、甚至化学反应的过渡态等。仅仅在平衡结构附近取样是远远不够的，因为分子动力学模拟会探索广阔的构型空间。</li>
<li><strong>温度和压力</strong>：在不同温度和压力下进行采样可以增加数据的多样性。</li>
<li><strong>缺陷和表面</strong>：对于材料科学，需要包含缺陷（空位、间隙原子、位错）和表面（不同晶面、吸附物）的构型。</li>
</ul>
</li>
<li><strong>数据规模</strong>：
<ul>
<li>训练数据点的数量取决于体系的复杂性、原子种类、以及所选的 ML 模型。通常需要数千到数十万个 QM 计算构型。对于更复杂的体系或要求更高泛化能力的力场，可能需要百万甚至更多的数据点。</li>
</ul>
</li>
<li><strong>数据生成策略</strong>：
<ul>
<li><strong>分子动力学采样</strong>：在不同温度下进行短时间的 AIMD 模拟，收集沿轨迹的构型、能量和力。这是一种非常有效且常用的方法。</li>
<li><strong>结构扰动</strong>：对平衡结构进行随机的原子位移扰动。</li>
<li><strong>主动学习（Active Learning）</strong>：这是一种更智能的数据生成策略。在主动学习框架中，MLFF 模型在模拟过程中不断评估其对新构型的预测不确定性。当遇到模型不确定的构型时（例如，预测误差大，或多个模型集成结果不一致），程序会停止并触发一次新的 QM 计算来获取该构型的真实能量和力，然后将新数据加入训练集，重新训练模型。这种迭代式的策略能够显著减少所需的 QM 计算次数，同时提高 MLFF 的泛化能力和可靠性。</li>
</ul>
</li>
</ul>
<h3 id="原子环境描述符：如何表示原子">原子环境描述符：如何表示原子</h3>
<p>原子环境描述符是将原子局部环境编码成机器学习模型可理解的、固定长度数值向量的关键步骤。一个好的描述符必须满足以下物理要求：</p>
<ul>
<li><strong>平移不变性（Translation Invariance）</strong>：描述符不应随体系整体平移而改变。</li>
<li><strong>旋转不变性（Rotation Invariance）</strong>：描述符不应随体系整体旋转而改变。</li>
<li><strong>原子置换不变性（Permutation Invariance）</strong>：对于同种原子，它们的顺序不应影响描述符。</li>
<li><strong>连续性（Continuity）</strong>：原子微小的位移应该导致描述符的微小变化，以保证势能面的光滑性。</li>
<li><strong>完备性（Completeness）</strong>：描述符应该能够充分区分不同的原子环境。</li>
<li><strong>紧凑性（Compactness）</strong>：描述符的维度不应过高，以提高计算效率。</li>
</ul>
<p>一些常见的原子环境描述符包括：</p>
<ol>
<li>
<p><strong>基于径向分布函数（Radial Distribution Function-based）</strong>：</p>
<ul>
<li><strong>高斯型径向基函数（Gaussian-type radial basis functions）</strong>：将原子周围的径向分布分解为一系列高斯函数。</li>
<li><strong>Smooth Overlap of Atomic Positions (SOAP)</strong>：由芬兰赫尔辛基大学的 Albert Bartók 和 Gábor Csányi 等人提出，它通过计算原子环境的局部原子密度，然后用球谐函数和径向基函数展开来表征。SOAP 描述符因其对局部环境的细致描述能力和良好的对称性，在许多 MLFF 框架中得到广泛应用。</li>
</ul>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>p</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold">r</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mo>∑</mo><mrow><mi>j</mi><mo mathvariant="normal">≠</mo><mi>i</mi></mrow></munder><mi>exp</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mo>−</mo><mfrac><mrow><mi mathvariant="normal">∣</mi><mi mathvariant="bold">r</mi><mo>−</mo><msub><mi mathvariant="bold">R</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><msup><mi mathvariant="normal">∣</mi><mn>2</mn></msup></mrow><mrow><mn>2</mn><msup><mi>σ</mi><mn>2</mn></msup></mrow></mfrac><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">p_i(\mathbf{r}) = \sum_{j \neq i} \exp\left(-\frac{|\mathbf{r} - \mathbf{R}_{ij}|^2}{2\sigma^2}\right) 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathbf">r</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.9293em;vertical-align:-1.4382em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight"><span class="mrel mtight"><span class="mord vbox mtight"><span class="thinbox mtight"><span class="rlap mtight"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="inner"><span class="mord mtight"><span class="mrel mtight"></span></span></span><span class="fix"></span></span></span></span></span><span class="mrel mtight">=</span></span><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4382em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">exp</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.4911em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7401em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣</span><span class="mord mathbf">r</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathbf">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span></span></span></span></span></p>
<p>然后将 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>i</mi></msub><mo stretchy="false">(</mo><mi mathvariant="bold">r</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p_i(\mathbf{r})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathbf">r</span><span class="mclose">)</span></span></span></span> 在以原子 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 为中心的球坐标系中展开。</p>
</li>
<li>
<p><strong>基于球谐函数（Spherical Harmonics-based）</strong>：</p>
<ul>
<li><strong>原子中心对称函数（Atom-centered Symmetry Functions, ACSFs）</strong>：由 Behler 和 Parrinello 提出，是最早且最成功的描述符之一。ACSFs 是一系列手动设计的函数，旨在捕捉原子周围环境的局部对称性。它们通常包含径向分量（描述距离和原子对）和角向分量（描述键角和原子三元组）。</li>
<li>SOAP 描述符也属于此类，因为它使用了球谐函数展开。</li>
</ul>
</li>
<li>
<p><strong>图神经网络（Graph Neural Networks, GNNs）</strong>：</p>
<ul>
<li>近年来，GNNs 成为 MLFF 领域的热点。在 GNN 中，分子或材料被表示为图：原子是节点，键是边。GNN 通过在图上进行“消息传递”（Message Passing）来学习原子环境的表示。每个原子节点会聚合其邻居节点的信息，经过多轮迭代后，每个节点的特征向量就编码了其局部环境的丰富信息。</li>
<li>GNN 天然地满足平移和置换不变性。旋转不变性则需要特殊设计，例如通过使用张量或等变表示（Equivariant Representations）。典型的 GNN-based MLFFs 框架如 SchNet、DimeNet、PaiNN、NequIP 和 MACE 都采用了这种思路。</li>
<li>它们的优势在于，描述符的生成是“端到端”的，即模型自己学习如何从原始坐标中提取特征，而无需手动设计复杂的函数。</li>
</ul>
</li>
</ol>
<h3 id="机器学习模型：学习能量与力">机器学习模型：学习能量与力</h3>
<p>选择合适的机器学习模型来学习描述符到能量和力的映射，是 MLFF 架构的另一个核心。</p>
<ol>
<li>
<p><strong>高斯过程回归（Gaussian Process Regression, GPR）</strong>：</p>
<ul>
<li><strong>原理</strong>：GPR 是一种非参数的贝叶斯机器学习方法，它将函数视为一个高斯过程的实现。它可以提供预测值，同时给出预测的不确定性，这对于主动学习和评估力场的可靠性非常有用。</li>
<li><strong>代表性工作</strong>：**高斯近似势（Gaussian Approximation Potentials, GAP）**是 GPR 在 MLFF 领域最成功的应用之一，由剑桥大学的 Gábor Csányi 团队开发。GAP 通常与 SOAP 描述符结合使用。</li>
<li><strong>优点</strong>：
<ul>
<li>提供不确定性量化。</li>
<li>对小到中等规模的训练数据表现优秀。</li>
<li>理论基础坚实。</li>
</ul>
</li>
<li><strong>缺点</strong>：
<ul>
<li>计算复杂度高：训练和预测的计算成本通常与训练数据点的立方（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msubsup><mi>N</mi><mrow><mi>t</mi><mi>r</mi><mi>a</mi><mi>i</mi><mi>n</mi></mrow><mn>3</mn></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N_{train}^3)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0728em;vertical-align:-0.2587em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-2.4413em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">ain</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2587em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>）甚至平方（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msubsup><mi>N</mi><mrow><mi>t</mi><mi>r</mi><mi>a</mi><mi>i</mi><mi>n</mi></mrow><mn>2</mn></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N_{train}^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0728em;vertical-align:-0.2587em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-2.4413em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">ain</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2587em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>）成正比，这使得它难以扩展到非常大的训练集。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>神经网络（Neural Networks, NN）</strong>：</p>
<ul>
<li><strong>原理</strong>：神经网络通过多层非线性变换来学习复杂的输入-输出映射。它能够拟合高度非线性的函数关系，并且在足够大的数据量下，具有强大的泛化能力。</li>
<li><strong>原子神经网络（Atom-centered Neural Networks）</strong>：
<ul>
<li><strong>Behler-Parrinello Neural Networks (BPNNs)</strong>：由 Jörg Behler 和 Michele Parrinello 于 2007 年提出，是第一个广泛成功的原子神经网络模型。它的核心思想是：将体系的总能量分解为每个原子的能量贡献之和，即 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mo>=</mo><msub><mo>∑</mo><mi>i</mi></msub><msub><mi>E</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">E = \sum_i E_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0497em;vertical-align:-0.2997em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.162em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。每个原子 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 的能量贡献 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">E_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是通过一个小型神经网络计算的，该网络的输入是原子 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 的原子环境描述符（如 ACSFs）。这种“局部-全局”的分解方式使得模型具有良好的可扩展性。</li>
<li><strong>优点</strong>：
<ul>
<li>可扩展性好：一旦训练完成，预测复杂度通常接近线性 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span>。</li>
<li>能够学习非常复杂的非线性关系。</li>
<li>适用于大规模训练数据。</li>
</ul>
</li>
<li><strong>缺点</strong>：
<ul>
<li>需要大量的训练数据。</li>
<li>“黑箱”特性，模型内部工作原理难以解释。</li>
<li>不确定性量化不如 GPR 直接。</li>
</ul>
</li>
</ul>
</li>
<li><strong>图神经网络（Graph Neural Networks, GNNs）</strong>：
<ul>
<li>作为神经网络的最新发展，GNNs 在处理图结构数据方面表现出色，与原子间相互作用的局部性和键连接特性天然契合。</li>
<li><strong>SchNet</strong> (Schütt et al., 2018)：第一个广泛应用于分子和材料模拟的端到端 GNN 模型。它直接从原子坐标和原子类型构建图，然后通过多层“消息传递”机制学习原子嵌入（embeddings），最终将这些嵌入映射到原子能量贡献。</li>
<li><strong>Deep Potential (DP)</strong> (Wang Han and Weinan E et al., 2018)：由王涵和鄂维南团队开发，以其超高的效率和在大规模数据集上的卓越表现而闻名。DP 结合了精心设计的局部坐标变换和深度神经网络，可以处理百万原子级别的模拟。</li>
<li><strong>DimeNet/PaiNN/NequIP/MACE</strong>：这些都是更先进的 GNN 架构，它们引入了等变性（equivariance）的概念。传统的 GNNs 只能保证旋转不变性（输入旋转不影响输出），而等变 GNNs 确保输入旋转会导致输出以可预测的方式旋转（例如，力向量也会相应旋转）。这对于力场预测至关重要，因为力是矢量。MACE (Message Passing ATOMATIC-based) 是当前表现非常优异的等变 GNN 模型，结合了先进的消息传递和原子类型依赖的权重。</li>
<li><strong>优点</strong>：
<ul>
<li>端到端学习，无需手动设计描述符。</li>
<li>可扩展性好，效率高。</li>
<li>等变 GNNs 能够自然地处理力的矢量特性，提高精度和稳定性。</li>
</ul>
</li>
<li><strong>缺点</strong>：
<ul>
<li>模型架构复杂，训练所需计算资源大。</li>
<li>对训练数据的质量和覆盖范围要求高。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="训练策略与损失函数">训练策略与损失函数</h3>
<p>MLFF 的训练目标是让模型预测的能量和力尽可能接近 QM 计算的真实值。这通常通过定义一个损失函数（Loss Function）并最小化它来实现。</p>
<ul>
<li><strong>损失函数</strong>：通常是能量误差和力误差的加权和。<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>L</mi><mo>=</mo><msub><mi>w</mi><mi>E</mi></msub><mo>∑</mo><mo stretchy="false">(</mo><msub><mi>E</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi></mrow></msub><mo>−</mo><msub><mi>E</mi><mrow><mi>Q</mi><mi>M</mi></mrow></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><msub><mi>w</mi><mi>F</mi></msub><mo>∑</mo><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><msub><mi>F</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi></mrow></msub><mo>−</mo><msub><mi>F</mi><mrow><mi>Q</mi><mi>M</mi></mrow></msub><mi mathvariant="normal">∣</mi><msup><mi mathvariant="normal">∣</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">L = w_E \sum (E_{pred} - E_{QM})^2 + w_F \sum ||F_{pred} - F_{QM}||^2 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.6em;vertical-align:-0.55em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">E</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-symbol large-op" style="position:relative;top:0em;">∑</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">re</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1502em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">QM</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.6em;vertical-align:-0.55em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">F</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-symbol large-op" style="position:relative;top:0em;">∑</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">∣∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">re</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1502em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">QM</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></p>
其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">E_{pred}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">re</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">F_{pred}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">re</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 是模型的预测值，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mrow><mi>Q</mi><mi>M</mi></mrow></msub></mrow><annotation encoding="application/x-tex">E_{QM}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">QM</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F</mi><mrow><mi>Q</mi><mi>M</mi></mrow></msub></mrow><annotation encoding="application/x-tex">F_{QM}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">QM</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 是 QM 算得的真实值。<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>E</mi></msub></mrow><annotation encoding="application/x-tex">w_E</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">E</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>F</mi></msub></mrow><annotation encoding="application/x-tex">w_F</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">F</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是权重因子，用于平衡能量和力在训练中的重要性。</li>
<li><strong>力的重要性</strong>：在分子动力学模拟中，力的准确性比能量更重要，因为它直接决定了原子的运动轨迹。如果力预测不准确，即使能量误差很小，模拟也可能不稳定或导致错误的物理行为。因此，通常会给力项赋予更高的权重。</li>
<li><strong>训练算法</strong>：常用的优化算法包括 Adam、L-BFGS 等，它们通过梯度下降来迭代更新模型的参数。</li>
</ul>
<h2 id="典型机器学习力场框架">典型机器学习力场框架</h2>
<p>理解了核心组成部分后，我们来看看一些具有代表性的 MLFF 框架，它们是当前研究和应用的主流。</p>
<h3 id="Behler-Parrinello-Neural-Networks-BPNNs">Behler-Parrinello Neural Networks (BPNNs)</h3>
<ul>
<li><strong>诞生</strong>：2007 年由 Behler 和 Parrinello 首次提出，开创了原子神经网络的先河。</li>
<li><strong>核心思想</strong>：
<ul>
<li><strong>能量分解</strong>：体系总能量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi><mo>=</mo><msub><mo>∑</mo><mi>i</mi></msub><msub><mi>E</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">E = \sum_i E_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0497em;vertical-align:-0.2997em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.162em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">E_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是原子 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 的能量贡献。</li>
<li><strong>局部环境</strong>：每个原子 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 的能量贡献 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">E_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 只取决于其局部化学环境。</li>
<li><strong>原子对称函数（ACSFs）</strong>：使用一系列精心设计的 ACSFs 作为输入描述符，编码了原子 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 周围的径向和角向分布信息。</li>
<li><strong>神经网络</strong>：每个原子 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 都有一个独立的（或共享权重的）小型前馈神经网络，将 ACSFs 作为输入，输出 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">E_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。</li>
</ul>
</li>
<li><strong>特点</strong>：
<ul>
<li>模块化、可扩展性好。</li>
<li>能够处理多组分体系。</li>
<li>是最早实现 QM 精度和经典效率结合的成功范例。</li>
</ul>
</li>
<li><strong>局限性</strong>：ACSFs 的设计需要经验，且其完备性和平滑性可能不如一些更先进的描述符。</li>
</ul>
<h3 id="Gaussian-Approximation-Potentials-GAP">Gaussian Approximation Potentials (GAP)</h3>
<ul>
<li><strong>核心思想</strong>：使用高斯过程回归（GPR）来拟合势能面。GPR 的优势在于能够提供预测的不确定性，这对于主动学习和评估力场的可靠性至关重要。</li>
<li><strong>描述符</strong>：通常与 Smooth Overlap of Atomic Positions (SOAP) 描述符结合使用。SOAP 能够提供对局部原子环境的精细、高维且对称不变的描述。</li>
<li><strong>特点</strong>：
<ul>
<li><strong>不确定性量化</strong>：这是 GAP 的标志性优势，对于指导数据采样和评估模型置信度非常有用。</li>
<li><strong>对小数据集表现出色</strong>：在训练数据量相对较少时，GAP 往往比神经网络模型表现更好。</li>
<li><strong>适用于复杂势能面</strong>：GPR 强大的非参数拟合能力使其能够捕捉复杂的能量景观。</li>
</ul>
</li>
<li><strong>局限性</strong>：GPR 的计算复杂度高（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msubsup><mi>N</mi><mrow><mi>t</mi><mi>r</mi><mi>a</mi><mi>i</mi><mi>n</mi></mrow><mn>3</mn></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N_{train}^3)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0728em;vertical-align:-0.2587em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-2.4413em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">ain</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2587em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>），限制了其在超大数据集上的应用。</li>
</ul>
<h3 id="Deep-Potential-DP">Deep Potential (DP)</h3>
<ul>
<li><strong>核心思想</strong>：由王涵和鄂维南团队开发，旨在构建能够处理大规模体系并具有高效率的深度学习力场。它强调“Deep”（深度学习）和“Potential”（势），通过端到端的深度神经网络来学习势能函数。</li>
<li><strong>描述符/嵌入网络</strong>：DP 使用一个独特的“嵌入网络”（embedding network）来学习原子环境的描述符。这个网络将原始笛卡尔坐标作为输入，通过巧妙的设计，它能够将原子局部环境编码成一个固定长度的向量，同时满足平移、旋转和原子置换对称性。这个过程是数据驱动的，无需手动设计对称函数。</li>
<li><strong>能量网络</strong>：在嵌入网络之后，另一个深度神经网络将嵌入向量作为输入，输出每个原子的能量贡献。</li>
<li><strong>特点</strong>：
<ul>
<li><strong>高效率</strong>：DP 在预测阶段的计算速度非常快，使其能够轻松地模拟百万甚至上亿个原子的体系。</li>
<li><strong>大规模数据处理</strong>：设计上能够处理超大规模的训练数据集。</li>
<li><strong>端到端</strong>：描述符和势能函数都是通过深度学习模型共同优化的。</li>
</ul>
</li>
<li><strong>代表性应用</strong>：在水、金属、催化剂等多种复杂体系中展现出卓越性能，特别是对大规模材料模拟有巨大推动作用。</li>
</ul>
<h3 id="基于图神经网络（GNN）的力场：SchNet-DimeNet-PaiNN-NequIP-MACE">基于图神经网络（GNN）的力场：SchNet, DimeNet, PaiNN, NequIP, MACE</h3>
<p>这是当前 MLFF 领域最活跃和前沿的方向，它们将分子/材料结构视为图，并利用 GNNs 的强大表达能力。</p>
<ul>
<li><strong>共同原理</strong>：
<ul>
<li><strong>图表示</strong>：原子是图的节点，原子间的相互作用或键是边。</li>
<li><strong>消息传递</strong>：GNN 通过迭代的消息传递机制，让每个原子节点从其邻居节点聚合信息，不断更新其特征向量。多轮消息传递后，每个原子节点的特征向量就能捕捉到其局部环境的丰富信息。</li>
<li><strong>端到端学习</strong>：描述符的提取和能量/力的预测都是通过神经网络完成，无需手动定义特征工程。</li>
</ul>
</li>
<li><strong>SchNet</strong>：
<ul>
<li>作为 GNNs 应用于量子化学的早期突破，它引入了连续滤波卷积层，允许在图上传播原子特征，并直接预测能量和力。其消息传递机制可以理解为原子间距离依赖的“注意力”。</li>
</ul>
</li>
<li><strong>DimeNet/PaiNN</strong>：
<ul>
<li>这些模型进一步引入了角度信息（三体项），并优化了消息传递过程，以更好地捕捉非键相互作用和立体化学特征。</li>
<li>PaiNN (PaiNN: Parallel Attention for Invariant Neural Networks) 特别强调了并行计算和等变性。</li>
</ul>
</li>
<li><strong>NequIP/MACE</strong>：
<ul>
<li><strong>等变性（Equivariance）</strong>：这是这些模型最重要的进展。与传统的旋转不变性（旋转输入不改变标量输出，如能量）不同，等变模型在输入旋转时，其矢量输出（如力）也会以相应的方式旋转。这确保了预测的物理量（如力、偶极矩）的物理一致性。NequIP (Neural Equivariant Interatomic Potentials) 和 MACE (Message Passing ATOMIC Equivariant) 都是基于 E(3) 等变神经网络，利用群论原理设计网络架构，使其天然地满足所有刚体运动的对称性。</li>
<li><strong>MACE</strong>：是当前等变 GNN 领域的一个顶尖模型，在原子表示和消息传递方面做了进一步优化，结合了多体相互作用和更好的表征能力，在多个基准测试中展现出卓越的精度和泛化能力。</li>
</ul>
</li>
<li><strong>GNN-based MLFF 的优势</strong>：
<ul>
<li>强大的表征能力和泛化能力。</li>
<li>端到端学习，简化了模型开发流程。</li>
<li>等变 GNNs 保证了物理量的对称性，提高了模拟的稳定性和准确性。</li>
</ul>
</li>
</ul>
<h2 id="机器学习力场的应用">机器学习力场的应用</h2>
<p>机器学习力场已经不再是实验室里的概念，它们正在材料科学、化学和生物学等多个领域发挥着越来越重要的作用，并逐步克服传统方法的限制。</p>
<h3 id="材料科学">材料科学</h3>
<p>MLFFs 在材料设计和模拟中展现出巨大潜力，特别是对于需要探索复杂相变、缺陷行为或高通量筛选的场景。</p>
<ul>
<li><strong>相变和结构探索</strong>：
<ul>
<li>传统 QM 方法难以模拟材料在不同温度和压力下的相变过程（例如，晶体-非晶态转变、晶体结构转变），因为这需要长时间的原子运动和大量原子。MLFFs 能够以 QM 精度模拟这些过程，例如研究高压下氢的金属化、固态材料的熔融行为等。</li>
<li>结合结构搜索算法（如粒子群优化、遗传算法），MLFFs 可以高效地探索材料的未知稳定或亚稳态结构。</li>
</ul>
</li>
<li><strong>缺陷形成与迁移</strong>：
<ul>
<li>材料中的缺陷（空位、间隙原子、位错）对材料的性能至关重要。MLFFs 能够模拟缺陷的形成能、扩散路径和迁移率，这对于理解材料的机械强度、导电性、辐照损伤等性质非常关键。</li>
</ul>
</li>
<li><strong>表面吸附与催化</strong>：
<ul>
<li>催化反应通常发生在材料表面，涉及复杂的吸附、解吸和化学键形成/断裂过程。MLFFs 能够模拟气体分子在催化剂表面的吸附位点、吸附能以及反应路径，从而帮助设计高效催化剂。</li>
</ul>
</li>
<li><strong>高通量筛选与设计</strong>：
<ul>
<li>结合高通量计算框架，MLFFs 可以快速评估大量候选材料的结构稳定性、力学性质、热学性质等，从而加速新材料的发现和设计，例如寻找新型热电材料、电池电极材料等。</li>
</ul>
</li>
</ul>
<h3 id="化学与生物学">化学与生物学</h3>
<p>MLFFs 也正在改变我们理解和模拟复杂化学反应以及生物大分子行为的方式。</p>
<ul>
<li><strong>反应路径探索与动力学</strong>：
<ul>
<li>传统经典力场无法处理化学反应。MLFFs 由于其能够准确捕捉化学键的形成与断裂，可以用于识别反应的过渡态、计算反应能垒，并模拟复杂的化学反应动力学，如有机反应、酶催化反应等。</li>
<li>这对于理解反应机理、优化合成路线具有里程碑式的意义。</li>
</ul>
</li>
<li><strong>大分子模拟</strong>：
<ul>
<li>蛋白质折叠、药物-靶点结合、膜转运等生物学过程涉及数万到数百万个原子，且时间尺度跨度大（微秒到毫秒）。虽然仍有挑战，但 MLFFs 正在为这些大规模生物体系的模拟提供新的可能性，它们可以在 QM 级别的精度上处理局部关键区域的相互作用，同时保持整体体系的效率。</li>
<li>例如，可以用于模拟蛋白质特定区域的构象变化或药物分子与受体结合时的诱导契合过程。</li>
</ul>
</li>
<li><strong>溶剂化效应</strong>：
<ul>
<li>在溶液中的化学反应和生物过程深受溶剂化效应的影响。MLFFs 可以模拟溶剂分子与溶质之间的复杂相互作用，从而更准确地描述溶液相中的性质和反应。</li>
</ul>
</li>
</ul>
<h3 id="克服传统限制">克服传统限制</h3>
<p>总而言之，机器学习力场最大的优势在于：</p>
<ul>
<li><strong>可处理大系统和长时尺度</strong>：它打破了传统 QM 模拟的原子数量和时间尺度的限制，使得我们能够以 QM 精度研究更接近真实世界尺度的体系。</li>
<li><strong>保持 QM 精度</strong>：通过从高精度 QM 数据中学习，MLFFs 能够保留第一性原理计算的准确性，远超传统经验力场。</li>
<li><strong>处理复杂化学过程</strong>：能够描述化学键的形成与断裂，这是传统经典力场无法做到的，为模拟化学反应提供了强大工具。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这是一个概念性的Python伪代码，展示MLFF训练的基本流程</span></span><br><span class="line"><span class="comment"># 实际的MLFF框架会复杂得多，涉及C++/CUDA优化等</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf <span class="comment"># 假设使用TensorFlow或PyTorch</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 模拟数据 (来自DFT计算)</span></span><br><span class="line"><span class="comment"># 假设我们有N个构型的数据</span></span><br><span class="line"><span class="comment"># configurations: 列表，每个元素是一个原子的[x, y, z]坐标数组</span></span><br><span class="line"><span class="comment"># energies: 列表，每个元素是对应构型的总能量</span></span><br><span class="line"><span class="comment"># forces: 列表，每个元素是对应构型的所有原子上的力向量数组</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 伪造一些数据，实际中这些数据来自DFT计算</span></span><br><span class="line">num_configs = <span class="number">1000</span></span><br><span class="line">num_atoms = <span class="number">10</span></span><br><span class="line">configs_data = [np.random.rand(num_atoms, <span class="number">3</span>) * <span class="number">5</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_configs)]</span><br><span class="line">energies_data = [np.random.rand() * <span class="number">100</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_configs)]</span><br><span class="line">forces_data = [np.random.rand(num_atoms, <span class="number">3</span>) * <span class="number">10</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_configs)] <span class="comment"># 力是能量的负梯度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 原子环境描述符生成</span></span><br><span class="line"><span class="comment"># 这一步是关键，将原子坐标转换为对称不变的特征向量</span></span><br><span class="line"><span class="comment"># 假设我们有一个名为 &#x27;generate_descriptor&#x27; 的函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_descriptor</span>(<span class="params">atom_coords_for_config, atom_idx, all_atom_types, cutoff_radius=<span class="number">6.0</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    概念性函数：根据给定构型中特定原子的局部环境，生成描述符。</span></span><br><span class="line"><span class="string">    这可以是SOAP、ACSFs或其他GNN的内部特征提取。</span></span><br><span class="line"><span class="string">    返回一个描述符向量。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 实际实现会非常复杂，涉及邻居列表、对称函数、球谐展开等</span></span><br><span class="line">    <span class="comment"># 这里只是一个占位符，返回一个随机向量作为示例</span></span><br><span class="line">    <span class="keyword">return</span> np.random.rand(<span class="number">64</span>) <span class="comment"># 假设描述符维度是64</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 为每个原子生成描述符和对应的能量贡献/力</span></span><br><span class="line">all_descriptors = []</span><br><span class="line">all_atom_energies_qm = [] <span class="comment"># 假设QM可以给出原子能量贡献，或者我们总能量除以原子数</span></span><br><span class="line">all_atom_forces_qm = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, config <span class="keyword">in</span> <span class="built_in">enumerate</span>(configs_data):</span><br><span class="line">    current_config_atom_types = [<span class="string">&#x27;H&#x27;</span>] * num_atoms <span class="comment"># 简化，假设都是氢原子</span></span><br><span class="line">    current_config_energy = energies_data[i]</span><br><span class="line">    current_config_forces = forces_data[i]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 简单地将总能量平均分配给每个原子作为原子能量贡献的“粗略目标”</span></span><br><span class="line">    <span class="comment"># 更严谨的做法是在训练时只用总能量和总力作为监督信号</span></span><br><span class="line">    <span class="comment"># 或者用一个内部机制从总能量推断原子能量</span></span><br><span class="line">    avg_atom_energy = current_config_energy / num_atoms</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> atom_idx <span class="keyword">in</span> <span class="built_in">range</span>(num_atoms):</span><br><span class="line">        descriptor = generate_descriptor(config, atom_idx, current_config_atom_types)</span><br><span class="line">        all_descriptors.append(descriptor)</span><br><span class="line">        all_atom_energies_qm.append(avg_atom_energy) <span class="comment"># 概念性原子能量</span></span><br><span class="line">        all_atom_forces_qm.append(current_config_forces[atom_idx])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">descriptors_train, descriptors_test, \</span><br><span class="line">energies_train, energies_test, \</span><br><span class="line">forces_train, forces_test = train_test_split(</span><br><span class="line">    np.array(all_descriptors),</span><br><span class="line">    np.array(all_atom_energies_qm), <span class="comment"># 训练原子能量贡献</span></span><br><span class="line">    np.array(all_atom_forces_qm),   <span class="comment"># 训练原子上的力</span></span><br><span class="line">    test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;训练集大小: <span class="subst">&#123;<span class="built_in">len</span>(descriptors_train)&#125;</span> 个原子环境&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;测试集大小: <span class="subst">&#123;<span class="built_in">len</span>(descriptors_test)&#125;</span> 个原子环境&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 机器学习模型训练 (原子神经网络示例)</span></span><br><span class="line"><span class="comment"># 构建一个简单的全连接神经网络来预测原子能量和力</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_nn_model</span>(<span class="params">input_dim</span>):</span><br><span class="line">    descriptor_input = tf.keras.Input(shape=(input_dim,), name=<span class="string">&#x27;descriptor_input&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 预测原子能量的网络分支</span></span><br><span class="line">    x_energy = tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(descriptor_input)</span><br><span class="line">    x_energy = tf.keras.layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(x_energy)</span><br><span class="line">    atom_energy_output = tf.keras.layers.Dense(<span class="number">1</span>, name=<span class="string">&#x27;atom_energy_output&#x27;</span>)(x_energy) <span class="comment"># 输出标量能量</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 预测原子力的网络分支 (这里简化了，实际力预测复杂得多，通常通过对能量的自动微分获得)</span></span><br><span class="line">    <span class="comment"># 对于力的直接预测，通常会设计为多输出，每个输出代表一个维度（x,y,z）</span></span><br><span class="line">    <span class="comment"># 或者，更常见的是，模型只预测能量，然后使用自动微分来计算力</span></span><br><span class="line">    <span class="comment"># 为了演示，我们先假设可以“直接”预测力</span></span><br><span class="line">    x_force = tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(descriptor_input)</span><br><span class="line">    x_force = tf.keras.layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(x_force)</span><br><span class="line">    atom_force_output = tf.keras.layers.Dense(<span class="number">3</span>, name=<span class="string">&#x27;atom_force_output&#x27;</span>)(x_force) <span class="comment"># 输出3D力向量</span></span><br><span class="line"></span><br><span class="line">    model = tf.keras.Model(inputs=descriptor_input, outputs=[atom_energy_output, atom_force_output])</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line">descriptor_dim = descriptors_train.shape[<span class="number">1</span>]</span><br><span class="line">mlff_model = build_nn_model(descriptor_dim)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 损失函数: 能量和力误差的加权和</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">total_loss</span>(<span class="params">y_true_energy, y_pred_energy, y_true_force, y_pred_force, energy_weight=<span class="number">1.0</span>, force_weight=<span class="number">100.0</span></span>):</span><br><span class="line">    energy_loss = tf.keras.losses.MSE(y_true_energy, y_pred_energy)</span><br><span class="line">    force_loss = tf.keras.losses.MSE(y_true_force, y_pred_force) <span class="comment"># MSE for force vectors</span></span><br><span class="line">    <span class="keyword">return</span> energy_weight * energy_loss + force_weight * force_loss</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译模型</span></span><br><span class="line"><span class="comment"># 注意：在实际的MLFFs中，力的计算通常是通过对预测能量进行自动微分得到的，</span></span><br><span class="line"><span class="comment"># 而不是直接预测力。这样可以保证力和能量之间的物理一致性。</span></span><br><span class="line"><span class="comment"># 这里的模型设计是为了简化演示多输出和加权损失。</span></span><br><span class="line">mlff_model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=&#123;<span class="string">&#x27;atom_energy_output&#x27;</span>: <span class="string">&#x27;mse&#x27;</span>, <span class="string">&#x27;atom_force_output&#x27;</span>: <span class="string">&#x27;mse&#x27;</span>&#125;,</span><br><span class="line">                  loss_weights=&#123;<span class="string">&#x27;atom_energy_output&#x27;</span>: <span class="number">1.0</span>, <span class="string">&#x27;atom_force_output&#x27;</span>: <span class="number">100.0</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n模型结构概览:&quot;</span>)</span><br><span class="line">mlff_model.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n开始训练模型...&quot;</span>)</span><br><span class="line">history = mlff_model.fit(</span><br><span class="line">    descriptors_train,</span><br><span class="line">    &#123;<span class="string">&#x27;atom_energy_output&#x27;</span>: energies_train, <span class="string">&#x27;atom_force_output&#x27;</span>: forces_train&#125;,</span><br><span class="line">    epochs=<span class="number">10</span>, <span class="comment"># 实际需要更多epochs</span></span><br><span class="line">    batch_size=<span class="number">32</span>,</span><br><span class="line">    validation_split=<span class="number">0.1</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n训练完成。&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 预测与应用 (概念性，在MD模拟中使用)</span></span><br><span class="line"><span class="comment"># 假设在MD模拟的每一步，我们有一个新的构型 new_config</span></span><br><span class="line"><span class="comment"># 我们需要预测其能量和力</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># new_config = np.random.rand(num_atoms, 3) * 5</span></span><br><span class="line"><span class="comment"># new_descriptors = []</span></span><br><span class="line"><span class="comment"># for atom_idx in range(num_atoms):</span></span><br><span class="line"><span class="comment">#     new_descriptors.append(generate_descriptor(new_config, atom_idx, [&#x27;H&#x27;]*num_atoms))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># predicted_atom_energies, predicted_atom_forces = mlff_model.predict(np.array(new_descriptors))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># total_predicted_energy = np.sum(predicted_atom_energies)</span></span><br><span class="line"><span class="comment"># total_predicted_forces = predicted_atom_forces # 这是每个原子的力，需要组织成总力</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># print(f&quot;\n新构型的总预测能量: &#123;total_predicted_energy.item()&#125;&quot;)</span></span><br><span class="line"><span class="comment"># print(f&quot;新构型的原子预测力: \n&#123;total_predicted_forces&#125;&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 然后这些能量和力会用于更新原子位置 (牛顿运动方程)</span></span><br><span class="line"><span class="comment"># F = ma</span></span><br><span class="line"><span class="comment"># a = F/m</span></span><br><span class="line"><span class="comment"># r_new = r_old + v*dt + 0.5*a*dt^2</span></span><br><span class="line"><span class="comment"># v_new = v_old + a*dt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在真实分子动力学中，通常还会集成一个MD引擎 (如 LAMMPS, OpenMM, ASE)</span></span><br><span class="line"><span class="comment"># 来处理时间积分、周期性边界条件、温度/压力控制等复杂细节。</span></span><br></pre></td></tr></table></figure>
<p><strong>代码块说明</strong>：<br>
上述伪代码是一个高度简化的概念性示例，旨在说明 MLFF 的基本流程。</p>
<ol>
<li><strong>数据生成</strong>：模拟了从 DFT 得到的构型、能量和力数据。在实际应用中，这是通过专业的 QM 软件完成的。</li>
<li><strong>描述符生成</strong>：<code>generate_descriptor</code> 函数是概念性的，它代表了将原子局部环境转换为机器学习模型可理解的数值向量的关键步骤。这一步是 MLFF 领域的核心研究内容（如 SOAP, ACSFs, GNNs 内部的特征提取）。</li>
<li><strong>模型训练</strong>：构建了一个简单的原子神经网络（类似于 BPNN 的简化版），它接收描述符作为输入，预测每个原子的能量贡献和力。<strong>需要特别指出的是</strong>：在实际的 MLFF 训练中，力的预测通常是通过对能量输出进行自动微分（autodiff）得到的，以确保力和能量之间的物理一致性。这里的代码为了演示方便，将力也作为神经网络的直接输出。损失函数结合了能量和力的误差，并对力项给予了更高的权重，这在实践中是常见的做法。</li>
<li><strong>预测与应用</strong>：简要说明了训练好的 MLFF 如何在分子动力学模拟中使用，以快速计算能量和力，从而推进原子运动。</li>
</ol>
<p>这个代码块旨在帮助理解 MLFF 的“数据-&gt;特征-&gt;模型-&gt;预测”核心流程，而非一个可以直接运行的完整 MLFF 实现。</p>
<h2 id="挑战与未来展望">挑战与未来展望</h2>
<p>尽管机器学习力场取得了显著进展，但它仍然是一个快速发展的领域，面临着诸多挑战，同时也充满了令人兴奋的未来可能性。</p>
<h3 id="挑战">挑战</h3>
<ol>
<li>
<p><strong>数据覆盖与外推性（Data Extrapolation and Coverage）</strong>：</p>
<ul>
<li>MLFFs 的精度高度依赖于训练数据的覆盖范围。如果模拟的构型或化学环境超出了训练数据的范围（即外推），模型的预测精度会急剧下降，甚至给出物理上不合理的结果。</li>
<li>例如，如果模型只在平衡态附近训练，就难以准确预测化学反应的过渡态或极端条件下的行为。</li>
<li><strong>缓解策略</strong>：主动学习是解决这一问题的主要方法，它通过在模拟过程中识别模型不确定的构型并触发新的 QM 计算，从而逐步扩展训练数据的覆盖范围。</li>
</ul>
</li>
<li>
<p><strong>泛化能力（Generalizability）</strong>：</p>
<ul>
<li>当前大多数 MLFFs 都是针对特定体系（例如，某种金属、某个有机分子家族）或少数几种原子训练的。构建一个能够同时准确模拟多种元素、不同化学环境、甚至不同相（固、液、气）的“通用”或“全局”力场仍然是一个巨大的挑战。</li>
<li>这要求模型能够学习跨体系的普适性物理规律，而不仅仅是记忆训练数据。</li>
</ul>
</li>
<li>
<p><strong>训练数据成本（Training Data Cost）</strong>：</p>
<ul>
<li>虽然 MLFF 在部署后效率高，但生成高质量的 QM 训练数据仍然是计算成本最高的环节。对于复杂体系或需要大量数据的模型，QM 计算时间仍然非常可观。</li>
<li><strong>缓解策略</strong>：更高效的主动学习算法、迁移学习（Transfer Learning）和预训练模型等技术有望进一步降低数据需求。</li>
</ul>
</li>
<li>
<p><strong>可解释性（Interpretability）</strong>：</p>
<ul>
<li>特别是基于深度神经网络的 MLFFs，其“黑箱”特性使得我们很难理解模型内部是如何学习和做出预测的。这限制了我们从模型中获取新的物理或化学洞察。</li>
<li><strong>研究方向</strong>：发展可解释性 AI（XAI）技术，尝试可视化和分析神经网络的内部表征。</li>
</ul>
</li>
<li>
<p><strong>不确定性量化（Uncertainty Quantification, UQ）</strong>：</p>
<ul>
<li>一个可靠的 MLFF 不仅要提供预测值，还要提供预测的置信度或不确定性。这对于主动学习、识别模型失效区域以及评估模拟结果的可靠性至关重要。</li>
<li><strong>现状</strong>：GPR 模型天然提供不确定性，而神经网络通常需要借助集成学习（Ensemble Learning）、贝叶斯神经网络或蒙特卡洛 dropout 等方法来估计不确定性。</li>
</ul>
</li>
</ol>
<h3 id="未来展望">未来展望</h3>
<p>MLFFs 领域正在经历指数级的发展，未来的方向充满希望：</p>
<ol>
<li>
<p><strong>更通用的力场（More General/Universal Force Fields）</strong>：</p>
<ul>
<li>终极目标是开发能够覆盖周期表所有元素、处理各种化学键合类型和材料相的“通用”力场。这可能需要超大规模的训练数据集和更强大的模型架构。</li>
<li>像 Open Catalyst Project 这样的公开数据集和基准测试正在推动这一目标。</li>
<li><strong>预训练与微调</strong>：借鉴自然语言处理领域的成功经验，训练一个在海量分子/材料数据上预训练的基础模型，然后针对特定任务进行微调，有望大大提高泛化能力和数据效率。</li>
</ul>
</li>
<li>
<p><strong>更高效的数据生成策略（More Efficient Data Generation）</strong>：</p>
<ul>
<li>主动学习将继续是核心方向，未来会发展出更智能、更鲁棒的主动学习算法。</li>
<li><strong>生成式模型</strong>：利用生成对抗网络（GANs）或变分自编码器（VAEs）等生成式模型来生成新的、具有多样性的训练构型，可以补充 QM 数据。</li>
</ul>
</li>
<li>
<p><strong>整合量子效应（Integrating Quantum Effects）</strong>：</p>
<ul>
<li>目前的 MLFFs 大多基于玻恩-奥本海默近似（Born-Oppenheimer approximation），即电子运动远快于原子核，电子态对核运动瞬时响应。</li>
<li>未来将探索如何将核量子效应（如零点能、隧穿效应）以及非玻恩-奥本海默效应（如电子激发态、非绝热过程）整合到 MLFF 中，以模拟更复杂的物理化学现象。</li>
</ul>
</li>
<li>
<p><strong>多尺度模拟（Multiscale Simulations）</strong>：</p>
<ul>
<li>MLFFs 可以作为连接微观量子世界与宏观连续介质模拟之间的桥梁。例如，在分子动力学模拟中，只在关键区域使用 MLFF，而在其他区域使用经典力场或粗粒化模型，从而实现不同尺度之间的无缝衔接。</li>
</ul>
</li>
<li>
<p><strong>硬件加速与软件生态（Hardware Acceleration &amp; Software Ecosystem）</strong>：</p>
<ul>
<li>图形处理器（GPUs）和专用 AI 芯片（TPUs, NPUs）的快速发展将为 MLFF 的训练和部署提供更强大的计算能力。</li>
<li>开源工具包（如 Deepmd-kit, FLARE, NequIP 等）和友好的软件生态系统将极大地促进 MLFFs 的普及和应用。</li>
</ul>
</li>
</ol>
<h2 id="总结">总结</h2>
<p>机器学习力场代表了计算科学领域的一个重大范式转变。它们通过巧妙地结合数据驱动的机器学习模型与物理第一性原理计算，成功地跨越了长期存在的“精度-效率”鸿沟。</p>
<p>从最初的 Behler-Parrinello 神经网络到基于高斯过程的 GAP，再到如今风头正劲的 Deep Potential 和等变图神经网络，MLFFs 的发展日新月异。它们不仅在材料科学、化学和生物学领域取得了令人瞩目的成就，使得我们能够模拟以前无法触及的体系规模和时间尺度，更是为我们打开了理解和设计复杂体系的新视角。</p>
<p>当然，挑战依然存在，如数据外推性、通用性以及高昂的训练数据成本。然而，随着主动学习、更强大的模型架构和不断完善的软件生态系统的发展，我们有理由相信，机器学习力场将在未来十年继续引领计算科学的前沿，成为材料设计、药物发现和能源科学等领域不可或缺的强大工具。</p>
<p>作为一名技术爱好者，我被这个领域所蕴含的无限可能性深深吸引。机器学习力场不仅仅是算法上的进步，它更是科学发现的一种新模式，预示着一个数据与物理深度融合的计算科学新时代。让我们拭目以待，看它们如何继续改变我们的世界。</p>
<hr>
<p>感谢您的阅读！我是 qmwneb946，下次再见！</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a target="_blank" rel="noopener" href="https://github.com/qmwneb946">qmwneb946</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://qmwneb946.dpdns.org/2025/07/21/2025-07-22-022641/">https://qmwneb946.dpdns.org/2025/07/21/2025-07-22-022641/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://opensource.org/licenses/MIT" target="_blank">MIT License</a> 许可协议。转载请注明来源 <a href="https://qmwneb946.dpdns.org" target="_blank">qmwneb946 的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/2025/">2025</a><a class="post-meta__tags" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/">计算机科学</a><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%9B%E5%9C%BA%E7%9A%84%E5%8F%91%E5%B1%95%E4%B8%8E%E5%BA%94%E7%94%A8/">机器学习力场的发展与应用</a></div><div class="post-share"><div class="social-share" data-image="/img/icon.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/07/21/2025-07-22-022722/" title="绿色天空的引擎：生物航油的催化转化奥秘"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">绿色天空的引擎：生物航油的催化转化奥秘</div></div><div class="info-2"><div class="info-item-1">引言：飞向碳中和的蔚蓝梦想 亲爱的技术爱好者们，我是qmwneb946，你们的博主。今天，我们不聊代码架构，也不深挖算法优化，而是将目光投向一个既古老又新兴的领域——化学工程，特别是其中一个对人类未来至关重要的方向：生物航油的催化转化。 在人类社会快速发展的今天，航空业作为连接全球的重要纽带，其对环境的影响也日益凸显。传统的航空燃料（煤油）燃烧会产生大量的二氧化碳、氮氧化物、硫氧化物及颗粒物，对全球气候变暖和空气污染造成了不可忽视的贡献。据国际航空运输协会（IATA）估计，航空业约占全球人为碳排放的2%至3%。面对日益严峻的气候挑战和“碳中和”的全球共识，开发可持续的替代燃料已成为当务之急。 生物航油（Sustainable Aviation Fuel, SAF），作为一种由生物质资源（如废弃油脂、农林废弃物、藻类等）转化而来的航空燃料，其生命周期内的碳排放量远低于传统化石燃料，最高可减少80%以上。这使得它成为实现航空业“净零排放”目标的关键技术路径。然而，将多样化的生物质转化为符合严格航空燃料标准的产物，并非易事。这其中，催化转化技术扮演了核心角色，它是连接生物质与航空煤油分...</div></div></div></a><a class="pagination-related" href="/2025/07/21/2025-07-22-022055/" title="离子淌度质谱技术：维度之舞与解析之力"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">离子淌度质谱技术：维度之舞与解析之力</div></div><div class="info-2"><div class="info-item-1">亲爱的技术与数学爱好者们， 我是 qmwneb946。今天，我们即将踏上一次深入探讨现代分析科学前沿技术的旅程——聚焦于“离子淌度质谱技术”（Ion Mobility Spectrometry Mass Spectrometry, IMS-MS）。在浩瀚的生命科学、材料科学、环境科学乃至药物研发领域，我们无时无刻不在与复杂的化学混合物打交道。如何在这混沌中抽丝剥茧，精准识别每一个分子，甚至洞察其三维构象，是分析科学家们孜孜以求的目标。传统的质谱技术凭借其无与伦比的灵敏度和鉴定能力，已成为不可或缺的工具。然而，面对日益精细的分析需求，单一的质荷比（m/z）维度有时显得力不从心。 想象一下，你面对的是一个由成千上万种分子组成的汤，其中许多分子拥有相同的分子量（即相同的m/z），但它们的化学结构却截然不同，甚至是彼此的异构体。传统质谱会把它们视为同一个信号，从而遗漏了至关重要的结构细节。这就是离子淌度质谱技术应运而生的核心驱动力——它为我们引入了一个全新的、基于分子大小和形状的“分离维度”，与质谱的m/z维度正交结合，使得原本无法区分的分子得以“各归各位”，让分析的“画卷”从二维平面跃...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/07/18/2025-07-18-082418/" title="机器学习算法的公平性问题：技术挑战与伦理困境"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">机器学习算法的公平性问题：技术挑战与伦理困境</div></div><div class="info-2"><div class="info-item-1">引言 机器学习 (ML) 正在迅速改变我们的世界，从医疗保健到金融，再到刑事司法系统，它的应用几乎无处不在。然而，随着 ML 系统的广泛部署，一个越来越令人担忧的问题浮出水面：公平性。  算法的输出可能反映并放大现有的社会偏见，导致对某些群体的不公平待遇。本文将深入探讨机器学习算法中的公平性问题，分析其技术根源和伦理困境，并探讨一些可能的解决方案。 偏见是如何进入机器学习模型的？ 机器学习模型的公平性问题并非源于算法本身的恶意，而是源于其训练数据的偏见。  这些偏见可能来自多种来源： 数据收集与标注  样本选择偏差 (Sampling Bias):  如果训练数据未能充分代表所有群体，模型就会学习到一个有偏的表示。例如，如果一个用于预测贷款偿还能力的模型主要基于白人申请人的数据，它可能会对少数族裔申请人产生不公平的负面预测。 测量偏差 (Measurement Bias):  数据收集过程中的错误或不一致也会引入偏见。例如，在犯罪预测模型中，如果某些社区的执法力度更大，导致该社区的犯罪数据被过度记录，模型就会对该社区产生负面偏见。 标注偏差 (Label Bias):  人工标注...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082429/" title="区块链技术与数字版权保护：一场技术与法律的博弈"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">区块链技术与数字版权保护：一场技术与法律的博弈</div></div><div class="info-2"><div class="info-item-1">大家好，我是你们的技术博主X，今天我们来聊一个非常热门的话题：区块链技术如何应用于数字版权保护。在数字内容飞速发展的时代，版权侵权问题日益严峻，传统的版权保护机制显得力不从心。而区块链技术，凭借其去中心化、不可篡改、透明等特性，为解决这一难题提供了新的思路。 区块链技术概述 首先，让我们简单回顾一下区块链技术的基本原理。区块链是一个由多个区块组成的链式数据库，每个区块包含一系列经过加密验证的交易记录。这些交易记录一旦被写入区块链，就无法被篡改或删除，保证了数据的完整性和安全性。  其核心技术包括：  密码学:  确保数据的安全性和完整性，例如哈希算法和数字签名。 共识机制:  例如工作量证明（PoW）和权益证明（PoS），用于维护区块链的统一性和安全性，防止恶意攻击。 分布式账本: 数据分布在多个节点上，提高了系统的容错性和安全性。  区块链如何保护数字版权 区块链技术可以为数字版权保护提供多种方案，主要体现在以下几个方面： 版权登记与确权 传统的版权登记流程繁琐且耗时，而区块链可以提供一个快速、透明的版权登记平台。创作者可以将作品的哈希值（作品的数字指纹）记录到区块链上，以此证...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082438/" title="云计算中的数据安全与隐私：挑战与应对"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">云计算中的数据安全与隐私：挑战与应对</div></div><div class="info-2"><div class="info-item-1">云计算为企业和个人提供了强大的计算资源和数据存储能力，但也带来了新的安全与隐私挑战。本文将深入探讨云计算环境下的数据安全与隐私问题，分析其背后的技术机制，并提出一些有效的应对策略。 云计算安全风险剖析 云计算环境中，数据安全与隐私面临着多种威胁，主要包括： 数据泄露与丢失 这是最常见的风险之一。  数据可能由于云提供商的内部安全漏洞、恶意攻击（例如SQL注入、DDoS攻击）、员工失误或意外事件（例如硬件故障）而泄露或丢失。  对于敏感数据，例如医疗记录、金融信息和个人身份信息，这种风险尤为严重。 数据违规 数据违规是指未经授权访问或使用数据的情况。这可能导致数据被篡改、删除或用于非法目的。  法规遵从性（例如 GDPR, CCPA）的压力也使得数据违规的代价越来越高。 权限管理不足 缺乏细粒度的访问控制机制可能导致数据被未授权的个人或应用程序访问。  复杂的云环境中，权限的管理和审核是一个极大的挑战。 数据完整性问题 云环境中的数据完整性需要得到保障，确保数据没有被未经授权的修改或破坏。  这需要使用诸如哈希算法和数字签名等技术来验证数据的完整性。 数据合规性 不同国家和地区对数...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082500/" title="物联网设备的网络安全协议：挑战与解决方案"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">物联网设备的网络安全协议：挑战与解决方案</div></div><div class="info-2"><div class="info-item-1">物联网 (IoT) 设备正以前所未有的速度渗透到我们生活的方方面面，从智能家居到工业自动化，再到医疗保健。然而，这种广泛的连接也带来了巨大的安全风险。由于物联网设备通常资源受限，安全性设计常常被忽视，导致它们成为网络攻击的理想目标。本文将深入探讨物联网设备面临的网络安全挑战，以及用于增强其安全性的各种协议和技术。 物联网安全面临的挑战 物联网设备的安全挑战与传统IT系统大相径庭，主要体现在以下几个方面： 资源受限 许多物联网设备具有有限的处理能力、内存和存储空间。这使得部署复杂的加密算法和安全协议变得困难，同时也增加了运行时开销。  运行资源消耗较大的安全软件可能会影响设备的性能甚至导致其崩溃。 设备异构性 物联网生态系统由各种各样的设备组成，这些设备运行不同的操作系统，使用不同的编程语言，并具有不同的安全特性。这种异构性使得实施统一的安全策略变得极其复杂。  很难找到一个适用于所有设备的通用安全解决方案。 数据隐私与安全 物联网设备通常会收集大量敏感数据，例如个人健康信息、位置数据和财务信息。保护这些数据的隐私和安全至关重要，但由于设备自身的安全缺陷和数据传输过程中的漏洞，这成...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082528/" title="量子计算对现代密码学的威胁：后量子密码学的挑战与机遇"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">量子计算对现代密码学的威胁：后量子密码学的挑战与机遇</div></div><div class="info-2"><div class="info-item-1">量子计算的飞速发展为许多领域带来了革命性的变革，但也对现有的密码体系构成了前所未有的挑战。本文将深入探讨量子计算如何威胁现代密码学，以及我们如何应对这一挑战。 量子计算的优势与密码学的困境 经典计算机基于比特，其值只能是 0 或 1。而量子计算机利用量子比特，可以同时表示 0 和 1 的叠加态，这使得它们能够进行并行计算，处理能力远超经典计算机。  这种巨大的计算能力为解决某些目前被认为是“不可解”的问题提供了可能性，其中就包括许多现代密码学的基石。 例如，RSA 算法，广泛应用于电子商务和安全通信，其安全性依赖于大数分解的困难性。经典计算机分解一个很大的数需要指数级的时间，因此被认为是安全的。然而，Shor 算法，一个在量子计算机上运行的算法，能够以多项式时间分解大数。这意味着，一台足够强大的量子计算机能够轻易破解 RSA 加密，从而威胁到大量的在线交易、数据安全以及国家安全。 同样，椭圆曲线密码学 (ECC)，另一种广泛使用的密码算法，其安全性也依赖于某些数学问题的复杂性。然而，量子计算机也能够有效地解决这些问题，例如离散对数问题。 Shor 算法与 Grover 算法：量子...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082537/" title="图论算法在社交网络分析中的应用"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">图论算法在社交网络分析中的应用</div></div><div class="info-2"><div class="info-item-1">社交网络已经成为我们生活中不可或缺的一部分。从Facebook和Twitter到微信和微博，这些平台连接着数十亿用户，产生着海量的数据。而理解这些数据，挖掘其背后的规律和价值，就需要借助强大的数学工具——图论。本文将深入探讨图论算法在社交网络分析中的多种应用。 社交网络的图表示 在图论中，社交网络可以被自然地表示为图 G=(V,E)G = (V, E)G=(V,E)，其中 VVV 代表用户集合（节点），EEE 代表用户之间的关系集合（边）。例如，在Facebook中，每个用户是一个节点，如果两个用户是朋友，则在他们之间存在一条无向边；在Twitter中，如果用户A关注用户B，则存在一条从A指向B的有向边。边的权重可以表示关系的强度（例如，朋友关系的亲密度，或者互动频率）。  这种图表示为我们分析社交网络提供了坚实的基础。 核心图论算法及其应用 社区发现 社区发现旨在将社交网络划分成多个紧密连接的社区（也称为集群）。这对于理解用户群体、推荐系统以及病毒式营销等都至关重要。常用的算法包括：  Louvain算法:  一种贪婪的启发式算法，通过迭代优化模块度来寻找最佳社区结构。模块度 ...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">qmwneb946</div><div class="author-info-description">一个专注于技术分享的个人博客，涵盖编程、算法、系统设计等内容</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">643</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">647</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/qmwneb946"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/qmwneb946" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:qmwneb946@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">代码与远方，技术与生活交织的篇章。</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%95%E8%A8%80%EF%BC%9A%E8%AE%A1%E7%AE%97%E7%A7%91%E5%AD%A6%E7%9A%84%E2%80%9C%E4%B8%8D%E5%8F%AF%E8%83%BD%E4%B8%89%E8%A7%92%E2%80%9D"><span class="toc-number">1.</span> <span class="toc-text">引言：计算科学的“不可能三角”</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%A0%E7%BB%9F%E5%8E%9F%E5%AD%90%E9%97%B4%E7%9B%B8%E4%BA%92%E4%BD%9C%E7%94%A8%E5%8A%BF%E7%9A%84%E5%B1%80%E9%99%90%E6%80%A7"><span class="toc-number">2.</span> <span class="toc-text">传统原子间相互作用势的局限性</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%87%8F%E5%AD%90%E5%8A%9B%E5%AD%A6%E6%96%B9%E6%B3%95%E7%9A%84%E7%B2%BE%E5%BA%A6%E4%B8%8E%E4%BB%A3%E4%BB%B7"><span class="toc-number">2.1.</span> <span class="toc-text">量子力学方法的精度与代价</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%8F%E5%85%B8%E5%8A%9B%E5%9C%BA%E7%9A%84%E6%95%88%E7%8E%87%E4%B8%8E%E7%BB%8F%E9%AA%8C%E6%80%A7"><span class="toc-number">2.2.</span> <span class="toc-text">经典力场的效率与经验性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8A%9B%E5%9C%BA%E7%9A%84%E2%80%9C%E7%B2%BE%E5%BA%A6-%E6%95%88%E7%8E%87%E2%80%9D%E5%9B%B0%E5%A2%83"><span class="toc-number">2.3.</span> <span class="toc-text">力场的“精度-效率”困境</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%9B%E5%9C%BA%E7%9A%84%E5%85%B4%E8%B5%B7%EF%BC%9A%E6%A1%A5%E6%8E%A5%E9%87%8F%E5%AD%90%E4%B8%8E%E7%BB%8F%E5%85%B8"><span class="toc-number">3.</span> <span class="toc-text">机器学习力场的兴起：桥接量子与经典</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3"><span class="toc-number">3.1.</span> <span class="toc-text">核心思想</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8F%AF%E8%A1%8C"><span class="toc-number">3.2.</span> <span class="toc-text">为什么可行</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E8%8C%83%E5%BC%8F"><span class="toc-number">3.3.</span> <span class="toc-text">基本范式</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E7%BB%84%E6%88%90%E9%83%A8%E5%88%86%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90"><span class="toc-number">4.</span> <span class="toc-text">核心组成部分深入解析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%EF%BC%9A%E9%AB%98%E8%B4%A8%E9%87%8F%E7%AC%AC%E4%B8%80%E6%80%A7%E5%8E%9F%E7%90%86%E8%AE%A1%E7%AE%97"><span class="toc-number">4.1.</span> <span class="toc-text">数据：高质量第一性原理计算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8E%9F%E5%AD%90%E7%8E%AF%E5%A2%83%E6%8F%8F%E8%BF%B0%E7%AC%A6%EF%BC%9A%E5%A6%82%E4%BD%95%E8%A1%A8%E7%A4%BA%E5%8E%9F%E5%AD%90"><span class="toc-number">4.2.</span> <span class="toc-text">原子环境描述符：如何表示原子</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%EF%BC%9A%E5%AD%A6%E4%B9%A0%E8%83%BD%E9%87%8F%E4%B8%8E%E5%8A%9B"><span class="toc-number">4.3.</span> <span class="toc-text">机器学习模型：学习能量与力</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5%E4%B8%8E%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">4.4.</span> <span class="toc-text">训练策略与损失函数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B8%E5%9E%8B%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%9B%E5%9C%BA%E6%A1%86%E6%9E%B6"><span class="toc-number">5.</span> <span class="toc-text">典型机器学习力场框架</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Behler-Parrinello-Neural-Networks-BPNNs"><span class="toc-number">5.1.</span> <span class="toc-text">Behler-Parrinello Neural Networks (BPNNs)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Gaussian-Approximation-Potentials-GAP"><span class="toc-number">5.2.</span> <span class="toc-text">Gaussian Approximation Potentials (GAP)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Deep-Potential-DP"><span class="toc-number">5.3.</span> <span class="toc-text">Deep Potential (DP)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88GNN%EF%BC%89%E7%9A%84%E5%8A%9B%E5%9C%BA%EF%BC%9ASchNet-DimeNet-PaiNN-NequIP-MACE"><span class="toc-number">5.4.</span> <span class="toc-text">基于图神经网络（GNN）的力场：SchNet, DimeNet, PaiNN, NequIP, MACE</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%8A%9B%E5%9C%BA%E7%9A%84%E5%BA%94%E7%94%A8"><span class="toc-number">6.</span> <span class="toc-text">机器学习力场的应用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9D%90%E6%96%99%E7%A7%91%E5%AD%A6"><span class="toc-number">6.1.</span> <span class="toc-text">材料科学</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8C%96%E5%AD%A6%E4%B8%8E%E7%94%9F%E7%89%A9%E5%AD%A6"><span class="toc-number">6.2.</span> <span class="toc-text">化学与生物学</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%8B%E6%9C%8D%E4%BC%A0%E7%BB%9F%E9%99%90%E5%88%B6"><span class="toc-number">6.3.</span> <span class="toc-text">克服传统限制</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8C%91%E6%88%98%E4%B8%8E%E6%9C%AA%E6%9D%A5%E5%B1%95%E6%9C%9B"><span class="toc-number">7.</span> <span class="toc-text">挑战与未来展望</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%91%E6%88%98"><span class="toc-number">7.1.</span> <span class="toc-text">挑战</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%AA%E6%9D%A5%E5%B1%95%E6%9C%9B"><span class="toc-number">7.2.</span> <span class="toc-text">未来展望</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">8.</span> <span class="toc-text">总结</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/23/hello-world/" title="Hello World">Hello World</a><time datetime="2025-07-23T06:08:46.095Z" title="发表于 2025-07-23 14:08:46">2025-07-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/23/%E5%8D%9A%E5%BC%88%E8%AE%BA%E5%9F%BA%E7%A1%80/" title="博弈论基础">博弈论基础</a><time datetime="2025-07-23T06:08:46.095Z" title="发表于 2025-07-23 14:08:46">2025-07-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/22/2025-07-23-060629/" title="实时操作系统RTOS的选型：决定嵌入式系统命运的关键抉择">实时操作系统RTOS的选型：决定嵌入式系统命运的关键抉择</a><time datetime="2025-07-22T22:06:29.000Z" title="发表于 2025-07-23 06:06:29">2025-07-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/22/2025-07-23-060515/" title="深入剖析 Redis 内部原理：从键值存储到分布式集群的奥秘">深入剖析 Redis 内部原理：从键值存储到分布式集群的奥秘</a><time datetime="2025-07-22T22:05:15.000Z" title="发表于 2025-07-23 06:05:15">2025-07-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/22/2025-07-23-060340/" title="微服务架构下的分布式事务：从理论到实践的深度探索">微服务架构下的分布式事务：从理论到实践的深度探索</a><time datetime="2025-07-22T22:03:40.000Z" title="发表于 2025-07-23 06:03:40">2025-07-23</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;2025 By qmwneb946</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.2</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css')
    if (true) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const getGiscusTheme = theme => theme === 'dark' ? 'dark' : 'light'

  const createScriptElement = config => {
    const ele = document.createElement('script')
    Object.entries(config).forEach(([key, value]) => {
      ele.setAttribute(key, value)
    })
    return ele
  }

  const loadGiscus = (el = document, key) => {
    const mappingConfig = isShuoshuo
      ? { 'data-mapping': 'specific', 'data-term': key }
      : { 'data-mapping': (option && option['data-mapping']) || 'pathname' }

    const giscusConfig = {
      src: 'https://giscus.app/client.js',
      'data-repo': 'qmwneb946/blog',
      'data-repo-id': 'R_kgDOPM6cWw',
      'data-category-id': 'DIC_kwDOPM6cW84CtEzo',
      'data-theme': getGiscusTheme(document.documentElement.getAttribute('data-theme')),
      'data-reactions-enabled': '1',
      crossorigin: 'anonymous',
      async: true,
      ...option,
      ...mappingConfig
    }

    const scriptElement = createScriptElement(giscusConfig)

    el.querySelector('#giscus-wrap').appendChild(scriptElement)

    if (isShuoshuo) {
      window.shuoshuoComment.destroyGiscus = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }
  }

  const changeGiscusTheme = theme => {
    const iframe = document.querySelector('#giscus-wrap iframe')
    if (iframe) {
      const message = {
        giscus: {
          setConfig: {
            theme: getGiscusTheme(theme)
          }
        }
      }
      iframe.contentWindow.postMessage(message, 'https://giscus.app')
    }
  }

  btf.addGlobalFn('themeChange', changeGiscusTheme, 'giscus')

  if (isShuoshuo) {
    'Giscus' === 'Giscus'
      ? window.shuoshuoComment = { loadComment: loadGiscus }
      : window.loadOtherComment = loadGiscus
    return
  }

  if ('Giscus' === 'Giscus' || !false) {
    if (false) btf.loadComment(document.getElementById('giscus-wrap'), loadGiscus)
    else loadGiscus()
  } else {
    window.loadOtherComment = loadGiscus
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>