<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>掌控与绽放：自然语言生成中的控制与多样性 | qmwneb946 的博客</title><meta name="author" content="qmwneb946"><meta name="copyright" content="qmwneb946"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="大家好，我是你们的老朋友 qmwneb946。 在人工智能浪潮席卷全球的今天，自然语言生成（NLG）无疑是其中最引人瞩目的领域之一。从自动写作、智能客服到代码生成、创意辅助，大型语言模型（LLMs）正以前所未有的速度改变着我们与数字世界的交互方式。然而，在惊叹于它们卓越的语言能力之余，我们也不禁思考：如何才能让这些强大的模型更好地“听话”——生成我们想要的内容、遵守特定的规则，同时又能保持“灵性”">
<meta property="og:type" content="article">
<meta property="og:title" content="掌控与绽放：自然语言生成中的控制与多样性">
<meta property="og:url" content="https://qmwneb946.dpdns.org/2025/07/21/2025-07-21-224212/index.html">
<meta property="og:site_name" content="qmwneb946 的博客">
<meta property="og:description" content="大家好，我是你们的老朋友 qmwneb946。 在人工智能浪潮席卷全球的今天，自然语言生成（NLG）无疑是其中最引人瞩目的领域之一。从自动写作、智能客服到代码生成、创意辅助，大型语言模型（LLMs）正以前所未有的速度改变着我们与数字世界的交互方式。然而，在惊叹于它们卓越的语言能力之余，我们也不禁思考：如何才能让这些强大的模型更好地“听话”——生成我们想要的内容、遵守特定的规则，同时又能保持“灵性”">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://qmwneb946.dpdns.org/img/icon.png">
<meta property="article:published_time" content="2025-07-21T14:42:12.000Z">
<meta property="article:modified_time" content="2025-07-23T10:38:26.142Z">
<meta property="article:author" content="qmwneb946">
<meta property="article:tag" content="科技前沿">
<meta property="article:tag" content="2025">
<meta property="article:tag" content="自然语言生成的控制与多样性">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://qmwneb946.dpdns.org/img/icon.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "掌控与绽放：自然语言生成中的控制与多样性",
  "url": "https://qmwneb946.dpdns.org/2025/07/21/2025-07-21-224212/",
  "image": "https://qmwneb946.dpdns.org/img/icon.png",
  "datePublished": "2025-07-21T14:42:12.000Z",
  "dateModified": "2025-07-23T10:38:26.142Z",
  "author": [
    {
      "@type": "Person",
      "name": "qmwneb946",
      "url": "https://github.com/qmwneb946"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://qmwneb946.dpdns.org/2025/07/21/2025-07-21-224212/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '掌控与绽放：自然语言生成中的控制与多样性',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2845632165165414" crossorigin="anonymous"></script><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="qmwneb946 的博客" type="application/atom+xml">
</head><body><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">qmwneb946 的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">掌控与绽放：自然语言生成中的控制与多样性</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">掌控与绽放：自然语言生成中的控制与多样性<a class="post-edit-link" href="https://github.com/qmwneb946/blog/edit/main/source/_posts/2025-07-21-224212.md" title="编辑" target="_blank"><i class="fas fa-pencil-alt"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-07-21T14:42:12.000Z" title="发表于 2025-07-21 22:42:12">2025-07-21</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-07-23T10:38:26.142Z" title="更新于 2025-07-23 18:38:26">2025-07-23</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%A7%91%E6%8A%80%E5%89%8D%E6%B2%BF/">科技前沿</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><p>大家好，我是你们的老朋友 qmwneb946。</p>
<p>在人工智能浪潮席卷全球的今天，自然语言生成（NLG）无疑是其中最引人瞩目的领域之一。从自动写作、智能客服到代码生成、创意辅助，大型语言模型（LLMs）正以前所未有的速度改变着我们与数字世界的交互方式。然而，在惊叹于它们卓越的语言能力之余，我们也不禁思考：如何才能让这些强大的模型更好地“听话”——生成我们想要的内容、遵守特定的规则，同时又能保持“灵性”——避免重复、产生多样且富有创意的输出？</p>
<p>这正是我们今天要深入探讨的核心问题：自然语言生成中的“控制”与“多样性”。它们是NLG的两大基石，如同硬币的两面，既相互依存又充满挑战。控制，意味着我们能够引导模型按照既定目标、风格、结构甚至语义来生成文本；而多样性，则关乎模型输出的广度、新颖性和非重复性。在理想的NLG系统中，两者缺一不可，只有达到巧妙的平衡，我们才能真正解锁语言模型在现实世界中的巨大潜力。</p>
<p>今天，我将带大家一起穿越NLG技术的演进之路，从基础概念入手，逐步深入到实现控制与多样性的各种前沿策略，包括经典的采样方法、复杂的解码算法、以及基于模型架构和训练范式的创新。我们还会探讨这两者之间的内在矛盾、面临的评估挑战，并展望未来的发展方向。</p>
<p>准备好了吗？让我们一起踏上这场充满智慧与挑战的探索之旅吧！</p>
<h2 id="Part-1-自然语言生成（NLG）概述及其挑战">Part 1: 自然语言生成（NLG）概述及其挑战</h2>
<p>自然语言生成（Natural Language Generation, NLG）是人工智能领域的一个分支，旨在让机器能够像人类一样生成自然语言文本。从广义上讲，NLG系统接收非语言形式的输入（如数据、知识图谱、图像特征、结构化数据）或语言形式的输入（如摘要任务的原文、机器翻译的源语言），然后输出人类可读的文本。</p>
<p>NLG的发展历程可以大致分为几个阶段：</p>
<ul>
<li><strong>基于模板和规则的生成 (Rule-based/Template-based Generation)：</strong> 早期的NLG系统主要依赖预定义的模板和手工编写的规则。例如，天气预报系统会根据气温、湿度等数据填充“今天气温是[温度]，湿度是[湿度]”这样的模板。这种方法的优点是输出可控、准确，但缺点是灵活性差，无法处理复杂或未预见的场景，且需要大量人工维护。</li>
<li><strong>统计学方法 (Statistical Methods)：</strong> 随着机器学习的发展，隐马尔可夫模型（HMM）、条件随机场（CRF）等统计模型开始应用于NLG。它们通过学习语料库中的模式来生成文本，但通常需要大量的特征工程。</li>
<li><strong>深度学习时代 (Deep Learning Era)：</strong> 循环神经网络（RNN）、长短期记忆网络（LSTM）的出现为NLG带来了革命性的变化，它们能够更好地捕捉语言的长期依赖关系。随后，Transformer架构的提出及其在预训练语言模型（如BERT、GPT系列）中的应用，将NLG推向了新的高度。Transformer的自注意力机制使其在处理长文本和捕捉复杂语言模式方面表现出色，并奠定了现代大型语言模型的基础。</li>
</ul>
<p>尽管取得了巨大进步，NNLG系统依然面临多重挑战：</p>
<ul>
<li><strong>流畅性 (Fluency)：</strong> 生成的文本是否语法正确、表达自然、符合人类的阅读习惯。</li>
<li><strong>连贯性 (Coherence)：</strong> 文本在语义上是否逻辑一致、主题明确，段落和句子之间衔接流畅。</li>
<li><strong>事实性/正确性 (Factuality/Correctness)：</strong> 生成的内容是否真实、准确，不包含虚假信息（特别是对于知识密集型任务）。这是当前LLM面临的一个核心挑战——“幻觉”（Hallucination）问题。</li>
<li><strong>自然性 (Naturalness)：</strong> 生成的文本是否听起来像人说的话，而不是机器生硬的拼接。</li>
<li><strong>安全与伦理 (Safety &amp; Ethics)：</strong> 模型是否可能生成有害、偏见或不当内容。</li>
<li><strong>计算成本 (Computational Cost)：</strong> 训练和部署大型NLG模型需要巨大的计算资源。</li>
</ul>
<p>然而，在所有这些挑战中，对于实际应用而言，**控制（Control）<strong>和</strong>多样性（Diversity）**是两个至关重要且相互关联的维度。一个仅仅能生成流畅连贯文本的模型，如果无法按照我们的意图生成特定内容，或者总是给出千篇一律的答案，那么它的实用价值将大打折扣。反之亦然，一个能生成各种天马行空内容的模型，如果无法控制其输出方向，也可能变得毫无用处甚至带来风险。</p>
<p>在接下来的章节中，我们将聚焦于如何克服控制与多样性的挑战。</p>
<h2 id="Part-2-控制：让AI“听话”地生成">Part 2: 控制：让AI“听话”地生成</h2>
<p>控制在NLG中至关重要，它决定了我们能否引导模型生成满足特定条件、符合特定目的的文本。这种“听话”的能力，是构建实用AI应用的基础。</p>
<h3 id="控制的维度">控制的维度</h3>
<p>控制可以从多个维度进行分类：</p>
<ul>
<li><strong>内容控制 (Content Control):</strong> 这是最直接的控制，要求模型在生成文本中包含特定的关键词、主题、实体或信息。例如，生成一篇关于“量子计算”的新闻稿，并必须提及“超导量子比特”。</li>
<li><strong>风格控制 (Style Control):</strong> 旨在让模型以特定的风格生成文本，如正式/非正式、幽默/严肃、诗意/散文，或者模仿特定作者（如莎士比亚）的写作风格。</li>
<li><strong>结构控制 (Structure Control):</strong> 指导模型按照预定义的结构生成文本，例如生成一篇包含引言、主体、结论的报告；生成符合特定格律的诗歌；或生成符合JSON格式的数据描述。</li>
<li><strong>属性控制 (Attribute Control):</strong> 控制文本中隐含的属性，如情感（积极、消极、中性）、人物性格（傲慢、谦逊）、语气（命令、请求）等。</li>
</ul>
<h3 id="经典控制策略">经典控制策略</h3>
<p>早期的NLG模型通常通过修改输入或模型结构来实现控制。</p>
<h4 id="提示工程-Prompt-Engineering">提示工程 (Prompt Engineering)</h4>
<p>随着大型语言模型（LLMs）的兴起，**提示工程（Prompt Engineering）**成为了最常见且成本最低的控制手段。通过精心设计的提示（Prompt），我们可以引导模型生成特定风格、内容或结构的结果。</p>
<ul>
<li><strong>Few-shot Learning 与 In-context Learning:</strong> 通过在提示中提供少量示例（few-shot examples），模型能够学习到任务模式，无需进行模型参数的更新。例如，给出几个问答对，然后让模型回答新的问题。</li>
<li><strong>指令微调 (Instruction Tuning):</strong> 在训练阶段，通过多样化的指令格式对模型进行微调，使其更好地理解和遵循用户的指令。这是GPT-3.5和GPT-4等模型强大的基础。</li>
<li><strong>链式思考 (Chain-of-Thought, CoT):</strong> 通过在提示中要求模型展示其推理过程，可以显著提高模型在复杂推理任务上的性能。
<ul>
<li><strong>例子：</strong> “请一步步思考，计算 123 * 456。” 模型不再直接给出答案，而是先列出乘法步骤。</li>
</ul>
</li>
<li><strong>高级提示技巧：</strong>
<ul>
<li><strong>ReAct (Reasoning and Acting):</strong> 结合CoT和外部工具调用的方法，模型交替地进行推理和采取行动（如搜索、调用API）。</li>
<li><strong>Self-Consistency:</strong> 让模型对同一问题生成多个CoT路径，然后投票选择最一致的答案。</li>
<li><strong>Tree-of-Thought (ToT):</strong> 扩展CoT，让模型探索多种推理路径，形成一个思维树。</li>
</ul>
</li>
</ul>
<p><strong>局限性：</strong> 提示工程虽然强大，但其控制能力是间接且非结构化的。对于复杂或严格的控制要求，提示可能难以准确表达，且模型行为有时仍不可预测。</p>
<h4 id="条件生成-Conditional-Generation">条件生成 (Conditional Generation)</h4>
<p>在模型层面，最基础的控制方式是<strong>条件生成（Conditional Generation）</strong>，即模型根据额外的输入条件来生成文本。</p>
<ul>
<li><strong>Encoder-Decoder 模型：</strong> 在 Seq2Seq 架构中，Encoder 将输入（如源语言句子、结构化数据、图片特征）编码成一个上下文向量，Decoder 依据这个向量生成目标文本。例如，机器翻译中源语言就是条件。</li>
<li><strong>Transformer Decoder-only 模型：</strong> 如 GPT 系列，它们通过将控制信号（如任务描述、特定标签、关键词）作为前缀拼接到输入序列中，从而实现条件生成。
<ul>
<li>例如，要生成一段积极情感的评论，可以将输入设置为：“情感：积极。评论：”</li>
</ul>
</li>
<li><strong>参数高效微调 (Parameter-Efficient Fine-Tuning, PEFT)：</strong>
<ul>
<li><strong>Prefix Tuning / Prompt Tuning:</strong> 通过在模型的每一层或输入层添加可学习的前缀向量（或称为“软提示”），来引导模型行为。这些前缀向量在微调过程中学习，而模型的原始参数保持不变，极大地降低了微调成本。</li>
<li><strong>Adapter Tuning:</strong> 在Transformer层的特定位置（如多头注意力之后或前馈网络之后）插入小型神经网络模块（Adapter）。这些Adapter负责学习任务特定的知识，而原始模型参数被冻结。</li>
<li><strong>LoRA (Low-Rank Adaptation):</strong> 通过向预训练模型的权重矩阵中注入低秩分解矩阵来微调模型。这种方法同样只训练少量参数，但效果显著。</li>
</ul>
</li>
</ul>
<p>这些PEFT方法通过修改模型的一部分或添加少量参数，实现了对模型行为的有效引导，使得在特定任务上实现精细控制成为可能。</p>
<h3 id="高级控制机制">高级控制机制</h3>
<p>为了实现更复杂、更精确的控制，研究者们开发了多种高级机制。</p>
<h4 id="受控解码-Controlled-Decoding">受控解码 (Controlled Decoding)</h4>
<p>除了在模型输入或微调阶段进行控制外，我们还可以在生成文本的解码阶段施加约束。</p>
<ul>
<li><strong>约束解码 (Constrained Decoding):</strong> 强制生成文本中包含或排除某些词汇、短语，或遵循特定的语法、格式。
<ul>
<li><strong>强制包含/排除特定词汇或短语：</strong> 这通常通过修改解码过程中的词汇概率分布来实现。例如，在每一步生成时，检查当前生成的序列是否能匹配到需要强制包含的关键词的前缀。如果匹配，则提高下一个词的概率；如果不匹配，则降低或排除不符合的词。这可以使用**Trie（前缀树）**结构来高效地管理和查找约束词汇。</li>
<li><strong>语法/结构约束：</strong> 例如，要求生成JSON格式的输出，或遵循特定的上下文无关文法（Context-Free Grammar, CFG）。解码器在生成每一步时，会根据CFG规则过滤掉不合法的下一个词。</li>
<li><strong>示例伪代码 (概念性)：</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">constrained_decode</span>(<span class="params">model, prompt, constraint_words</span>):</span><br><span class="line">    generated_text = <span class="string">&quot;&quot;</span></span><br><span class="line">    current_trie_nodes = [trie.root] <span class="comment"># For each constraint word, track its path in the trie</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(max_length):</span><br><span class="line">        logits = model(prompt + generated_text) <span class="comment"># Get next token probabilities</span></span><br><span class="line">        probs = softmax(logits)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Apply constraint filtering</span></span><br><span class="line">        allowed_tokens = <span class="built_in">set</span>()</span><br><span class="line">        <span class="keyword">for</span> token_id <span class="keyword">in</span> <span class="built_in">range</span>(vocab_size):</span><br><span class="line">            token_text = tokenizer.decode(token_id)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># Check if any constraint path can continue with this token</span></span><br><span class="line">            is_allowed = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">for</span> node <span class="keyword">in</span> current_trie_nodes:</span><br><span class="line">                <span class="keyword">if</span> token_text <span class="keyword">in</span> node.children:</span><br><span class="line">                    is_allowed = <span class="literal">True</span></span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> is_allowed:</span><br><span class="line">                allowed_tokens.add(token_id)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Filter probabilities to only allow `allowed_tokens`</span></span><br><span class="line">        filtered_probs = [<span class="number">0.0</span>] * vocab_size</span><br><span class="line">        <span class="keyword">for</span> token_id <span class="keyword">in</span> allowed_tokens:</span><br><span class="line">            filtered_probs[token_id] = probs[token_id]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Resample or pick best from filtered_probs</span></span><br><span class="line">        next_token_id = sample_from_probs(filtered_probs)</span><br><span class="line">        next_token_text = tokenizer.decode(next_token_id)</span><br><span class="line">        </span><br><span class="line">        generated_text += next_token_text</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Update trie nodes for next iteration</span></span><br><span class="line">        new_current_trie_nodes = []</span><br><span class="line">        <span class="keyword">for</span> node <span class="keyword">in</span> current_trie_nodes:</span><br><span class="line">            <span class="keyword">if</span> next_token_text <span class="keyword">in</span> node.children:</span><br><span class="line">                new_current_trie_nodes.append(node.children[next_token_text])</span><br><span class="line">        current_trie_nodes = new_current_trie_nodes</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Check for constraint completion</span></span><br><span class="line">        <span class="comment"># ... (logic to mark constraints as met or fail if impossible)</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> generated_text</span><br></pre></td></tr></table></figure>
（请注意，这是一个高度简化的概念性伪代码，实际实现会复杂得多，涉及到Beam Search的修改、Trie的深度遍历、以及高效的 token-trie 匹配等。）</li>
</ul>
</li>
</ul>
<h4 id="强化学习从人类反馈中学习-Reinforcement-Learning-from-Human-Feedback-RLHF">强化学习从人类反馈中学习 (Reinforcement Learning from Human Feedback, RLHF)</h4>
<p>RLHF是当前大模型实现指令遵循、价值对齐和行为控制的关键技术之一。</p>
<ul>
<li><strong>奖励模型 (Reward Model, RM):</strong> 收集人类对模型生成文本的偏好数据（例如，让人类对两个生成的回复进行比较并打分）。然后训练一个奖励模型，使其能够预测人类对给定文本的评分。</li>
<li><strong>强化学习 (Reinforcement Learning):</strong> 将预训练语言模型（通常是Instruction-tuned的模型）视为策略网络，其目标是最大化奖励模型给出的奖励。常用的算法是PPO（Proximal Policy Optimization）。
<ul>
<li>通过PPO，模型学习生成那些能获得更高奖励的文本，从而使其输出与人类的偏好和指令更加对齐。这使得模型在安全性、有用性和遵循指令方面表现出更强的可控性。</li>
<li><strong>核心思想：</strong>
<ul>
<li><strong>微调 SFT 模型（Supervised Fine-Tuning）</strong>：在人类标注的指令数据上进行监督微调，让模型初步学习遵循指令。</li>
<li><strong>训练奖励模型 (RM)</strong>：收集大量人类对模型输出的偏好排序或打分数据，训练一个分类器或回归模型，使其能够预测人类对任何给定文本的“好坏”评分。奖励模型通常是另一个预训练模型，其顶部添加了一个线性层。</li>
<li><strong>使用强化学习优化 SFT 模型</strong>：将SFT模型视为Actor（策略），奖励模型视为Critic。使用PPO等算法，让SFT模型根据奖励模型的反馈，调整其生成策略，以生成更高质量、更符合人类偏好的文本。为了防止模型在优化过程中偏离原始语言模型的能力，通常还会加入一个KL散度惩罚项，限制新策略与旧策略之间的差异。
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi>E</mi><mrow><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo><mo>∼</mo><msub><mi>π</mi><msub><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msub></msub></mrow></msub><mo stretchy="false">[</mo><mfrac><mrow><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>s</mi><mo stretchy="false">)</mo></mrow><mrow><msub><mi>π</mi><msub><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msub></msub><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>s</mi><mo stretchy="false">)</mo></mrow></mfrac><msub><mover accent="true"><mi>A</mi><mo>^</mo></mover><mi>t</mi></msub><mo>−</mo><mi>β</mi><mi>K</mi><mi>L</mi><mo stretchy="false">(</mo><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mo>⋅</mo><mi mathvariant="normal">∣</mi><mi>s</mi><mo stretchy="false">)</mo><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><msub><mi>π</mi><msub><mi>θ</mi><mrow><mi>o</mi><mi>l</mi><mi>d</mi></mrow></msub></msub><mo stretchy="false">(</mo><mo>⋅</mo><mi mathvariant="normal">∣</mi><mi>s</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">L(\theta) = E_{(s,a) \sim \pi_{\theta_{old}}} [\frac{\pi_{\theta}(a|s)}{\pi_{\theta_{old}}(a|s)} \hat{A}_t - \beta KL(\pi_{\theta}(\cdot|s) || \pi_{\theta_{old}}(\cdot|s))]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.6357em;vertical-align:-0.6257em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">s</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">a</span><span class="mclose mtight">)</span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:-0.0359em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3448em;margin-left:-0.0278em;margin-right:0.1em;"><span class="pstrut" style="height:2.6944em;"></span><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3496em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.401em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4609em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:-0.0359em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3448em;margin-left:-0.0278em;margin-right:0.1em;"><span class="pstrut" style="height:2.6944em;"></span><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3496em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.401em;"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">a</span><span class="mord mtight">∣</span><span class="mord mathnormal mtight">s</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:-0.0359em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">a</span><span class="mord mtight">∣</span><span class="mord mathnormal mtight">s</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6257em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9468em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">A</span></span><span style="top:-3.2523em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1111em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0059em;vertical-align:-0.2559em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">⋅</span><span class="mord">∣</span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mord">∣∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:-0.0278em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2559em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">⋅</span><span class="mord">∣</span><span class="mord mathnormal">s</span><span class="mclose">))]</span></span></span></span></li>
<li>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>A</mi><mo>^</mo></mover><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\hat{A}_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0968em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9468em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">A</span></span><span style="top:-3.2523em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1111em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是优势函数，反映了采取某个动作相对于平均水平的收益。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="可控生成模型-Controllable-Generation-Models">可控生成模型 (Controllable Generation Models)</h4>
<p>除了直接在解码或训练阶段施加约束，还有一些模型架构或训练范式本身就旨在实现可控性。</p>
<ul>
<li><strong>属性分类器/编码器引导：</strong> 训练一个独立的属性分类器（例如，情感分类器），在模型生成过程中，根据分类器对生成文本的预测，动态调整生成词的概率。例如，如果目标是积极情感，但当前生成的文本情感偏中性，则可以提高与积极情感相关的词的概率，降低与消极情感相关的词的概率。</li>
<li><strong>对抗生成网络 (GANs) 中的判别器引导：</strong> 尽管在文本生成中GANs不如Transformer流行，但其判别器的思想可以用于控制。训练一个判别器来区分“符合某种属性的文本”和“不符合某种属性的文本”。生成器则试图欺骗判别器，从而学会生成具有该属性的文本。</li>
<li><strong>离散化潜在空间 (Disentangled Latent Spaces)：</strong> 在变分自编码器（VAEs）或扩散模型（Diffusion Models）中，尝试学习一个潜在空间，其中不同的维度对应于文本的不同可控属性（如内容、风格、长度）。通过在潜在空间中操作这些维度，可以精确地控制生成文本的属性。</li>
</ul>
<h2 id="Part-3-多样性：让AI“有灵感”地生成">Part 3: 多样性：让AI“有灵感”地生成</h2>
<p>除了控制，**多样性（Diversity）**是NLG的另一个核心目标。一个优秀的NLG系统不仅能按指令生成内容，还能在合理范围内提供多种不同的表达方式，避免重复和刻板印象。</p>
<h3 id="多样性的重要性">多样性的重要性</h3>
<ul>
<li><strong>提升用户体验：</strong> 在对话系统或内容创作中，如果模型总是生成相同的短语或回答，用户会感到单调乏味，甚至认为模型不够智能。多样性可以提供更丰富的交互体验。</li>
<li><strong>探索生成空间的潜力：</strong> 语言模型的参数空间巨大，理论上可以生成无穷无尽的文本。多样性使得模型能够充分探索这个空间，发现新颖、有创意的表达。</li>
<li><strong>在创造性应用中的核心作用：</strong> 无论是诗歌、小说、剧本还是营销文案，创新和独特性是其价值的根本。没有多样性，NLG就难以在这些领域发挥真正的创造力。</li>
<li><strong>避免生成偏差和刻板印象：</strong> 过度追求特定类型的输出可能导致模型陷入局部最优，并强化训练数据中的偏见。多样性有助于生成更广泛、更平衡的视角。</li>
</ul>
<h3 id="经典解码策略与多样性">经典解码策略与多样性</h3>
<p>模型在生成文本时，从其预测的下一个词的概率分布中选择词语，这一过程称为<strong>解码（Decoding）</strong>。不同的解码策略对生成文本的多样性有显著影响。</p>
<h4 id="贪婪搜索-Greedy-Search">贪婪搜索 (Greedy Search)</h4>
<ul>
<li><strong>工作原理：</strong> 在每一步，总是选择下一个词概率最高的词。
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>t</mi></msub><mo>=</mo><mi>arg</mi><mo>⁡</mo><msub><mrow><mi>max</mi><mo>⁡</mo></mrow><mi>w</mi></msub><mi>P</mi><mo stretchy="false">(</mo><mi>w</mi><mi mathvariant="normal">∣</mi><msub><mi>w</mi><mrow><mo>&lt;</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">w_t = \arg\max_{w} P(w | w_{&lt;t})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">ar<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop">max</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></li>
</ul>
</li>
<li><strong>特点：</strong> 生成速度快，但生成的文本通常缺乏多样性，容易陷入局部最优，产生重复短语，或者无法生成全局最优的序列。</li>
</ul>
<h4 id="束搜索-Beam-Search">束搜索 (Beam Search)</h4>
<ul>
<li><strong>工作原理：</strong> 不仅仅考虑当前最优的词，而是保留一个“束”（beam）大小的候选序列（k个概率最高的序列），在每一步都扩展这k个序列，然后从所有扩展中选出新的k个概率最高的序列。</li>
<li><strong>特点：</strong> 相比贪婪搜索，束搜索能够生成更高质量、更流畅、连贯的文本，因为它考虑了更长的上下文。然而，它仍然存在多样性不足的问题：
<ul>
<li><strong>重复短语：</strong> 束搜索倾向于选择那些在训练数据中出现频率高的短语，这可能导致生成结果缺乏新意，甚至出现冗余。</li>
<li><strong>“束搜索坍塌” (Beam Search Collapse)：</strong> 许多束中的序列可能在早期共享相同的前缀，导致最终的k个输出非常相似，从而限制了多样性。</li>
<li><strong>曝光偏差 (Exposure Bias)：</strong> 模型在训练时是基于真实数据序列来预测下一个词，而在推理时，束搜索生成的序列可能与训练数据中的真实序列存在偏差，模型从未见过自己生成的错误，导致错误累积。</li>
</ul>
</li>
</ul>
<h4 id="采样方法-Sampling-Methods">采样方法 (Sampling Methods)</h4>
<p>为了引入随机性，增加多样性，研究者们引入了各种采样方法。</p>
<ul>
<li>
<p><strong>温度采样 (Temperature Sampling):</strong></p>
<ul>
<li><strong>工作原理：</strong> 通过引入一个“温度”参数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span> 来调整Softmax的输出分布。</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mi>T</mi></msub><mo stretchy="false">(</mo><msub><mi>w</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy="false">(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>i</mi><mi>t</mi><mi>s</mi><mo stretchy="false">(</mo><msub><mi>w</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mi>T</mi><mo stretchy="false">)</mo></mrow><mrow><msub><mo>∑</mo><mi>j</mi></msub><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy="false">(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mi>i</mi><mi>t</mi><mi>s</mi><mo stretchy="false">(</mo><msub><mi>w</mi><mi>j</mi></msub><mo stretchy="false">)</mo><mi mathvariant="normal">/</mi><mi>T</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">P_T(w_i) = \frac{exp(logits(w_i)/T)}{\sum_j exp(logits(w_j)/T)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.6772em;vertical-align:-0.6672em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1496em;"><span style="top:-2.1786em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4603em;"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.1952em;"></span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">p</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">s</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0269em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span><span class="mord mtight">/</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">p</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">s</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0269em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span><span class="mord mtight">/</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6672em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></li>
<li>当 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">T=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span> 时，是标准的Softmax。</li>
<li>当 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>→</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">T \to 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span> 时，分布变得尖锐，接近贪婪搜索（只选择概率最高的词）。</li>
<li>当 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>&gt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">T &gt; 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span> 时，分布变得平坦，高概率词和低概率词之间的差异减小，增加了选择低概率词的机会，从而增加了多样性。</li>
<li><strong>优点：</strong> 简单有效，可以灵活调整生成的多样性。</li>
<li><strong>缺点：</strong> 温度过高可能导致生成完全不连贯的“胡言乱语”。</li>
</ul>
</li>
<li>
<p><strong>Top-K 采样 (Top-K Sampling):</strong></p>
<ul>
<li><strong>工作原理：</strong> 在每一步生成时，只从概率最高的 K 个词中进行采样，而不是从整个词汇表中采样。</li>
<li><strong>优点：</strong> 相比温度采样，Top-K 采样能更好地避免采样到低质量的“胡言乱语”，同时仍能引入多样性。</li>
<li><strong>缺点：</strong> 固定 K 值可能不总是最优。如果词汇分布在不同生成步骤中差异很大，一个固定的 K 值可能在某些情况下过于限制（K太小），而在另一些情况下又过于宽松（K太大）。</li>
</ul>
</li>
<li>
<p><strong>Nucleus 采样 (Top-P Sampling 或 P-sampling):</strong></p>
<ul>
<li><strong>工作原理：</strong> Top-P 采样旨在解决 Top-K 采样中 K 值选择的难题。它不是固定选择 K 个词，而是选择一个最小的词汇集合，使得这个集合中词的累积概率超过一个阈值 P (例如 P=0.9)。然后只从这个集合中进行采样。</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mrow><mi>t</mi><mi>o</mi><mi>p</mi><mo>−</mo><mi>P</mi></mrow></msub><mo>=</mo><mo stretchy="false">{</mo><msub><mi>w</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><msub><mo>∑</mo><mrow><msub><mi>w</mi><mi>j</mi></msub><mo>∈</mo><msub><mi>V</mi><mrow><mi>s</mi><mi>o</mi><mi>r</mi><mi>t</mi><mi>e</mi><mi>d</mi></mrow></msub><mo separator="true">,</mo><mi>j</mi><mo>≤</mo><mi>i</mi></mrow></msub><mi>P</mi><mo stretchy="false">(</mo><msub><mi>w</mi><mi>j</mi></msub><mo stretchy="false">)</mo><mo>≥</mo><mi>P</mi><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">V_{top-P} = \{w_i | \sum_{w_j \in V_{sorted}, j \le i} P(w_j) \ge P\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">p</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.247em;vertical-align:-0.497em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1786em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0269em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em;"><span></span></span></span></span></span></span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:-0.2222em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">sor</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">≤</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.497em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mclose">}</span></span></span></span></li>
<li><strong>优点：</strong> 动态地选择词汇集合大小，更适应不同的概率分布形状。当分布集中时，选择的词汇少；当分布平坦时，选择的词汇多，从而更好地平衡质量和多样性。</li>
<li><strong>缺点：</strong> 依然需要选择一个合适的 P 值。</li>
</ul>
</li>
</ul>
<h3 id="提升多样性的高级策略">提升多样性的高级策略</h3>
<p>除了调整解码过程中的采样方法，还有一些更高级的策略来从根本上提升生成文本的多样性。</p>
<h4 id="惩罚机制-Penalty-Mechanisms">惩罚机制 (Penalty Mechanisms)</h4>
<ul>
<li><strong>重复惩罚 (Repetition Penalty):</strong> 在生成下一个词时，降低已经生成过的词的 logits（对数概率）值。这可以有效地避免模型陷入重复循环。
<ul>
<li><strong>计算方式：</strong><br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi><mo stretchy="false">(</mo><msub><mi>w</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mi>i</mi><mi>t</mi><mi>s</mi><mo stretchy="false">(</mo><msub><mi>w</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><mrow><mi>t</mi><mi>e</mi><mi>m</mi><mi>p</mi><mi>e</mi><mi>r</mi><mi>a</mi><mi>t</mi><mi>u</mi><mi>r</mi><mi>e</mi></mrow></mfrac><mo>−</mo><mi>α</mi><mo>⋅</mo><mtext>count</mtext><mo stretchy="false">(</mo><msub><mi>w</mi><mi>i</mi></msub><mo separator="true">,</mo><mtext>history</mtext><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">score(w_i) = \frac{logits(w_i)}{temperature} - \alpha \cdot \text{count}(w_i, \text{history})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">score</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.4911em;vertical-align:-0.4811em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">er</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">re</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">s</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0269em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4811em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4445em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">count</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord text"><span class="mord">history</span></span><span class="mclose">)</span></span></span></span><br>
其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span> 是惩罚系数，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>count</mtext><mo stretchy="false">(</mo><msub><mi>w</mi><mi>i</mi></msub><mo separator="true">,</mo><mtext>history</mtext><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{count}(w_i, \text{history})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">count</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord text"><span class="mord">history</span></span><span class="mclose">)</span></span></span></span> 是词 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">w_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 在已生成历史中出现的次数。通常会惩罚最近出现的词，而不是所有出现过的词。</li>
</ul>
</li>
<li><strong>N-gram 惩罚：</strong> 惩罚生成与之前N-gram重复的词，以避免重复的短语和句子结构。</li>
</ul>
<h4 id="多样性导向的解码-Diversity-Aware-Decoding">多样性导向的解码 (Diversity-Aware Decoding)</h4>
<p>这些方法旨在在束搜索的基础上，主动强制生成不同寻常的序列。</p>
<ul>
<li>
<p><strong>Diverse Beam Search:</strong> 旨在解决传统束搜索的“坍塌”问题。它通过在束搜索的得分函数中加入一个惩罚项，鼓励不同束中的序列在某个阶段后保持更大的差异。</p>
<ul>
<li>例如，可以为每个束计算一个惩罚，使其生成的N-gram与当前批次中其他束生成的N-gram的重叠程度相关。这使得模型在探索更高概率路径的同时，也能保持生成路径的多样性。</li>
<li>核心思想是，对于每个beam，除了计算其自身序列的对数概率外，还计算它与同一组中其他beam的“距离”或“相似度”惩罚。</li>
</ul>
</li>
<li>
<p><strong>Contrastive Search:</strong> 这是一种相对较新的解码策略，旨在平衡生成文本的质量和多样性。它通过最大化生成下一个token的对数概率，同时最小化与上一个token的语义相似度来选择下一个token。</p>
<ul>
<li>这意味着模型会选择那些既符合上下文逻辑，又能引入新信息的词。</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi><mo stretchy="false">(</mo><msub><mi>w</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>α</mi><mo stretchy="false">)</mo><mi>log</mi><mo>⁡</mo><mi>P</mi><mo stretchy="false">(</mo><msub><mi>w</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><mtext>context</mtext><mo stretchy="false">)</mo><mo>−</mo><mi>α</mi><msub><mrow><mi>max</mi><mo>⁡</mo></mrow><mrow><mi>j</mi><mo>&lt;</mo><mi>i</mi></mrow></msub><mtext>sim</mtext><mo stretchy="false">(</mo><mtext>embedding</mtext><mo stretchy="false">(</mo><msub><mi>w</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><mtext>embedding</mtext><mo stretchy="false">(</mo><msub><mi>w</mi><mi>j</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">score(w_i) = (1-\alpha) \log P(w_i | \text{context}) - \alpha \max_{j &lt; i} \text{sim}(\text{embedding}(w_i), \text{embedding}(w_j))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">score</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord text"><span class="mord">context</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop">max</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord text"><span class="mord">sim</span></span><span class="mopen">(</span><span class="mord text"><span class="mord">embedding</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord text"><span class="mord">embedding</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">))</span></span></span></span></li>
<li>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span></span></span></span> 是一个超参数，用于平衡概率和相似度惩罚。</li>
</ul>
</li>
</ul>
<h4 id="模型层面的多样性增强">模型层面的多样性增强</h4>
<p>除了解码策略，模型架构和训练方法也能在深层次上影响生成的多样性。</p>
<ul>
<li>
<p><strong>潜在空间操作 (Latent Space Manipulation):</strong></p>
<ul>
<li>在诸如变分自编码器（VAEs）或扩散模型中，可以学习一个潜在空间，其中文本的不同属性（如风格、内容、情感）被“解耦”到不同的维度。通过在潜在空间中对这些维度进行随机采样或插值，可以生成在这些属性上具有多样性的文本。</li>
<li>例如，固定内容向量，但在风格维度上进行随机采样，即可生成相同内容不同风格的文本。</li>
</ul>
</li>
<li>
<p><strong>对抗性训练 (Adversarial Training):</strong></p>
<ul>
<li>在GANs中，生成器（Generator）和判别器（Discriminator）进行对抗训练。判别器试图区分真实数据和生成数据，而生成器则试图生成足以欺骗判别器的数据。这种对抗性迫使生成器探索更广泛的生成空间，从而产生更多样化的输出。</li>
<li>在文本GANs中，判别器可以用来鼓励生成器产生更多样化的句子，以避免判别器学习到简单的模式（如重复的短语）。</li>
</ul>
</li>
<li>
<p><strong>扩散模型 (Diffusion Models) for Text Generation:</strong></p>
<ul>
<li>近年来，扩散模型在图像生成领域取得了革命性进展，并逐渐被应用于文本生成。扩散模型通过一个逐步去噪的过程来生成数据。</li>
<li>其固有的随机性（从完全随机的噪声开始去噪）使得它在生成多样化样本方面具有天然优势。通过改变初始噪声向量，模型可以生成截然不同但高质量的文本样本，从而提供了强大的多样性控制能力。</li>
</ul>
</li>
</ul>
<h2 id="Part-4-控制与多样性的平衡与挑战">Part 4: 控制与多样性的平衡与挑战</h2>
<p>在NLG中，控制与多样性往往呈现出一种内在的矛盾关系：</p>
<ul>
<li><strong>控制意味着约束：</strong> 当我们要求模型生成特定内容、遵循特定格式时，我们实际上是在限制模型的自由发挥空间。越是严格的控制，模型可以探索的输出越少，多样性自然会降低。</li>
<li><strong>多样性意味着探索：</strong> 追求多样性意味着鼓励模型生成更多新颖、不重复的输出，这通常需要更大的随机性和更少的限制。</li>
</ul>
<p>如何在这两者之间找到最佳平衡，是NLG研究和应用的核心挑战。</p>
<h3 id="评估：衡量控制与多样性">评估：衡量控制与多样性</h3>
<p>准确地评估NLG系统的控制和多样性至关重要。</p>
<h4 id="控制的评估">控制的评估</h4>
<p>控制的评估通常更加直接，因为它往往与任务的准确性或符合度相关：</p>
<ul>
<li><strong>准确性 (Accuracy)：</strong> 对于事实性或内容约束，评估生成的文本是否准确无误地包含了所需信息。</li>
<li><strong>遵循度 (Adherence)：</strong> 对于风格、结构或属性控制，评估生成的文本在多大程度上符合预设的规则或标准。这通常需要人工评估或训练一个分类器来自动评估。</li>
<li><strong>相关性 (Relevance)：</strong> 生成的内容是否与控制指令高度相关。</li>
<li><strong>特定指标：</strong> 例如，在摘要任务中，看是否包含所有关键实体；在代码生成中，看是否通过所有测试用例。</li>
</ul>
<h4 id="多样性的评估">多样性的评估</h4>
<p>多样性的评估则更具挑战性，因为它通常没有单一的“正确答案”。常用的指标包括：</p>
<ul>
<li><strong>Distinct-N (Unique N-grams):</strong> 计算生成文本集合中不重复的 unigram（Distinct-1）、bigram（Distinct-2）、trigram 等的数量。这些指标越高，表明文本的多样性越好。
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi><mi>i</mi><mi>s</mi><mi>t</mi><mi>i</mi><mi>n</mi><mi>c</mi><mi>t</mi><mo>−</mo><mi>N</mi><mo>=</mo><mfrac><mtext>Number of unique N-grams</mtext><mtext>Total number of N-grams</mtext></mfrac></mrow><annotation encoding="application/x-tex">Distinct-N = \frac{\text{Number of unique N-grams}}{\text{Total number of N-grams}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal">i</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">in</span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.4133em;vertical-align:-0.4811em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9322em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">Total number of N-grams</span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4461em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">Number of unique N-grams</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4811em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></li>
</ul>
</li>
<li><strong>Self-BLEU:</strong> 计算一组生成文本中，每个文本与其他文本之间的BLEU分数。如果分数较低，表示文本之间差异较大，多样性较高。反之，如果分数较高，则表示文本相似性高，多样性低。</li>
<li><strong>Repetition Rate:</strong> 衡量特定N-gram在生成文本中重复出现的频率。</li>
<li><strong>Novelty Scores:</strong> 衡量生成文本与训练语料或其他现有文本的差异程度。</li>
<li><strong>主观评估 (Human Evaluation):</strong> 最可靠但成本最高的方式。让人类评估者对生成文本的多样性、新颖性进行打分。</li>
</ul>
<h3 id="挑战">挑战</h3>
<ul>
<li><strong>如何在保持高质量的同时实现高度控制和多样性：</strong> 这是最核心的难题。过度追求多样性可能导致胡言乱语；过度追求控制可能导致刻板和生硬。</li>
<li><strong>泛化性 (Generalizability)：</strong> 训练出的控制和多样性策略是否能在不同的任务、领域和模型中保持有效。</li>
<li><strong>可解释性 (Interpretability)：</strong> 模型为何会生成这样的结果？尤其是在采用了复杂解码策略或强化学习后，模型行为的可解释性降低，难以调试和优化。</li>
<li><strong>计算成本 (Computational Cost)：</strong> 复杂的解码策略（如 Diverse Beam Search、Contrastive Search）和强化学习训练（如RLHF）通常需要更多的计算资源和时间。</li>
<li><strong>伦理问题与滥用：</strong> 精确的控制能力可能被滥用于生成虚假信息（深度伪造文本）、煽动仇恨言论或进行钓鱼攻击。高度的多样性也可能导致难以追踪和管理生成内容的来源。</li>
</ul>
<h2 id="Part-5-未来展望">Part 5: 未来展望</h2>
<p>自然语言生成中的控制与多样性研究是一个充满活力的领域，未来有望在多个方向取得突破：</p>
<ul>
<li>
<p><strong>更细粒度的、语义驱动的控制：</strong></p>
<ul>
<li>目前许多控制方法仍停留在词汇或句法层面。未来，我们将看到更多基于深层语义、意图或用户情感的控制。例如，直接指定“这段话要表达对XX的强烈不满”或“请以诗歌的意境描述XX”。</li>
<li>结合知识图谱、本体论等外部知识，让模型能够进行更精确、事实性更强的受控生成。</li>
</ul>
</li>
<li>
<p><strong>更智能、自适应的评估指标：</strong></p>
<ul>
<li>开发能够更好地量化控制与多样性之间平衡的自动化指标，减少对昂贵的人工评估的依赖。</li>
<li>探索基于下游任务性能的端到端评估，例如，生成的报告能否帮助用户更好地决策。</li>
</ul>
</li>
<li>
<p><strong>将人类反馈更深层次地融入模型训练和解码：</strong></p>
<ul>
<li>RLHF的成功预示着人类反馈在模型对齐中的巨大潜力。未来将出现更高效、更灵活的人类反馈收集机制，以及更先进的强化学习算法，将人类偏好更精细地编码到模型行为中。</li>
<li>实时、交互式的人机协作生成，允许用户在生成过程中随时调整控制参数或纠正模型行为。</li>
</ul>
</li>
<li>
<p><strong>结合多模态生成中的控制与多样性：</strong></p>
<ul>
<li>随着多模态模型的兴起（如文生图、图文问答），如何在跨模态场景下实现文本、图像、音频等多种模态内容的协同控制和多样化生成，将是下一个前沿。例如，生成一段包含特定情感、描述特定场景的文本，并同时生成匹配的图像。</li>
</ul>
</li>
<li>
<p><strong>探索新的模型架构和解码范式：</strong></p>
<ul>
<li>除了Transformer，新的模型架构（如状态空间模型SSM、更高效的稀疏注意力机制）可能带来新的可控性和多样性实现方式。</li>
<li>扩散模型在文本生成领域的潜力仍待充分挖掘，其固有的多样性生成能力结合控制机制，有望带来革新。</li>
</ul>
</li>
<li>
<p><strong>安全性与伦理的深度考量：</strong></p>
<ul>
<li>随着生成能力越来越强，如何确保模型的安全使用，防止生成有害、偏见或虚假内容，将成为研究和部署的重中之重。需要发展更强大的内容过滤、风险检测和归因机制。</li>
</ul>
</li>
</ul>
<h2 id="结论">结论</h2>
<p>自然语言生成，特别是大型语言模型，正在以前所未有的速度改变着我们与信息交互的方式。然而，要真正发挥其全部潜力，我们必须学会如何驯服这匹“野马”，让它既能听从指令（控制），又能保持生机与活力（多样性）。</p>
<p>我们深入探讨了实现控制的各种策略，从巧妙的提示工程，到条件生成、参数高效微调，再到强大的强化学习从人类反馈中学习，以及精密的受控解码。我们还分析了提升多样性的多种方法，包括温度采样、Top-K/Top-P采样，以及更高级的惩罚机制和多样性导向的解码算法。两者之间的内在矛盾，以及如何平衡和评估它们，构成了当前NLG领域的核心挑战。</p>
<p>未来的NLG系统将不仅仅是流畅的语言机器，更是能够理解人类意图、适应复杂语境、并提供创造性解决方案的智能伙伴。掌控与绽放，正是通往这一未来的必由之路。</p>
<p>作为技术爱好者，我们很幸运能亲历这一变革。让我们持续关注并参与到这一激动人心的领域中来，共同塑造一个更加智能、可控且充满无限可能的未来。</p>
<p>感谢您的阅读，我是 qmwneb946，我们下期再见！</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a target="_blank" rel="noopener" href="https://github.com/qmwneb946">qmwneb946</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://qmwneb946.dpdns.org/2025/07/21/2025-07-21-224212/">https://qmwneb946.dpdns.org/2025/07/21/2025-07-21-224212/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://opensource.org/licenses/MIT" target="_blank">MIT License</a> 许可协议。转载请注明来源 <a href="https://qmwneb946.dpdns.org" target="_blank">qmwneb946 的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%A7%91%E6%8A%80%E5%89%8D%E6%B2%BF/">科技前沿</a><a class="post-meta__tags" href="/tags/2025/">2025</a><a class="post-meta__tags" href="/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90%E7%9A%84%E6%8E%A7%E5%88%B6%E4%B8%8E%E5%A4%9A%E6%A0%B7%E6%80%A7/">自然语言生成的控制与多样性</a></div><div class="post-share"><div class="social-share" data-image="/img/icon.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/07/21/2025-07-21-225607/" title="深入探讨空天地一体化网络技术：构建无界互联的未来"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">深入探讨空天地一体化网络技术：构建无界互联的未来</div></div><div class="info-2"><div class="info-item-1">作者：qmwneb946  引言：跨越界限，连接无限 在数字化浪潮汹涌澎湃的今天，人类对信息的需求从未如此迫切与多样。从偏远地区的物联网传感器到大都市的自动驾驶汽车，从全球灾难应急通信到高带宽的沉浸式体验，传统地面网络的覆盖范围、带宽和弹性正面临前所未有的挑战。在广袤的海洋深处、崎岖的山脉之巅，乃至浩瀚的宇宙空间，仍存在着无数的信息孤岛，亟待打破。 为了实现真正的“万物互联”和“无处不在的智能”，科学家和工程师们正将目光投向一个宏伟的愿景：构建一个融合空间、空中和地面多维度网络的“空天地一体化网络”（Space-Air-Ground Integrated Network, SAGIN）。这个愿景不再仅仅是科幻作品中的想象，而是全球通信领域最前沿、最具挑战性，也最具潜力的研究方向之一。它旨在打破地理、海拔和场景的限制，提供无缝、高效、可靠、安全的全球覆盖通信服务，成为未来信息基础设施的“神经网络”。 作为一名热爱技术和数学的博主，我（qmwneb946）将带领大家深入剖析空天地一体化网络技术。我们将探讨它的核心理念、组成部分、关键技术挑战，以及它如何重塑我们的通信未来。这不仅是一场...</div></div></div></a><a class="pagination-related" href="/2025/07/21/2025-07-21-221511/" title="驾驭数据之海：自监督学习的研究进展与前沿探索"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">驾驭数据之海：自监督学习的研究进展与前沿探索</div></div><div class="info-2"><div class="info-item-1">亲爱的技术与数学爱好者们，你们好！我是 qmwneb946，你们的老朋友。在人工智能的浪潮中，我们目睹了各种技术的崛起与演进。其中，有一颗明星正以其独特的光芒照亮了通往通用智能的道路，那就是“自监督学习”（Self-Supervised Learning, SSL）。它不仅是对传统机器学习范式的颠覆，更是我们驾驭海量无标注数据，挖掘其内在价值的强大武器。 长期以来，监督学习以其卓越的性能主宰着机器学习领域，但其对大量高质量标注数据的饥渴，在许多实际应用中成为了难以逾越的瓶颈。而无监督学习，尽管无需标注，却又常因难以定义明确的目标，导致学习到的特征缺乏足够的语义信息。自监督学习的出现，巧妙地在两者之间架起了一座桥梁——它利用数据自身的结构或属性来生成监督信号，从而在没有人类干预的情况下学习到有用的特征表示。 本文将带领大家深入探讨自监督学习的奥秘。我们将从其基本原理和早期探索开始，逐步解析对比学习的崛起与辉煌，感受无需负样本的非对比学习的魔力，领略基于掩码建模在视觉领域的突破，并展望自监督学习在多模态、生成模型等前沿领域的融合与挑战。准备好了吗？让我们一同踏上这段充满发现的旅程！ ...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/07/18/2025-07-18-082408/" title="人工智能在医疗诊断中的应用：机遇与挑战"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">人工智能在医疗诊断中的应用：机遇与挑战</div></div><div class="info-2"><div class="info-item-1">大家好，我是你们的技术和数学博主！今天，我们来深入探讨一个激动人心的领域：人工智能 (AI) 在医疗诊断中的应用。AI 的快速发展正在彻底改变医疗行业，为更精准、高效的诊断提供了前所未有的可能性。但同时，我们也需要审慎地看待其挑战和局限性。 引言：AI 赋能医疗诊断 医疗诊断是一个复杂的过程，需要医生具备丰富的知识、经验和判断力。然而，人类医生可能会受到主观偏差、疲劳以及信息过载的影响。AI 的介入，则为提高诊断准确性和效率提供了新的途径。通过分析大量的医学影像数据、病历记录和基因组信息，AI 算法可以学习识别疾病模式，辅助医生进行诊断，甚至在某些情况下独立完成初步诊断。 AI 在医疗诊断中的核心技术 深度学习在医学影像分析中的应用 深度学习，特别是卷积神经网络 (CNN)，在医学影像分析中取得了显著的成功。CNN 可以从大量的医学影像数据（例如 X 光片、CT 扫描、MRI 图像）中学习特征，并识别出细微的病变，例如肺癌结节、脑瘤或心血管疾病。 例如，一个训练良好的 CNN 模型可以比人类放射科医生更早地检测出肺癌，从而提高早期诊断率和治疗成功率。  这其中的关键在于大量的标注...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082643/" title="高分子化学与可降解塑料：迈向可持续未来的关键"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">高分子化学与可降解塑料：迈向可持续未来的关键</div></div><div class="info-2"><div class="info-item-1">近年来，塑料污染已成为全球性环境问题。传统塑料由于其难以降解的特性，对环境造成了巨大的压力。而可降解塑料的出现，为解决这一问题提供了一条可行的途径。本文将深入探讨高分子化学在可降解塑料研发中的关键作用，并介绍几种主要的降解机制和材料。 高分子化学：可降解塑料的基础 可降解塑料并非简单的“可被分解的塑料”，其核心在于高分子材料的分子结构设计。高分子化学为我们提供了理解和操纵聚合物结构的工具，从而设计出具有特定降解性能的材料。传统塑料通常由难以断裂的强共价键连接而成，而可降解塑料则通过引入特定的化学键或结构单元，使其在特定条件下能够断裂，从而实现降解。  这需要对聚合物的合成方法、分子量分布、链结构以及结晶度等进行精细的控制。 常见的可降解塑料聚合物 目前，市场上常见的可降解塑料主要包括以下几种：   聚乳酸 (PLA):  PLA 是一种生物基聚合物，由可再生资源（例如玉米淀粉）制成。其降解过程主要依靠水解反应，在特定条件下（例如堆肥环境）可以被微生物降解。PLA 的机械性能较好，但耐热性相对较差。   聚羟基脂肪酸酯 (PHAs): PHAs 是一类由微生物合成的聚酯。它们具有良...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082805/" title="电化学储能技术的新进展：迈向更清洁、更持久的能源未来"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">电化学储能技术的新进展：迈向更清洁、更持久的能源未来</div></div><div class="info-2"><div class="info-item-1">电化学储能技术作为解决可再生能源间歇性问题的关键技术，近年来取得了显著进展。从电动汽车到智能电网，电化学储能系统正深刻地改变着我们的生活。本文将深入探讨电化学储能技术的最新突破，涵盖不同类型的储能技术及其面临的挑战与机遇。 电化学储能技术的类型 目前，市场上主要的电化学储能技术包括： 锂离子电池 锂离子电池凭借其高能量密度、长循环寿命和相对较低的成本，占据了当前电化学储能市场的主导地位。然而，锂资源的有限性和安全性问题仍然是制约其发展的瓶颈。  近年来，研究者们致力于开发高能量密度锂离子电池，例如：  固态锂电池:  固态电解质的采用可以显著提高电池的安全性，并有望实现更高的能量密度。然而，固态电解质的离子电导率和界面接触仍然是需要克服的挑战。 锂硫电池:  锂硫电池具有极高的理论能量密度，但其循环寿命和硫的穿梭效应仍然是需要解决的关键问题。  研究者们正在探索各种改性策略来提高锂硫电池的性能。 锂空气电池:  锂空气电池拥有理论上最高的能量密度，但其反应动力学缓慢，副反应多，循环寿命短等问题限制了其商业化应用。  钠离子电池 作为锂离子的潜在替代品，钠离子电池具有成本低、资源丰...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-092352/" title="材料科学与新型半导体材料：摩尔定律的未来"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">材料科学与新型半导体材料：摩尔定律的未来</div></div><div class="info-2"><div class="info-item-1">引言 摩尔定律，即集成电路上的晶体管数量每隔两年翻一番，几十年来一直驱动着信息技术产业的飞速发展。然而，随着晶体管尺寸逼近物理极限，摩尔定律的持续性受到了挑战。为了维持这种指数级增长，我们需要探索新型半导体材料，突破硅基技术的瓶颈。本文将深入探讨材料科学在新型半导体材料研发中的关键作用，并介绍一些具有前景的候选材料。 新型半导体材料的需求 硅作为半导体材料的主力，其优势在于成本低、工艺成熟。但其固有的物理特性限制了其在更高频率、更高功率和更低功耗方面的性能提升。例如，硅的载流子迁移率相对较低，导致能量损耗增加，尤其是在高频应用中。因此，我们需要寻找具有更高载流子迁移率、更宽禁带宽度、更高饱和电子漂移速度等优异特性的材料。 性能瓶颈及解决方案 硅基技术的性能瓶颈主要体现在以下几个方面：  漏电流:  随着晶体管尺寸的缩小，漏电流问题日益严重，导致功耗增加和性能下降。 热耗散: 高频运行会导致晶体管产生大量热量，影响器件稳定性和可靠性。 开关速度: 硅的载流子迁移率限制了晶体管的开关速度，限制了处理器的运行频率。  为了解决这些问题，研究人员正在积极探索各种新型半导体材料，例如：  ...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-092411/" title="弦理论中的额外维度探索：超越我们感知的宇宙"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">弦理论中的额外维度探索：超越我们感知的宇宙</div></div><div class="info-2"><div class="info-item-1">引言 我们生活在一个看似三维的空间中，加上时间构成四维时空。然而，弦理论，这个试图统一所有基本力的优雅理论，却预言了额外维度的存在。这些额外维度并非我们日常经验所能感知，它们蜷缩在比原子尺度还要小得多的空间里。本文将深入探讨弦理论中额外维度的概念，并解释科学家们如何尝试探测这些隐藏的宇宙维度。 弦理论与额外维度：一个必要的假设 弦理论的核心思想是将基本粒子视为微小的振动弦，不同振动模式对应不同的粒子。为了使理论自洽，并消除量子场论中的一些困扰，弦理论需要引入额外空间维度。最初的弦理论版本需要 26 个维度，而超弦理论则将维度数量缩减到 10 个（或 11 个，在 M 理论中）。这多出来的 6 个（或 7 个）维度是如何隐藏起来的呢？ 卡拉比-丘空间：卷曲的维度 弦理论提出，额外维度并非不存在，而是以紧致化的形式存在，就像一根细细的管子卷曲得非常紧密，以至于在宏观尺度上无法被察觉。这些紧致化的额外维度通常被描述为卡拉比-丘空间，这是一类复杂的六维流形，具有独特的几何性质。卡拉比-丘空间的形状和大小直接影响了我们观察到的粒子物理学特性，例如粒子质量和相互作用强度。 R6R^6R6 表...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-092451/" title="粒子物理学的标准模型之外：探索宇宙未解之谜"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">粒子物理学的标准模型之外：探索宇宙未解之谜</div></div><div class="info-2"><div class="info-item-1">我们生活在一个由基本粒子及其相互作用组成的宇宙中。粒子物理学的标准模型，如同一个精妙的乐章，成功地描述了已知的基本粒子及其三种基本作用力（电磁力、弱力和强力），并准确预测了许多实验结果。然而，这个模型并非完美无缺，它留下了许多未解之谜，指引着我们向标准模型之外的更广阔领域探索。 标准模型的局限性 标准模型尽管取得了巨大的成功，但它并不能解释宇宙中的一切现象。一些关键的不足之处包括： 暗物质与暗能量 宇宙学观测表明，宇宙中存在大量的暗物质和暗能量，它们构成了宇宙质量能量的大部分，但标准模型中却无法解释它们的本质。暗物质不参与电磁相互作用，因此我们无法直接观测到它，只能通过其引力效应间接探测。暗能量则是一种神秘的能量形式，导致宇宙加速膨胀。它们的发现暗示着标准模型之外存在着新的物理学。 中微子质量 标准模型最初假设中微子是无质量的。然而，实验观测表明中微子具有微小的质量，这与标准模型的预言相矛盾。中微子的质量之谜需要新的物理机制来解释，例如 seesaw 机制。 质子衰变 标准模型预言质子是稳定的，然而，一些大统一理论（GUTs）预测质子会发生极其缓慢的衰变。虽然到目前为止还没有观测...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">qmwneb946</div><div class="author-info-description">一个专注于技术分享的个人博客，涵盖编程、算法、系统设计等内容</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">688</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">692</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/qmwneb946"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/qmwneb946" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:qmwneb946@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">代码与远方，技术与生活交织的篇章。</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Part-1-%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E7%94%9F%E6%88%90%EF%BC%88NLG%EF%BC%89%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%85%B6%E6%8C%91%E6%88%98"><span class="toc-number">1.</span> <span class="toc-text">Part 1: 自然语言生成（NLG）概述及其挑战</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Part-2-%E6%8E%A7%E5%88%B6%EF%BC%9A%E8%AE%A9AI%E2%80%9C%E5%90%AC%E8%AF%9D%E2%80%9D%E5%9C%B0%E7%94%9F%E6%88%90"><span class="toc-number">2.</span> <span class="toc-text">Part 2: 控制：让AI“听话”地生成</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8E%A7%E5%88%B6%E7%9A%84%E7%BB%B4%E5%BA%A6"><span class="toc-number">2.1.</span> <span class="toc-text">控制的维度</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%8F%E5%85%B8%E6%8E%A7%E5%88%B6%E7%AD%96%E7%95%A5"><span class="toc-number">2.2.</span> <span class="toc-text">经典控制策略</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B-Prompt-Engineering"><span class="toc-number">2.2.1.</span> <span class="toc-text">提示工程 (Prompt Engineering)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9D%A1%E4%BB%B6%E7%94%9F%E6%88%90-Conditional-Generation"><span class="toc-number">2.2.2.</span> <span class="toc-text">条件生成 (Conditional Generation)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%AB%98%E7%BA%A7%E6%8E%A7%E5%88%B6%E6%9C%BA%E5%88%B6"><span class="toc-number">2.3.</span> <span class="toc-text">高级控制机制</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%97%E6%8E%A7%E8%A7%A3%E7%A0%81-Controlled-Decoding"><span class="toc-number">2.3.1.</span> <span class="toc-text">受控解码 (Controlled Decoding)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%BB%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E4%B8%AD%E5%AD%A6%E4%B9%A0-Reinforcement-Learning-from-Human-Feedback-RLHF"><span class="toc-number">2.3.2.</span> <span class="toc-text">强化学习从人类反馈中学习 (Reinforcement Learning from Human Feedback, RLHF)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%AF%E6%8E%A7%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B-Controllable-Generation-Models"><span class="toc-number">2.3.3.</span> <span class="toc-text">可控生成模型 (Controllable Generation Models)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Part-3-%E5%A4%9A%E6%A0%B7%E6%80%A7%EF%BC%9A%E8%AE%A9AI%E2%80%9C%E6%9C%89%E7%81%B5%E6%84%9F%E2%80%9D%E5%9C%B0%E7%94%9F%E6%88%90"><span class="toc-number">3.</span> <span class="toc-text">Part 3: 多样性：让AI“有灵感”地生成</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E6%A0%B7%E6%80%A7%E7%9A%84%E9%87%8D%E8%A6%81%E6%80%A7"><span class="toc-number">3.1.</span> <span class="toc-text">多样性的重要性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%8F%E5%85%B8%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5%E4%B8%8E%E5%A4%9A%E6%A0%B7%E6%80%A7"><span class="toc-number">3.2.</span> <span class="toc-text">经典解码策略与多样性</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B4%AA%E5%A9%AA%E6%90%9C%E7%B4%A2-Greedy-Search"><span class="toc-number">3.2.1.</span> <span class="toc-text">贪婪搜索 (Greedy Search)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9D%9F%E6%90%9C%E7%B4%A2-Beam-Search"><span class="toc-number">3.2.2.</span> <span class="toc-text">束搜索 (Beam Search)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%87%87%E6%A0%B7%E6%96%B9%E6%B3%95-Sampling-Methods"><span class="toc-number">3.2.3.</span> <span class="toc-text">采样方法 (Sampling Methods)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8F%90%E5%8D%87%E5%A4%9A%E6%A0%B7%E6%80%A7%E7%9A%84%E9%AB%98%E7%BA%A7%E7%AD%96%E7%95%A5"><span class="toc-number">3.3.</span> <span class="toc-text">提升多样性的高级策略</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%83%A9%E7%BD%9A%E6%9C%BA%E5%88%B6-Penalty-Mechanisms"><span class="toc-number">3.3.1.</span> <span class="toc-text">惩罚机制 (Penalty Mechanisms)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%9A%E6%A0%B7%E6%80%A7%E5%AF%BC%E5%90%91%E7%9A%84%E8%A7%A3%E7%A0%81-Diversity-Aware-Decoding"><span class="toc-number">3.3.2.</span> <span class="toc-text">多样性导向的解码 (Diversity-Aware Decoding)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E5%B1%82%E9%9D%A2%E7%9A%84%E5%A4%9A%E6%A0%B7%E6%80%A7%E5%A2%9E%E5%BC%BA"><span class="toc-number">3.3.3.</span> <span class="toc-text">模型层面的多样性增强</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Part-4-%E6%8E%A7%E5%88%B6%E4%B8%8E%E5%A4%9A%E6%A0%B7%E6%80%A7%E7%9A%84%E5%B9%B3%E8%A1%A1%E4%B8%8E%E6%8C%91%E6%88%98"><span class="toc-number">4.</span> <span class="toc-text">Part 4: 控制与多样性的平衡与挑战</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%84%E4%BC%B0%EF%BC%9A%E8%A1%A1%E9%87%8F%E6%8E%A7%E5%88%B6%E4%B8%8E%E5%A4%9A%E6%A0%B7%E6%80%A7"><span class="toc-number">4.1.</span> <span class="toc-text">评估：衡量控制与多样性</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8E%A7%E5%88%B6%E7%9A%84%E8%AF%84%E4%BC%B0"><span class="toc-number">4.1.1.</span> <span class="toc-text">控制的评估</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%9A%E6%A0%B7%E6%80%A7%E7%9A%84%E8%AF%84%E4%BC%B0"><span class="toc-number">4.1.2.</span> <span class="toc-text">多样性的评估</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%91%E6%88%98"><span class="toc-number">4.2.</span> <span class="toc-text">挑战</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Part-5-%E6%9C%AA%E6%9D%A5%E5%B1%95%E6%9C%9B"><span class="toc-number">5.</span> <span class="toc-text">Part 5: 未来展望</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA"><span class="toc-number">6.</span> <span class="toc-text">结论</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/23/hello-world/" title="Hello World">Hello World</a><time datetime="2025-07-23T10:38:26.207Z" title="发表于 2025-07-23 18:38:26">2025-07-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/23/%E5%8D%9A%E5%BC%88%E8%AE%BA%E5%9F%BA%E7%A1%80/" title="博弈论基础">博弈论基础</a><time datetime="2025-07-23T10:38:26.207Z" title="发表于 2025-07-23 18:38:26">2025-07-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/23/2025-07-23-103548/" title="深度学习在代码生成中的应用：从原理到实践的全面解析">深度学习在代码生成中的应用：从原理到实践的全面解析</a><time datetime="2025-07-23T02:35:48.000Z" title="发表于 2025-07-23 10:35:48">2025-07-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/23/2025-07-23-103507/" title="区块链的可持续性与能耗：技术、挑战与未来之路">区块链的可持续性与能耗：技术、挑战与未来之路</a><time datetime="2025-07-23T02:35:07.000Z" title="发表于 2025-07-23 10:35:07">2025-07-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/23/2025-07-23-103413/" title="生成模型与变分自编码器：从原理到实践的深度探索">生成模型与变分自编码器：从原理到实践的深度探索</a><time datetime="2025-07-23T02:34:13.000Z" title="发表于 2025-07-23 10:34:13">2025-07-23</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;2025 By qmwneb946</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.2</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css')
    if (true) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const getGiscusTheme = theme => theme === 'dark' ? 'dark' : 'light'

  const createScriptElement = config => {
    const ele = document.createElement('script')
    Object.entries(config).forEach(([key, value]) => {
      ele.setAttribute(key, value)
    })
    return ele
  }

  const loadGiscus = (el = document, key) => {
    const mappingConfig = isShuoshuo
      ? { 'data-mapping': 'specific', 'data-term': key }
      : { 'data-mapping': (option && option['data-mapping']) || 'pathname' }

    const giscusConfig = {
      src: 'https://giscus.app/client.js',
      'data-repo': 'qmwneb946/blog',
      'data-repo-id': 'R_kgDOPM6cWw',
      'data-category-id': 'DIC_kwDOPM6cW84CtEzo',
      'data-theme': getGiscusTheme(document.documentElement.getAttribute('data-theme')),
      'data-reactions-enabled': '1',
      crossorigin: 'anonymous',
      async: true,
      ...option,
      ...mappingConfig
    }

    const scriptElement = createScriptElement(giscusConfig)

    el.querySelector('#giscus-wrap').appendChild(scriptElement)

    if (isShuoshuo) {
      window.shuoshuoComment.destroyGiscus = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }
  }

  const changeGiscusTheme = theme => {
    const iframe = document.querySelector('#giscus-wrap iframe')
    if (iframe) {
      const message = {
        giscus: {
          setConfig: {
            theme: getGiscusTheme(theme)
          }
        }
      }
      iframe.contentWindow.postMessage(message, 'https://giscus.app')
    }
  }

  btf.addGlobalFn('themeChange', changeGiscusTheme, 'giscus')

  if (isShuoshuo) {
    'Giscus' === 'Giscus'
      ? window.shuoshuoComment = { loadComment: loadGiscus }
      : window.loadOtherComment = loadGiscus
    return
  }

  if ('Giscus' === 'Giscus' || !false) {
    if (false) btf.loadComment(document.getElementById('giscus-wrap'), loadGiscus)
    else loadGiscus()
  } else {
    window.loadOtherComment = loadGiscus
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>