<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>洞察永恒的互动：重复博弈的深度解析 | qmwneb946 的博客</title><meta name="author" content="qmwneb946"><meta name="copyright" content="qmwneb946"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="作者：qmwneb946 引言：当一次博弈不足以定义全部 在博弈论的宏伟殿堂中，我们常常从一个简洁而有力的起点开始：单次博弈（One-shot Game）。在这样的场景中，参与者在某个时刻做出一次决策，随后博弈结束，支付随之确定。囚徒困境、性别战、剪刀石头布——这些经典范例无不深刻揭示了理性决策者在特定情境下的策略选择及均衡结果。然而，真实世界中的互动远非如此简单而孤立。 试想一下，你与商业伙伴的">
<meta property="og:type" content="article">
<meta property="og:title" content="洞察永恒的互动：重复博弈的深度解析">
<meta property="og:url" content="https://qmwneb946.dpdns.org/2025/07/23/2025-07-23-205150/index.html">
<meta property="og:site_name" content="qmwneb946 的博客">
<meta property="og:description" content="作者：qmwneb946 引言：当一次博弈不足以定义全部 在博弈论的宏伟殿堂中，我们常常从一个简洁而有力的起点开始：单次博弈（One-shot Game）。在这样的场景中，参与者在某个时刻做出一次决策，随后博弈结束，支付随之确定。囚徒困境、性别战、剪刀石头布——这些经典范例无不深刻揭示了理性决策者在特定情境下的策略选择及均衡结果。然而，真实世界中的互动远非如此简单而孤立。 试想一下，你与商业伙伴的">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://qmwneb946.dpdns.org/img/icon.png">
<meta property="article:published_time" content="2025-07-23T12:51:50.000Z">
<meta property="article:modified_time" content="2025-07-26T06:50:50.175Z">
<meta property="article:author" content="qmwneb946">
<meta property="article:tag" content="科技前沿">
<meta property="article:tag" content="2025">
<meta property="article:tag" content="重复博&quot;game theory&quot;">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://qmwneb946.dpdns.org/img/icon.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "洞察永恒的互动：重复博弈的深度解析",
  "url": "https://qmwneb946.dpdns.org/2025/07/23/2025-07-23-205150/",
  "image": "https://qmwneb946.dpdns.org/img/icon.png",
  "datePublished": "2025-07-23T12:51:50.000Z",
  "dateModified": "2025-07-26T06:50:50.175Z",
  "author": [
    {
      "@type": "Person",
      "name": "qmwneb946",
      "url": "https://github.com/qmwneb946"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://qmwneb946.dpdns.org/2025/07/23/2025-07-23-205150/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '洞察永恒的互动：重复博弈的深度解析',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2845632165165414" crossorigin="anonymous"></script><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="qmwneb946 的博客" type="application/atom+xml">
</head><body><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">qmwneb946 的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">洞察永恒的互动：重复博弈的深度解析</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">洞察永恒的互动：重复博弈的深度解析<a class="post-edit-link" href="https://github.com/qmwneb946/blog/edit/main/source/_posts/2025-07-23-205150.md" title="编辑" target="_blank"><i class="fas fa-pencil-alt"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-07-23T12:51:50.000Z" title="发表于 2025-07-23 20:51:50">2025-07-23</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-07-26T06:50:50.175Z" title="更新于 2025-07-26 14:50:50">2025-07-26</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%A7%91%E6%8A%80%E5%89%8D%E6%B2%BF/">科技前沿</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><p>作者：qmwneb946</p>
<h2 id="引言：当一次博弈不足以定义全部">引言：当一次博弈不足以定义全部</h2>
<p>在博弈论的宏伟殿堂中，我们常常从一个简洁而有力的起点开始：单次博弈（One-shot Game）。在这样的场景中，参与者在某个时刻做出一次决策，随后博弈结束，支付随之确定。囚徒困境、性别战、剪刀石头布——这些经典范例无不深刻揭示了理性决策者在特定情境下的策略选择及均衡结果。然而，真实世界中的互动远非如此简单而孤立。</p>
<p>试想一下，你与商业伙伴的合作，与竞争对手的长期较量，甚至是国际社会中不同国家间的关系，这些都不是一次性的交易。它们是持续的、多轮的、甚至是永无止境的互动。今天的决策不仅影响眼前的收益，更会深远地塑造未来的互动模式、声誉以及互信程度。在这样的情境下，一次性博弈的分析框架显得捉襟见肘。</p>
<p>正是为了捕捉这种“历史”与“未来”交织的动态性，博弈论引入了“重复博弈”（Repeated Games）这一核心概念。重复博弈研究的是相同基本博弈（称为“阶段博弈”，Stage Game）在时间上重复进行多次的情形。通过引入重复性，我们打开了理解信任、声誉、合作与惩罚机制的潘多拉魔盒。它解释了为什么即使在理性个体自利驱动下，合作也能在许多看似不可能的情境中涌现并维持；也解释了为什么有时看似微不足道的背叛，却能引发长期的报复和关系破裂。</p>
<p>本文将带领你深入重复博弈的奥秘。我们将从基础概念出发，剖析有限次重复博弈与无限次重复博弈之间的根本差异及其对均衡结果的影响。特别地，我们将聚焦于无限次重复博弈，探讨贴现因子（Discount Factor）的作用，并详细解读博弈论中最具颠覆性的结论之一——民间定理（Folk Theorem）。我们将深入探讨冷酷触发策略（Grim Trigger）和以牙还牙策略（Tit-for-Tat）等核心合作策略，并分析它们如何在理性选择的框架下维持合作。最后，我们将探讨重复博弈在经济学、政治学、社会学乃至生物学中的广泛应用，并展望这一领域的进阶挑战。准备好了吗？让我们一同揭开永恒互动的面纱。</p>
<h2 id="一、-博弈论基础概念速览">一、 博弈论基础概念速览</h2>
<p>在深入重复博弈之前，我们有必要快速回顾一些基本的博弈论概念，这将有助于我们更好地理解重复博弈的魅力所在。</p>
<h3 id="1-1-什么是博弈？">1.1 什么是博弈？</h3>
<p>在博弈论中，博弈（Game）通常定义为一种战略性互动，其中有多个理性参与者（Players），每个参与者都有各自的目标和可选择的行动（Actions/Strategies）。参与者的行动组合决定了每个参与者所获得的支付（Payoffs）。</p>
<p>一个博弈的核心要素包括：</p>
<ul>
<li><strong>参与者（Players）</strong>: 谁在参与博弈？</li>
<li><strong>行动（Actions）</strong>: 每个参与者可以采取哪些可行的选择？</li>
<li><strong>策略（Strategies）</strong>: 一个完整的行动计划，它指定了在博弈的每个可能状态下参与者将如何行动。</li>
<li><strong>支付（Payoffs）</strong>: 每个行动组合对应每个参与者的收益或损失。</li>
<li><strong>信息（Information）</strong>: 参与者对博弈结构、其他参与者的支付和策略的了解程度。</li>
</ul>
<h3 id="1-2-囚徒困境：一个永恒的悖论">1.2 囚徒困境：一个永恒的悖论</h3>
<p>囚徒困境（Prisoner’s Dilemma）是博弈论中最著名的例子之一，它生动地展示了理性个体在追求自身利益最大化时，可能导致整体次优结果的困境。</p>
<p>考虑两个嫌疑人（A和B）被捕，警方分别审讯他们，并提供以下交易：</p>
<ul>
<li>如果A和B都选择“坦白”，各判刑5年。</li>
<li>如果A“坦白”，B“抵赖”，A无罪释放，B判刑10年。</li>
<li>如果A“抵赖”，B“坦白”，A判刑10年，B无罪释放。</li>
<li>如果A和B都选择“抵赖”，各判刑1年。</li>
</ul>
<p>我们可以用支付矩阵来表示：</p>
<table>
<thead>
<tr>
<th style="text-align:left"></th>
<th style="text-align:left"><strong>B 坦白</strong></th>
<th style="text-align:left"><strong>B 抵赖</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>A 坦白</strong></td>
<td style="text-align:left">(-5, -5)</td>
<td style="text-align:left">(0, -10)</td>
</tr>
<tr>
<td style="text-align:left"><strong>A 抵赖</strong></td>
<td style="text-align:left">(-10, 0)</td>
<td style="text-align:left">(-1, -1)</td>
</tr>
</tbody>
</table>
<p>（注：支付为负值表示刑期，越小越好，如0 &gt; -1 &gt; -5 &gt; -10）</p>
<p>对于A而言：</p>
<ul>
<li>如果B坦白，A坦白 (-5) 好于抵赖 (-10)。</li>
<li>如果B抵赖，A坦白 (0) 好于抵赖 (-1)。<br>
因此，无论B做什么，A的最佳选择都是“坦白”。“坦白”是A的严格优势策略。</li>
</ul>
<p>同理，对于B而言，“坦白”也是其严格优势策略。</p>
<h3 id="1-3-纳什均衡：稳定点">1.3 纳什均衡：稳定点</h3>
<p>纳什均衡（Nash Equilibrium）是博弈论中的一个核心概念，它定义了一种策略组合，其中没有任何一个参与者可以通过单方面改变自己的策略来获得更好的支付，假设其他参与者的策略保持不变。</p>
<p>在囚徒困境中，唯一一个纳什均衡是 (坦白, 坦白)。尽管 (抵赖, 抵赖) 会给双方带来更高的集体收益（-1, -1），但由于个体理性决策的驱动，双方最终都会走向 (坦白, 坦白) 的次优结局。这是一个单次博弈的典型特征：缺乏未来互动的考量，导致合作的瓦解。</p>
<h2 id="二、-什么是重复博弈？">二、 什么是重复博弈？</h2>
<p>重复博弈是阶段博弈（Stage Game）在时间上重复进行多次的动态博弈。它允许我们分析参与者的长期互动、声誉建立、学习过程以及惩罚和奖励机制。</p>
<h3 id="2-1-阶段博弈与超级博弈">2.1 阶段博弈与超级博弈</h3>
<ul>
<li><strong>阶段博弈（Stage Game）</strong>: 这是重复博弈中每一次重复的基础博弈。例如，囚徒困境就可以作为一个阶段博弈。</li>
<li><strong>超级博弈（Supergame）</strong>: 阶段博弈的重复序列构成了超级博弈。</li>
</ul>
<p>在重复博弈中，参与者在每一轮博弈中根据历史信息（之前所有轮次中所有参与者的行动）来选择当前行动。这种信息流使得参与者能够实施依赖于过去行为的策略，例如“如果对手背叛我，我将在未来惩罚他”。</p>
<h3 id="2-2-有限次重复博弈-Finitely-Repeated-Games">2.2 有限次重复博弈 (Finitely Repeated Games)</h3>
<p>当阶段博弈被重复有限次（例如 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span> 次）时，我们称之为有限次重复博弈。</p>
<h4 id="2-2-1-逆向归纳法-Backward-Induction">2.2.1 逆向归纳法 (Backward Induction)</h4>
<p>有限次重复博弈的分析通常依赖于逆向归纳法。这种方法从博弈的最后一轮开始分析，逐步向前推导：</p>
<ol>
<li><strong>最后一轮 (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span>)</strong>: 在最后一轮，参与者知道博弈即将结束，没有未来互动的顾虑。因此，他们会选择该阶段博弈的纳什均衡策略。例如，在囚徒困境中，最后一轮双方都会选择“坦白”。</li>
<li><strong>倒数第二轮 (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">T-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span>)</strong>: 参与者知道第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span> 轮的结果是既定的纳什均衡。因此，第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">T-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span> 轮的决策不会影响第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span> 轮的理性选择。所以，在第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">T-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span> 轮，他们也会选择该阶段博弈的纳什均衡策略。</li>
<li><strong>依此类推</strong>: 持续向前推导，直到第一轮。</li>
</ol>
<p><strong>有限次囚徒困境的困境</strong></p>
<p>让我们以囚徒困境为例，假设它重复 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span> 次。</p>
<ul>
<li><strong>第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span> 轮</strong>: 唯一子博弈完美纳什均衡（Subgame Perfect Nash Equilibrium, SPNE）是 (坦白, 坦白)，因为这是阶段博弈的纳什均衡，且没有未来惩罚或奖励的可能性。</li>
<li><strong>第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">T-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span> 轮</strong>: 无论这轮发生什么，下一轮都会是 (坦白, 坦白)。因此，对于第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">T-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span> 轮而言，双方仍然会选择 (坦白, 坦白)。</li>
<li><strong>…直至第 1 轮</strong>: 通过逆向归纳法，每一轮的唯一SPNE都是 (坦白, 坦白)。</li>
</ul>
<p>这意味着，即使囚徒困境重复进行有限次，理性的参与者最终也会在每一轮都选择“坦白”，导致合作的彻底瓦解。这与我们日常生活中观察到的许多长期合作现象相悖。例如，商家和顾客的长期关系，通常会维持某种程度的合作和信任，而不是每次都“背叛”对方。这种矛盾之处正是有限次重复博弈的局限性，也引出了无限次重复博弈的重要性。</p>
<h3 id="2-3-无限次重复博弈-Infinitely-Repeated-Games">2.3 无限次重复博弈 (Infinitely Repeated Games)</h3>
<p>当阶段博弈被重复无限次时，博弈的性质发生了根本性的变化。此时，逆向归纳法不再适用，因为没有“最后一轮”。这种没有终点的特性为未来潜在的惩罚和奖励提供了可能，从而为合作的维持创造了条件。</p>
<h4 id="2-3-1-贴现因子-delta">2.3.1 贴现因子 (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span></span></span></span>)</h4>
<p>在无限次重复博弈中，我们引入了贴现因子（Discount Factor），通常用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span></span></span></span> 表示，其取值范围是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>≤</mo><mi>δ</mi><mo>&lt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">0 \le \delta &lt; 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7804em;vertical-align:-0.136em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7335em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span>。贴现因子的作用是衡量参与者对未来支付的重视程度：</p>
<ul>
<li><strong>直观理解</strong>: 今天的1美元通常比一年后的1美元更有价值。贴现因子就反映了这种时间偏好。<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span></span></span></span> 越接近1，表示参与者对未来支付越重视（越有耐心）；<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span></span></span></span> 越接近0，表示参与者越不重视未来支付（越不耐心）。</li>
<li><strong>数学表示</strong>: 如果在当前轮获得 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">v_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 收益，在下一轮获得 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">v_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 收益，在再下一轮获得 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">v_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 收益，那么总现值收益为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>=</mo><msub><mi>v</mi><mn>0</mn></msub><mo>+</mo><mi>δ</mi><msub><mi>v</mi><mn>1</mn></msub><mo>+</mo><msup><mi>δ</mi><mn>2</mn></msup><msub><mi>v</mi><mn>2</mn></msub><mo>+</mo><mo>⋯</mo><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>0</mn></mrow><mi mathvariant="normal">∞</mi></msubsup><msup><mi>δ</mi><mi>t</mi></msup><msub><mi>v</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">V = v_0 + \delta v_1 + \delta^2 v_2 + \dots = \sum_{t=0}^{\infty} \delta^t v_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.9641em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.3669em;"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.104em;vertical-align:-0.2997em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8043em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∞</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7936em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。</li>
<li><strong>其他解释</strong>: 贴现因子也可以解释为博弈在每一轮后继续进行的概率。如果博弈以概率 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">p</span></span></span></span> 继续，那么 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi><mo>=</mo><mi>p</mi></mrow><annotation encoding="application/x-tex">\delta = p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">p</span></span></span></span>。</li>
</ul>
<p>贴现因子是理解无限次重复博弈中合作如何维持的关键。如果 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span></span></span></span> 足够大，即参与者足够重视未来，那么通过威胁未来的惩罚，就可以使得当前的合作成为理性选择。</p>
<h2 id="三、-无限次重复博弈中的合作与惩罚">三、 无限次重复博弈中的合作与惩罚</h2>
<p>无限次重复博弈中最引人入胜的发现是，即使是像囚徒困境这样的博弈，通过设计巧妙的策略，也能在均衡中维持合作。这得益于“未来”的存在，它使得“现在”的背叛行为可能面临“未来”的报复，从而威慑了自利行为。</p>
<h3 id="3-1-民间定理-Folk-Theorem">3.1 民间定理 (Folk Theorem)</h3>
<p>民间定理是无限次重复博弈中最重要也是最令人惊讶的结果之一。它表明，在无限次重复博弈中，如果参与者足够有耐心（即贴现因子 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span></span></span></span> 足够高），那么任何满足特定条件的支付组合都可以成为某个子博弈完美纳什均衡的平均支付。</p>
<h4 id="3-1-1-个人理性支付-Individually-Rational-Payoffs">3.1.1 个人理性支付 (Individually Rational Payoffs)</h4>
<p>在理解民间定理之前，我们首先需要理解“个人理性支付”的概念。对于每个参与者 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span>，其个人理性支付 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>v</mi><mi>i</mi><mo>∗</mo></msubsup></mrow><annotation encoding="application/x-tex">v_i^*</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9474em;vertical-align:-0.2587em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-2.4413em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2587em;"><span></span></span></span></span></span></span></span></span></span> 是指在所有可能的策略组合中，参与者 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 能在最差情况下（即其他参与者采取对 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 最不利的策略时）所能保证的最小支付。<br>
更具体地，一个支付向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>v</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>v</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>v</mi><mi>N</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(v_1, v_2, \dots, v_N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 被认为是可强制（或可实现）的，如果存在某种策略组合，使得每个参与者 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 的平均支付至少达到其“安全”支付水平 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>v</mi><mi>i</mi><mo>∗</mo></msubsup></mrow><annotation encoding="application/x-tex">v_i^*</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9474em;vertical-align:-0.2587em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-2.4413em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2587em;"><span></span></span></span></span></span></span></span></span></span>。这个安全支付通常指的是在阶段博弈中，每个参与者能够通过选择自己的混合策略，来保证自己至少能得到的最低支付。对于囚徒困境，这个安全支付就是“坦白”所能带来的支付。</p>
<h4 id="3-1-2-民间定理的非正式表述">3.1.2 民间定理的非正式表述</h4>
<p>非正式地，民间定理指出：在无限次重复的阶段博弈中，如果贴现因子 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span></span></span></span> 足够接近1，那么任何能给所有参与者带来比他们在阶段博弈的任何纳什均衡中所得支付<strong>更高</strong>，且能通过某种策略组合实现的平均支付（通常是指比“安全支付”更高的支付，有时更严格地定义为比所有阶段博弈纳什均衡支付更高的支付），都可以作为超级博弈的一个子博弈完美纳什均衡的平均支付。</p>
<p>简单来说，只要未来足够重要，那么玩家们就可以通过威胁未来惩罚来维持合作。即使某个行为在当前看来是“次优”的（比如合作而不是背叛），但由于背叛可能招致长期的严厉惩罚，导致未来总收益的下降，因此合作就变得“理性”了。</p>
<h4 id="3-1-3-民间定理的数学表述（简化版）">3.1.3 民间定理的数学表述（简化版）</h4>
<p>设 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">G</span></span></span></span> 为一个有限的阶段博弈。设 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>e</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>e</mi><mi>N</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(e_1, \dots, e_N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">G</span></span></span></span> 的一个纳什均衡支付向量。设 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>v</mi><mi>i</mi><mo>∗</mo></msubsup></mrow><annotation encoding="application/x-tex">v_i^*</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9474em;vertical-align:-0.2587em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6887em;"><span style="top:-2.4413em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2587em;"><span></span></span></span></span></span></span></span></span></span> 为参与者 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 在阶段博弈中能保证的最小支付（即 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 的安全值，或最低限支付，mini-max payoff）。<br>
民间定理的一种常见形式（例如，关于纳什均衡的版本）指出：如果支付向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>x</mi><mi>N</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(x_1, \dots, x_N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 满足对所有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span>，有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>≥</mo><msub><mi>e</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i \ge e_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.786em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>（即每个玩家的平均支付至少不低于他在阶段博弈任何纳什均衡中的支付），并且 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>x</mi><mi>N</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(x_1, \dots, x_N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 是可实现的（即可通过某种策略组合获得），那么存在一个足够大的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>δ</mi><mo>ˉ</mo></mover><mo>&lt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\bar{\delta} &lt; 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8703em;vertical-align:-0.0391em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8312em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">ˉ</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span>，使得对于所有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi><mo>∈</mo><mo stretchy="false">(</mo><mover accent="true"><mi>δ</mi><mo>ˉ</mo></mover><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\delta \in (\bar{\delta}, 1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0812em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8312em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span></span><span style="top:-3.2634em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">ˉ</span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span>， <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>x</mi><mi>N</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(x_1, \dots, x_N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 可以在无限次重复博弈 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><mi mathvariant="normal">∞</mi><mo separator="true">,</mo><mi>δ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">G(\infty, \delta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">G</span><span class="mopen">(</span><span class="mord">∞</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mclose">)</span></span></span></span> 中作为某个子博弈完美纳什均衡的平均支付。</p>
<p>更普遍的（和强大的）版本是关于<strong>可强制支付</strong>（Feasible and Individually Rational Payoffs）的：任何可强制且每个玩家的支付都高于其“安全支付”的向量，如果 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span></span></span></span> 足够大，都可以作为SPNE的平均支付。</p>
<h3 id="3-2-经典的合作策略">3.2 经典的合作策略</h3>
<p>民间定理告诉我们合作是可能的，但它没有具体说明如何实现。这就需要我们引入一些具体的合作策略。这些策略通常是“历史依赖型”的，即当前的选择取决于过去发生的事件。</p>
<h4 id="3-2-1-冷酷触发策略-Grim-Trigger">3.2.1 冷酷触发策略 (Grim Trigger)</h4>
<p>冷酷触发策略是一种非常严厉的惩罚策略。其核心思想是：</p>
<ul>
<li><strong>初始状态</strong>: 所有参与者都选择合作（例如，在囚徒困境中都选择“抵赖”）。</li>
<li><strong>触发条件</strong>: 如果任何一个参与者在任何一轮偏离了合作策略（即背叛了），那么从下一轮开始，所有参与者将永远选择阶段博弈的纳什均衡策略（即永远“坦白”）。这种惩罚是“冷酷”的，因为一旦触发，就永不停止。</li>
</ul>
<p>让我们以囚徒困境为例，分析冷酷触发策略如何维持合作。<br>
假设合作（C）的支付是 (R, R) = (-1, -1)，背叛（D）的支付是 (T, S) = (0, -10) 或 (S, T) = (-10, 0)，以及纳什均衡（NE）的支付是 (P, P) = (-5, -5)。</p>
<p>考虑玩家A选择合作，而玩家B考虑是否背叛。<br>
如果B合作：B的支付流是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mo>−</mo><mn>1</mn><mo separator="true">,</mo><mo>−</mo><mn>1</mn><mo separator="true">,</mo><mo>−</mo><mn>1</mn><mo separator="true">,</mo><mo>…</mo><mtext> </mtext><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(-1, -1, -1, \dots)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">−</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">−</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">−</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mclose">)</span></span></span></span>，总现值支付是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mo>−</mo><mn>1</mn></mrow><mrow><mn>1</mn><mo>−</mo><mi>δ</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{-1}{1-\delta}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2484em;vertical-align:-0.4033em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.03785em;">δ</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>。<br>
如果B背叛（假设A仍然合作）：B在当前轮获得短期的“背叛收益”0，但从下一轮开始，A将永远选择坦白，导致B的支付永远是-5。B的支付流是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mo>−</mo><mn>5</mn><mo separator="true">,</mo><mo>−</mo><mn>5</mn><mo separator="true">,</mo><mo>−</mo><mn>5</mn><mo separator="true">,</mo><mo>…</mo><mtext> </mtext><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(0, -5, -5, -5, \dots)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">−</span><span class="mord">5</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">−</span><span class="mord">5</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">−</span><span class="mord">5</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mclose">)</span></span></span></span>，总现值支付是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>+</mo><mi>δ</mi><mfrac><mrow><mo>−</mo><mn>5</mn></mrow><mrow><mn>1</mn><mo>−</mo><mi>δ</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">0 + \delta \frac{-5}{1-\delta}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.2484em;vertical-align:-0.4033em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.03785em;">δ</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">5</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>。</p>
<p>为了使B选择合作（即不背叛），合作的总现值必须大于或等于背叛的总现值：<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mo>−</mo><mn>1</mn></mrow><mrow><mn>1</mn><mo>−</mo><mi>δ</mi></mrow></mfrac><mo>≥</mo><mn>0</mn><mo>+</mo><mfrac><mrow><mo>−</mo><mn>5</mn><mi>δ</mi></mrow><mrow><mn>1</mn><mo>−</mo><mi>δ</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{-1}{1-\delta} \ge 0 + \frac{-5\delta}{1-\delta}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2484em;vertical-align:-0.4033em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.03785em;">δ</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.2834em;vertical-align:-0.4033em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.03785em;">δ</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">5</span><span class="mord mathnormal mtight" style="margin-right:0.03785em;">δ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>1</mn><mo>≥</mo><mo>−</mo><mn>5</mn><mi>δ</mi></mrow><annotation encoding="application/x-tex">-1 \ge -5\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7804em;vertical-align:-0.136em;"></span><span class="mord">−</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord">−</span><span class="mord">5</span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span></span></span></span><br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn><mi>δ</mi><mo>≥</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">5\delta \ge 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8304em;vertical-align:-0.136em;"></span><span class="mord">5</span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span><br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi><mo>≥</mo><mfrac><mn>1</mn><mn>5</mn></mfrac></mrow><annotation encoding="application/x-tex">\delta \ge \frac{1}{5}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8304em;vertical-align:-0.136em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">5</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<p>这意味着，只要贴现因子 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi><mo>≥</mo><mn>0.2</mn></mrow><annotation encoding="application/x-tex">\delta \ge 0.2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8304em;vertical-align:-0.136em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.2</span></span></span></span>，即玩家对未来的重视程度达到或超过20%，那么冷酷触发策略就能在囚徒困境中维持合作。这展示了未来惩罚的巨大威慑力。</p>
<p><strong>冷酷触发策略的特点：</strong></p>
<ul>
<li><strong>简单且有效</strong>: 策略规则明确，易于理解。</li>
<li><strong>强大的威慑</strong>: 一旦背叛，将面临永久的惩罚，这使得短期背叛的诱惑变得非常小。</li>
<li><strong>不宽容</strong>: 一旦偏离，没有回头路，这在现实中可能过于严厉，导致僵局。</li>
<li><strong>可能导致效率低下</strong>: 如果有人不小心犯了错（比如观测误差），可能会引发永久的惩罚循环，导致所有人的收益都下降。</li>
</ul>
<h4 id="3-2-2-以牙还牙策略-Tit-for-Tat">3.2.2 以牙还牙策略 (Tit-for-Tat)</h4>
<p>以牙还牙策略是另一种著名的合作策略，由阿纳托尔·拉波波特（Anatol Rapoport）在罗伯特·阿克塞尔罗德（Robert Axelrod）组织的计算机囚徒困境锦标赛中提出，并赢得了两次比赛。它的规则比冷酷触发策略更具适应性和宽容性：</p>
<ul>
<li><strong>第一轮</strong>: 选择合作。</li>
<li><strong>后续轮次</strong>: 复制对手在上一轮的行动。如果对手上一轮合作，我这轮也合作；如果对手上一轮背叛，我这轮也背叛。</li>
</ul>
<p><strong>以牙还牙策略的特点：</strong></p>
<ul>
<li><strong>善良 (Nice)</strong>: 永不首先背叛。它从合作开始，并愿意一直合作下去。</li>
<li><strong>报复 (Retaliatory)</strong>: 对背叛行为迅速做出回应。一旦对手背叛，它会立即反击。</li>
<li><strong>宽恕 (Forgiving)</strong>: 如果对手停止背叛并开始合作，它也会停止报复并恢复合作。它不会像冷酷触发那样永久惩罚。</li>
<li><strong>清晰 (Clear)</strong>: 策略规则简单明了，容易被其他参与者理解和预测。</li>
</ul>
<p><strong>以牙还牙策略的优势：</strong></p>
<ul>
<li><strong>鲁棒性</strong>: 在各种不同策略的混合环境中表现良好。</li>
<li><strong>促进合作</strong>: 通过快速响应和宽容的特点，有助于建立和维持合作关系。</li>
<li><strong>避免永久僵局</strong>: 即使出现背叛，也有恢复合作的可能性。</li>
</ul>
<p><strong>以牙还牙策略的局限性：</strong></p>
<ul>
<li><strong>容易陷入“互咬”循环</strong>: 如果出现观测误差或双方都误判对方的行动，可能导致长时间的相互报复。</li>
<li><strong>无法利用“傻瓜”</strong>: 对于一直合作但从不反击的对手，以牙还牙无法利用其善意来获取更多收益。</li>
</ul>
<p><strong>Python 模拟示例：囚徒困境与策略</strong></p>
<p>为了更好地理解这些策略，我们用Python模拟一个简单的囚徒困境游戏。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 囚徒困境支付矩阵 (Player 1, Player 2)</span></span><br><span class="line"><span class="comment"># C = Cooperate (抵赖), D = Defect (坦白)</span></span><br><span class="line"><span class="comment"># Payoffs: (R,R)=(-1,-1), (S,T)=(-10,0), (T,S)=(0,-10), (P,P)=(-5,-5)</span></span><br><span class="line"><span class="comment"># 我们使用正值表示收益，因此我们将负值刑期转换为正值收益，越大越好</span></span><br><span class="line"><span class="comment"># (C,C) -&gt; (4,4)  (刑期-1 -&gt; 收益 4)</span></span><br><span class="line"><span class="comment"># (C,D) -&gt; (0,5)  (刑期-10,0 -&gt; 收益 0,5)</span></span><br><span class="line"><span class="comment"># (D,C) -&gt; (5,0)  (刑期0,-10 -&gt; 收益 5,0)</span></span><br><span class="line"><span class="comment"># (D,D) -&gt; (1,1)  (刑期-5,-5 -&gt; 收益 1,1)</span></span><br><span class="line"></span><br><span class="line">PAYOFFS = &#123;</span><br><span class="line">    (<span class="string">&#x27;C&#x27;</span>, <span class="string">&#x27;C&#x27;</span>): (<span class="number">4</span>, <span class="number">4</span>),</span><br><span class="line">    (<span class="string">&#x27;C&#x27;</span>, <span class="string">&#x27;D&#x27;</span>): (<span class="number">0</span>, <span class="number">5</span>), <span class="comment"># Player 1 C, Player 2 D (Player 1 gets 0, Player 2 gets 5)</span></span><br><span class="line">    (<span class="string">&#x27;D&#x27;</span>, <span class="string">&#x27;C&#x27;</span>): (<span class="number">5</span>, <span class="number">0</span>), <span class="comment"># Player 1 D, Player 2 C (Player 1 gets 5, Player 2 gets 0)</span></span><br><span class="line">    (<span class="string">&#x27;D&#x27;</span>, <span class="string">&#x27;D&#x27;</span>): (<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义策略</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Strategy</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, name</span>):</span><br><span class="line">        <span class="variable language_">self</span>.name = name</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">choose_action</span>(<span class="params">self, history_self, history_opponent</span>):</span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GrimTrigger</span>(<span class="title class_ inherited__">Strategy</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(<span class="string">&quot;Grim Trigger&quot;</span>)</span><br><span class="line">        <span class="variable language_">self</span>.betrayed = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">choose_action</span>(<span class="params">self, history_self, history_opponent</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.betrayed:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">&#x27;D&#x27;</span> <span class="comment"># Once betrayed, always defect</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Check if opponent defected in any past round</span></span><br><span class="line">        <span class="keyword">for</span> action <span class="keyword">in</span> history_opponent:</span><br><span class="line">            <span class="keyword">if</span> action == <span class="string">&#x27;D&#x27;</span>:</span><br><span class="line">                <span class="variable language_">self</span>.betrayed = <span class="literal">True</span></span><br><span class="line">                <span class="keyword">return</span> <span class="string">&#x27;D&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;C&#x27;</span> <span class="comment"># Otherwise, cooperate</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TitForTat</span>(<span class="title class_ inherited__">Strategy</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(<span class="string">&quot;Tit-for-Tat&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">choose_action</span>(<span class="params">self, history_self, history_opponent</span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> history_opponent: <span class="comment"># First round</span></span><br><span class="line">            <span class="keyword">return</span> <span class="string">&#x27;C&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> history_opponent[-<span class="number">1</span>] <span class="comment"># Do what opponent did last round</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AlwaysCooperate</span>(<span class="title class_ inherited__">Strategy</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(<span class="string">&quot;Always Cooperate&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">choose_action</span>(<span class="params">self, history_self, history_opponent</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;C&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AlwaysDefect</span>(<span class="title class_ inherited__">Strategy</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(<span class="string">&quot;Always Defect&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">choose_action</span>(<span class="params">self, history_self, history_opponent</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&#x27;D&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟博弈</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">simulate_game</span>(<span class="params">player1_strategy, player2_strategy, rounds=<span class="number">10</span></span>):</span><br><span class="line">    history_p1 = []</span><br><span class="line">    history_p2 = []</span><br><span class="line">    total_payoff_p1 = <span class="number">0</span></span><br><span class="line">    total_payoff_p2 = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n--- Simulating <span class="subst">&#123;player1_strategy.name&#125;</span> vs <span class="subst">&#123;player2_strategy.name&#125;</span> for <span class="subst">&#123;rounds&#125;</span> rounds ---&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(rounds):</span><br><span class="line">        action_p1 = player1_strategy.choose_action(history_p1, history_p2)</span><br><span class="line">        action_p2 = player2_strategy.choose_action(history_p2, history_p1) <span class="comment"># Note: history_p2 for p1, history_p1 for p2</span></span><br><span class="line"></span><br><span class="line">        payoff_p1, payoff_p2 = PAYOFFS[(action_p1, action_p2)]</span><br><span class="line">        </span><br><span class="line">        total_payoff_p1 += payoff_p1</span><br><span class="line">        total_payoff_p2 += payoff_p2</span><br><span class="line"></span><br><span class="line">        history_p1.append(action_p1)</span><br><span class="line">        history_p2.append(action_p2)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Round <span class="subst">&#123;i+<span class="number">1</span>&#125;</span>: P1 plays <span class="subst">&#123;action_p1&#125;</span>, P2 plays <span class="subst">&#123;action_p2&#125;</span> | Payoffs: (<span class="subst">&#123;payoff_p1&#125;</span>, <span class="subst">&#123;payoff_p2&#125;</span>)&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;--- Simulation Ended ---&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Total Payoff for <span class="subst">&#123;player1_strategy.name&#125;</span>: <span class="subst">&#123;total_payoff_p1&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Total Payoff for <span class="subst">&#123;player2_strategy.name&#125;</span>: <span class="subst">&#123;total_payoff_p2&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Reset strategy state for next simulation if needed</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(player1_strategy, GrimTrigger):</span><br><span class="line">        player1_strategy.betrayed = <span class="literal">False</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(player2_strategy, GrimTrigger):</span><br><span class="line">        player2_strategy.betrayed = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行模拟</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 场景1: 冷酷触发 vs 冷酷触发</span></span><br><span class="line">    simulate_game(GrimTrigger(), GrimTrigger(), rounds=<span class="number">5</span>) </span><br><span class="line">    <span class="comment"># 预期: 都合作，获得高收益 (4,4)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 场景2: 冷酷触发 vs 总是背叛</span></span><br><span class="line">    simulate_game(GrimTrigger(), AlwaysDefect(), rounds=<span class="number">5</span>)</span><br><span class="line">    <span class="comment"># 预期: 第一轮冷酷触发合作，总是背叛背叛 (0,5)，第二轮开始冷酷触发也背叛 (1,1)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 场景3: 以牙还牙 vs 以牙还牙</span></span><br><span class="line">    simulate_game(TitForTat(), TitForTat(), rounds=<span class="number">5</span>)</span><br><span class="line">    <span class="comment"># 预期: 都合作，获得高收益 (4,4)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 场景4: 以牙还牙 vs 总是背叛</span></span><br><span class="line">    simulate_game(TitForTat(), AlwaysDefect(), rounds=<span class="number">5</span>)</span><br><span class="line">    <span class="comment"># 预期: 第一轮 (0,5)，之后都 (1,1)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 场景5: 总是合作 vs 总是背叛</span></span><br><span class="line">    simulate_game(AlwaysCooperate(), AlwaysDefect(), rounds=<span class="number">5</span>)</span><br><span class="line">    <span class="comment"># 预期: 总是合作方被剥削 (0,5)</span></span><br></pre></td></tr></table></figure>
<p><strong>代码解释：</strong></p>
<ul>
<li><code>PAYOFFS</code> 字典定义了囚徒困境的支付矩阵。我将其转换为正向收益，以便“越大越好”的直观理解。</li>
<li><code>Strategy</code> 是一个基类，定义了策略的接口。</li>
<li><code>GrimTrigger</code> 实现了冷酷触发策略：一旦对手背叛过，就永远背叛。</li>
<li><code>TitForTat</code> 实现了以牙还牙策略：第一轮合作，之后模仿对手上一轮的行动。</li>
<li><code>AlwaysCooperate</code> 和 <code>AlwaysDefect</code> 是简单的基准策略。</li>
<li><code>simulate_game</code> 函数运行指定轮数的博弈，并打印每轮的行动和总支付。</li>
</ul>
<p>通过运行这段代码，你可以直观地看到不同策略在重复博弈中的动态表现，尤其是在面对背叛时，冷酷触发和以牙还牙如何做出反应，以及它们如何影响长期收益。</p>
<h3 id="3-3-子博弈完美纳什均衡-Subgame-Perfect-Nash-Equilibrium-SPNE">3.3 子博弈完美纳什均衡 (Subgame Perfect Nash Equilibrium, SPNE)</h3>
<p>在无限次重复博弈中，纳什均衡的概念不足以排除一些非理性的威胁。因此，我们需要一个更强的均衡概念：子博弈完美纳什均衡（SPNE）。</p>
<h4 id="3-3-1-定义">3.3.1 定义</h4>
<p>一个策略组合构成一个子博弈完美纳什均衡，如果它在博弈的每一个子博弈中都构成一个纳什均衡。在重复博弈中，每个历史（即从第一轮到当前轮之前所有行动的序列）都定义了一个子博弈。这意味着，在博弈的任何一个时点，无论过去发生了什么，未来玩家的行动都必须是彼此的最佳回应。</p>
<h4 id="3-3-2-验证冷酷触发策略是否为SPNE">3.3.2 验证冷酷触发策略是否为SPNE</h4>
<p>让我们回顾冷酷触发策略。它规定：</p>
<ol>
<li>如果从未有玩家背叛过，则所有玩家合作。</li>
<li>如果曾经有玩家背叛过，则所有玩家永远背叛。</li>
</ol>
<p>为了验证它是否是SPNE，我们需要检查两个主要的子博弈：</p>
<p><strong>子博弈1：合作路径（从未有人背叛过）</strong></p>
<ul>
<li>在这个子博弈中，每个玩家都选择合作。如果任何玩家偏离合作，他会在当前轮获得短期背叛收益，但从下一轮开始，所有玩家将永远转入“惩罚阶段”（都选择背叛）。</li>
<li>如前所述，只要 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi><mo>≥</mo><mfrac><mn>1</mn><mn>5</mn></mfrac></mrow><annotation encoding="application/x-tex">\delta \ge \frac{1}{5}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8304em;vertical-align:-0.136em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">≥</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1901em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">5</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>，合作的长期收益就会高于一次性背叛的短期收益加上未来的低收益。因此，在这个子博弈中，没有人有动机单方面偏离合作。</li>
</ul>
<p><strong>子博弈2：惩罚路径（已经有人背叛过）</strong></p>
<ul>
<li>在这个子博弈中，冷酷触发策略规定所有玩家都选择背叛（坦白）。</li>
<li>假设当前处于惩罚阶段，如果玩家A选择合作而非背叛，而玩家B仍然选择背叛（按照策略），那么A将获得更低的支付（-10而不是-5）。如果A也选择背叛，那么支付是-5。由于惩罚阶段已经启动，合作的威胁已经失效，无论A做什么，B都会继续背叛。因此，对于A而言，继续背叛是最佳选择。</li>
<li>同理，对于B而言，继续背叛也是最佳选择。</li>
<li>所以，在惩罚阶段，(背叛, 背叛) 是阶段博弈的纳什均衡，因此它在该子博弈中也是一个纳什均衡。</li>
</ul>
<p>由于冷酷触发策略在所有可能的子博弈（合作路径和惩罚路径）中都构成纳什均衡，所以它是一个子博弈完美纳什均衡。</p>
<p>理解SPNE的关键在于，它要求在博弈的任何节点（无论是否处于均衡路径上），玩家的策略都必须是理性的。这意味着，即使惩罚是严厉的，当惩罚被触发后，执行惩罚的策略本身也必须是理性的。冷酷触发策略满足了这一条件，因为一旦进入惩罚阶段，玩家会永远停留在阶段博弈的纳什均衡，这本身就是理性的。</p>
<h2 id="四、-重复博弈的应用与洞察">四、 重复博弈的应用与洞察</h2>
<p>重复博弈理论为我们理解现实世界中许多复杂的战略互动提供了强大的分析工具。</p>
<h3 id="4-1-经济学中的应用">4.1 经济学中的应用</h3>
<ul>
<li><strong>寡头垄断与合谋</strong>: 在少数几家公司主导的市场中，公司之间往往存在重复的价格竞争。尽管单次博弈（如古诺模型或伯特兰模型）可能预测价格战或产量竞争，但重复博弈解释了为什么公司能够维持较高的价格并分享垄断利润（即合谋）。通过威胁在未来对偏离合谋者发动价格战，公司可以维持默契的合作。冷酷触发策略或以牙还牙策略在解释这种现象时非常有用。</li>
<li><strong>劳资关系</strong>: 雇主和员工之间的互动是持续的。员工可能会在工作中偷懒，但如果被发现，可能面临解雇或工资下降的惩罚。雇主也可能承诺奖励高绩效员工，以鼓励长期努力。这些都是重复博弈的体现。</li>
<li><strong>国际贸易协定与制裁</strong>: 国家之间的贸易关系也是重复博弈。一个国家可能会背离贸易协定，但如果其他国家威胁采取报复性关税或停止贸易，这种背离的诱惑就会降低。国际制裁可以被视为一种冷酷触发式的惩罚。</li>
<li><strong>信贷市场</strong>: 银行与借款人之间的关系也是重复博弈。借款人有动机违约，但如果违约，将面临信用评级受损、未来无法获得贷款的惩罚。</li>
</ul>
<h3 id="4-2-社会学与政治学中的应用">4.2 社会学与政治学中的应用</h3>
<ul>
<li><strong>信任与声誉</strong>: 重复博弈是建立信任和声誉的基石。在一次性互动中，信任可能很难建立。但在重复互动中，如果一个人每次都信守承诺，他的声誉就会提高，从而获得更多的合作机会。声誉机制本质上是一种期望未来合作的策略。</li>
<li><strong>国际关系与军备竞赛</strong>: 国家之间的冲突与合作也是重复博弈。军备竞赛可以被视为囚徒困境的一种形式，两国都有动机增加军备，但最终可能导致双方都更不安全。然而，通过重复互动和互惠原则（以牙还牙），军备控制协议有可能被维持。</li>
<li><strong>社区规范与惩罚</strong>: 在没有正式法律的社区中，社会规范和群体压力可以通过重复互动来维持。对偏离规范者的孤立或排斥可以看作是一种惩罚机制，促使个体遵守社区规则。</li>
</ul>
<h3 id="4-3-生物学中的应用">4.3 生物学中的应用</h3>
<ul>
<li><strong>合作的进化</strong>: 在进化生物学中，重复博弈被用来解释为什么合作行为能在自然界中进化。例如，吸血蝙蝠分享食物、鸟类发出捕食者警报等。即使在个体层面看起来是利他的行为，但在长期的群体互动中，通过互惠互利和惩罚机制，合作可以成为一种稳定的进化策略。阿克塞尔罗德的计算机囚徒困境锦标赛及其后续研究对“合作的进化”这一领域产生了深远影响。</li>
</ul>
<h3 id="4-4-日常生活中的应用">4.4 日常生活中的应用</h3>
<ul>
<li><strong>朋友关系与家庭互动</strong>: 朋友和家人之间的关系也是持续的重复博弈。一次小小的冲突或背叛，如果处理得当，可以通过随后的合作和宽恕来修复。但如果持续的背叛，就会导致关系的破裂。</li>
<li><strong>商业伙伴关系</strong>: 长期稳定的商业伙伴关系往往建立在相互信任和反复互动的基础上。一次性欺诈可能带来短期利益，但会损害长期合作关系带来的巨大利益。</li>
<li><strong>消费者行为</strong>: 消费者对品牌的忠诚度，部分原因在于品牌长期提供优质产品和服务的承诺，这是一种重复博弈中的合作策略。</li>
</ul>
<h2 id="五、-高级主题与挑战">五、 高级主题与挑战</h2>
<p>重复博弈理论虽然强大，但也面临一些挑战和复杂性，这催生了更深入的研究方向。</p>
<h3 id="5-1-不完全信息与不完美监测-Imperfect-Information-and-Imperfect-Monitoring">5.1 不完全信息与不完美监测 (Imperfect Information and Imperfect Monitoring)</h3>
<p>我们前面讨论的重复博弈模型假设参与者可以完美地观察到对手在每一轮的行动。然而，在现实中，这往往是不可能的。</p>
<ul>
<li><strong>不完美监测 (Imperfect Monitoring)</strong>: 参与者无法直接观察到对手的行动，而只能观察到与这些行动相关的结果，且这些结果可能带有噪声。例如，公司可能无法直接观察竞争对手的生产成本或生产决策，而只能观察到市场价格。在这种情况下，要判断对手是否背叛变得困难，因为低收益可能是由于随机事件而非对手的背叛。
<ul>
<li>这导致需要更复杂的策略，例如<strong>信息共享策略</strong>或<strong>信号策略</strong>，以在不确定性下维持合作。简单的冷酷触发可能会因为“误判”而导致不必要的惩罚循环。</li>
</ul>
</li>
<li><strong>不完全信息 (Incomplete Information)</strong>: 参与者对其他参与者的类型（例如，他们的支付函数或贴现因子）不完全了解。例如，你可能不知道你的商业伙伴是天生合作的还是天生自私的。
<ul>
<li>这引入了贝叶斯博弈论的元素。玩家可能会尝试通过观察对手的行动来推断他们的类型，并据此调整自己的策略。这种情况下，建立声誉（即让对手相信你是某种特定类型）变得尤为重要。</li>
</ul>
</li>
</ul>
<h3 id="5-2-可重谈性-Renegotiation-Proofness">5.2 可重谈性 (Renegotiation Proofness)</h3>
<p>在冷酷触发策略中，一旦惩罚被触发，惩罚会一直持续下去。然而，这种无限期的惩罚对于执行惩罚的双方来说，可能都是次优的。例如，如果双方都进入了长期相互背叛的阶段（支付都是-5），他们可能会发现，即使是过去发生了背叛，重新回到合作状态（支付都是-1）会更好。</p>
<ul>
<li><strong>可重谈性均衡 (Renegotiation Proof Equilibrium)</strong>: 这一概念旨在寻找那些不仅是SPNE，而且在任何时候，如果参与者可以重新谈判并达成一个共同有利的新均衡，他们也不会偏离原有策略的均衡。也就是说，即使处于惩罚阶段，参与者也没有动机通过“重新谈判”来改变他们的策略。</li>
<li>这通常意味着惩罚不能过于严厉，或者惩罚必须是有限期的，以便在惩罚结束后，合作可以恢复。这使得策略设计变得更加复杂，需要在威慑力和灵活性之间取得平衡。</li>
</ul>
<h3 id="5-3-学习与适应性动力学-Learning-and-Adaptive-Dynamics">5.3 学习与适应性动力学 (Learning and Adaptive Dynamics)</h3>
<p>传统的重复博弈理论假设参与者是完全理性的，并且对博弈结构和对手的策略有完美的了解。然而，在现实世界中，参与者可能并不总是完全理性的，他们可能通过试错和学习来调整自己的策略。</p>
<ul>
<li><strong>经验学习</strong>: 参与者根据过去的经验调整他们的信念和行动。例如，如果一种策略在过去表现良好，玩家可能会继续使用它。</li>
<li><strong>进化博弈论 (Evolutionary Game Theory)</strong>: 这种方法不假设个体是完全理性的，而是将策略视为可以随时间“进化”的特征。成功的策略会“繁殖”得更多，而不成功的策略则会被淘汰。它关注的是在重复互动中，哪些策略能够稳定地存在并传播开来。这与阿克塞尔罗德的囚徒困境锦标赛中的策略演化有着密切联系。</li>
<li><strong>强化学习</strong>: 在人工智能领域，重复博弈被广泛用于训练强化学习代理。代理通过与环境互动和接收奖励/惩罚来学习最佳策略，这与人类在重复博弈中的学习过程有异曲同工之妙。</li>
</ul>
<h3 id="5-4-复杂阶段博弈与网络重复博弈">5.4 复杂阶段博弈与网络重复博弈</h3>
<ul>
<li><strong>复杂阶段博弈</strong>: 当阶段博弈本身非常复杂，具有多个纳什均衡，或参与者众多时，重复博弈的分析变得更加困难。如何选择一个协调的合作均衡，以及如何设计有效的惩罚机制，都是挑战。</li>
<li><strong>网络重复博弈</strong>: 现代社会中，许多互动发生在一个复杂的网络结构中。例如，社交网络中的信息传播、供应链中的合作。在这种情况下，一个参与者的行动不仅影响直接互动者，还可能通过网络效应影响其他间接参与者。重复博弈在网络结构中的应用是一个新兴且富有挑战性的研究方向。</li>
</ul>
<h2 id="结论：永恒互动的智慧">结论：永恒互动的智慧</h2>
<p>重复博弈理论为我们提供了一副透视镜，让我们能够更深刻地理解人类社会乃至自然界中无处不在的长期互动。它揭示了“未来”的力量——正是对未来收益的期望和对未来惩罚的担忧，才使得合作在看似自私自利的世界中得以萌芽、成长并维持。</p>
<p>从囚徒困境的单次背叛到冷酷触发和以牙还牙策略所维持的长期合作，我们看到了理性选择的边界被无限的互动所拓展。贴现因子 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span></span></span></span> 不再仅仅是一个数学参数，它成为了耐心、远见和信任的量化体现。民间定理则以一种令人震撼的方式宣告了合作的普遍可能性。</p>
<p>重复博弈的智慧远不止于解释经济中的合谋或国际政治中的制裁。它渗透到我们日常生活的方方面面：朋友间的友谊、家庭中的和谐、商业中的声誉，乃至社区中的规范。所有这些长期关系的稳定，都离不开某种形式的重复博弈机制在背后默默运作，无论是自觉的策略选择，还是无意识的文化演化。</p>
<p>当然，重复博弈并非万能。不完全信息、不完美监测、策略的可重谈性以及有限理性下的学习过程，都为这一领域带来了新的挑战和研究前沿。这些进阶主题不仅促使我们发展出更精妙的数学模型，也更深刻地反映了真实世界中互动决策的复杂性和动态性。</p>
<p>作为技术爱好者，重复博弈理论的严谨逻辑和广阔应用前景无疑是令人着迷的。它提醒我们，理解系统行为不仅要看单个节点的瞬时选择，更要关注它们在时间维度上的相互作用和反馈。无论是设计AI代理使其在复杂环境中更“社会化”，还是构建去中心化系统中的激励机制，重复博弈的原理都将为我们提供宝贵的启示。</p>
<p>让我们继续探索，继续思考，因为在永恒的互动中，隐藏着理解世界最深层的秘密。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a target="_blank" rel="noopener" href="https://github.com/qmwneb946">qmwneb946</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://qmwneb946.dpdns.org/2025/07/23/2025-07-23-205150/">https://qmwneb946.dpdns.org/2025/07/23/2025-07-23-205150/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://opensource.org/licenses/MIT" target="_blank">MIT License</a> 许可协议。转载请注明来源 <a href="https://qmwneb946.dpdns.org" target="_blank">qmwneb946 的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%A7%91%E6%8A%80%E5%89%8D%E6%B2%BF/">科技前沿</a><a class="post-meta__tags" href="/tags/2025/">2025</a><a class="post-meta__tags" href="/tags/%E9%87%8D%E5%A4%8D%E5%8D%9A-game-theory/">重复博&quot;game theory&quot;</a></div><div class="post-share"><div class="social-share" data-image="/img/icon.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/07/23/2025-07-23-205304/" title="遗传算法与进化计算：探索自然启发的智能优化"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">遗传算法与进化计算：探索自然启发的智能优化</div></div><div class="info-2"><div class="info-item-1">你好，各位技术爱好者和数学狂人！我是qmwneb946，今天我们不聊最新的框架，也不谈炫酷的AI模型，而是将目光投向一个古老而又充满智慧的领域——遗传算法（Genetic Algorithms, GA）与进化计算（Evolutionary Computation, EC）。想象一下，大自然在亿万年间通过物竞天择，演化出了地球上如此多样而精妙的生命形态。这种强大的优化和适应能力，难道不能为我们的计算机科学所用吗？答案是肯定的！进化计算正是受到了大自然的启发，通过模拟生物进化的过程来解决复杂的计算问题。 这并非仅仅是一种理论上的浪漫想象，进化计算，尤其是遗传算法，在许多传统优化方法束手无策的领域展现出了惊人的效力。从复杂的工程设计到金融建模，从生物信息学到机器学习的超参数调优，它们的身影无处不在。 在这篇深度博客文章中，我们将一起探索遗传算法与进化计算的奥秘。我们将从它们诞生的历史讲起，深入剖析其核心概念，一步步解构其工作原理，并通过实际案例加深理解。我们还会涉足进化计算家族的其他成员以及一些高级话题，最终探讨它们的优势、局限性及其广阔的应用前景。系好安全带，准备踏上这场算法的“进化...</div></div></div></a><a class="pagination-related" href="/2025/07/23/2025-07-23-205049/" title="分形与信号处理：从自然之形到信号之韵的深度探索"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">分形与信号处理：从自然之形到信号之韵的深度探索</div></div><div class="info-2"><div class="info-item-1">你好，各位技术爱好者和数学追随者！我是 qmwneb946，今天我们将踏上一段引人入胜的旅程，探索两个看似独立却又深刻交织的领域：分形（Fractals）与信号处理（Signal Processing）。这不仅仅是一次技术解析，更是一次对自然、数学与工程之间奇妙联系的哲学思考。准备好了吗？让我们深入这片充满无限细节和复杂韵律的知识海洋！ 引言：当混沌遇上秩序，当几何拥抱信号 我们所处的世界，远比欧几里得几何所能描绘的更加复杂和美丽。云朵的边缘、海岸线的曲折、树枝的生长、血管的分布，这些自然现象无不展现出一种独特的、在不同尺度下重复出现的图案——这就是分形。它们是无限精细的、自相似的、具有非整数维度的几何形状，由本华·曼德尔布罗特（Benoît Mandelbrot）在20世纪70年代系统地提出。分形理论的出现，为我们理解和描述自然界的复杂性打开了一扇全新的大门。 与此同时，信号处理，这门致力于从数据中提取信息、改善数据质量或将其转化为可用形式的学科，早已渗透到我们生活的方方面面。从手机的无线通信到医疗影像诊断，从金融市场预测到地震波分析，信号处理技术无处不在。然而，传统的信号处理...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/07/18/2025-07-18-082408/" title="人工智能在医疗诊断中的应用：机遇与挑战"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">人工智能在医疗诊断中的应用：机遇与挑战</div></div><div class="info-2"><div class="info-item-1">大家好，我是你们的技术和数学博主！今天，我们来深入探讨一个激动人心的领域：人工智能 (AI) 在医疗诊断中的应用。AI 的快速发展正在彻底改变医疗行业，为更精准、高效的诊断提供了前所未有的可能性。但同时，我们也需要审慎地看待其挑战和局限性。 引言：AI 赋能医疗诊断 医疗诊断是一个复杂的过程，需要医生具备丰富的知识、经验和判断力。然而，人类医生可能会受到主观偏差、疲劳以及信息过载的影响。AI 的介入，则为提高诊断准确性和效率提供了新的途径。通过分析大量的医学影像数据、病历记录和基因组信息，AI 算法可以学习识别疾病模式，辅助医生进行诊断，甚至在某些情况下独立完成初步诊断。 AI 在医疗诊断中的核心技术 深度学习在医学影像分析中的应用 深度学习，特别是卷积神经网络 (CNN)，在医学影像分析中取得了显著的成功。CNN 可以从大量的医学影像数据（例如 X 光片、CT 扫描、MRI 图像）中学习特征，并识别出细微的病变，例如肺癌结节、脑瘤或心血管疾病。 例如，一个训练良好的 CNN 模型可以比人类放射科医生更早地检测出肺癌，从而提高早期诊断率和治疗成功率。  这其中的关键在于大量的标注...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082643/" title="高分子化学与可降解塑料：迈向可持续未来的关键"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">高分子化学与可降解塑料：迈向可持续未来的关键</div></div><div class="info-2"><div class="info-item-1">近年来，塑料污染已成为全球性环境问题。传统塑料由于其难以降解的特性，对环境造成了巨大的压力。而可降解塑料的出现，为解决这一问题提供了一条可行的途径。本文将深入探讨高分子化学在可降解塑料研发中的关键作用，并介绍几种主要的降解机制和材料。 高分子化学：可降解塑料的基础 可降解塑料并非简单的“可被分解的塑料”，其核心在于高分子材料的分子结构设计。高分子化学为我们提供了理解和操纵聚合物结构的工具，从而设计出具有特定降解性能的材料。传统塑料通常由难以断裂的强共价键连接而成，而可降解塑料则通过引入特定的化学键或结构单元，使其在特定条件下能够断裂，从而实现降解。  这需要对聚合物的合成方法、分子量分布、链结构以及结晶度等进行精细的控制。 常见的可降解塑料聚合物 目前，市场上常见的可降解塑料主要包括以下几种：   聚乳酸 (PLA):  PLA 是一种生物基聚合物，由可再生资源（例如玉米淀粉）制成。其降解过程主要依靠水解反应，在特定条件下（例如堆肥环境）可以被微生物降解。PLA 的机械性能较好，但耐热性相对较差。   聚羟基脂肪酸酯 (PHAs): PHAs 是一类由微生物合成的聚酯。它们具有良...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082805/" title="电化学储能技术的新进展：迈向更清洁、更持久的能源未来"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">电化学储能技术的新进展：迈向更清洁、更持久的能源未来</div></div><div class="info-2"><div class="info-item-1">电化学储能技术作为解决可再生能源间歇性问题的关键技术，近年来取得了显著进展。从电动汽车到智能电网，电化学储能系统正深刻地改变着我们的生活。本文将深入探讨电化学储能技术的最新突破，涵盖不同类型的储能技术及其面临的挑战与机遇。 电化学储能技术的类型 目前，市场上主要的电化学储能技术包括： 锂离子电池 锂离子电池凭借其高能量密度、长循环寿命和相对较低的成本，占据了当前电化学储能市场的主导地位。然而，锂资源的有限性和安全性问题仍然是制约其发展的瓶颈。  近年来，研究者们致力于开发高能量密度锂离子电池，例如：  固态锂电池:  固态电解质的采用可以显著提高电池的安全性，并有望实现更高的能量密度。然而，固态电解质的离子电导率和界面接触仍然是需要克服的挑战。 锂硫电池:  锂硫电池具有极高的理论能量密度，但其循环寿命和硫的穿梭效应仍然是需要解决的关键问题。  研究者们正在探索各种改性策略来提高锂硫电池的性能。 锂空气电池:  锂空气电池拥有理论上最高的能量密度，但其反应动力学缓慢，副反应多，循环寿命短等问题限制了其商业化应用。  钠离子电池 作为锂离子的潜在替代品，钠离子电池具有成本低、资源丰...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-092352/" title="材料科学与新型半导体材料：摩尔定律的未来"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">材料科学与新型半导体材料：摩尔定律的未来</div></div><div class="info-2"><div class="info-item-1">引言 摩尔定律，即集成电路上的晶体管数量每隔两年翻一番，几十年来一直驱动着信息技术产业的飞速发展。然而，随着晶体管尺寸逼近物理极限，摩尔定律的持续性受到了挑战。为了维持这种指数级增长，我们需要探索新型半导体材料，突破硅基技术的瓶颈。本文将深入探讨材料科学在新型半导体材料研发中的关键作用，并介绍一些具有前景的候选材料。 新型半导体材料的需求 硅作为半导体材料的主力，其优势在于成本低、工艺成熟。但其固有的物理特性限制了其在更高频率、更高功率和更低功耗方面的性能提升。例如，硅的载流子迁移率相对较低，导致能量损耗增加，尤其是在高频应用中。因此，我们需要寻找具有更高载流子迁移率、更宽禁带宽度、更高饱和电子漂移速度等优异特性的材料。 性能瓶颈及解决方案 硅基技术的性能瓶颈主要体现在以下几个方面：  漏电流:  随着晶体管尺寸的缩小，漏电流问题日益严重，导致功耗增加和性能下降。 热耗散: 高频运行会导致晶体管产生大量热量，影响器件稳定性和可靠性。 开关速度: 硅的载流子迁移率限制了晶体管的开关速度，限制了处理器的运行频率。  为了解决这些问题，研究人员正在积极探索各种新型半导体材料，例如：  ...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-092411/" title="弦理论中的额外维度探索：超越我们感知的宇宙"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">弦理论中的额外维度探索：超越我们感知的宇宙</div></div><div class="info-2"><div class="info-item-1">引言 我们生活在一个看似三维的空间中，加上时间构成四维时空。然而，弦理论，这个试图统一所有基本力的优雅理论，却预言了额外维度的存在。这些额外维度并非我们日常经验所能感知，它们蜷缩在比原子尺度还要小得多的空间里。本文将深入探讨弦理论中额外维度的概念，并解释科学家们如何尝试探测这些隐藏的宇宙维度。 弦理论与额外维度：一个必要的假设 弦理论的核心思想是将基本粒子视为微小的振动弦，不同振动模式对应不同的粒子。为了使理论自洽，并消除量子场论中的一些困扰，弦理论需要引入额外空间维度。最初的弦理论版本需要 26 个维度，而超弦理论则将维度数量缩减到 10 个（或 11 个，在 M 理论中）。这多出来的 6 个（或 7 个）维度是如何隐藏起来的呢？ 卡拉比-丘空间：卷曲的维度 弦理论提出，额外维度并非不存在，而是以紧致化的形式存在，就像一根细细的管子卷曲得非常紧密，以至于在宏观尺度上无法被察觉。这些紧致化的额外维度通常被描述为卡拉比-丘空间，这是一类复杂的六维流形，具有独特的几何性质。卡拉比-丘空间的形状和大小直接影响了我们观察到的粒子物理学特性，例如粒子质量和相互作用强度。 R6R^6R6 表...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-092451/" title="粒子物理学的标准模型之外：探索宇宙未解之谜"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">粒子物理学的标准模型之外：探索宇宙未解之谜</div></div><div class="info-2"><div class="info-item-1">我们生活在一个由基本粒子及其相互作用组成的宇宙中。粒子物理学的标准模型，如同一个精妙的乐章，成功地描述了已知的基本粒子及其三种基本作用力（电磁力、弱力和强力），并准确预测了许多实验结果。然而，这个模型并非完美无缺，它留下了许多未解之谜，指引着我们向标准模型之外的更广阔领域探索。 标准模型的局限性 标准模型尽管取得了巨大的成功，但它并不能解释宇宙中的一切现象。一些关键的不足之处包括： 暗物质与暗能量 宇宙学观测表明，宇宙中存在大量的暗物质和暗能量，它们构成了宇宙质量能量的大部分，但标准模型中却无法解释它们的本质。暗物质不参与电磁相互作用，因此我们无法直接观测到它，只能通过其引力效应间接探测。暗能量则是一种神秘的能量形式，导致宇宙加速膨胀。它们的发现暗示着标准模型之外存在着新的物理学。 中微子质量 标准模型最初假设中微子是无质量的。然而，实验观测表明中微子具有微小的质量，这与标准模型的预言相矛盾。中微子的质量之谜需要新的物理机制来解释，例如 seesaw 机制。 质子衰变 标准模型预言质子是稳定的，然而，一些大统一理论（GUTs）预测质子会发生极其缓慢的衰变。虽然到目前为止还没有观测...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">qmwneb946</div><div class="author-info-description">一个专注于技术分享的个人博客，涵盖编程、算法、系统设计等内容</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">1332</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">1336</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/qmwneb946"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/qmwneb946" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:qmwneb946@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">代码与远方，技术与生活交织的篇章。</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%95%E8%A8%80%EF%BC%9A%E5%BD%93%E4%B8%80%E6%AC%A1%E5%8D%9A%E5%BC%88%E4%B8%8D%E8%B6%B3%E4%BB%A5%E5%AE%9A%E4%B9%89%E5%85%A8%E9%83%A8"><span class="toc-number">1.</span> <span class="toc-text">引言：当一次博弈不足以定义全部</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81-%E5%8D%9A%E5%BC%88%E8%AE%BA%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%E9%80%9F%E8%A7%88"><span class="toc-number">2.</span> <span class="toc-text">一、 博弈论基础概念速览</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-%E4%BB%80%E4%B9%88%E6%98%AF%E5%8D%9A%E5%BC%88%EF%BC%9F"><span class="toc-number">2.1.</span> <span class="toc-text">1.1 什么是博弈？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-%E5%9B%9A%E5%BE%92%E5%9B%B0%E5%A2%83%EF%BC%9A%E4%B8%80%E4%B8%AA%E6%B0%B8%E6%81%92%E7%9A%84%E6%82%96%E8%AE%BA"><span class="toc-number">2.2.</span> <span class="toc-text">1.2 囚徒困境：一个永恒的悖论</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-%E7%BA%B3%E4%BB%80%E5%9D%87%E8%A1%A1%EF%BC%9A%E7%A8%B3%E5%AE%9A%E7%82%B9"><span class="toc-number">2.3.</span> <span class="toc-text">1.3 纳什均衡：稳定点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81-%E4%BB%80%E4%B9%88%E6%98%AF%E9%87%8D%E5%A4%8D%E5%8D%9A%E5%BC%88%EF%BC%9F"><span class="toc-number">3.</span> <span class="toc-text">二、 什么是重复博弈？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E9%98%B6%E6%AE%B5%E5%8D%9A%E5%BC%88%E4%B8%8E%E8%B6%85%E7%BA%A7%E5%8D%9A%E5%BC%88"><span class="toc-number">3.1.</span> <span class="toc-text">2.1 阶段博弈与超级博弈</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E6%9C%89%E9%99%90%E6%AC%A1%E9%87%8D%E5%A4%8D%E5%8D%9A%E5%BC%88-Finitely-Repeated-Games"><span class="toc-number">3.2.</span> <span class="toc-text">2.2 有限次重复博弈 (Finitely Repeated Games)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-1-%E9%80%86%E5%90%91%E5%BD%92%E7%BA%B3%E6%B3%95-Backward-Induction"><span class="toc-number">3.2.1.</span> <span class="toc-text">2.2.1 逆向归纳法 (Backward Induction)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-%E6%97%A0%E9%99%90%E6%AC%A1%E9%87%8D%E5%A4%8D%E5%8D%9A%E5%BC%88-Infinitely-Repeated-Games"><span class="toc-number">3.3.</span> <span class="toc-text">2.3 无限次重复博弈 (Infinitely Repeated Games)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-1-%E8%B4%B4%E7%8E%B0%E5%9B%A0%E5%AD%90-delta"><span class="toc-number">3.3.1.</span> <span class="toc-text">2.3.1 贴现因子 (δ\deltaδ)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81-%E6%97%A0%E9%99%90%E6%AC%A1%E9%87%8D%E5%A4%8D%E5%8D%9A%E5%BC%88%E4%B8%AD%E7%9A%84%E5%90%88%E4%BD%9C%E4%B8%8E%E6%83%A9%E7%BD%9A"><span class="toc-number">4.</span> <span class="toc-text">三、 无限次重复博弈中的合作与惩罚</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E6%B0%91%E9%97%B4%E5%AE%9A%E7%90%86-Folk-Theorem"><span class="toc-number">4.1.</span> <span class="toc-text">3.1 民间定理 (Folk Theorem)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-1-%E4%B8%AA%E4%BA%BA%E7%90%86%E6%80%A7%E6%94%AF%E4%BB%98-Individually-Rational-Payoffs"><span class="toc-number">4.1.1.</span> <span class="toc-text">3.1.1 个人理性支付 (Individually Rational Payoffs)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-2-%E6%B0%91%E9%97%B4%E5%AE%9A%E7%90%86%E7%9A%84%E9%9D%9E%E6%AD%A3%E5%BC%8F%E8%A1%A8%E8%BF%B0"><span class="toc-number">4.1.2.</span> <span class="toc-text">3.1.2 民间定理的非正式表述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-3-%E6%B0%91%E9%97%B4%E5%AE%9A%E7%90%86%E7%9A%84%E6%95%B0%E5%AD%A6%E8%A1%A8%E8%BF%B0%EF%BC%88%E7%AE%80%E5%8C%96%E7%89%88%EF%BC%89"><span class="toc-number">4.1.3.</span> <span class="toc-text">3.1.3 民间定理的数学表述（简化版）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E7%BB%8F%E5%85%B8%E7%9A%84%E5%90%88%E4%BD%9C%E7%AD%96%E7%95%A5"><span class="toc-number">4.2.</span> <span class="toc-text">3.2 经典的合作策略</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-1-%E5%86%B7%E9%85%B7%E8%A7%A6%E5%8F%91%E7%AD%96%E7%95%A5-Grim-Trigger"><span class="toc-number">4.2.1.</span> <span class="toc-text">3.2.1 冷酷触发策略 (Grim Trigger)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-2-%E4%BB%A5%E7%89%99%E8%BF%98%E7%89%99%E7%AD%96%E7%95%A5-Tit-for-Tat"><span class="toc-number">4.2.2.</span> <span class="toc-text">3.2.2 以牙还牙策略 (Tit-for-Tat)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E5%AD%90%E5%8D%9A%E5%BC%88%E5%AE%8C%E7%BE%8E%E7%BA%B3%E4%BB%80%E5%9D%87%E8%A1%A1-Subgame-Perfect-Nash-Equilibrium-SPNE"><span class="toc-number">4.3.</span> <span class="toc-text">3.3 子博弈完美纳什均衡 (Subgame Perfect Nash Equilibrium, SPNE)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-1-%E5%AE%9A%E4%B9%89"><span class="toc-number">4.3.1.</span> <span class="toc-text">3.3.1 定义</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-2-%E9%AA%8C%E8%AF%81%E5%86%B7%E9%85%B7%E8%A7%A6%E5%8F%91%E7%AD%96%E7%95%A5%E6%98%AF%E5%90%A6%E4%B8%BASPNE"><span class="toc-number">4.3.2.</span> <span class="toc-text">3.3.2 验证冷酷触发策略是否为SPNE</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81-%E9%87%8D%E5%A4%8D%E5%8D%9A%E5%BC%88%E7%9A%84%E5%BA%94%E7%94%A8%E4%B8%8E%E6%B4%9E%E5%AF%9F"><span class="toc-number">5.</span> <span class="toc-text">四、 重复博弈的应用与洞察</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-%E7%BB%8F%E6%B5%8E%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8"><span class="toc-number">5.1.</span> <span class="toc-text">4.1 经济学中的应用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-%E7%A4%BE%E4%BC%9A%E5%AD%A6%E4%B8%8E%E6%94%BF%E6%B2%BB%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8"><span class="toc-number">5.2.</span> <span class="toc-text">4.2 社会学与政治学中的应用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-%E7%94%9F%E7%89%A9%E5%AD%A6%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8"><span class="toc-number">5.3.</span> <span class="toc-text">4.3 生物学中的应用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-%E6%97%A5%E5%B8%B8%E7%94%9F%E6%B4%BB%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8"><span class="toc-number">5.4.</span> <span class="toc-text">4.4 日常生活中的应用</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81-%E9%AB%98%E7%BA%A7%E4%B8%BB%E9%A2%98%E4%B8%8E%E6%8C%91%E6%88%98"><span class="toc-number">6.</span> <span class="toc-text">五、 高级主题与挑战</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-%E4%B8%8D%E5%AE%8C%E5%85%A8%E4%BF%A1%E6%81%AF%E4%B8%8E%E4%B8%8D%E5%AE%8C%E7%BE%8E%E7%9B%91%E6%B5%8B-Imperfect-Information-and-Imperfect-Monitoring"><span class="toc-number">6.1.</span> <span class="toc-text">5.1 不完全信息与不完美监测 (Imperfect Information and Imperfect Monitoring)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-%E5%8F%AF%E9%87%8D%E8%B0%88%E6%80%A7-Renegotiation-Proofness"><span class="toc-number">6.2.</span> <span class="toc-text">5.2 可重谈性 (Renegotiation Proofness)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-%E5%AD%A6%E4%B9%A0%E4%B8%8E%E9%80%82%E5%BA%94%E6%80%A7%E5%8A%A8%E5%8A%9B%E5%AD%A6-Learning-and-Adaptive-Dynamics"><span class="toc-number">6.3.</span> <span class="toc-text">5.3 学习与适应性动力学 (Learning and Adaptive Dynamics)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-%E5%A4%8D%E6%9D%82%E9%98%B6%E6%AE%B5%E5%8D%9A%E5%BC%88%E4%B8%8E%E7%BD%91%E7%BB%9C%E9%87%8D%E5%A4%8D%E5%8D%9A%E5%BC%88"><span class="toc-number">6.4.</span> <span class="toc-text">5.4 复杂阶段博弈与网络重复博弈</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA%EF%BC%9A%E6%B0%B8%E6%81%92%E4%BA%92%E5%8A%A8%E7%9A%84%E6%99%BA%E6%85%A7"><span class="toc-number">7.</span> <span class="toc-text">结论：永恒互动的智慧</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/26/hello-world/" title="Hello World">Hello World</a><time datetime="2025-07-26T06:50:50.282Z" title="发表于 2025-07-26 14:50:50">2025-07-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/26/%E5%8D%9A%E5%BC%88%E8%AE%BA%E5%9F%BA%E7%A1%80/" title="博弈论基础">博弈论基础</a><time datetime="2025-07-26T06:50:50.282Z" title="发表于 2025-07-26 14:50:50">2025-07-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/25/2025-07-26-062627/" title="蛋白质组学的翻译后修饰组学：解码生命复杂性的密码">蛋白质组学的翻译后修饰组学：解码生命复杂性的密码</a><time datetime="2025-07-25T22:26:27.000Z" title="发表于 2025-07-26 06:26:27">2025-07-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/25/2025-07-26-062521/" title="钠离子电池的负极材料：开启储能新纪元的核心密码">钠离子电池的负极材料：开启储能新纪元的核心密码</a><time datetime="2025-07-25T22:25:21.000Z" title="发表于 2025-07-26 06:25:21">2025-07-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/25/2025-07-26-062424/" title="基于人工智能的靶点识别：重塑药物发现的未来">基于人工智能的靶点识别：重塑药物发现的未来</a><time datetime="2025-07-25T22:24:24.000Z" title="发表于 2025-07-26 06:24:24">2025-07-26</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;2025 By qmwneb946</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.2</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css')
    if (true) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const getGiscusTheme = theme => theme === 'dark' ? 'dark' : 'light'

  const createScriptElement = config => {
    const ele = document.createElement('script')
    Object.entries(config).forEach(([key, value]) => {
      ele.setAttribute(key, value)
    })
    return ele
  }

  const loadGiscus = (el = document, key) => {
    const mappingConfig = isShuoshuo
      ? { 'data-mapping': 'specific', 'data-term': key }
      : { 'data-mapping': (option && option['data-mapping']) || 'pathname' }

    const giscusConfig = {
      src: 'https://giscus.app/client.js',
      'data-repo': 'qmwneb946/blog',
      'data-repo-id': 'R_kgDOPM6cWw',
      'data-category-id': 'DIC_kwDOPM6cW84CtEzo',
      'data-theme': getGiscusTheme(document.documentElement.getAttribute('data-theme')),
      'data-reactions-enabled': '1',
      crossorigin: 'anonymous',
      async: true,
      ...option,
      ...mappingConfig
    }

    const scriptElement = createScriptElement(giscusConfig)

    el.querySelector('#giscus-wrap').appendChild(scriptElement)

    if (isShuoshuo) {
      window.shuoshuoComment.destroyGiscus = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }
  }

  const changeGiscusTheme = theme => {
    const iframe = document.querySelector('#giscus-wrap iframe')
    if (iframe) {
      const message = {
        giscus: {
          setConfig: {
            theme: getGiscusTheme(theme)
          }
        }
      }
      iframe.contentWindow.postMessage(message, 'https://giscus.app')
    }
  }

  btf.addGlobalFn('themeChange', changeGiscusTheme, 'giscus')

  if (isShuoshuo) {
    'Giscus' === 'Giscus'
      ? window.shuoshuoComment = { loadComment: loadGiscus }
      : window.loadOtherComment = loadGiscus
    return
  }

  if ('Giscus' === 'Giscus' || !false) {
    if (false) btf.loadComment(document.getElementById('giscus-wrap'), loadGiscus)
    else loadGiscus()
  } else {
    window.loadOtherComment = loadGiscus
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>