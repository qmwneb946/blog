<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>强化学习的二元博弈：探索与利用的艺术与科学 | qmwneb946 的博客</title><meta name="author" content="qmwneb946"><meta name="copyright" content="qmwneb946"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="作为一名致力于探索技术与数学边界的博主 qmwneb946，我深知在人工智能的宏伟蓝图中，强化学习（Reinforcement Learning, RL）占据着举足轻重的地位。它赋予了智能体从与环境的交互中学习并做出最优决策的能力，其应用从机器人控制、自动驾驶到推荐系统、金融交易，无所不包。然而，在这看似魔法般的能力背后，隐藏着一个核心且深刻的挑战：探索（Exploration）与利用（Explo">
<meta property="og:type" content="article">
<meta property="og:title" content="强化学习的二元博弈：探索与利用的艺术与科学">
<meta property="og:url" content="https://qmwneb946.dpdns.org/2025/07/23/2025-07-24-041423/index.html">
<meta property="og:site_name" content="qmwneb946 的博客">
<meta property="og:description" content="作为一名致力于探索技术与数学边界的博主 qmwneb946，我深知在人工智能的宏伟蓝图中，强化学习（Reinforcement Learning, RL）占据着举足轻重的地位。它赋予了智能体从与环境的交互中学习并做出最优决策的能力，其应用从机器人控制、自动驾驶到推荐系统、金融交易，无所不包。然而，在这看似魔法般的能力背后，隐藏着一个核心且深刻的挑战：探索（Exploration）与利用（Explo">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://qmwneb946.dpdns.org/img/icon.png">
<meta property="article:published_time" content="2025-07-23T20:14:23.000Z">
<meta property="article:modified_time" content="2025-07-26T08:21:24.307Z">
<meta property="article:author" content="qmwneb946">
<meta property="article:tag" content="2025">
<meta property="article:tag" content="数学">
<meta property="article:tag" content="强化学习中的探索与利用">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://qmwneb946.dpdns.org/img/icon.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "强化学习的二元博弈：探索与利用的艺术与科学",
  "url": "https://qmwneb946.dpdns.org/2025/07/23/2025-07-24-041423/",
  "image": "https://qmwneb946.dpdns.org/img/icon.png",
  "datePublished": "2025-07-23T20:14:23.000Z",
  "dateModified": "2025-07-26T08:21:24.307Z",
  "author": [
    {
      "@type": "Person",
      "name": "qmwneb946",
      "url": "https://github.com/qmwneb946"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://qmwneb946.dpdns.org/2025/07/23/2025-07-24-041423/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '强化学习的二元博弈：探索与利用的艺术与科学',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2845632165165414" crossorigin="anonymous"></script><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="qmwneb946 的博客" type="application/atom+xml">
</head><body><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">qmwneb946 的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">强化学习的二元博弈：探索与利用的艺术与科学</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">强化学习的二元博弈：探索与利用的艺术与科学<a class="post-edit-link" href="https://github.com/qmwneb946/blog/edit/main/source/_posts/2025-07-24-041423.md" title="编辑" target="_blank"><i class="fas fa-pencil-alt"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-07-23T20:14:23.000Z" title="发表于 2025-07-24 04:14:23">2025-07-24</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-07-26T08:21:24.307Z" title="更新于 2025-07-26 16:21:24">2025-07-26</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%95%B0%E5%AD%A6/">数学</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><p>作为一名致力于探索技术与数学边界的博主 qmwneb946，我深知在人工智能的宏伟蓝图中，强化学习（Reinforcement Learning, RL）占据着举足轻重的地位。它赋予了智能体从与环境的交互中学习并做出最优决策的能力，其应用从机器人控制、自动驾驶到推荐系统、金融交易，无所不包。然而，在这看似魔法般的能力背后，隐藏着一个核心且深刻的挑战：探索（Exploration）与利用（Exploitation）之间的永恒博弈。</p>
<p>这并非仅仅是一个技术难题，它更是我们日常生活决策的微观缩影。想象一下，你发现了一家你非常喜欢的餐馆（已知回报高）。你会每次都去那家餐馆（利用），还是偶尔尝试一些新餐馆（探索），以期找到可能更好的选择，即使这可能带来不佳的体验（潜在负回报）？这个简单的选择中，就蕴含着探索与利用的精髓。</p>
<p>在强化学习中，智能体同样面临这样的困境。它需要在利用现有知识来最大化当前奖励与探索未知环境以发现更高潜在奖励之间做出权衡。如果智能体过于“保守”，只是一味地利用已知最好的策略，它可能会陷入局部最优，错过全局最优解。反之，如果它过于“激进”，盲目地进行探索，可能导致效率低下，甚至难以收敛。</p>
<p>本文将深入探讨强化学习中探索与利用的本质、经典策略、前沿方法以及未来的发展方向。我们将剖析这些策略背后的数学原理和直观思想，并通过代码片段进行说明，希望能为广大技术爱好者揭开这层神秘的面纱，助您更好地理解和应用强化学习。</p>
<h2 id="探索与利用的本质：智能体生存的哲学">探索与利用的本质：智能体生存的哲学</h2>
<p>在深入探讨具体策略之前，我们必须先理解探索与利用这两个概念的内在含义及其在强化学习范式中的重要性。</p>
<h3 id="什么是探索？">什么是探索？</h3>
<p><strong>探索 (Exploration)</strong> 指的是智能体采取的那些旨在收集新信息、了解环境未知区域或验证现有知识不确定性的行为。这些行为可能不会立即带来高回报，甚至可能导致暂时的损失。</p>
<ul>
<li><strong>动机：</strong>
<ul>
<li><strong>发现更优策略：</strong> 避免陷入局部最优，找到全局最优解。例如，机器人可能需要尝试不同的路径，才能发现一条更短、更安全的路线。</li>
<li><strong>适应环境变化：</strong> 真实世界环境并非一成不变，探索有助于智能体适应新的动态。</li>
<li><strong>建立环境模型：</strong> 对于基于模型的强化学习方法，探索是构建准确环境模型的关键。</li>
</ul>
</li>
<li><strong>特征：</strong>
<ul>
<li>风险性：可能会遭遇低奖励甚至惩罚。</li>
<li>不确定性：行动结果未知。</li>
<li>长期收益：其价值体现在未来能带来更好的决策。</li>
</ul>
</li>
</ul>
<h3 id="什么是利用？">什么是利用？</h3>
<p><strong>利用 (Exploitation)</strong> 指的是智能体基于当前已有的知识和经验，选择那些预期能带来最高回报的行为。这是一种“收获”现有成果的行为。</p>
<ul>
<li><strong>动机：</strong>
<ul>
<li><strong>最大化短期奖励：</strong> 在已知最优策略下获取最高收益。</li>
<li><strong>性能保证：</strong> 确保智能体在已学习的知识范围内表现良好。</li>
</ul>
</li>
<li><strong>特征：</strong>
<ul>
<li>确定性：基于已知信息，结果相对可预测。</li>
<li>即时收益：直接获取当前的最大回报。</li>
<li>短期导向：主要关注当下，可能忽略潜在的更优解。</li>
</ul>
</li>
</ul>
<h3 id="困境：权衡的艺术">困境：权衡的艺术</h3>
<p>探索与利用之间存在一种固有的紧张关系。它们是互斥的：在任何给定的时间点，智能体要么选择探索（尝试新事物），要么选择利用（做已知最好的事情）。这种选择是强化学习中一个根本性的挑战，被称为<strong>探索-利用困境 (Exploration-Exploitation Dilemma)</strong>。</p>
<p>一个优秀的强化学习算法，其核心目标之一就是找到一种有效的策略来平衡探索与利用。在学习的早期阶段，由于对环境知之甚少，探索可能更为重要；而在学习的后期，随着知识的积累，利用的重要性会逐渐增加，以确保智能体能够高效地执行任务。然而，何时以及如何从探索转向利用，或者如何在两者之间动态切换，是设计强化学习算法时需要仔细考量的问题。这不单单是一个技术难题，更是一门艺术，需要深思熟虑。</p>
<h2 id="经典的探索策略：从简单到复杂">经典的探索策略：从简单到复杂</h2>
<p>理解了探索与利用的本质后，我们来看看一些最常见且行之有效的探索策略。这些策略构成了许多复杂算法的基础。</p>
<h3 id="贪婪策略-Greedy-Strategy">贪婪策略 (Greedy Strategy)</h3>
<p>最简单的策略就是纯粹的利用。<strong>贪婪策略</strong>在每一步都选择当前状态下预期价值最高的行动。</p>
<ul>
<li><strong>选择规则：</strong> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mi>t</mi></msub><mo>=</mo><mi>arg</mi><mo>⁡</mo><msub><mrow><mi>max</mi><mo>⁡</mo></mrow><mi>a</mi></msub><mi>Q</mi><mo stretchy="false">(</mo><msub><mi>s</mi><mi>t</mi></msub><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">a_t = \arg\max_a Q(s_t, a)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">ar<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop">max</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">a</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span></span></span></span></li>
<li><strong>优点：</strong> 简单直观，在已知最优策略的情况下性能最佳。</li>
<li><strong>缺点：</strong> 容易陷入局部最优，对环境的未知部分完全不敏感。一旦初始随机探索不够充分，它可能永远无法发现真正的全局最优解。</li>
</ul>
<h3 id="ε-贪婪策略-ε-Greedy-Strategy">ε-贪婪策略 (ε-Greedy Strategy)</h3>
<p>为了解决纯贪婪策略的局部最优问题，<strong>ε-贪婪策略 (epsilon-Greedy Strategy)</strong> 应运而生。它是最常用、最基础的探索策略之一。</p>
<ul>
<li>
<p><strong>基本思想：</strong> 以小概率 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">ϵ</span></span></span></span> 随机选择一个动作进行探索，以 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>−</mo><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">1-\epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">ϵ</span></span></span></span> 的概率选择当前已知最优的动作进行利用。</p>
</li>
<li>
<p><strong>选择规则：</strong></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>a</mi><mo>=</mo><mrow><mo fence="true">{</mo><mtable rowspacing="0.36em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mtext>random action from action space</mtext></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>with probability </mtext><mi>ϵ</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mi>arg</mi><mo>⁡</mo><msub><mrow><mi>max</mi><mo>⁡</mo></mrow><mi>a</mi></msub><mi>Q</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>with probability </mtext><mn>1</mn><mo>−</mo><mi>ϵ</mi></mrow></mstyle></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">a = \begin{cases}
\text{random action from action space} &amp; \text{with probability } \epsilon \\
\arg\max_a Q(s,a) &amp; \text{with probability } 1-\epsilon
\end{cases}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3em;vertical-align:-1.25em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size4">{</span></span><span class="mord"><span class="mtable"><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em;"><span style="top:-3.69em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord text"><span class="mord">random action from action space</span></span></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mop">ar<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop">max</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">a</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.19em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:1em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.69em;"><span style="top:-3.69em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord text"><span class="mord">with probability </span></span><span class="mord mathnormal">ϵ</span></span></span><span style="top:-2.25em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord text"><span class="mord">with probability </span></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal">ϵ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.19em;"><span></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Q(s,a)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span></span></span></span> 是在状态 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">s</span></span></span></span> 下执行动作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">a</span></span></span></span> 的预期回报。</p>
</li>
<li>
<p><strong>优点：</strong></p>
<ul>
<li><strong>简单易实现：</strong> 只需要一个超参数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">ϵ</span></span></span></span>。</li>
<li><strong>保证探索：</strong> 无论状态-动作值函数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span> 如何，总有一定概率进行随机探索，从而有机会发现新的高回报动作。</li>
<li><strong>适用性广：</strong> 几乎可以与任何基于值函数的RL算法结合使用。</li>
</ul>
</li>
<li>
<p><strong>缺点：</strong></p>
<ul>
<li><strong>随机探索效率低下：</strong> 随机探索可能是不高效的，它不区分“有希望但未探索”的区域和“已知回报很低”的区域。</li>
<li><strong><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">ϵ</span></span></span></span> 的选择：</strong> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">ϵ</span></span></span></span> 的值很难确定。太小可能探索不足，太大会导致学习速度慢，收敛困难。</li>
</ul>
</li>
<li>
<p><strong>ε 的衰减：</strong> 为了平衡探索与利用，通常会将 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">ϵ</span></span></span></span> 的值随着训练的进行而逐渐减小（衰减）。</p>
<ul>
<li><strong>初期：</strong> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">ϵ</span></span></span></span> 较大，鼓励智能体进行更多探索，快速了解环境。</li>
<li><strong>后期：</strong> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">ϵ</span></span></span></span> 较小（或趋近于0），智能体更多地利用已学习到的最优策略，以达到更好的性能。</li>
<li>常见的衰减方式有线性衰减、指数衰减等。</li>
</ul>
</li>
<li>
<p><strong>代码示例 (ε-贪婪动作选择):</strong></p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">epsilon_greedy_action</span>(<span class="params">q_values, epsilon</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    使用 epsilon-贪婪策略选择动作。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    参数:</span></span><br><span class="line"><span class="string">    q_values (np.array): 当前状态下所有动作的Q值。</span></span><br><span class="line"><span class="string">    epsilon (float): 探索的概率。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    返回:</span></span><br><span class="line"><span class="string">    int: 选择的动作索引。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> np.random.rand() &lt; epsilon:</span><br><span class="line">        <span class="comment"># 探索：随机选择一个动作</span></span><br><span class="line">        action = np.random.randint(<span class="built_in">len</span>(q_values))</span><br><span class="line">        <span class="comment"># print(f&quot;Exploring: Chosen action &#123;action&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 利用：选择Q值最大的动作</span></span><br><span class="line">        action = np.argmax(q_values)</span><br><span class="line">        <span class="comment"># print(f&quot;Exploiting: Chosen action &#123;action&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">return</span> action</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例使用</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 假设有3个动作，它们的Q值如下</span></span><br><span class="line">    current_q_values = np.array([<span class="number">1.0</span>, <span class="number">5.0</span>, <span class="number">2.0</span>]) <span class="comment"># 动作1的Q值最高</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;--- 较高探索率 ---&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        action = epsilon_greedy_action(current_q_values, epsilon=<span class="number">0.5</span>) <span class="comment"># 50% 探索概率</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Epsilon=0.5, Chosen action: <span class="subst">&#123;action&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n--- 较低探索率 ---&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        action = epsilon_greedy_action(current_q_values, epsilon=<span class="number">0.1</span>) <span class="comment"># 10% 探索概率</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Epsilon=0.1, Chosen action: <span class="subst">&#123;action&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n--- 衰减的 Epsilon ---&quot;</span>)</span><br><span class="line">    initial_epsilon = <span class="number">1.0</span></span><br><span class="line">    min_epsilon = <span class="number">0.01</span></span><br><span class="line">    decay_rate = <span class="number">0.9</span> <span class="comment"># 每步衰减10%</span></span><br><span class="line">    current_epsilon = initial_epsilon</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        action = epsilon_greedy_action(current_q_values, current_epsilon)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Step <span class="subst">&#123;i+<span class="number">1</span>&#125;</span>, Epsilon=<span class="subst">&#123;current_epsilon:<span class="number">.2</span>f&#125;</span>, Chosen action: <span class="subst">&#123;action&#125;</span>&quot;</span>)</span><br><span class="line">        current_epsilon = <span class="built_in">max</span>(min_epsilon, current_epsilon * decay_rate)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>上述代码展示了 ε-贪婪策略的动作选择过程以及 ε 衰减的简单模拟。通过调整 <code>epsilon</code> 参数，我们可以观察到探索和利用之间的动态平衡。</p>
<h3 id="乐观初始值-Optimistic-Initialization">乐观初始值 (Optimistic Initialization)</h3>
<p><strong>乐观初始值 (Optimistic Initialization)</strong> 是一种简单但有效的探索机制，特别适用于表格型（Tabular）的强化学习问题。</p>
<ul>
<li><strong>基本思想：</strong> 将所有状态-动作对的初始 Q 值设置得非常高（例如，高于任何可能获得的实际奖励）。</li>
<li><strong>工作原理：</strong> 由于智能体期望从所有动作中获得高回报，当它实际执行某个动作并获得一个比预期低得多的奖励时，它会“失望”，从而降低该动作的 Q 值。这使得智能体更有动力去尝试其他动作，特别是那些尚未被充分探索的动作，因为它们的 Q 值仍然很高。这种“乐观”的期望驱动了探索。</li>
<li><strong>优点：</strong>
<ul>
<li>实现简单。</li>
<li>在小型、确定性或不确定性较低的环境中效果显著。</li>
</ul>
</li>
<li><strong>缺点：</strong>
<ul>
<li>在大型状态空间中，这种方法可能不再实用，因为很难保证所有未访问的状态-动作对都有高的初始值。</li>
<li>初始值的选择非常关键，不当的初始值可能导致过度探索或探索不足。</li>
<li>对于奖励范围不明确的环境，很难设定一个合适的“乐观”初始值。</li>
</ul>
</li>
</ul>
<h3 id="UCB-Upper-Confidence-Bound">UCB (Upper Confidence Bound)</h3>
<p><strong>UCB (Upper Confidence Bound)</strong> 算法，最初用于解决多臂老虎机（Multi-Armed Bandit, MAB）问题，但其核心思想也广泛应用于强化学习的探索。它试图在已知最佳动作和具有高不确定性的动作之间找到一个平衡点。</p>
<ul>
<li>
<p><strong>基本思想：</strong> UCB 认为，一个动作的“价值”不仅仅在于其已知的平均回报，还在于其“潜在的”回报，即它还有多少提升空间。这种潜力由其被探索的次数来衡量。被探索次数越少的动作，其不确定性越高，其“潜在价值”也就越大。</p>
</li>
<li>
<p><strong>选择规则：</strong> 智能体选择使得以下表达式最大的动作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">A_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>A</mi><mi>t</mi></msub><mo>=</mo><mi>arg</mi><mo>⁡</mo><munder><mrow><mi>max</mi><mo>⁡</mo></mrow><mi>a</mi></munder><mrow><mo fence="true">[</mo><msub><mi>Q</mi><mi>t</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo><mo>+</mo><mi>c</mi><msqrt><mfrac><mrow><mi>ln</mi><mo>⁡</mo><mi>t</mi></mrow><mrow><msub><mi>N</mi><mi>t</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo></mrow></mfrac></msqrt><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">A_t = \arg\max_a \left[ Q_t(a) + c \sqrt{\frac{\ln t}{N_t(a)}} \right]
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.1016em;vertical-align:-1.25em;"></span><span class="mop">ar<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.4306em;"><span style="top:-2.4em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">a</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size4">[</span></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal">c</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8516em;"><span class="svg-align" style="top:-5em;"><span class="pstrut" style="height:5em;"></span><span class="mord" style="padding-left:1em;"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">ln</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:-3.8116em;"><span class="pstrut" style="height:5em;"></span><span class="hide-tail" style="min-width:1.02em;height:3.08em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="3.08em" viewBox="0 0 400000 3240" preserveAspectRatio="xMinYMin slice"><path d="M473,2793
c339.3,-1799.3,509.3,-2700,510,-2702 l0 -0
c3.3,-7.3,9.3,-11,18,-11 H400000v40H1017.7
s-90.5,478,-276.2,1466c-185.7,988,-279.5,1483,-281.5,1485c-2,6,-10,9,-24,9
c-8,0,-12,-0.7,-12,-2c0,-1.3,-5.3,-32,-16,-92c-50.7,-293.3,-119.7,-693.3,-207,-1200
c0,-1.3,-5.3,8.7,-16,30c-10.7,21.3,-21.3,42.7,-32,64s-16,33,-16,33s-26,-26,-26,-26
s76,-153,76,-153s77,-151,77,-151c0.7,0.7,35.7,202,105,604c67.3,400.7,102,602.7,104,
606zM1001 80h400000v40H1017.7z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.1884em;"><span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size4">]</span></span></span></span></span></span></span></p>
<p>其中：</p>
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mi>t</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Q_t(a)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mclose">)</span></span></span></span> 是截至时间步 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em;"></span><span class="mord mathnormal">t</span></span></span></span> 时，动作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">a</span></span></span></span> 的平均奖励估计值（即其利用项）。</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mi>t</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">N_t(a)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mclose">)</span></span></span></span> 是截至时间步 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em;"></span><span class="mord mathnormal">t</span></span></span></span> 时，动作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">a</span></span></span></span> 被选择的次数。</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em;"></span><span class="mord mathnormal">t</span></span></span></span> 是总的时间步数（或总的尝试次数）。</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">c</span></span></span></span> 是一个正数，用于控制探索的程度。<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">c</span></span></span></span> 值越大，探索的倾向性越强。</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msqrt><mfrac><mrow><mi>ln</mi><mo>⁡</mo><mi>t</mi></mrow><mrow><msub><mi>N</mi><mi>t</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo></mrow></mfrac></msqrt></mrow><annotation encoding="application/x-tex">\sqrt{\frac{\ln t}{N_t(a)}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.84em;vertical-align:-0.6749em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1651em;"><span class="svg-align" style="top:-3.8em;"><span class="pstrut" style="height:3.8em;"></span><span class="mord" style="padding-left:1em;"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2963em;"><span style="top:-2.357em;margin-left:-0.109em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">a</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mtight">l</span><span class="mtight">n</span></span><span class="mspace mtight" style="margin-right:0.1952em;"></span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:-3.1251em;"><span class="pstrut" style="height:3.8em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.88em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.88em" viewBox="0 0 400000 1944" preserveAspectRatio="xMinYMin slice"><path d="M983 90
l0 -0
c4,-6.7,10,-10,18,-10 H400000v40
H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7
s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744
c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30
c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722
c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5
c53.7,-170.3,84.5,-266.8,92.5,-289.5z
M1001 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6749em;"><span></span></span></span></span></span></span></span></span> 是探索项，被称为“置信区间宽度”。当 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mi>t</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">N_t(a)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mclose">)</span></span></span></span> 越小（即动作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">a</span></span></span></span> 被选择的次数越少）时，该项越大，鼓励智能体选择该动作。当 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em;"></span><span class="mord mathnormal">t</span></span></span></span> 越大时，也会轻微增加探索的欲望，但主要还是由 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mi>t</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">N_t(a)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mclose">)</span></span></span></span> 主导。</li>
</ul>
</li>
<li>
<p><strong>优点：</strong></p>
<ul>
<li><strong>原理性强：</strong> UCB 具有坚实的理论基础，在特定条件下能提供次优性的上限保证。</li>
<li><strong>有效平衡：</strong> 它有效地平衡了探索与利用。对已被充分利用的动作，其 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mi>t</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">N_t(a)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mclose">)</span></span></span></span> 会很大，导致探索项变小；对尚未充分探索的动作，其 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mi>t</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">N_t(a)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mclose">)</span></span></span></span> 小，探索项变大，从而鼓励智能体去尝试。</li>
<li><strong>无需参数衰减：</strong> 与 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">ϵ</span></span></span></span>-贪婪不同，UCB 的探索程度是自动调整的，通常不需要手动衰减 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">c</span></span></span></span>。</li>
</ul>
</li>
<li>
<p><strong>缺点：</strong></p>
<ul>
<li><strong>适用于静态环境：</strong> 原始的 UCB 算法假设奖励是静止的（即每个动作的真实平均奖励不会随时间变化），这在许多动态的强化学习环境中不成立。</li>
<li><strong>需要计数：</strong> 需要记录每个动作被选择的次数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mi>t</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">N_t(a)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mclose">)</span></span></span></span>，这对于连续动作空间或非常大的离散动作空间是困难的。</li>
<li><strong>对初始值敏感：</strong> 如果 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mi>t</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">N_t(a)=0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0</span></span></span></span>，公式会报错。通常会为每个动作预先执行一次，或初始化 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mi>t</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">N_t(a)=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span> 且 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Q</mi><mi>t</mi></msub><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Q_t(a)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mclose">)</span></span></span></span> 为一个乐观值。</li>
</ul>
</li>
<li>
<p><strong>代码示例 (UCB 动作选择):</strong></p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">UCBAgent</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_actions, c_param</span>):</span><br><span class="line">        <span class="variable language_">self</span>.num_actions = num_actions</span><br><span class="line">        <span class="variable language_">self</span>.q_values = np.zeros(num_actions)  <span class="comment"># 每个动作的平均奖励估计</span></span><br><span class="line">        <span class="variable language_">self</span>.action_counts = np.zeros(num_actions) <span class="comment"># 每个动作被选择的次数</span></span><br><span class="line">        <span class="variable language_">self</span>.total_steps = <span class="number">0</span> <span class="comment"># 总的尝试次数</span></span><br><span class="line">        <span class="variable language_">self</span>.c_param = c_param <span class="comment"># 探索参数</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">choose_action</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.total_steps += <span class="number">1</span></span><br><span class="line">        ucb_values = np.zeros(<span class="variable language_">self</span>.num_actions)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> a <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.num_actions):</span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.action_counts[a] == <span class="number">0</span>:</span><br><span class="line">                <span class="comment"># 对于从未尝试过的动作，赋予其无穷大UCB值以确保探索</span></span><br><span class="line">                <span class="comment"># 实际实现中，可以直接返回该动作，或赋予一个很大的值</span></span><br><span class="line">                <span class="keyword">return</span> a</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                exploration_term = <span class="variable language_">self</span>.c_param * np.sqrt(np.log(<span class="variable language_">self</span>.total_steps) / <span class="variable language_">self</span>.action_counts[a])</span><br><span class="line">                ucb_values[a] = <span class="variable language_">self</span>.q_values[a] + exploration_term</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 选择UCB值最大的动作</span></span><br><span class="line">        action = np.argmax(ucb_values)</span><br><span class="line">        <span class="keyword">return</span> action</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, action, reward</span>):</span><br><span class="line">        <span class="comment"># 更新Q值和动作计数</span></span><br><span class="line">        <span class="variable language_">self</span>.action_counts[action] += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 增量式更新平均Q值</span></span><br><span class="line">        <span class="variable language_">self</span>.q_values[action] += (reward - <span class="variable language_">self</span>.q_values[action]) / <span class="variable language_">self</span>.action_counts[action]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例使用 (简化版的多臂老虎机问题)</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    np.random.seed(<span class="number">0</span>) <span class="comment"># 为了结果可复现</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 假设3个老虎机，真实平均奖励</span></span><br><span class="line">    true_rewards = [<span class="number">0.1</span>, <span class="number">0.8</span>, <span class="number">0.2</span>] </span><br><span class="line">    num_actions = <span class="built_in">len</span>(true_rewards)</span><br><span class="line">    agent = UCBAgent(num_actions=num_actions, c_param=<span class="number">2.0</span>) <span class="comment"># c_param 可以调整</span></span><br><span class="line"></span><br><span class="line">    num_steps = <span class="number">1000</span></span><br><span class="line">    rewards_history = []</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;UCB Agent Simulation:&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(num_steps):</span><br><span class="line">        action = agent.choose_action()</span><br><span class="line">        <span class="comment"># 模拟从环境中获取奖励 (这里是一个简单的随机过程)</span></span><br><span class="line">        reward = np.random.normal(loc=true_rewards[action], scale=<span class="number">0.1</span>) </span><br><span class="line">        agent.update(action, reward)</span><br><span class="line">        rewards_history.append(reward)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (step + <span class="number">1</span>) % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Step <span class="subst">&#123;step+<span class="number">1</span>&#125;</span>: Chosen Action=<span class="subst">&#123;action&#125;</span>, Avg Q-values=<span class="subst">&#123;np.<span class="built_in">round</span>(agent.q_values, <span class="number">2</span>)&#125;</span>, Counts=<span class="subst">&#123;agent.action_counts&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\nFinal Q-values:&quot;</span>, np.<span class="built_in">round</span>(agent.q_values, <span class="number">3</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Final Action Counts:&quot;</span>, agent.action_counts)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Total average reward: <span class="subst">&#123;np.mean(rewards_history):<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="comment"># 理想情况下，动作1（索引为1）会被选择最多次，因为其真实奖励最高。</span></span><br></pre></td></tr></table></figure>
<p>UCB 算法通过数学公式巧妙地平衡了利用已知信息和探索未知可能性，是设计高效探索策略的重要思路。</p>
<h2 id="基于不确定性的探索：从计数到好奇心">基于不确定性的探索：从计数到好奇心</h2>
<p>UCB 算法的思想是，对那些我们“不确定”的动作给予额外的探索奖励。这种“不确定性”可以通过动作被选择的次数来量化。在此基础上，更高级的探索策略开始直接量化和利用不确定性，或者通过内在机制来驱动探索。</p>
<h3 id="基于计数-Count-Based-Exploration">基于计数 (Count-Based Exploration)</h3>
<p><strong>基于计数 (Count-Based Exploration)</strong> 策略是对 UCB 思路的直接扩展和应用。核心思想是：智能体应该更频繁地访问或选择那些之前很少访问或选择的状态-动作对。</p>
<ul>
<li><strong>基本思想：</strong> 为稀疏访问的状态或动作提供一个额外的“奖励”或“探索红利”。</li>
<li><strong>实现方式：</strong>
<ul>
<li><strong>直接奖励修改：</strong> 将环境的真实奖励 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">R_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 与一个与访问计数相关的探索奖励 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mi>e</mi></msub></mrow><annotation encoding="application/x-tex">R_e</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 相加，得到新的奖励 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>R</mi><mi>t</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo>=</mo><msub><mi>R</mi><mi>t</mi></msub><mo>+</mo><msub><mi>R</mi><mi>e</mi></msub><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">R_t&#x27; = R_t + R_e(s,a)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9989em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-2.453em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span></span></span></span>。</li>
<li><strong>探索奖励计算：</strong> 探索奖励 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>R</mi><mi>e</mi></msub><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">R_e(s,a)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span></span></span></span> 通常与状态-动作对 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(s,a)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span></span></span></span> 的访问次数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">N(s,a)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span></span></span></span> 成反比。例如，可以设置为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi><mi mathvariant="normal">/</mi><msqrt><mrow><mi>N</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo></mrow></msqrt></mrow><annotation encoding="application/x-tex">\beta / \sqrt{N(s,a)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.24em;vertical-align:-0.305em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mord">/</span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.935em;"><span class="svg-align" style="top:-3.2em;"><span class="pstrut" style="height:3.2em;"></span><span class="mord" style="padding-left:1em;"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span></span></span><span style="top:-2.895em;"><span class="pstrut" style="height:3.2em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.28em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.28em" viewBox="0 0 400000 1296" preserveAspectRatio="xMinYMin slice"><path d="M263,681c0.7,0,18,39.7,52,119
c34,79.3,68.167,158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120
c340,-704.7,510.7,-1060.3,512,-1067
l0 -0
c4.7,-7.3,11,-11,19,-11
H40000v40H1012.3
s-271.3,567,-271.3,567c-38.7,80.7,-84,175,-136,283c-52,108,-89.167,185.3,-111.5,232
c-22.3,46.7,-33.8,70.3,-34.5,71c-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1
s-109,-253,-109,-253c-72.7,-168,-109.3,-252,-110,-252c-10.7,8,-22,16.7,-34,26
c-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26s76,-59,76,-59s76,-60,76,-60z
M1001 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.305em;"><span></span></span></span></span></span></span></span></span> 或者 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi><mi mathvariant="normal">/</mi><mi>N</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\beta / N(s,a)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span></span></span></span>，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span> 是一个控制探索强度的常数。</li>
</ul>
</li>
<li><strong>优点：</strong>
<ul>
<li>直观且有效，特别适用于离散状态和动作空间。</li>
<li>鼓励智能体系统性地探索环境的所有部分。</li>
</ul>
</li>
<li><strong>缺点：</strong>
<ul>
<li><strong>状态空间爆炸：</strong> 对于具有大量状态或连续状态空间的问题，精确地为每个状态-动作对计数变得不可行。</li>
<li><strong>泛化能力差：</strong> 如果一个状态从未被访问过，其计数为0，如何处理？通常需要引入状态泛化技术（如哈希、特征编码）或使用更复杂的模型。</li>
</ul>
</li>
</ul>
<p>为了应对状态空间爆炸的问题，研究人员提出了多种方法来近似状态计数，例如使用伪计数（pseudo-counts），通过一个神经网络来学习一个“密度模型”来估计状态的“新颖性”。</p>
<h3 id="内在奖励-Intrinsic-Motivation-Intrinsic-Reward">内在奖励 (Intrinsic Motivation / Intrinsic Reward)</h3>
<p>传统的强化学习依赖于环境提供的外部奖励（Extrinsic Reward）。然而，在许多现实世界的任务中，外部奖励可能是稀疏的、延迟的或者根本不存在的（例如，在开放世界中自由探索）。为了解决这个问题，<strong>内在奖励 (Intrinsic Reward)</strong> 机制被引入。它赋予智能体一种“好奇心”或“求知欲”，促使它主动探索环境。</p>
<p>内在奖励是智能体自己生成的一种信号，而不是来自环境。这种奖励通常与新颖性、不确定性减少、或预测误差等概念相关联。</p>
<h4 id="好奇心驱动-Curiosity-driven-Exploration">好奇心驱动 (Curiosity-driven Exploration)</h4>
<p><strong>好奇心驱动的探索</strong> 是一种重要的内在奖励形式。其核心思想是，智能体应该被鼓励去探索那些能够最大化其“好奇心”的区域。</p>
<ul>
<li>
<p><strong>核心机制：</strong> 通常通过学习一个<strong>预测模型</strong>（例如，一个神经网络）来预测未来状态或动作的结果。当智能体对预测结果感到“惊讶”（即预测误差较大）时，它会获得一个内在奖励。</p>
</li>
<li>
<p><strong>具体实现：</strong></p>
<ul>
<li><strong>前向模型 (Forward Model):</strong> 训练一个模型 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo>:</mo><mo stretchy="false">(</mo><msub><mi>s</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>a</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo>→</mo><msub><mi>s</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">f: (s_t, a_t) \to s_{t+1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.2083em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span></span></span></span>，预测在状态 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">s_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 执行动作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">a_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 后将到达的状态 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">s_{t+1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.2083em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span></span></span></span>。内在奖励 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">r_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 可以是实际 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">s_{t+1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.2083em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span></span></span></span> 与预测 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>s</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup></mrow><annotation encoding="application/x-tex">s_{t+1}&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0583em;vertical-align:-0.3064em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-2.4519em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3064em;"><span></span></span></span></span></span></span></span></span></span> 之间的误差范数：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mi>i</mi></msub><mo>=</mo><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><msub><mi>s</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>−</mo><msubsup><mi>s</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mi mathvariant="normal">∣</mi><msubsup><mi mathvariant="normal">∣</mi><mn>2</mn><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">r_i = ||s_{t+1} - s_{t+1}&#x27;||_2^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣∣</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1205em;vertical-align:-0.3064em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-2.4519em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3064em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-2.4519em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2481em;"><span></span></span></span></span></span></span></span></span></span>。</li>
<li><strong>逆向模型 (Inverse Model):</strong> 训练一个模型 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>g</mi><mo>:</mo><mo stretchy="false">(</mo><msub><mi>s</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>s</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo><mo>→</mo><msubsup><mi>a</mi><mi>t</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup></mrow><annotation encoding="application/x-tex">g: (s_t, s_{t+1}) \to a_t&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.9989em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span>，预测从 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">s_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">s_{t+1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.2083em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span></span></span></span> 采取了什么动作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>a</mi><mi>t</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup></mrow><annotation encoding="application/x-tex">a_t&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9989em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span>。内在奖励可以基于预测动作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>a</mi><mi>t</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup></mrow><annotation encoding="application/x-tex">a_t&#x27;</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9989em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span> 与实际动作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">a_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的差异。</li>
<li><strong>Intrinsic Curiosity Module (ICM):</strong> 结合了前向模型和逆向模型，通过预测误差作为内在奖励。其目标是学习一个好的特征表示，并在该特征空间中计算预测误差。</li>
</ul>
</li>
<li>
<p><strong>优点：</strong></p>
<ul>
<li><strong>解决稀疏奖励问题：</strong> 即使没有外部奖励，智能体也能通过好奇心驱动进行学习。</li>
<li><strong>促进复杂行为：</strong> 好奇心可以促使智能体学习到复杂的、探索性的行为，这些行为可能最终导致发现外部奖励。</li>
<li><strong>无需手动设计奖励：</strong> 降低了奖励工程的难度。</li>
</ul>
</li>
<li>
<p><strong>缺点：</strong></p>
<ul>
<li><strong>“噪声电视”问题 (Noisy TV Problem)：</strong> 如果环境中存在不可预测但无意义的噪声源（例如，一台随机播放画面的电视），智能体可能会被这些噪声吸引，不断获得高预测误差（高好奇心奖励），但却无法学到有用的行为。</li>
<li><strong>计算开销：</strong> 需要训练额外的预测模型。</li>
<li><strong>特征表示学习：</strong> 预测模型依赖于对状态的良好特征表示。</li>
</ul>
</li>
</ul>
<h4 id="基于信息增益-不确定性减少">基于信息增益/不确定性减少</h4>
<p>这种方法的核心是奖励那些能够最大程度地减少智能体对环境或最佳策略不确定性的行为。</p>
<ul>
<li><strong>核心思想：</strong> 智能体被激励去执行那些能够获得最多“有用信息”的行动。</li>
<li><strong>实现方式：</strong>
<ul>
<li><strong>贝叶斯强化学习：</strong> 维护一个关于环境模型或最优策略的后验分布。选择那些能最大化信息增益（例如，关于模型参数的熵减少）的行动。</li>
<li><strong>PAC-MDP (Probably Approximately Correct-Markov Decision Process):</strong> 在理论上保证以高概率找到一个近似最优策略，其探索策略也是基于减少不确定性。</li>
</ul>
</li>
<li><strong>优点：</strong>
<ul>
<li>原理性强，有坚实的理论基础。</li>
<li>能够进行更“智能”的探索，避免无意义的随机游走。</li>
</ul>
</li>
<li><strong>缺点：</strong>
<ul>
<li><strong>计算复杂：</strong> 维护和更新概率分布的计算成本很高，尤其是在高维空间中。</li>
<li><strong>扩展性挑战：</strong> 很难扩展到大型或连续状态/动作空间。</li>
</ul>
</li>
</ul>
<p>内在奖励机制代表了探索策略的一个重要发展方向，它使得智能体能够以更智能、更自发的方式进行探索，从而解决许多传统方法难以处理的复杂任务。</p>
<h2 id="高级探索策略：超越传统框架">高级探索策略：超越传统框架</h2>
<p>随着深度学习与强化学习的结合，涌现出许多更高级、更复杂的探索策略，它们通常与特定的RL算法架构紧密结合。</p>
<h3 id="基于噪声的探索-Noise-Based-Exploration">基于噪声的探索 (Noise-Based Exploration)</h3>
<p>对于连续动作空间（例如机器人关节角度），直接使用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">ϵ</span></span></span></span>-贪婪策略不再适用，因为选择“随机动作”意味着从一个无限空间中随机采样。<strong>基于噪声的探索</strong>通过在策略输出的动作上添加随机噪声来实现探索。</p>
<ul>
<li><strong>核心思想：</strong> 在智能体选择的确定性动作上叠加随机噪声，使其动作略微偏离预期，从而实现探索。</li>
<li><strong>实现方式：</strong>
<ul>
<li><strong>动作空间噪声：</strong> 对于确定性策略（如DDPG, TD3），策略网络输出一个确定的动作 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mi>t</mi></msub><mo>=</mo><mi>μ</mi><mo stretchy="false">(</mo><msub><mi>s</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">a_t = \mu(s_t)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">μ</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>。为了探索，实际执行的动作是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>a</mi><mi>t</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo>=</mo><mi>μ</mi><mo stretchy="false">(</mo><msub><mi>s</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo>+</mo><msub><mi mathvariant="script">N</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">a_t&#x27; = \mu(s_t) + \mathcal{N}_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9989em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7519em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">μ</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.14736em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.1474em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">N</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">\mathcal{N}_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.14736em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:-0.1474em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是一个随机噪声，例如高斯噪声（Gaussian Noise）或奥恩斯坦-乌伦贝克过程（Ornstein-Uhlenbeck process, OU-Noise）。OU-Noise 相比纯高斯噪声，具有时间相关性，更适合模拟物理世界中惯性运动。</li>
<li><strong>参数空间噪声：</strong> 不在动作空间加噪声，而是直接在策略网络的参数上添加噪声。每次选择动作时，策略网络使用一组略微扰动过的参数来生成动作。这会导致智能体在一段时间内遵循一个连贯的、稍微不同的行为模式，而不是在每个时间步都进行随机跳跃。这有助于智能体探索更远的轨迹。</li>
</ul>
</li>
<li><strong>优点：</strong>
<ul>
<li>适用于连续动作空间。</li>
<li>实现相对简单。</li>
</ul>
</li>
<li><strong>缺点：</strong>
<ul>
<li><strong>无结构探索：</strong> 噪声是随机的，不具备指导性。它可能导致在已知不良区域进行无效探索，或者无法系统地探索高价值区域。</li>
<li>噪声参数的调整：噪声的方差或 OU 噪声的参数需要仔细调整。</li>
</ul>
</li>
</ul>
<h3 id="基于策略的探索-Policy-Based-Exploration">基于策略的探索 (Policy-Based Exploration)</h3>
<p>在策略梯度（Policy Gradient）方法中，智能体直接学习一个策略 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>π</mi><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi>s</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\pi(a|s)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">π</span><span class="mopen">(</span><span class="mord mathnormal">a</span><span class="mord">∣</span><span class="mord mathnormal">s</span><span class="mclose">)</span></span></span></span>，它是一个动作的概率分布。这种方法天然地包含了探索。</p>
<ul>
<li><strong>核心思想：</strong> 探索是策略本身固有的属性。随机策略天生就会进行探索，因为它不会每次都选择同一个动作，而是根据概率分布进行采样。</li>
<li><strong>实现方式：</strong>
<ul>
<li><strong>随机策略：</strong>
<ul>
<li><strong>离散动作空间：</strong> 策略网络通常输出每个动作的 logit，通过 Softmax 函数转换为概率分布，然后从该分布中采样动作。例如，在 A2C/A3C、PPO 等算法中，策略是一个高斯分布（用于连续动作）或分类分布（用于离散动作）。</li>
<li><strong>连续动作空间：</strong> 策略网络输出高斯分布的均值和标准差，然后从该高斯分布中采样动作。例如，SAC（Soft Actor-Critic）算法明确地将最大化熵项加入目标函数，鼓励策略保持足够的随机性，从而促进探索。</li>
</ul>
</li>
</ul>
</li>
<li><strong>优点：</strong>
<ul>
<li><strong>自然探索：</strong> 探索是策略学习过程的内在部分，无需额外添加探索机制。</li>
<li><strong>学习结构化探索：</strong> 随着训练的进行，策略会学习到哪些动作是有效的，并根据这些信息调整其概率分布，从而实现更“智能”的探索。</li>
<li><strong>适用于复杂环境：</strong> 能够处理高维观测和连续动作空间。</li>
</ul>
</li>
<li><strong>缺点：</strong>
<ul>
<li><strong>样本效率：</strong> 策略梯度方法通常比基于值函数的方法样本效率低，需要更多的交互数据。</li>
<li><strong>收敛性：</strong> 策略梯度方法可能在局部最优处收敛，且对步长和参数敏感。</li>
</ul>
</li>
</ul>
<h3 id="基于模型-Model-Based-Exploration">基于模型 (Model-Based Exploration)</h3>
<p>基于模型的强化学习（Model-Based RL）算法首先学习一个环境模型，然后利用这个模型进行规划或模拟，从而指导决策。模型本身可以成为探索的强大工具。</p>
<ul>
<li><strong>核心思想：</strong>
<ul>
<li><strong>规划指导探索：</strong> 智能体可以在内部模拟环境中进行“试错”，而无需与真实环境交互，从而高效地探索潜在的有益轨迹。</li>
<li><strong>不确定性量化：</strong> 模型可以估计其对不同状态或转换的预测不确定性。智能体可以被激励去探索那些模型预测不确定性高的区域，以改进模型。</li>
</ul>
</li>
<li><strong>实现方式：</strong>
<ul>
<li><strong>Dyna-Q：</strong> 智能体在与真实环境交互的同时，也通过学习到的环境模型生成模拟经验，用这些模拟经验来更新Q值函数。这使得智能体在少量真实交互后就能快速提升其策略。</li>
<li><strong>基于模型的不确定性：</strong> 训练一个概率性环境模型，该模型不仅预测下一个状态，还预测其不确定性。智能体优先探索那些模型不确定性大的状态-动作对，以降低模型误差。</li>
<li><strong>AlphaZero/MuZero：</strong> 这些算法通过蒙特卡洛树搜索（MCTS）在内部构建一个模型，并利用这个模型进行深度搜索来评估状态和动作。MCTS 本身就包含了探索元素（例如，PUCT（Polynomial Upper Confidence Trees）算法，是 UCB 的变种，用于树搜索中的探索）。</li>
</ul>
</li>
<li><strong>优点：</strong>
<ul>
<li><strong>高样本效率：</strong> 能够显著减少与真实环境的交互次数。</li>
<li><strong>提前规划：</strong> 可以在模型中预演未来，避免在真实世界中犯错。</li>
<li><strong>目标性探索：</strong> 可以通过模型的不确定性来引导探索，使其更具针对性。</li>
</ul>
</li>
<li><strong>缺点：</strong>
<ul>
<li><strong>模型误差：</strong> 如果学习到的环境模型不准确，可能会导致智能体学习到次优策略，甚至“幻觉”出不存在的奖励。</li>
<li><strong>模型学习难度：</strong> 学习一个准确的环境模型本身就是一个挑战，尤其是在复杂或高维环境中。</li>
</ul>
</li>
</ul>
<h3 id="分层强化学习-Hierarchical-Reinforcement-Learning-HRL">分层强化学习 (Hierarchical Reinforcement Learning - HRL)</h3>
<p>在处理非常复杂的、长时间跨度的任务时，传统的单层强化学习会面临探索效率低下的问题。<strong>分层强化学习 (HRL)</strong> 将任务分解为多个子任务或层级，可以在不同粒度上进行探索。</p>
<ul>
<li><strong>核心思想：</strong>
<ul>
<li><strong>高层策略：</strong> 学习在抽象的“宏动作”或“子目标”空间中进行探索和决策。</li>
<li><strong>低层策略：</strong> 学习如何实现这些子目标。</li>
</ul>
</li>
<li><strong>如何帮助探索：</strong>
<ul>
<li><strong>降低复杂性：</strong> 将一个大的探索空间分解为多个小的、更容易探索的子空间。高层策略负责探索“哪些子目标是重要的”，低层策略负责探索“如何达到这些子目标”。</li>
<li><strong>重用性：</strong> 一旦学会了如何完成一个子任务（例如“打开门”），这个技能可以在不同的高层任务中被重用，减少重复探索。</li>
<li><strong>更深远的探索：</strong> 智能体可以规划更长的宏观行动序列，从而实现更深远的探索，而不仅仅是步进式的局部探索。</li>
</ul>
</li>
<li><strong>优点：</strong>
<ul>
<li><strong>提高样本效率：</strong> 通过分解和重用技能，可以更快地学习复杂任务。</li>
<li><strong>处理长视界问题：</strong> 能够解决奖励稀疏且需要长时间行动序列才能达到的问题。</li>
<li><strong>更好的可解释性：</strong> 层次结构可以提供对智能体行为的更直观理解。</li>
</ul>
</li>
<li><strong>缺点：</strong>
<ul>
<li><strong>子目标设计：</strong> 如何有效划分任务、定义子目标和宏动作是一个挑战。</li>
<li><strong>多层训练：</strong> 训练多个层级的策略可能增加训练的复杂性。</li>
</ul>
</li>
</ul>
<p>这些高级策略往往结合了多个底层探索机制，以适应更复杂、更现实的强化学习场景。它们的出现标志着强化学习在处理大规模、高维、稀疏奖励问题方面的进步。</p>
<h2 id="探索与利用的衡量与评估：如何判断好坏？">探索与利用的衡量与评估：如何判断好坏？</h2>
<p>设计了各种探索与利用策略，那么我们如何评估它们的有效性呢？在强化学习中，衡量一个算法的性能和探索-利用策略的优劣，通常需要关注以下几个关键指标：</p>
<h3 id="学习曲线-Learning-Curves">学习曲线 (Learning Curves)</h3>
<ul>
<li><strong>定义：</strong> 记录智能体在训练过程中，随着时间（例如，训练步数、回合数）的推移，所获得的累积奖励（或平均奖励）的变化趋势图。</li>
<li><strong>评估指标：</strong>
<ul>
<li><strong>最终性能 (Asymptotic Performance)：</strong> 学习曲线的最终稳定高度，代表算法所能达到的最佳表现。</li>
<li><strong>收敛速度 (Convergence Speed)：</strong> 学习曲线达到稳定所需的时间或步数。更快的收敛速度通常意味着更好的探索-利用平衡。</li>
<li><strong>稳定性 (Stability)：</strong> 学习曲线的平滑程度。剧烈波动的曲线可能表明探索策略不稳定或训练过程存在问题。</li>
</ul>
</li>
<li><strong>与探索的关系：</strong>
<ul>
<li>如果学习曲线早期上升缓慢或陷入低谷，可能表明探索不足，智能体未能有效发现高回报路径。</li>
<li>如果学习曲线波动剧烈，可能表明探索过度，智能体在已知好动作和随机探索之间频繁切换。</li>
<li>理想的学习曲线通常在早期有快速的上升（有效探索），然后在后期逐渐趋于稳定且保持高位（有效利用）。</li>
</ul>
</li>
</ul>
<h3 id="收敛性-Convergence">收敛性 (Convergence)</h3>
<ul>
<li><strong>定义：</strong> 算法能否稳定地收敛到一个最优或近似最优的策略。</li>
<li><strong>评估指标：</strong> 通常通过检查学习曲线是否最终趋于稳定，以及最终性能是否接近理论上的最优值来判断。</li>
<li><strong>与探索的关系：</strong>
<ul>
<li><strong>探索不足：</strong> 可能导致算法收敛到局部最优解。</li>
<li><strong>探索过度/不当：</strong> 可能导致算法无法收敛，或者收敛速度极慢。</li>
</ul>
</li>
</ul>
<h3 id="样本效率-Sample-Efficiency">样本效率 (Sample Efficiency)</h3>
<ul>
<li><strong>定义：</strong> 智能体需要与环境交互多少次（即收集多少经验数据）才能达到满意的性能水平。</li>
<li><strong>评估指标：</strong> 通常用达到某个性能阈值所需的训练步数或回合数来衡量。</li>
<li><strong>与探索的关系：</strong>
<ul>
<li><strong>高效的探索策略：</strong> 能够在较少的交互次数内发现关键信息，从而显著提高样本效率。这对于真实世界中与环境交互成本高昂（如机器人训练、自动驾驶）的应用至关重要。</li>
<li><strong>随机或无结构探索：</strong> 通常会导致较低的样本效率，因为智能体可能会在低价值区域浪费大量交互。</li>
</ul>
</li>
<li><strong>重要性：</strong> 在许多实际应用中，样本效率是比最终性能更重要的指标，因为它直接影响训练成本和时间。</li>
</ul>
<h3 id="鲁棒性-Robustness">鲁棒性 (Robustness)</h3>
<ul>
<li><strong>定义：</strong> 算法在面对环境变化、噪声或初始条件差异时，仍能保持良好性能的能力。</li>
<li><strong>评估指标：</strong> 在不同随机种子、不同环境初始化或不同噪声水平下，算法表现的一致性。</li>
<li><strong>与探索的关系：</strong>
<ul>
<li>一个好的探索策略不仅能找到最优解，还能帮助智能体学习到对环境变化不那么敏感的策略，从而提高鲁棒性。</li>
<li>过于依赖特定探索路径的策略，可能在环境稍有变化时就失效。</li>
</ul>
</li>
</ul>
<p>这些指标共同为我们提供了一个全面的视角，来评估一个强化学习算法中探索与利用策略的有效性。在实践中，往往需要在这些指标之间进行权衡，以适应特定任务的需求。</p>
<h2 id="探索与利用的未来方向：未完待续的征程">探索与利用的未来方向：未完待续的征程</h2>
<p>探索与利用是强化学习领域的一个永恒话题，也是其持续进步的关键瓶颈之一。尽管取得了显著进展，但仍有许多开放性问题和活跃的研究方向：</p>
<h3 id="1-结构化与目标导向的探索">1. 结构化与目标导向的探索</h3>
<p>随机探索（如 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">\epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">ϵ</span></span></span></span>-贪婪）效率低下，而基于不确定性的探索（如好奇心、信息增益）虽然更智能，但仍可能陷入“噪声电视”问题或计算复杂。未来的研究将更加关注如何设计<strong>结构化、目标导向的探索策略</strong>，即智能体能够“知道”它应该探索什么，以及为什么探索。这可能涉及：</p>
<ul>
<li><strong>学习探索策略：</strong> 使用元学习（Meta-Learning）来学习如何探索，而不是手动设计探索规则。</li>
<li><strong>可解释的探索：</strong> 智能体不仅探索，还能解释其探索行为的理由。</li>
<li><strong>基于技能的探索：</strong> 在分层RL框架下，高层策略引导低层技能进行有目的的探索。</li>
</ul>
<h3 id="2-泛化与迁移探索">2. 泛化与迁移探索</h3>
<p>当前许多探索策略在新的环境中需要从头开始。如何让智能体将其在一个任务中获得的探索经验或探索能力<strong>泛化到新的、相似但未知的环境</strong>中，是未来研究的重点。</p>
<ul>
<li><strong>迁移学习（Transfer Learning）在探索中的应用：</strong> 将已学习的探索策略或内在奖励模块迁移到新任务。</li>
<li><strong>领域适应性探索：</strong> 智能体在不同但相关的领域中保持或调整其探索行为。</li>
</ul>
<h3 id="3-高维与连续空间的探索挑战">3. 高维与连续空间的探索挑战</h3>
<p>在图像、视频等高维观测空间以及连续动作空间中，探索的难度急剧增加。</p>
<ul>
<li><strong>高效的特征表示学习：</strong> 学习能够捕捉环境关键信息且利于探索的低维、鲁棒的特征表示。</li>
<li><strong>生成模型与探索：</strong> 利用生成对抗网络（GANs）或其他生成模型来生成新颖的、有潜力的状态或动作进行探索。</li>
</ul>
<h3 id="4-离线强化学习与探索">4. 离线强化学习与探索</h3>
<p><strong>离线强化学习 (Offline Reinforcement Learning)</strong> 试图仅从一个固定的、预先收集的数据集中学习策略，而不能与环境进行额外的交互。这给探索带来了独特的挑战：如何从有限的、可能分布不均的数据中推断出最优策略，同时避免“虚假”的探索行为（即在数据中从未见过的状态-动作对上做出预测，可能导致不准确的Q值估计）。未来的研究将专注于设计能够处理数据分布偏移和非覆盖性问题的离线探索策略。</p>
<h3 id="5-人机协作探索">5. 人机协作探索</h3>
<p>在许多复杂任务中，人类专家的经验和直觉是无价的。如何将人类的先验知识或实时反馈融入到强化学习的探索过程中，实现<strong>人机协作的探索</strong>，也是一个富有前景的方向。例如，人类可以引导智能体去探索某个有前景的区域，或者对智能体的探索行为进行纠正。</p>
<h3 id="6-统一的探索框架">6. 统一的探索框架</h3>
<p>目前存在多种探索策略，但它们往往各自为政。未来的研究可能会寻求构建一个<strong>统一的、自适应的探索框架</strong>，能够根据环境的特性、任务的需求以及训练阶段动态地选择、组合或调整不同的探索机制。</p>
<p>探索与利用的权衡，是强化学习迈向更智能、更自主的通用人工智能体所必须跨越的鸿沟。每一次新的探索策略的提出，都如同为智能体点亮了一盏新的探照灯，照亮了它在未知世界中前行的道路。</p>
<h2 id="结论：艺术与科学的交响">结论：艺术与科学的交响</h2>
<p>在强化学习的宏伟篇章中，探索与利用无疑是最为核心和引人入胜的章节之一。它不仅是一个纯粹的技术难题，更蕴含着智能体面对未知世界时，生存与发展的哲学思考。我们回顾了从简单的 ε-贪婪到复杂的内在奖励、基于模型的探索、以及分层强化学习等一系列策略，它们共同构成了智能体在学习过程中驾驭不确定性的工具箱。</p>
<p>探索是进步的动力，是发现新知、突破局限的必由之路。它赋予智能体摆脱局部最优、寻找全局真理的能力。而利用则是效率与成果的保证，它使得智能体能够有效地应用已学知识，最大化其性能。这两者并非你死我活的对抗，而是一种精妙的共生关系，一种动态平衡的艺术。</p>
<p>没有一种“放之四海而皆准”的探索与利用策略。最佳的平衡点取决于具体的任务、环境的特性（如稀疏奖励、连续空间）、可用的计算资源以及对样本效率的要求。设计一个高效的强化学习系统，往往需要根据实际情况，巧妙地选择和组合不同的探索机制。</p>
<p>未来的研究将继续在这一领域深耕，探索更智能、更自适应、更具泛化能力的探索策略。随着深度学习和强化学习的不断融合，以及计算能力的持续提升，我们有理由相信，智能体将能够以更加优雅和高效的方式，在复杂多变的世界中学习和成长。</p>
<p>探索与利用的博弈，是强化学习从实验室走向现实世界的关键。它不仅仅是关于算法的优化，更是关于如何赋予机器像人类一样，带着好奇心去探索未知，带着智慧去利用已知，最终实现更高级的智能行为。这是一场艺术与科学的交响，其旋律将伴随着人工智能的进步而不断奏响。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a target="_blank" rel="noopener" href="https://github.com/qmwneb946">qmwneb946</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://qmwneb946.dpdns.org/2025/07/23/2025-07-24-041423/">https://qmwneb946.dpdns.org/2025/07/23/2025-07-24-041423/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://opensource.org/licenses/MIT" target="_blank">MIT License</a> 许可协议。转载请注明来源 <a href="https://qmwneb946.dpdns.org" target="_blank">qmwneb946 的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/2025/">2025</a><a class="post-meta__tags" href="/tags/%E6%95%B0%E5%AD%A6/">数学</a><a class="post-meta__tags" href="/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%88%A9%E7%94%A8/">强化学习中的探索与利用</a></div><div class="post-share"><div class="social-share" data-image="/img/icon.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/07/23/2025-07-24-041529/" title="智能合约的升级与治理：在不可变性中寻求柔性与秩序"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">智能合约的升级与治理：在不可变性中寻求柔性与秩序</div></div><div class="info-2"><div class="info-item-1">引言 智能合约，作为区块链的核心构建模块，以其“不可篡改性”和“自动执行”的特性，正在重塑我们对信任和协作的认知。它们承诺在无需中心化第三方的情况下，以确定性的方式强制执行协议。然而，正是这种看似完美的“不可篡改性”，在实际应用中带来了巨大的挑战。 想象一下，一个价值数亿美元的去中心化金融（DeFi）协议，其核心智能合约被部署到区块链上。如果合约中存在一个微小的逻辑漏洞，或者需要根据市场变化、法律法规进行功能调整，又或者仅仅是用户界面体验需要升级，我们该怎么办？“不可篡改性”意味着我们无法简单地修改已部署的合约。这就像建造了一座混凝土大厦，一旦浇筑完成，就无法更改其结构。但在瞬息万变的技术和商业环境中，这种绝对的“不可变”往往成为创新的桎梏和潜在的灾难来源。 因此，智能合约的“升级”能力应运而生，它旨在为不可变的合约注入必要的灵活性。但这并非没有代价。引入升级机制，意味着合约的执行逻辑可能发生变化，这与区块链固有的去中心化和透明原则形成了微妙的张力。谁有权决定升级？如何确保升级过程安全透明？如何防止恶意升级？这些问题直接指向了智能合约的另一个核心议题——“治理”。 本篇博客文章将...</div></div></div></a><a class="pagination-related" href="/2025/07/23/2025-07-24-041312/" title="粒子群优化算法：群体智能的涌现与实践"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">粒子群优化算法：群体智能的涌现与实践</div></div><div class="info-2"><div class="info-item-1">你好，我是 qmwneb946，一名热爱技术与数学的博主。 在浩瀚的优化算法宇宙中，有一颗明星以其独特的仿生智慧和卓越的性能脱颖而出，那就是粒子群优化（Particle Swarm Optimization, PSO）算法。它不依赖复杂的梯度信息，而是模拟鸟群觅食或鱼群捕食的行为，通过群体成员间的协作与信息共享，在复杂的搜索空间中寻找最优解。这不仅仅是一种算法，更是一种关于自然界集体智慧如何涌现的深刻哲学思考。 今天，我将带你深入探索粒子群优化算法的奥秘，从其灵感来源、核心原理，到数学推导、算法流程，再到其各种变体、优缺点以及广泛的应用场景。我们甚至会亲手用 Python 实现一个简单的 PSO 算法，让你对其运作方式有更直观的理解。准备好了吗？让我们一同踏上这段充满智慧与启发的旅程吧！ 优化问题简介 在进入粒子群优化算法的细节之前，我们首先需要理解什么是“优化问题”。简单来说，优化问题就是在给定约束条件下，找到使某个目标函数达到最大或最小值的变量组合。 一个典型的优化问题通常包含以下几个要素：  决策变量 (Decision Variables)：我们希望通过调整这些变量来影响...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/07/18/2025-07-18-082519/" title="增强现实与工业维修：一场效率革命"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">增强现实与工业维修：一场效率革命</div></div><div class="info-2"><div class="info-item-1">增强现实 (AR) 技术正以前所未有的速度改变着我们的生活，而其在工业维修领域的应用更是展现出了巨大的潜力。不再局限于科幻电影中的场景，AR 如今已成为提升维修效率、降低维护成本、提高安全性的强大工具。本文将深入探讨 AR 如何与工业维修相结合，并分析其背后的技术和未来发展趋势。 引言：传统工业维修的挑战 传统的工业维修往往面临着诸多挑战：  信息获取困难: 维修人员需要查阅大量的纸质文档、图纸和视频，耗时费力，容易出错。 培训成本高昂:  熟练技工的培养需要漫长的学习过程和大量的实践经验，成本高昂。 安全风险较高:  一些复杂的设备维修存在高风险，例如高压电、高温部件等，容易发生意外事故。 维修效率低下:  由于缺乏实时信息和有效的指导，维修时间往往较长，导致生产停机时间增加，损失巨大。  AR 如何改变工业维修的游戏规则 AR 技术通过将数字信息叠加到现实世界中，为工业维修提供了全新的解决方案： 远程专家指导 通过 AR 眼镜或平板电脑，现场维修人员可以与远程专家实时互动。专家可以通过 AR 系统看到现场设备的实时图像，并利用虚拟标注、3D 模型等工具进行远程指导，大大缩短了...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082652/" title="纳米材料在靶向药物中的革命性应用"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">纳米材料在靶向药物中的革命性应用</div></div><div class="info-2"><div class="info-item-1">近年来，癌症等重大疾病的治疗面临着巨大的挑战，传统的化疗药物往往毒性大、副作用强，难以实现精准治疗。而纳米技术的兴起为解决这一难题提供了新的思路，特别是纳米材料在靶向药物递送系统中的应用，正引发一场医学革命。本文将深入探讨纳米材料如何提升靶向药物的疗效，降低其毒副作用。 纳米材料的特性及其在药物递送中的优势 纳米材料，是指至少在一个维度上尺寸小于100纳米的材料。这种极小的尺寸赋予了它们许多独特的物理和化学性质，使其在药物递送领域具有显著优势： 增强的药物溶解度和稳定性 许多药物具有较低的溶解度，限制了其在体内的吸收和生物利用度。纳米载体，例如脂质体、聚合物纳米颗粒和无机纳米颗粒（如金纳米颗粒、氧化铁纳米颗粒），可以显著提高药物的溶解度和稳定性，延长其在体内的循环时间。例如，将抗癌药物负载在聚合物纳米颗粒中，可以保护药物免受降解，并提高其在肿瘤组织中的积累。 靶向药物递送 纳米材料可以通过表面修饰，例如结合特异性配体（如抗体、肽或小分子），实现对特定细胞或组织的靶向递送。这种靶向递送可以最大限度地减少药物对健康组织的毒性，并提高药物在靶标部位的浓度，从而增强治疗效果。例如，修饰有...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082925/" title="生物化学中的蛋白质折叠问题：一个复杂而迷人的计算挑战"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">生物化学中的蛋白质折叠问题：一个复杂而迷人的计算挑战</div></div><div class="info-2"><div class="info-item-1">生命，这奇妙的现象，其本质很大程度上取决于蛋白质的精确三维结构。蛋白质是由氨基酸链组成的长链分子，但仅仅是氨基酸序列并不能完全决定其功能。蛋白质必须折叠成特定的三维结构（构象），才能发挥其生物学功能，例如催化酶促反应、运输分子或构建细胞结构。  而这个折叠过程，就是著名的“蛋白质折叠问题”。 蛋白质折叠：从线性序列到三维结构 蛋白质的氨基酸序列由基因编码决定，这是一个线性的一维结构。然而，这些氨基酸链并非随机地盘踞在一起，而是会遵循特定的物理和化学原理，自发地折叠成独特的、功能性的三维结构。这个折叠过程涉及到多种相互作用，包括： 疏水相互作用 蛋白质内部的疏水氨基酸残基倾向于聚集在一起，远离水性环境，形成蛋白质的核心区域。而亲水性氨基酸残基则倾向于暴露在蛋白质的表面，与水分子相互作用。 静电相互作用 带电荷的氨基酸残基之间会发生静电吸引或排斥作用，影响蛋白质的折叠。 氢键 氢键在维持蛋白质二级结构（例如α螺旋和β折叠）中起着关键作用。 二硫键 某些氨基酸残基（例如半胱氨酸）之间可以形成二硫键，进一步稳定蛋白质的三维结构。 这些相互作用共同决定了蛋白质的最终构象，这是一个极其复杂的...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-092536/" title="CRISPR基因编辑：技术的奇迹与伦理的挑战"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">CRISPR基因编辑：技术的奇迹与伦理的挑战</div></div><div class="info-2"><div class="info-item-1">大家好！我是你们的技术和数学博主，今天我们要深入探讨一个既令人兴奋又充满争议的话题：CRISPR-Cas9基因编辑技术及其伦理挑战。CRISPR技术以其精准性和效率，为治疗遗传疾病、改良作物等领域带来了革命性的变革，但与此同时，它也引发了诸多伦理难题，需要我们认真思考和谨慎应对。 CRISPR技术：一把双刃剑 CRISPR-Cas9系统，简单来说，就是一种可以精确地“剪切和粘贴”DNA的工具。它源自细菌的天然防御机制，利用向导RNA（gRNA）引导Cas9酶到基因组中的特定位置，从而进行基因的敲除、插入或替换。其操作简便、成本低廉、效率高，使其成为基因编辑领域的“明星”技术。 CRISPR的工作原理 CRISPR系统的工作机制可以概括为以下几个步骤：  设计gRNA:  根据目标基因序列设计相应的gRNA，使其能够特异性地结合目标DNA序列。 Cas9酶的结合: gRNA引导Cas9酶到目标DNA序列。 DNA双链断裂: Cas9酶在目标位点切割DNA双链，形成双链断裂（DSB）。 DNA修复: 细胞利用非同源末端连接（NHEJ）或同源定向修复（HDR）机制修复DSB。NHEJ修...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-094115/" title="免疫学与癌症免疫疗法：一场人体内部的战争与和平"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">免疫学与癌症免疫疗法：一场人体内部的战争与和平</div></div><div class="info-2"><div class="info-item-1">免疫系统，人体精妙的防御机制，日夜不停地抵御着病毒、细菌和其他有害物质的入侵。然而，当这套系统出现故障，对自身细胞发起攻击，或者无法有效清除癌细胞时，疾病便会发生，其中最可怕的莫过于癌症。近年来，癌症免疫疗法异军突起，为癌症治疗带来了新的希望，让我们深入探索这场人体内部的战争与和平。 免疫系统：人体精妙的防御网络 我们的免疫系统由先天免疫和适应性免疫两大支柱组成。 先天免疫：第一道防线 先天免疫是人体抵御病原体的第一道防线，它包含物理屏障（例如皮肤和黏膜）、化学屏障（例如胃酸和酶）以及细胞介导的免疫反应，例如巨噬细胞和自然杀伤细胞（NK细胞）的吞噬和杀伤作用。这些细胞能够识别并清除被感染的细胞或癌细胞，但其特异性较低。 适应性免疫：精准打击 适应性免疫系统则更为精细，它具有特异性和记忆性。T细胞和B细胞是适应性免疫的主角。T细胞负责细胞介导的免疫，其中细胞毒性T细胞（CTL）能够特异性识别并杀死靶细胞，例如被病毒感染的细胞或癌细胞。B细胞则负责体液免疫，产生抗体，中和病原体或标记癌细胞以便清除。  抗原呈递细胞（APC），例如树突状细胞，在将抗原信息呈递给T细胞，启动适应性免疫反...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-094141/" title="生态学中的生物多样性保护：一个复杂系统工程的视角"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">生态学中的生物多样性保护：一个复杂系统工程的视角</div></div><div class="info-2"><div class="info-item-1">大家好！今天我们要深入探讨一个既充满挑战又至关重要的话题：生态学中的生物多样性保护。  这不仅是环境保护的基石，也与我们人类的福祉息息相关。对技术爱好者来说，这更像是一个巨大的、复杂的系统工程，充满了需要解决的优化问题和值得探索的算法。 生物多样性的价值：超越简单的物种数量 我们通常将生物多样性理解为物种数量的多样性。但实际上，它是一个多层次的概念，包括：  遗传多样性 (Genetic Diversity):  同一物种内基因组的差异性，这决定了物种的适应性和进化潜力。  想象一下，一个抗旱基因的缺失可能导致整个小麦品种在干旱年份面临灭绝的风险。 物种多样性 (Species Diversity):  不同物种的数量及其相对丰度。 这通常用Shannon多样性指数 (H=−∑i=1Spilog⁡2piH = -\sum_{i=1}^{S} p_i \log_2 p_iH=−∑i=1S​pi​log2​pi​) 来衡量，其中 pip_ipi​ 是第 iii 个物种的比例，SSS 是物种总数。  更高的Shannon指数表示更高的物种多样性。 生态系统多样性 (Ecosystem ...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">qmwneb946</div><div class="author-info-description">一个专注于技术分享的个人博客，涵盖编程、算法、系统设计等内容</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">1357</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">1361</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/qmwneb946"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/qmwneb946" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:qmwneb946@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">代码与远方，技术与生活交织的篇章。</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%88%A9%E7%94%A8%E7%9A%84%E6%9C%AC%E8%B4%A8%EF%BC%9A%E6%99%BA%E8%83%BD%E4%BD%93%E7%94%9F%E5%AD%98%E7%9A%84%E5%93%B2%E5%AD%A6"><span class="toc-number">1.</span> <span class="toc-text">探索与利用的本质：智能体生存的哲学</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%8E%A2%E7%B4%A2%EF%BC%9F"><span class="toc-number">1.1.</span> <span class="toc-text">什么是探索？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%88%A9%E7%94%A8%EF%BC%9F"><span class="toc-number">1.2.</span> <span class="toc-text">什么是利用？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%B0%E5%A2%83%EF%BC%9A%E6%9D%83%E8%A1%A1%E7%9A%84%E8%89%BA%E6%9C%AF"><span class="toc-number">1.3.</span> <span class="toc-text">困境：权衡的艺术</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%8F%E5%85%B8%E7%9A%84%E6%8E%A2%E7%B4%A2%E7%AD%96%E7%95%A5%EF%BC%9A%E4%BB%8E%E7%AE%80%E5%8D%95%E5%88%B0%E5%A4%8D%E6%9D%82"><span class="toc-number">2.</span> <span class="toc-text">经典的探索策略：从简单到复杂</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B4%AA%E5%A9%AA%E7%AD%96%E7%95%A5-Greedy-Strategy"><span class="toc-number">2.1.</span> <span class="toc-text">贪婪策略 (Greedy Strategy)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%CE%B5-%E8%B4%AA%E5%A9%AA%E7%AD%96%E7%95%A5-%CE%B5-Greedy-Strategy"><span class="toc-number">2.2.</span> <span class="toc-text">ε-贪婪策略 (ε-Greedy Strategy)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B9%90%E8%A7%82%E5%88%9D%E5%A7%8B%E5%80%BC-Optimistic-Initialization"><span class="toc-number">2.3.</span> <span class="toc-text">乐观初始值 (Optimistic Initialization)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#UCB-Upper-Confidence-Bound"><span class="toc-number">2.4.</span> <span class="toc-text">UCB (Upper Confidence Bound)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%9A%84%E6%8E%A2%E7%B4%A2%EF%BC%9A%E4%BB%8E%E8%AE%A1%E6%95%B0%E5%88%B0%E5%A5%BD%E5%A5%87%E5%BF%83"><span class="toc-number">3.</span> <span class="toc-text">基于不确定性的探索：从计数到好奇心</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E8%AE%A1%E6%95%B0-Count-Based-Exploration"><span class="toc-number">3.1.</span> <span class="toc-text">基于计数 (Count-Based Exploration)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%85%E5%9C%A8%E5%A5%96%E5%8A%B1-Intrinsic-Motivation-Intrinsic-Reward"><span class="toc-number">3.2.</span> <span class="toc-text">内在奖励 (Intrinsic Motivation &#x2F; Intrinsic Reward)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A5%BD%E5%A5%87%E5%BF%83%E9%A9%B1%E5%8A%A8-Curiosity-driven-Exploration"><span class="toc-number">3.2.1.</span> <span class="toc-text">好奇心驱动 (Curiosity-driven Exploration)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A-%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E5%87%8F%E5%B0%91"><span class="toc-number">3.2.2.</span> <span class="toc-text">基于信息增益&#x2F;不确定性减少</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%AB%98%E7%BA%A7%E6%8E%A2%E7%B4%A2%E7%AD%96%E7%95%A5%EF%BC%9A%E8%B6%85%E8%B6%8A%E4%BC%A0%E7%BB%9F%E6%A1%86%E6%9E%B6"><span class="toc-number">4.</span> <span class="toc-text">高级探索策略：超越传统框架</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%99%AA%E5%A3%B0%E7%9A%84%E6%8E%A2%E7%B4%A2-Noise-Based-Exploration"><span class="toc-number">4.1.</span> <span class="toc-text">基于噪声的探索 (Noise-Based Exploration)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E7%AD%96%E7%95%A5%E7%9A%84%E6%8E%A2%E7%B4%A2-Policy-Based-Exploration"><span class="toc-number">4.2.</span> <span class="toc-text">基于策略的探索 (Policy-Based Exploration)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E6%A8%A1%E5%9E%8B-Model-Based-Exploration"><span class="toc-number">4.3.</span> <span class="toc-text">基于模型 (Model-Based Exploration)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%B1%82%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-Hierarchical-Reinforcement-Learning-HRL"><span class="toc-number">4.4.</span> <span class="toc-text">分层强化学习 (Hierarchical Reinforcement Learning - HRL)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%88%A9%E7%94%A8%E7%9A%84%E8%A1%A1%E9%87%8F%E4%B8%8E%E8%AF%84%E4%BC%B0%EF%BC%9A%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E5%A5%BD%E5%9D%8F%EF%BC%9F"><span class="toc-number">5.</span> <span class="toc-text">探索与利用的衡量与评估：如何判断好坏？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF-Learning-Curves"><span class="toc-number">5.1.</span> <span class="toc-text">学习曲线 (Learning Curves)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%94%B6%E6%95%9B%E6%80%A7-Convergence"><span class="toc-number">5.2.</span> <span class="toc-text">收敛性 (Convergence)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B7%E6%9C%AC%E6%95%88%E7%8E%87-Sample-Efficiency"><span class="toc-number">5.3.</span> <span class="toc-text">样本效率 (Sample Efficiency)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%B2%81%E6%A3%92%E6%80%A7-Robustness"><span class="toc-number">5.4.</span> <span class="toc-text">鲁棒性 (Robustness)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%88%A9%E7%94%A8%E7%9A%84%E6%9C%AA%E6%9D%A5%E6%96%B9%E5%90%91%EF%BC%9A%E6%9C%AA%E5%AE%8C%E5%BE%85%E7%BB%AD%E7%9A%84%E5%BE%81%E7%A8%8B"><span class="toc-number">6.</span> <span class="toc-text">探索与利用的未来方向：未完待续的征程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E7%BB%93%E6%9E%84%E5%8C%96%E4%B8%8E%E7%9B%AE%E6%A0%87%E5%AF%BC%E5%90%91%E7%9A%84%E6%8E%A2%E7%B4%A2"><span class="toc-number">6.1.</span> <span class="toc-text">1. 结构化与目标导向的探索</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%B3%9B%E5%8C%96%E4%B8%8E%E8%BF%81%E7%A7%BB%E6%8E%A2%E7%B4%A2"><span class="toc-number">6.2.</span> <span class="toc-text">2. 泛化与迁移探索</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E9%AB%98%E7%BB%B4%E4%B8%8E%E8%BF%9E%E7%BB%AD%E7%A9%BA%E9%97%B4%E7%9A%84%E6%8E%A2%E7%B4%A2%E6%8C%91%E6%88%98"><span class="toc-number">6.3.</span> <span class="toc-text">3. 高维与连续空间的探索挑战</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E7%A6%BB%E7%BA%BF%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%8E%A2%E7%B4%A2"><span class="toc-number">6.4.</span> <span class="toc-text">4. 离线强化学习与探索</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E4%BA%BA%E6%9C%BA%E5%8D%8F%E4%BD%9C%E6%8E%A2%E7%B4%A2"><span class="toc-number">6.5.</span> <span class="toc-text">5. 人机协作探索</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E7%BB%9F%E4%B8%80%E7%9A%84%E6%8E%A2%E7%B4%A2%E6%A1%86%E6%9E%B6"><span class="toc-number">6.6.</span> <span class="toc-text">6. 统一的探索框架</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA%EF%BC%9A%E8%89%BA%E6%9C%AF%E4%B8%8E%E7%A7%91%E5%AD%A6%E7%9A%84%E4%BA%A4%E5%93%8D"><span class="toc-number">7.</span> <span class="toc-text">结论：艺术与科学的交响</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/26/hello-world/" title="Hello World">Hello World</a><time datetime="2025-07-26T08:21:24.408Z" title="发表于 2025-07-26 16:21:24">2025-07-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/26/%E5%8D%9A%E5%BC%88%E8%AE%BA%E5%9F%BA%E7%A1%80/" title="博弈论基础">博弈论基础</a><time datetime="2025-07-26T08:21:24.408Z" title="发表于 2025-07-26 16:21:24">2025-07-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/26/2025-07-26-081818/" title="深入解析量子信息处理的物理实现：从原理到前沿">深入解析量子信息处理的物理实现：从原理到前沿</a><time datetime="2025-07-26T00:18:18.000Z" title="发表于 2025-07-26 08:18:18">2025-07-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/26/2025-07-26-081652/" title="金融风险的传染模型：洞悉系统性危机的数学之美与工程实践">金融风险的传染模型：洞悉系统性危机的数学之美与工程实践</a><time datetime="2025-07-26T00:16:52.000Z" title="发表于 2025-07-26 08:16:52">2025-07-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/26/2025-07-26-081535/" title="动力系统中的分形吸引子：混沌之美与秩序">动力系统中的分形吸引子：混沌之美与秩序</a><time datetime="2025-07-26T00:15:35.000Z" title="发表于 2025-07-26 08:15:35">2025-07-26</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;2025 By qmwneb946</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.2</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css')
    if (true) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const getGiscusTheme = theme => theme === 'dark' ? 'dark' : 'light'

  const createScriptElement = config => {
    const ele = document.createElement('script')
    Object.entries(config).forEach(([key, value]) => {
      ele.setAttribute(key, value)
    })
    return ele
  }

  const loadGiscus = (el = document, key) => {
    const mappingConfig = isShuoshuo
      ? { 'data-mapping': 'specific', 'data-term': key }
      : { 'data-mapping': (option && option['data-mapping']) || 'pathname' }

    const giscusConfig = {
      src: 'https://giscus.app/client.js',
      'data-repo': 'qmwneb946/blog',
      'data-repo-id': 'R_kgDOPM6cWw',
      'data-category-id': 'DIC_kwDOPM6cW84CtEzo',
      'data-theme': getGiscusTheme(document.documentElement.getAttribute('data-theme')),
      'data-reactions-enabled': '1',
      crossorigin: 'anonymous',
      async: true,
      ...option,
      ...mappingConfig
    }

    const scriptElement = createScriptElement(giscusConfig)

    el.querySelector('#giscus-wrap').appendChild(scriptElement)

    if (isShuoshuo) {
      window.shuoshuoComment.destroyGiscus = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }
  }

  const changeGiscusTheme = theme => {
    const iframe = document.querySelector('#giscus-wrap iframe')
    if (iframe) {
      const message = {
        giscus: {
          setConfig: {
            theme: getGiscusTheme(theme)
          }
        }
      }
      iframe.contentWindow.postMessage(message, 'https://giscus.app')
    }
  }

  btf.addGlobalFn('themeChange', changeGiscusTheme, 'giscus')

  if (isShuoshuo) {
    'Giscus' === 'Giscus'
      ? window.shuoshuoComment = { loadComment: loadGiscus }
      : window.loadOtherComment = loadGiscus
    return
  }

  if ('Giscus' === 'Giscus' || !false) {
    if (false) btf.loadComment(document.getElementById('giscus-wrap'), loadGiscus)
    else loadGiscus()
  } else {
    window.loadOtherComment = loadGiscus
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>