<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>深入探讨文本摘要的忠实度问题：幻觉、事实不符与信任危机 | qmwneb946 的博客</title><meta name="author" content="qmwneb946"><meta name="copyright" content="qmwneb946"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="你好，各位技术与数学爱好者们！我是你们的老朋友 qmwneb946。 在信息爆炸的时代，文本摘要技术无疑是帮助我们高效获取知识、把握核心信息的利器。从新闻报道到科研论文，从会议纪要到法律文档，自动文本摘要正在逐渐渗透到我们生活的方方面面。然而，当你满怀期待地点击“生成摘要”按钮时，有没有那么一刻，你发现机器给出的总结似乎“说了谎”？它可能杜撰了一个人名，扭曲了一个数字，或者干脆发明了一个从未发生过">
<meta property="og:type" content="article">
<meta property="og:title" content="深入探讨文本摘要的忠实度问题：幻觉、事实不符与信任危机">
<meta property="og:url" content="https://qmwneb946.dpdns.org/2025/07/24/2025-07-24-115511/index.html">
<meta property="og:site_name" content="qmwneb946 的博客">
<meta property="og:description" content="你好，各位技术与数学爱好者们！我是你们的老朋友 qmwneb946。 在信息爆炸的时代，文本摘要技术无疑是帮助我们高效获取知识、把握核心信息的利器。从新闻报道到科研论文，从会议纪要到法律文档，自动文本摘要正在逐渐渗透到我们生活的方方面面。然而，当你满怀期待地点击“生成摘要”按钮时，有没有那么一刻，你发现机器给出的总结似乎“说了谎”？它可能杜撰了一个人名，扭曲了一个数字，或者干脆发明了一个从未发生过">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://qmwneb946.dpdns.org/img/icon.png">
<meta property="article:published_time" content="2025-07-24T03:55:11.000Z">
<meta property="article:modified_time" content="2025-07-26T07:43:24.629Z">
<meta property="article:author" content="qmwneb946">
<meta property="article:tag" content="2025">
<meta property="article:tag" content="技术">
<meta property="article:tag" content="文本摘要的忠实度问题">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://qmwneb946.dpdns.org/img/icon.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "深入探讨文本摘要的忠实度问题：幻觉、事实不符与信任危机",
  "url": "https://qmwneb946.dpdns.org/2025/07/24/2025-07-24-115511/",
  "image": "https://qmwneb946.dpdns.org/img/icon.png",
  "datePublished": "2025-07-24T03:55:11.000Z",
  "dateModified": "2025-07-26T07:43:24.629Z",
  "author": [
    {
      "@type": "Person",
      "name": "qmwneb946",
      "url": "https://github.com/qmwneb946"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://qmwneb946.dpdns.org/2025/07/24/2025-07-24-115511/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '深入探讨文本摘要的忠实度问题：幻觉、事实不符与信任危机',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2845632165165414" crossorigin="anonymous"></script><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="qmwneb946 的博客" type="application/atom+xml">
</head><body><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">qmwneb946 的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">深入探讨文本摘要的忠实度问题：幻觉、事实不符与信任危机</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">深入探讨文本摘要的忠实度问题：幻觉、事实不符与信任危机<a class="post-edit-link" href="https://github.com/qmwneb946/blog/edit/main/source/_posts/2025-07-24-115511.md" title="编辑" target="_blank"><i class="fas fa-pencil-alt"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-07-24T03:55:11.000Z" title="发表于 2025-07-24 11:55:11">2025-07-24</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-07-26T07:43:24.629Z" title="更新于 2025-07-26 15:43:24">2025-07-26</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%8A%80%E6%9C%AF/">技术</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><p>你好，各位技术与数学爱好者们！我是你们的老朋友 qmwneb946。</p>
<p>在信息爆炸的时代，文本摘要技术无疑是帮助我们高效获取知识、把握核心信息的利器。从新闻报道到科研论文，从会议纪要到法律文档，自动文本摘要正在逐渐渗透到我们生活的方方面面。然而，当你满怀期待地点击“生成摘要”按钮时，有没有那么一刻，你发现机器给出的总结似乎“说了谎”？它可能杜撰了一个人名，扭曲了一个数字，或者干脆发明了一个从未发生过的事件。这就是我们今天要深入探讨的核心问题——文本摘要的“忠实度”（Fidelity）问题。</p>
<p>忠实度，简单来说，就是指生成的摘要在事实层面上与原文保持一致，不包含任何虚假或歪曲的信息。如果一个摘要流畅、连贯，但却充满了“幻觉”或“事实不符”，那么它不仅失去了帮助用户的价值，反而可能误导用户，甚至引发信任危机。今天，我们就来一场深度探索，剖析忠实度问题的本质、成因、评估方法，以及前沿的解决方案。</p>
<h2 id="忠实度是什么？定义与重要性">忠实度是什么？定义与重要性</h2>
<p>在深入技术细节之前，我们首先需要明确“忠实度”在文本摘要语境下的具体含义。</p>
<h3 id="忠实度的核心定义">忠实度的核心定义</h3>
<p>忠实度（Fidelity），也常被称为“事实一致性”（Factual Consistency）或“准确性”（Accuracy），指的是生成的摘要内容必须真实、准确地反映原文所陈述的事实和语义。它要求摘要中的信息点（如实体、事件、属性、数量、时间等）与原文完全吻合，不得凭空捏造、篡改或曲解。</p>
<p>例如，如果原文写道：“会议于2023年10月26日在北京举行，共有50名代表参加。”<br>
一个忠实的摘要会是：“会议于2023年10月26日在北京举行，50名代表出席。”<br>
一个缺乏忠实度的摘要可能是：“会议于2023年10月27日在上海举行，约100名代表参加。”——这就出现了时间、地点、人数的“幻觉”和“事实不符”。</p>
<h3 id="忠实度为何如此关键？">忠实度为何如此关键？</h3>
<p>文本摘要的质量通常由多个维度衡量：</p>
<ol>
<li><strong>流畅性 (Fluency):</strong> 摘要的语言是否自然、语法是否正确。</li>
<li><strong>连贯性 (Coherence):</strong> 摘要的句子之间是否逻辑清晰，上下文是否顺畅。</li>
<li><strong>简洁性 (Conciseness):</strong> 摘要是否有效地压缩了信息，去除冗余。</li>
<li><strong>忠实度 (Fidelity):</strong> 摘要内容是否与原文事实一致。</li>
<li><strong>完整性 (Completeness):</strong> 摘要是否涵盖了原文的关键信息。</li>
</ol>
<p>在很长一段时间里，研究者和开发者更侧重于提升前三点，即让模型生成听起来“像人话”的摘要。然而，随着深度学习模型生成能力的飞跃，尤其是在抽象式摘要（Abstractive Summarization）方面，模型能够写出非常流畅且看似合理的文本。但这时，忠实度问题开始凸显，并成为阻碍摘要技术落地应用的最大障碍之一。</p>
<p>想象一下以下场景：</p>
<ul>
<li><strong>医疗领域：</strong> 自动总结的病历报告中，如果将“患者无过敏史”总结为“患者有青霉素过敏史”，后果不堪设想。</li>
<li><strong>法律领域：</strong> 法律文书摘要中，如果将“被告无罪”总结为“被告有罪”，或者混淆了日期和罚款金额，将直接影响司法公正。</li>
<li><strong>金融领域：</strong> 财经新闻摘要中，如果模型“发明”了一个错误的股票代码或公司名称，可能导致投资者重大损失。</li>
</ul>
<p>在这些对准确性要求极高的领域，即使是细微的忠实度问题也可能带来灾难性的后果。即使在日常信息消费中，用户也希望从摘要中获取可靠的事实，而不是误导性的信息。因此，忠实度不仅仅是一个技术指标，更关乎摘要系统的“信任度”和“可靠性”。没有忠实度，再流畅、再连贯的摘要也毫无价值，甚至适得其反。</p>
<h2 id="忠实度问题的具体表现：幻觉与事实不符">忠实度问题的具体表现：幻觉与事实不符</h2>
<p>忠实度问题并非单一概念，它通常以两种主要形式出现：幻觉（Hallucinations）和事实不符（Factual Inconsistencies）。虽然两者紧密相关，但理解它们的细微差别有助于我们更好地分析问题和寻找解决方案。</p>
<h3 id="幻觉-Hallucinations">幻觉 (Hallucinations)</h3>
<p>“幻觉”一词最早在自然语言生成（NLG）领域中被广泛使用，形象地描述了模型“凭空想象”出不存在于原文中的内容。</p>
<h4 id="幻觉的定义">幻觉的定义</h4>
<p>幻觉是指模型生成了原文中根本没有提及的信息，或者与原文内容直接冲突的信息。这些信息可能是完全虚构的，也可能是模型从其训练数据中“记住”的外部世界知识，但与当前原文上下文不符。</p>
<h4 id="幻觉的分类">幻觉的分类</h4>
<p>根据幻觉内容与原文的关系，可以进一步细分为：</p>
<ol>
<li>
<p><strong>内源性幻觉 (Intrinsic Hallucinations):</strong></p>
<ul>
<li>定义：生成的摘要内容与原文中明确陈述的事实发生矛盾或冲突。</li>
<li>示例：
<ul>
<li>原文：“科学家发现了<strong>一种新的</strong>行星，它位于<strong>天鹅座</strong>。”</li>
<li>摘要（内源性幻觉）：“科学家发现了<strong>三颗已知</strong>行星，它们位于<strong>仙女座</strong>。”（数量、状态、位置与原文冲突）</li>
<li>原文：“该公司<strong>并未</strong>宣布新产品发布会日期。”</li>
<li>摘要（内源性幻觉）：“该公司宣布新产品发布会将于<strong>下周</strong>举行。”（否定关系被篡改）</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>外源性幻觉 (Extrinsic Hallucinations):</strong></p>
<ul>
<li>定义：生成的摘要内容在原文中根本找不到对应信息，但这些信息可能是真实存在的外部世界知识（或者并非事实，只是模型凭空捏造）。</li>
<li>示例：
<ul>
<li>原文：“电影在<strong>东京</strong>的一个小剧院首映，观众反响热烈。”</li>
<li>摘要（外源性幻觉）：“电影在<strong>柏林电影节</strong>首映，获得了金熊奖。”（柏林电影节和金熊奖原文未提及，即使可能真实存在，但与原文内容无关且未被证实）</li>
<li>原文：“会议讨论了气候变化的影响。”</li>
<li>摘要（外源性幻觉）：“<strong>联合国秘书长安东尼奥·古特雷斯</strong>出席了会议。”（原文未提及任何与会人员）</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>内源性幻觉通常被认为是更严重的问题，因为它直接扭曲了原文的意义；而外源性幻觉虽然也令人困扰，但其危害程度取决于其内容的真实性以及是否会误导用户。</p>
<h3 id="事实不符-Factual-Inconsistencies">事实不符 (Factual Inconsistencies)</h3>
<p>事实不符是幻觉的一种常见表现形式，特指摘要中的特定事实点与原文不一致。</p>
<h4 id="事实不符的定义">事实不符的定义</h4>
<p>事实不符是指摘要中关于特定实体、事件、属性、数量、时间、地点等关键信息与原文存在差异或矛盾。</p>
<h4 id="事实不符的例子">事实不符的例子</h4>
<ul>
<li><strong>数字/数量不符：</strong>
<ul>
<li>原文：“项目耗资<strong>200万美元</strong>。”</li>
<li>摘要：“项目耗资<strong>2000万美元</strong>。”</li>
</ul>
</li>
<li><strong>时间/日期不符：</strong>
<ul>
<li>原文：“活动定于<strong>周五下午3点</strong>开始。”</li>
<li>摘要：“活动定于<strong>周六上午10点</strong>开始。”</li>
</ul>
</li>
<li><strong>地点不符：</strong>
<ul>
<li>原文：“公司在<strong>旧金山</strong>设立了新办事处。”</li>
<li>摘要：“公司在<strong>纽约</strong>设立了新办事处。”</li>
</ul>
</li>
<li><strong>实体/属性不符：</strong>
<ul>
<li>原文：“这位科学家名叫<strong>李明</strong>。”</li>
<li>摘要：“这位科学家名叫<strong>王伟</strong>。”</li>
</ul>
</li>
<li><strong>关系/逻辑不符：</strong>
<ul>
<li>原文：“由于<strong>下雨</strong>，比赛<strong>被取消</strong>。”</li>
<li>摘要：“尽管<strong>下雨</strong>，比赛<strong>仍按时进行</strong>。”</li>
</ul>
</li>
</ul>
<p>尽管幻觉和事实不符的概念在实践中常常交织在一起，但我们可以将“幻觉”看作是模型生成了“不存在于原文中”或“与原文冲突”的任何文本，而“事实不符”更侧重于其中具体的、可验证的事实信息的错误。一个摘要可能既有内源性幻觉（事实不符），又有外源性幻觉（凭空捏造）。它们共同构成了文本摘要的“信任危机”。</p>
<h2 id="忠实度问题的成因：深度学习模型的局限性">忠实度问题的成因：深度学习模型的局限性</h2>
<p>了解了忠实度问题的表现，我们自然会问：为什么强大的深度学习模型，尤其是基于Transformer架构的大型语言模型，会产生这些“幻觉”和“事实不符”？答案在于这些模型的内在工作机制及其固有的局限性。</p>
<h3 id="数据驱动的本质与偏差">数据驱动的本质与偏差</h3>
<p>当前主流的抽象式摘要模型，如BART、T5、Pegasus以及更先进的GPT系列，都是在大规模文本数据上进行预训练，然后针对摘要任务进行微调的。这种数据驱动的范式带来了巨大的成功，但也埋下了忠实度问题的种子。</p>
<h4 id="训练数据中的噪声与偏差">训练数据中的噪声与偏差</h4>
<ul>
<li><strong>噪声数据：</strong> 互联网上的数据并非完美无瑕，其中可能包含重复、错误、不一致甚至虚假的信息。模型在学习这些数据时，可能会将这些噪声内化。</li>
<li><strong>摘要对的质量：</strong> 许多摘要数据集是通过启发式规则（如新闻标题作为摘要）或众包方式构建的。众包的质量参差不齐，有时人工摘要本身就存在事实性错误或过度概括。</li>
<li><strong>统计关联而非语义理解：</strong> 模型通过学习词语、短语之间的统计关联来预测下一个词。它善于捕捉“形似”而非“神似”，容易将表面上的关联误认为深层的语义因果。</li>
</ul>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>Y</mi><mi mathvariant="normal">∣</mi><mi>X</mi><mo stretchy="false">)</mo><mo>=</mo><msubsup><mo>∏</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>L</mi><mi>Y</mi></msub></msubsup><mi>P</mi><mo stretchy="false">(</mo><msub><mi>y</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>y</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>y</mi><mrow><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><mi>X</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(Y|X) = \prod_{i=1}^{L_Y} P(y_i|y_1, \dots, y_{i-1}, X)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2809em;vertical-align:-0.2997em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∏</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3567em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">Y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1433em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span></span></span></span></p>
<p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span> 是原文，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span></span></span></span> 是摘要，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">y_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是摘要中的第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 个词。模型的目标是最大化这个条件概率，这本质上是一个模式匹配问题，而不是真正理解原文的意义和事实。</p>
<h3 id="注意力机制的缺陷">注意力机制的缺陷</h3>
<p>Transformer模型的核心是自注意力机制（Self-Attention）和交叉注意力机制（Cross-Attention）。它们允许模型在编码和解码过程中关注输入序列的不同部分。然而，注意力机制并非完美：</p>
<ul>
<li><strong>“分心”问题：</strong> 模型的注意力可能被原文中不重要的词语或句子吸引，导致忽略了关键的事实信息。尤其是在长文本摘要中，有限的上下文窗口和注意力分配可能使得模型难以全局把握所有事实。</li>
<li><strong>信息瓶颈：</strong> 编码器将整个原文压缩成一个固定大小的上下文向量。尽管Transformer的上下文能力远超RNN，但在极长文本的情况下，这种表示仍然可能丢失细粒度的事实信息，导致解码器无法准确重建所有事实。</li>
<li><strong>过分关注语言模式：</strong> 注意力机制在捕捉句法结构和局部语义上表现出色，但在处理复杂逻辑、多跳推理或跨句事实关联时，其能力有限。</li>
</ul>
<h3 id="解码策略的探索性">解码策略的探索性</h3>
<p>解码阶段是模型生成摘要文本的过程。常用的解码策略包括贪婪搜索、束搜索（Beam Search）以及Top-k/Nucleus采样等。这些策略在提高摘要流畅性和多样性方面有优势，但也可能引入忠实度问题：</p>
<ul>
<li><strong>贪婪搜索/束搜索的局部最优：</strong> 贪婪搜索每次选择概率最高的词，可能陷入局部最优，导致后续生成的词与原文事实不符。束搜索虽然考虑了多个候选序列，但在探索空间有限的情况下，仍可能错过真正事实一致的路径。</li>
<li><strong>随机性引入幻觉：</strong> Top-k或Nucleus采样会引入一定的随机性，以增加生成文本的多样性。但这种随机性也可能导致模型偏离原文事实，生成一些“意外”的幻觉。模型在生成过程中并不显式地进行“事实核查”，只是根据概率分布选择下一个词。</li>
</ul>
<h3 id="知识外化与推理能力的缺乏">知识外化与推理能力的缺乏</h3>
<p>当前的大型语言模型虽然拥有庞大的参数量，似乎“无所不知”，但它们本质上是“概率机器”，而非“推理引擎”或“知识库”。</p>
<ul>
<li><strong>缺乏常识和世界知识的显式表示：</strong> 模型通过训练数据隐式地学习了大量的世界知识和常识，但这些知识并没有结构化的显式表示。当原文信息不完整或需要结合外部常识进行推理时，模型容易出错。</li>
<li><strong>难以进行多步推理：</strong> 忠实地总结长文本往往需要理解复杂的逻辑关系、事件链条和因果关系，甚至进行简单的推理。例如，从“A导致B”和“B导致C”推理出“A导致C”。目前的模型在处理这类多步推理时仍显不足，容易在推理过程中引入错误。</li>
<li><strong>非符号化表示：</strong> 模型内部的知识是分散在海量参数中的数值，而不是像知识图谱那样结构化的符号。这使得模型难以进行精确的事实检索和验证。</li>
</ul>
<h3 id="过拟合与欠拟合">过拟合与欠拟合</h3>
<p>无论是过拟合还是欠拟合，都可能加剧忠实度问题：</p>
<ul>
<li><strong>过拟合：</strong> 模型过度记忆了训练数据中的特定模式，导致泛化能力差。在面对训练集中未见过的实体或表述时，容易产生幻觉。例如，如果训练数据中所有关于“苹果”的摘要都将其描述为“电子公司”，模型可能难以正确总结“苹果树”的信息。</li>
<li><strong>欠拟合：</strong> 模型未能充分学习原文和摘要之间的映射关系。这会导致生成的摘要泛泛而谈，或者无法捕捉原文中的关键事实细节。</li>
</ul>
<p>总而言之，忠实度问题是当前深度学习文本摘要模型面临的深层次挑战，它源于模型数据驱动的本质、注意力机制的局限、解码策略的选择以及缺乏真正的语义理解和推理能力。</p>
<h2 id="评估忠实度：挑战与方法">评估忠实度：挑战与方法</h2>
<p>解决了忠实度问题的第一步是能够准确地评估它。然而，相比于流畅性或连贯性，忠实度的评估更加复杂和困难，尤其是在自动化评估方面。</p>
<h3 id="评估的困难性">评估的困难性</h3>
<ol>
<li><strong>主观性与细粒度：</strong> 忠实度往往需要判断生成内容与原文在事实层面是否一致，这需要细致的语义理解和事实核查能力，难以用简单的字符串匹配或统计指标来衡量。</li>
<li><strong>“正确但原文未提及”的困境：</strong> 外源性幻觉可能生成原文未提及但真实存在的信息。虽然这是一种幻觉，但如果信息本身是正确的且不具误导性，其危害程度低于内源性幻觉。自动化评估很难区分“错误的幻觉”和“正确的补充”（当然，摘要应以原文为基础）。</li>
<li><strong>多文本与长文本的挑战：</strong> 对于多源文本摘要（Multi-document Summarization）或极长文本摘要，原文事实的数量庞大且分散，人工或自动化评估的难度呈指数级增长。</li>
<li><strong>事实的复杂性：</strong> 事实不仅仅是实体名称，还包括时间、地点、数量、属性、关系、事件、因果链等。判断这些复杂事实的一致性需要高度复杂的模型。</li>
</ol>
<h3 id="人工评估">人工评估</h3>
<p>人工评估仍然是忠实度评估的“金标准”，因为它能够捕捉机器难以理解的细微语义差别和事实冲突。</p>
<h4 id="人工评估的指标">人工评估的指标</h4>
<p>在进行人工评估时，评估者通常会被要求对摘要的以下方面进行打分：</p>
<ul>
<li><strong>事实准确性 (Factual Accuracy):</strong> 摘要中的所有事实是否与原文一致？是否存在错误、虚构或歪曲的事实？（这是忠实度的核心）</li>
<li><strong>一致性 (Consistency):</strong> 摘要内部的逻辑是否自洽？与原文的整体意义是否一致？</li>
<li><strong>内容覆盖度 (Content Coverage):</strong> 摘要是否涵盖了原文的关键信息？</li>
</ul>
<h4 id="人工评估的局限性">人工评估的局限性</h4>
<ul>
<li><strong>成本高昂：</strong> 需要大量训练有素的标注员，耗时耗力。</li>
<li><strong>主观偏差：</strong> 不同标注员可能对“事实一致”有不同的理解，导致评估结果存在一定的主观性。</li>
<li><strong>效率低下：</strong> 无法用于模型训练的即时反馈或大规模模型的快速迭代。</li>
</ul>
<h3 id="自动化评估指标">自动化评估指标</h3>
<p>为了克服人工评估的局限性，研究者们一直在探索更高效的自动化评估指标。</p>
<h4 id="基于N-gram重叠度">基于N-gram重叠度</h4>
<ul>
<li>
<p><strong>ROUGE (Recall-Oriented Understudy for Gisting Evaluation):</strong> ROUGE系列指标是最常用的摘要评估指标，通过比较生成摘要和参考摘要（通常是人工编写的）之间的N-gram重叠度来衡量质量。</p>
<ul>
<li><strong>ROUGE-N:</strong> 计算生成摘要和参考摘要之间N-gram的重叠度（N=1为unigram，N=2为bigram等）。</li>
<li><strong>ROUGE-L:</strong> 计算最长公共子序列（Longest Common Subsequence, LCS）的长度，能够捕捉句子层面的结构相似性。</li>
<li><strong>ROUGE-S:</strong> 基于跳跃二元组（Skip-bigram）的重叠度，允许中间有跳过词。</li>
</ul>
<p><strong>公式示例 (ROUGE-1 F1-score):</strong></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mo>=</mo><mfrac><mtext>Count of overlapping unigrams</mtext><mtext>Count of unigrams in system summary</mtext></mfrac></mrow><annotation encoding="application/x-tex">P = \frac{\text{Count of overlapping unigrams}}{\text{Count of unigrams in system summary}}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.2519em;vertical-align:-0.8804em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">Count of unigrams in system summary</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">Count of overlapping unigrams</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>R</mi><mo>=</mo><mfrac><mtext>Count of overlapping unigrams</mtext><mtext>Count of unigrams in reference summary</mtext></mfrac></mrow><annotation encoding="application/x-tex">R = \frac{\text{Count of overlapping unigrams}}{\text{Count of unigrams in reference summary}}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.2519em;vertical-align:-0.8804em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">Count of unigrams in reference summary</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord text"><span class="mord">Count of overlapping unigrams</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>F</mi><mn>1</mn><mo>=</mo><mn>2</mn><mo>×</mo><mfrac><mrow><mi>P</mi><mo>×</mo><mi>R</mi></mrow><mrow><mi>P</mi><mo>+</mo><mi>R</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">F1 = 2 \times \frac{P \times R}{P + R}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:2.1297em;vertical-align:-0.7693em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3603em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
</li>
<li>
<p><strong>局限性：</strong> ROUGE系列指标的主要问题是<strong>无法捕捉语义相似性</strong>。它们只关注词汇重叠，这意味着即使摘要完全改变了原文的事实，只要使用了类似的词语，ROUGE分数可能仍然很高。例如，“总统签署了法案”和“总统未签署法案”在ROUGE-1上可能得分很高，但事实完全相反。因此，ROUGE不足以评估忠实度。</p>
</li>
</ul>
<h4 id="基于语义相似度">基于语义相似度</h4>
<p>随着预训练语言模型（PLM）的发展，基于语义嵌入的评估指标开始出现，它们能够更好地捕捉语义层面的相似性。</p>
<ul>
<li>
<p><strong>BERTScore:</strong> 利用BERT模型的词嵌入来计算生成摘要和参考摘要中词语之间的语义相似度，然后进行匹配和聚合。它比ROUGE更能反映语义一致性，因为即使词语不同，只要语义接近，也能获得高分。</p>
<ul>
<li><strong>优势：</strong> 相比ROUGE，更好地捕捉同义词和释义，在语义层面上更鲁棒。</li>
<li><strong>局限性：</strong> 仍然无法直接判断“事实”的一致性。例如，“他买了一辆红色的车”和“他买了一辆蓝色的车”在BERTScore上可能相似度很高，但颜色事实是矛盾的。它仍然无法识别事实性错误或幻觉。</li>
</ul>
</li>
<li>
<p><strong>MoverScore, Brio等：</strong> 都是基于PLM的语义相似度指标，旨在更全面地评估生成文本的质量，但忠实度问题依然是其痛点。</p>
</li>
</ul>
<h4 id="事实性评估-Factuality-Evaluation">事实性评估 (Factuality Evaluation)</h4>
<p>这是目前最前沿、最具挑战性的自动化忠实度评估方法。它试图直接判断摘要中的事实是否与原文一致。</p>
<ol>
<li>
<p><strong>基于问答的评估 (QA-based Metrics):</strong></p>
<ul>
<li><strong>思想：</strong> 将原文和生成的摘要转化为一系列问答对。然后使用一个QA模型从原文中抽取答案，再将生成的摘要中的相同问题与答案进行比对。如果摘要中的答案与原文中的答案一致，则认为该事实是忠实的。</li>
<li><strong>代表工作：</strong> QAEG (Question Answering-based Evaluation of Generated text), FactCC。</li>
<li><strong>流程示意：</strong>
<ol>
<li>从原文中抽取事实三元组或生成问题。</li>
<li>使用QA模型在原文上回答这些问题，得到“黄金答案”。</li>
<li>使用QA模型在生成摘要上回答相同的问题，得到“系统答案”。</li>
<li>比较“黄金答案”和“系统答案”的一致性。</li>
</ol>
</li>
<li><strong>优势：</strong> 直接针对事实进行评估，能够识别具体的幻觉。</li>
<li><strong>局限性：</strong> 依赖于QA模型的性能，如果QA模型本身不完善，评估结果也会受影响。需要生成大量高质量的问答对。</li>
</ul>
</li>
<li>
<p><strong>基于自然语言推理的评估 (NLI-based Metrics):</strong></p>
<ul>
<li><strong>思想：</strong> 将原文的句子（或事实片段）作为前提（Premise），将摘要的句子（或事实片段）作为假设（Hypothesis）。然后使用一个预训练的NLI模型判断两者之间是蕴含（Entailment）、矛盾（Contradiction）还是中立（Neutral）关系。</li>
<li><strong>代表工作：</strong> SummaC, Factual-NLI。</li>
<li><strong>公式/概念：</strong><br>
对于原文中的一个句子 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mrow><mi>s</mi><mi>r</mi><mi>c</mi></mrow></msub></mrow><annotation encoding="application/x-tex">S_{src}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">src</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和摘要中的一个句子 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mrow><mi>s</mi><mi>u</mi><mi>m</mi></mrow></msub></mrow><annotation encoding="application/x-tex">S_{sum}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>：<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mi>L</mi><mi>I</mi><mo stretchy="false">(</mo><msub><mi>S</mi><mrow><mi>s</mi><mi>r</mi><mi>c</mi></mrow></msub><mo separator="true">,</mo><msub><mi>S</mi><mrow><mi>s</mi><mi>u</mi><mi>m</mi></mrow></msub><mo stretchy="false">)</mo><mo>→</mo><mo stretchy="false">{</mo><mtext>Entailment, Contradiction, Neutral</mtext><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">NLI(S_{src}, S_{sum}) \rightarrow \{ \text{Entailment, Contradiction, Neutral} \}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal">L</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">src</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span><span class="mord text"><span class="mord">Entailment, Contradiction, Neutral</span></span><span class="mclose">}</span></span></span></span><br>
如果大部分句子对都是“蕴含”关系，则摘要忠实度高；如果存在“矛盾”，则忠实度低。</li>
<li><strong>优势：</strong> 能够识别原文与摘要之间的逻辑冲突，直接量化忠实度。</li>
<li><strong>局限性：</strong> 依赖于NLI模型的泛化能力。NLI模型在处理复杂的、多跳的、需要外部知识的推理时仍有不足。长文本的句子对组合爆炸，计算量大。</li>
</ul>
</li>
</ol>
<p><strong>概念代码示例（NLI-based Factuality Check）</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 假设我们有一个预训练的NLI模型，例如基于Hugging Face Transformers的</span></span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载NLI模型</span></span><br><span class="line"><span class="comment"># 通常是用于文本蕴含任务的模型，例如 &#x27;facebook/bart-large-mnli&#x27;</span></span><br><span class="line">nli_classifier = pipeline(<span class="string">&quot;zero-shot-classification&quot;</span>, model=<span class="string">&quot;facebook/bart-large-mnli&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">check_fidelity_nli</span>(<span class="params">source_text: <span class="built_in">str</span>, summary_text: <span class="built_in">str</span></span>) -&gt; <span class="built_in">float</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    基于NLI模型检查摘要的忠实度。</span></span><br><span class="line"><span class="string">    简化的示例，实际应用中会更复杂，需要将原文和摘要拆分为更小的语义单元。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 假设将原文和摘要粗略地看作一个前提和一个假设</span></span><br><span class="line">    <span class="comment"># 实际中需要更细粒度的句子或事实抽取</span></span><br><span class="line">    premise = source_text</span><br><span class="line">    hypothesis = summary_text</span><br><span class="line"></span><br><span class="line">    <span class="comment"># NLI标签：蕴含 (entailment), 矛盾 (contradiction), 中立 (neutral)</span></span><br><span class="line">    <span class="comment"># 我们关心的是“矛盾”标签的概率</span></span><br><span class="line">    <span class="comment"># 或者直接定义一个分类问题：是事实一致的吗？ (is_factual), 不是事实一致的吗？ (is_not_factual)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 零样本分类的标签：</span></span><br><span class="line">    candidate_labels = [<span class="string">&quot;蕴含 (entailment)&quot;</span>, <span class="string">&quot;矛盾 (contradiction)&quot;</span>, <span class="string">&quot;中立 (neutral)&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 进行NLI判断</span></span><br><span class="line">    result = nli_classifier(hypothesis, candidate_labels=candidate_labels, hypothesis_template=<span class="string">&quot;The text is &#123;&#125;.&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 找到矛盾标签的概率</span></span><br><span class="line">    contradiction_score = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> label_info <span class="keyword">in</span> result[<span class="string">&#x27;labels&#x27;</span>]:</span><br><span class="line">        <span class="keyword">if</span> label_info == <span class="string">&quot;矛盾 (contradiction)&quot;</span>:</span><br><span class="line">            contradiction_score = result[<span class="string">&#x27;scores&#x27;</span>][result[<span class="string">&#x27;labels&#x27;</span>].index(label_info)]</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">            </span><br><span class="line">    <span class="comment"># 一个简单的忠实度分数：1 - 矛盾概率</span></span><br><span class="line">    <span class="comment"># 分数越高表示越忠实</span></span><br><span class="line">    fidelity_score = <span class="number">1.0</span> - contradiction_score</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 进一步的判断，例如如果蕴含概率远高于矛盾和中立，则忠实</span></span><br><span class="line">    <span class="comment"># if result[&#x27;labels&#x27;][0] == &quot;蕴含 (entailment)&quot; and result[&#x27;scores&#x27;][0] &gt; 0.8:</span></span><br><span class="line">    <span class="comment">#     print(&quot;高度忠实&quot;)</span></span><br><span class="line">    <span class="comment"># elif result[&#x27;labels&#x27;][0] == &quot;矛盾 (contradiction)&quot; and result[&#x27;scores&#x27;][0] &gt; 0.5:</span></span><br><span class="line">    <span class="comment">#     print(&quot;存在事实不符&quot;)</span></span><br><span class="line">    <span class="comment"># else:</span></span><br><span class="line">    <span class="comment">#     print(&quot;中立或难以判断&quot;)</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;NLI判断结果: <span class="subst">&#123;result&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> fidelity_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例用法</span></span><br><span class="line"><span class="comment"># source = &quot;奥巴马于2009年就任美国总统，他是美国第44任总统。&quot;</span></span><br><span class="line"><span class="comment"># summary_faithful = &quot;奥巴马在2009年成为美国第44任总统。&quot;</span></span><br><span class="line"><span class="comment"># summary_hallucinated = &quot;奥巴马于2008年就任美国总统，他是美国第43任总统。&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># print(&quot;\n--- 忠实摘要评估 ---&quot;)</span></span><br><span class="line"><span class="comment"># score_faithful = check_fidelity_nli(source, summary_faithful)</span></span><br><span class="line"><span class="comment"># print(f&quot;忠实摘要的忠实度分数: &#123;score_faithful:.2f&#125;&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># print(&quot;\n--- 幻觉摘要评估 ---&quot;)</span></span><br><span class="line"><span class="comment"># score_hallucinated = check_fidelity_nli(source, summary_hallucinated)</span></span><br><span class="line"><span class="comment"># print(f&quot;幻觉摘要的忠实度分数: &#123;score_hallucinated:.2f&#125;&quot;)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>以上代码只是一个概念性的展示。在实际应用中，需要更复杂的逻辑将原文和摘要分割成细粒度的语义单元（如事实三元组或事件），并对每对单元进行NLI判断，然后聚合结果。此外，NLI模型本身也需要针对事实一致性判断进行微调。</p>
<p>总的来说，自动化忠实度评估仍是一个活跃的研究领域。虽然基于PLM和事实判断的指标比传统指标有了显著进步，但它们距离完美还有很长的路要走，尤其是在处理复杂推理和区分细微语义差异方面。</p>
<h2 id="提升忠实度：前沿技术与策略">提升忠实度：前沿技术与策略</h2>
<p>面对忠实度这一核心挑战，研究者们正在从多个层面积极探索解决方案，包括数据、模型架构和训练策略等。</p>
<h3 id="数据层面">数据层面</h3>
<p>高质量、经过事实核查的数据是解决幻觉问题的基础。</p>
<ol>
<li>
<p><strong>构建事实核查数据集：</strong></p>
<ul>
<li><strong>人工标注：</strong> 投入更多资源，聘请领域专家进行细致的人工标注，确保摘要对的事实一致性。例如，通过众包平台，让多个标注员对同一摘要进行事实性评估，取多数意见。</li>
<li><strong>半自动化构建：</strong> 利用现有知识图谱（如WikiData）和文本（如维基百科），通过信息抽取技术自动构建包含事实和其来源的摘要对。</li>
<li><strong>错误纠正数据集：</strong> 专门收集模型容易产生幻觉的案例，并提供正确版本，用于模型的微调和强化学习。</li>
</ul>
</li>
<li>
<p><strong>数据增强与去噪：</strong></p>
<ul>
<li><strong>噪声过滤：</strong> 开发算法识别并过滤掉训练数据中已知的错误或不一致的摘要对。</li>
<li><strong>事实性数据增强：</strong> 在训练数据中注入更多显式的事实信息，或者通过重写（paraphrasing）来增加事实表达的多样性，同时确保事实的一致性。</li>
<li><strong>反向生成：</strong> 有些方法尝试从摘要反向生成原文，并通过对比原始原文来评估摘要的忠实度，并用这种信号来改进训练。</li>
</ul>
</li>
<li>
<p><strong>引入外部知识库/知识图谱：</strong></p>
<ul>
<li>将结构化的知识图谱（Knowledge Graph, KG）或关系数据库作为辅助信息源。在生成摘要时，模型可以查询这些知识库来验证或补充信息，从而减少幻觉。</li>
<li>通过链接实体到知识库，确保生成的实体信息（如属性、关系）的准确性。</li>
</ul>
</li>
</ol>
<h3 id="模型架构层面">模型架构层面</h3>
<p>针对模型生成忠实度问题的内在机制，研究者们提出了多种创新的模型架构和模块。</p>
<ol>
<li>
<p><strong>检索增强型生成 (Retrieval-Augmented Generation, RAG)：</strong></p>
<ul>
<li><strong>核心思想：</strong> 不让模型完全凭空生成，而是在生成每个词时，允许模型从原文或外部知识库中检索相关的文本片段，然后将这些检索到的信息作为额外的上下文输入到解码器。</li>
<li><strong>工作原理：</strong> 通常包含一个检索器（Retriever）和一个生成器（Generator）。检索器根据当前输入查询相关文档片段，生成器则结合查询和检索到的信息进行生成。</li>
<li><strong>优势：</strong> 大幅减少幻觉，因为生成的内容有明确的来源支撑。特别适用于需要精确事实的领域。</li>
<li><strong>示例：</strong> REALSum、RetriBERT、RAG模型。</li>
<li>P(y|x) = \sum_{z \in \text{retrieved_docs}} P(y|x, z)P(z|x)<br>
其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> 是原文，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span></span></span> 是摘要，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span></span> 是检索到的相关文档片段。</li>
</ul>
</li>
<li>
<p><strong>强化学习 (Reinforcement Learning, RL)：</strong></p>
<ul>
<li><strong>核心思想：</strong> 将摘要生成视为一个序列决策过程。引入忠实度相关的奖励函数（Reward Function），激励模型生成事实一致的摘要。</li>
<li><strong>奖励信号：</strong> 奖励可以来源于：
<ul>
<li>人工标注的忠实度评分。</li>
<li>自动化忠实度评估指标（如NLI-based factuality score）。</li>
<li>外部事实核查模块的反馈。</li>
</ul>
</li>
<li><strong>优势：</strong> 能够让模型通过试错来学习如何规避幻觉，因为它被明确地“告知”哪些行为会导致惩罚。</li>
<li><strong>挑战：</strong> 奖励信号的设计复杂，训练不稳定。</li>
</ul>
</li>
<li>
<p><strong>可控生成 (Controllable Generation)：</strong></p>
<ul>
<li>允许用户或系统在生成摘要时，显式地指定某些关键事实必须包含，或者某些事实必须被避免。</li>
<li>这可以通过在输入中添加控制Token，或在解码过程中引入约束来实现。例如，强制模型生成特定的实体或数值。</li>
</ul>
</li>
<li>
<p><strong>显式事实抽取与融合 (Explicit Fact Extraction and Fusion)：</strong></p>
<ul>
<li><strong>思想：</strong> 将摘要生成分解为两个阶段：
<ol>
<li><strong>事实抽取：</strong> 从原文中识别并抽取关键的事实三元组（Subject-Predicate-Object）或事件。</li>
<li><strong>基于事实的生成：</strong> 将抽取到的结构化事实作为指导信息，输入到生成模型中，使其围绕这些事实进行文本生成。</li>
</ol>
</li>
<li><strong>优势：</strong> 确保生成内容的事实基础，减少模型自由发挥的空间。</li>
<li><strong>挑战：</strong> 事实抽取本身的准确性会影响最终摘要的质量。</li>
</ul>
</li>
<li>
<p><strong>纠错与校正机制：</strong></p>
<ul>
<li>在摘要生成后，引入一个独立的“事实核查器”（Fact Checker）模块。这个模块的任务是识别摘要中的幻觉和事实不符，然后将错误信息反馈给一个修正器（Corrector），由修正器对摘要进行改写。</li>
<li>这个过程可以迭代进行，直到摘要达到可接受的忠实度水平。</li>
</ul>
</li>
</ol>
<h3 id="训练策略层面">训练策略层面</h3>
<p>除了模型架构，训练过程中的一些技巧和策略也能帮助提升忠实度。</p>
<ol>
<li>
<p><strong>多任务学习 (Multi-task Learning)：</strong></p>
<ul>
<li>让模型同时学习摘要任务和另一个辅助任务，如：
<ul>
<li><strong>事实核查：</strong> 训练模型判断一对文本（原文句子-摘要句子）是否事实一致。</li>
<li><strong>问答：</strong> 训练模型从原文中回答关于摘要内容的问题。</li>
</ul>
</li>
<li>通过共享底层表示，辅助任务可以帮助模型更好地理解事实和逻辑关系，从而提升摘要的忠实度。</li>
</ul>
</li>
<li>
<p><strong>对比学习 (Contrastive Learning)：</strong></p>
<ul>
<li>构造正例（忠实摘要-原文）和负例（非忠实摘要-原文）。</li>
<li>通过对比学习，训练模型区分忠实和非忠实的摘要，使模型生成更接近正例的摘要。</li>
<li>负例可以通过人工构造、混淆原文事实、或者从模型早期生成中抽样得到。</li>
</ul>
</li>
<li>
<p><strong>强化忠实度指标作为损失函数：</strong></p>
<ul>
<li>在训练过程中，除了标准的交叉熵损失外，加入与忠实度相关的损失项。例如，使用NLI模型的输出作为惩罚项，如果摘要与原文矛盾，则施加更大的损失。</li>
<li>这使得模型在训练时就直接优化忠实度。</li>
</ul>
</li>
<li>
<p><strong>序列级训练与评估：</strong></p>
<ul>
<li>传统的词级交叉熵损失可能不足以捕捉忠实度。采用序列级的奖励（如ROUGE的强化学习）或更复杂的损失函数，鼓励模型生成整体上更忠实完整的摘要。</li>
</ul>
</li>
</ol>
<h3 id="解释性与可信度">解释性与可信度</h3>
<p>提升忠实度不仅仅是技术问题，也关乎用户体验和信任。</p>
<ol>
<li>
<p><strong>事实来源引用：</strong></p>
<ul>
<li>在生成的摘要中，为每个事实点提供其在原文中的对应引用（如段落或句子编号）。</li>
<li>这不仅增加了摘要的可验证性，也增强了用户的信任感。如果用户对某个事实存疑，可以迅速追溯到原文进行核实。</li>
</ul>
</li>
<li>
<p><strong>不确定性量化：</strong></p>
<ul>
<li>模型可以输出其对生成的事实点“忠实度”的置信度。</li>
<li>例如，用不同的颜色或标记来表示某个句子或事实的准确性得分。当置信度较低时，可以提醒用户谨慎使用，或提供替代的、更保守的表述。</li>
</ul>
</li>
<li>
<p><strong>用户反馈循环：</strong></p>
<ul>
<li>建立用户反馈机制，允许用户标记摘要中的事实性错误。</li>
<li>这些反馈数据可以用于模型的迭代优化和错误分析。</li>
</ul>
</li>
</ol>
<p>总的来说，提升文本摘要的忠实度是一个系统性工程，需要从数据准备、模型架构、训练策略、评估方法等多个维度进行综合考量和创新。这是一个充满挑战但也极具潜力的研究方向，它的突破将直接决定自动文本摘要技术能否真正走向成熟并广泛应用。</p>
<h2 id="结论">结论</h2>
<p>亲爱的读者们，我们今天深入探讨了文本摘要领域中一个至关重要且极具挑战性的问题——忠实度问题。我们了解到，忠实度不仅仅是衡量摘要质量的一个指标，它更是摘要系统能否在实际应用中获得用户信任、避免误导性风险的基石。</p>
<p>从“幻觉”和“事实不符”的具体表现，到其背后深度学习模型固有的数据驱动、注意力缺陷、解码策略和推理能力不足等深层原因，我们剖析了问题的复杂性。同时，我们也看到了忠实度评估的固有难题，以及从传统ROUGE到基于预训练语言模型的语义评估，再到目前最前沿的基于问答和自然语言推理的事实性评估方法的演进。</p>
<p>欣慰的是，随着研究的深入，学术界和工业界正积极探索提升忠实度的有效策略。从高质量数据集的构建，到检索增强型生成（RAG）、强化学习、显式事实抽取等创新模型架构，再到多任务学习、对比学习等训练策略，每一步都在努力弥补模型对事实理解和推理能力的不足。而提供事实来源引用、量化不确定性等增强可信度的措施，也预示着文本摘要技术将更加透明和负责。</p>
<p>尽管取得了显著进展，文本摘要的忠实度问题远未被彻底解决。尤其是在处理复杂、多源、长文本的摘要任务时，如何确保摘要在高度概括的同时丝毫不偏离原文事实，依然是未来研究的核心方向。这需要更强大的模型能够进行深层语义理解、更可靠的外部知识融合，以及更智能的自我纠错机制。</p>
<p>作为技术爱好者，我们应该认识到，任何强大的AI工具都并非完美。理解其局限性，特别是像忠实度这样的“硬伤”，才能更好地使用它，并推动技术的进步。我相信，随着自然语言处理技术的不断演进，我们终将能够构建出既流畅连贯，又高度忠实可靠的文本摘要系统，真正赋能信息时代，让我们更高效、更准确地获取知识。</p>
<p>感谢大家的阅读！如果你对文本摘要的忠实度问题有任何看法或疑问，欢迎在评论区与我交流。我们下次再见！</p>
<hr>
<p>博主: qmwneb946</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a target="_blank" rel="noopener" href="https://github.com/qmwneb946">qmwneb946</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://qmwneb946.dpdns.org/2025/07/24/2025-07-24-115511/">https://qmwneb946.dpdns.org/2025/07/24/2025-07-24-115511/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://opensource.org/licenses/MIT" target="_blank">MIT License</a> 许可协议。转载请注明来源 <a href="https://qmwneb946.dpdns.org" target="_blank">qmwneb946 的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/2025/">2025</a><a class="post-meta__tags" href="/tags/%E6%8A%80%E6%9C%AF/">技术</a><a class="post-meta__tags" href="/tags/%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81%E7%9A%84%E5%BF%A0%E5%AE%9E%E5%BA%A6%E9%97%AE%E9%A2%98/">文本摘要的忠实度问题</a></div><div class="post-share"><div class="social-share" data-image="/img/icon.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/07/24/2025-07-24-115623/" title="深入解析无线光通信的链路预算：从理论到实践"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">深入解析无线光通信的链路预算：从理论到实践</div></div><div class="info-2"><div class="info-item-1">作为一名痴迷于技术与数学的博主 qmwneb946，我始终坚信，理解任何复杂系统，都必须从其核心的量化分析开始。今天，我们将聚焦于一个充满未来感的领域——无线光通信 (Free-Space Optical, FSO)，并深入探讨其系统设计的基石：链路预算 (Link Budget)。 无线光通信，又称自由空间光通信，是一种利用大气作为传输介质，通过激光或LED光束在空中进行数据传输的技术。想象一下，一道无形的“光缆”划破天际，承载着Gbps甚至Tbps的数据流，这不仅是科幻电影中的场景，更是FSO正在实现的现实。然而，与有线光纤不同，FSO系统面临着复杂多变的大气信道挑战。要确保光束能够“翻山越岭”，将数据可靠地从发射端送达接收端，精准的链路预算分析必不可少。 本篇文章将从FSO的基础概念讲起，逐步剖析链路预算的各个组成部分，包括发射功率、自由空间损耗、复杂的大气效应（衰减与湍流）、指向误差，以及接收机灵敏度等。我们将深入理解每一个参数背后的物理原理和数学模型，最终构建出完整的链路预算方程，并探讨如何通过优化设计来提升FSO系统的性能和可靠性。无论你是通信领域的学生、工程师，还是...</div></div></div></a><a class="pagination-related" href="/2025/07/24/2025-07-24-115406/" title="深入探索小样本语义分割：挑战、方法与前沿"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">深入探索小样本语义分割：挑战、方法与前沿</div></div><div class="info-2"><div class="info-item-1">你好，各位技术爱好者！我是 qmwneb946，很高兴再次与大家在技术的海洋中遨游。今天，我们将聚焦一个充满挑战且极具潜力的前沿领域——小样本语义分割（Few-Shot Semantic Segmentation, FSS）。在人工智能，特别是计算机视觉领域，我们常常感叹深度学习模型的强大，它们在海量数据的喂养下展现出惊人的性能。然而，真实世界往往并非如此理想，许多场景下，我们无法获得足够多的标注数据。这正是小样本学习大显身手之地，而将其应用于像素级的精细任务——语义分割，无疑是将挑战推向了新的高度。 本文将带领大家深入剖析小样本语义分割的来龙去脉。我们将从语义分割的基础概念出发，逐步揭示小样本学习的核心思想，探讨小样本语义分割所面临的独特挑战。随后，我们将详细阐述当前主流的解决方案，包括元学习、度量学习、数据增强以及任务自适应等多种范式。文章中还会穿插关键的技术细节、评估指标以及未来研究方向的探讨，希望能为大家构建一个全面而深入的认知框架。系好安全带，让我们一同踏上这场探索之旅吧！ 语义分割基础回顾 在深入小样本语义分割之前，我们有必要回顾一下语义分割的“庐山真面目”。 什么是...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/07/18/2025-07-18-082448/" title="数据挖掘在金融风控的应用：从算法到实践"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">数据挖掘在金融风控的应用：从算法到实践</div></div><div class="info-2"><div class="info-item-1">大家好，我是你们的技术博主，今天我们来深入探讨一个与我们日常生活息息相关，却又充满技术挑战的领域：金融风控。在这个领域中，数据挖掘技术发挥着越来越重要的作用，它帮助金融机构有效识别和管理风险，保障金融体系的稳定运行。本文将从多个角度深入探讨数据挖掘在金融风控中的应用，并结合实际案例进行分析。 数据挖掘在金融风控中的关键作用 金融风控的目标是识别、评估和控制各种金融风险，例如信用风险、欺诈风险、操作风险等。传统的风控方法往往依赖于人工审核和简单的统计模型，效率低、准确率不高。而数据挖掘技术的出现，为金融风控带来了革命性的变革。它能够从海量数据中提取有价值的信息，建立更精确的风险模型，从而提高风控效率和准确性。 具体来说，数据挖掘在金融风控中主要发挥以下作用： 欺诈检测 欺诈行为日益猖獗，给金融机构造成巨大的经济损失。数据挖掘技术，特别是异常检测算法，能够有效识别出可疑交易行为。例如，基于机器学习的异常检测模型可以学习正常交易的模式，然后识别偏离该模式的异常交易，从而有效识别潜在的欺诈行为。常用的算法包括：  孤立森林 (Isolation Forest): 通过随机分割数据来隔离异...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082509/" title="虚拟现实技术的沉浸式体验：从感知到认知"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">虚拟现实技术的沉浸式体验：从感知到认知</div></div><div class="info-2"><div class="info-item-1">虚拟现实（VR）技术不再是科幻小说中的幻想，它已经逐渐融入我们的生活，并正在深刻地改变着我们与世界互动的方式。本文将深入探讨VR技术的沉浸式体验，从技术原理到感知机制，再到其潜在的应用和未来发展方向，为技术爱好者提供一个全面的视角。 沉浸式体验的奥秘：技术层面 VR技术能够创造出令人信服的沉浸式体验，这依赖于多项关键技术的协同作用。 显示技术与图像渲染 高质量的图像渲染是VR体验的关键。高分辨率、高刷新率的显示器能够有效减少画面延迟和模糊感，提升视觉舒适度。目前主流的VR头显大多采用OLED或LCD屏幕，并通过透镜系统将图像投射到用户的视网膜上，模拟真实世界的视觉体验。  为了实现更广阔的视野（FOV），厂商们也在不断改进透镜设计和显示面板技术。 空间音频技术 除了视觉，听觉在构建沉浸式环境中也扮演着至关重要的角色。空间音频技术通过模拟声音在三维空间中的传播，让用户能够准确感知声音的方位和距离，增强临场感。例如，头部追踪技术配合精密的算法，可以根据用户头部姿态实时调整声音的输出，使声音效果更加逼真。 追踪技术与交互方式 精确的追踪技术是VR体验流畅的关键。目前常用的追踪技术包括：...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082730/" title="有机合成中的手性催化技术：构建分子世界的精巧艺术"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">有机合成中的手性催化技术：构建分子世界的精巧艺术</div></div><div class="info-2"><div class="info-item-1">有机合成，这门将简单的化学物质转化为复杂分子的艺术，正因手性分子的存在而变得更加精妙和挑战性。手性分子如同左右手一样，结构互为镜像，但性质却可能大相径庭。在药物研发、材料科学等领域，获得特定手性的分子至关重要，而手性催化技术正是实现这一目标的关键。本文将深入探讨有机合成中的手性催化技术，揭示其背后的原理和应用。 手性与手性催化：从镜像到精准控制 手性，源于希腊语“cheir”（手），指的是分子不能与其镜像重合的特性。这种结构差异导致手性分子具有不同的物理性质和生物活性。例如，一种药物的左旋体可能具有疗效，而其右旋体则可能无效甚至有害。因此，精准控制手性合成至关重要。 手性催化技术利用手性催化剂来控制反应的立体选择性，即优先生成特定手性的产物。催化剂本身是手性的，它通过与反应物形成短暂的超分子复合物，影响反应路径，从而引导反应朝特定立体异构体方向进行。这就好比一个熟练的工匠，用巧妙的手法引导反应物“组装”成预期的分子结构。 手性催化剂的类型及作用机制 目前，广泛应用的手性催化剂主要包括： 过渡金属配合物催化剂 这类催化剂通常含有手性配体与过渡金属中心（如铑、钌、钯等）结合而成。配体...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082852/" title="光谱分析技术在环境监测的应用：从原理到实践"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">光谱分析技术在环境监测的应用：从原理到实践</div></div><div class="info-2"><div class="info-item-1">大家好，我是你们的技术博主 DataWhisperer！今天我们来聊一个既高大上又贴近生活的技术领域：光谱分析技术在环境监测中的应用。  这可不是简单的“看看颜色”就能搞定的，它背后蕴含着丰富的物理学、化学和数学原理，并且在保护我们的环境方面发挥着越来越重要的作用。 引言：光谱分析 – 环境监测的“火眼金睛” 环境监测的目标是及时、准确地获取环境污染物的信息，为环境保护和管理提供科学依据。传统监测方法往往费时费力，且灵敏度有限。而光谱分析技术，凭借其快速、灵敏、多组分同时检测等优点，成为了环境监测领域的一匹黑马。  它利用物质与电磁辐射相互作用的特性，分析物质的成分和结构，从而实现对环境污染物的精准识别和定量分析。 光谱分析技术的种类及原理 光谱分析技术涵盖多种方法，根据所用电磁波的波长范围不同，可以分为： 紫外-可见光谱法 (UV-Vis) UV-Vis 光谱法利用物质对紫外和可见光区域电磁波的吸收特性进行分析。  不同物质具有独特的吸收光谱，通过测量吸收光谱的特征峰，可以确定物质的种类和浓度。  这在水质监测中应用广泛，例如检测重金属离子、有机污染物等。  其原理基于朗伯-比...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082903/" title="计算化学模拟分子间相互作用：从经典力场到量子力学"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">计算化学模拟分子间相互作用：从经典力场到量子力学</div></div><div class="info-2"><div class="info-item-1">引言 分子间相互作用是化学和生物学领域的核心概念，它支配着物质的物理和化学性质，例如溶解度、沸点、蛋白质折叠等等。精确地模拟这些相互作用对于理解和预测分子行为至关重要。计算化学为我们提供了一套强大的工具来研究分子间相互作用，从经典的力场方法到复杂的量子力学计算，本文将深入探讨这些方法及其应用。 经典力场方法 经典力场方法基于牛顿力学，将分子简化为一系列原子，并通过经验参数化的势能函数来描述原子间的相互作用。这种方法计算效率高，适用于模拟大量的原子和分子，例如蛋白质、DNA和材料科学中的大分子体系。 势能函数 经典力场通常包含以下几种类型的相互作用项：  键伸缩 (Bond Stretching): 描述键长偏离平衡键长的能量变化，通常用谐振势能函数表示：Ebond=12kb(r−r0)2E_{bond} = \frac{1}{2}k_b(r - r_0)^2Ebond​=21​kb​(r−r0​)2，其中 kbk_bkb​ 是力常数，rrr 是键长，r0r_0r0​ 是平衡键长。 键角弯曲 (Angle Bending): 描述键角偏离平衡键角的能量变化，通常也用谐振势能函数表示...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082912/" title="绿色化学与可持续发展目标：技术与未来的融合"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">绿色化学与可持续发展目标：技术与未来的融合</div></div><div class="info-2"><div class="info-item-1">近年来，可持续发展已成为全球关注的焦点，联合国提出的17个可持续发展目标 (SDGs) 为全球共同努力提供了蓝图。其中，许多目标都与化学工业息息相关，而绿色化学作为一种旨在减少或消除有害物质使用的化学方法，扮演着至关重要的角色。本文将探讨绿色化学如何为实现可持续发展目标做出贡献，并从技术角度深入分析其应用。 绿色化学的十二原则：通向可持续未来的基石 绿色化学的核心是其十二项原则，这些原则指导着化学家的研究和工业生产，力求最大限度地减少环境影响。这些原则并非相互独立，而是相互关联，共同构成了一个整体的框架。 预防原则 这是绿色化学的首要原则，强调在化学反应的设计阶段就应避免产生有害物质，而非在产生后进行处理。这需要化学家们从根本上重新思考化学反应的设计和工艺流程。 原子经济性 理想情况下，所有反应物原子都应转化为最终产物，没有任何浪费。原子经济性是衡量化学反应效率的重要指标，其计算公式为： 原子经济性=目标产物的分子量所有反应物的分子量总和×100%原子经济性 = \frac{目标产物的分子量}{所有反应物的分子量总和} \times 100\%原子经济性=所有反应物的分子量总和目...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">qmwneb946</div><div class="author-info-description">一个专注于技术分享的个人博客，涵盖编程、算法、系统设计等内容</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">1347</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">1351</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/qmwneb946"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/qmwneb946" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:qmwneb946@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">代码与远方，技术与生活交织的篇章。</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BF%A0%E5%AE%9E%E5%BA%A6%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%E5%AE%9A%E4%B9%89%E4%B8%8E%E9%87%8D%E8%A6%81%E6%80%A7"><span class="toc-number">1.</span> <span class="toc-text">忠实度是什么？定义与重要性</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BF%A0%E5%AE%9E%E5%BA%A6%E7%9A%84%E6%A0%B8%E5%BF%83%E5%AE%9A%E4%B9%89"><span class="toc-number">1.1.</span> <span class="toc-text">忠实度的核心定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BF%A0%E5%AE%9E%E5%BA%A6%E4%B8%BA%E4%BD%95%E5%A6%82%E6%AD%A4%E5%85%B3%E9%94%AE%EF%BC%9F"><span class="toc-number">1.2.</span> <span class="toc-text">忠实度为何如此关键？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BF%A0%E5%AE%9E%E5%BA%A6%E9%97%AE%E9%A2%98%E7%9A%84%E5%85%B7%E4%BD%93%E8%A1%A8%E7%8E%B0%EF%BC%9A%E5%B9%BB%E8%A7%89%E4%B8%8E%E4%BA%8B%E5%AE%9E%E4%B8%8D%E7%AC%A6"><span class="toc-number">2.</span> <span class="toc-text">忠实度问题的具体表现：幻觉与事实不符</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B9%BB%E8%A7%89-Hallucinations"><span class="toc-number">2.1.</span> <span class="toc-text">幻觉 (Hallucinations)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B9%BB%E8%A7%89%E7%9A%84%E5%AE%9A%E4%B9%89"><span class="toc-number">2.1.1.</span> <span class="toc-text">幻觉的定义</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B9%BB%E8%A7%89%E7%9A%84%E5%88%86%E7%B1%BB"><span class="toc-number">2.1.2.</span> <span class="toc-text">幻觉的分类</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8B%E5%AE%9E%E4%B8%8D%E7%AC%A6-Factual-Inconsistencies"><span class="toc-number">2.2.</span> <span class="toc-text">事实不符 (Factual Inconsistencies)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%8B%E5%AE%9E%E4%B8%8D%E7%AC%A6%E7%9A%84%E5%AE%9A%E4%B9%89"><span class="toc-number">2.2.1.</span> <span class="toc-text">事实不符的定义</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%8B%E5%AE%9E%E4%B8%8D%E7%AC%A6%E7%9A%84%E4%BE%8B%E5%AD%90"><span class="toc-number">2.2.2.</span> <span class="toc-text">事实不符的例子</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BF%A0%E5%AE%9E%E5%BA%A6%E9%97%AE%E9%A2%98%E7%9A%84%E6%88%90%E5%9B%A0%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B1%80%E9%99%90%E6%80%A7"><span class="toc-number">3.</span> <span class="toc-text">忠实度问题的成因：深度学习模型的局限性</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%A9%B1%E5%8A%A8%E7%9A%84%E6%9C%AC%E8%B4%A8%E4%B8%8E%E5%81%8F%E5%B7%AE"><span class="toc-number">3.1.</span> <span class="toc-text">数据驱动的本质与偏差</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E4%B8%AD%E7%9A%84%E5%99%AA%E5%A3%B0%E4%B8%8E%E5%81%8F%E5%B7%AE"><span class="toc-number">3.1.1.</span> <span class="toc-text">训练数据中的噪声与偏差</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E7%9A%84%E7%BC%BA%E9%99%B7"><span class="toc-number">3.2.</span> <span class="toc-text">注意力机制的缺陷</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E7%A0%81%E7%AD%96%E7%95%A5%E7%9A%84%E6%8E%A2%E7%B4%A2%E6%80%A7"><span class="toc-number">3.3.</span> <span class="toc-text">解码策略的探索性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9F%A5%E8%AF%86%E5%A4%96%E5%8C%96%E4%B8%8E%E6%8E%A8%E7%90%86%E8%83%BD%E5%8A%9B%E7%9A%84%E7%BC%BA%E4%B9%8F"><span class="toc-number">3.4.</span> <span class="toc-text">知识外化与推理能力的缺乏</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%87%E6%8B%9F%E5%90%88%E4%B8%8E%E6%AC%A0%E6%8B%9F%E5%90%88"><span class="toc-number">3.5.</span> <span class="toc-text">过拟合与欠拟合</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%84%E4%BC%B0%E5%BF%A0%E5%AE%9E%E5%BA%A6%EF%BC%9A%E6%8C%91%E6%88%98%E4%B8%8E%E6%96%B9%E6%B3%95"><span class="toc-number">4.</span> <span class="toc-text">评估忠实度：挑战与方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%84%E4%BC%B0%E7%9A%84%E5%9B%B0%E9%9A%BE%E6%80%A7"><span class="toc-number">4.1.</span> <span class="toc-text">评估的困难性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%BA%E5%B7%A5%E8%AF%84%E4%BC%B0"><span class="toc-number">4.2.</span> <span class="toc-text">人工评估</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%BA%E5%B7%A5%E8%AF%84%E4%BC%B0%E7%9A%84%E6%8C%87%E6%A0%87"><span class="toc-number">4.2.1.</span> <span class="toc-text">人工评估的指标</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%BA%E5%B7%A5%E8%AF%84%E4%BC%B0%E7%9A%84%E5%B1%80%E9%99%90%E6%80%A7"><span class="toc-number">4.2.2.</span> <span class="toc-text">人工评估的局限性</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E5%8A%A8%E5%8C%96%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87"><span class="toc-number">4.3.</span> <span class="toc-text">自动化评估指标</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8EN-gram%E9%87%8D%E5%8F%A0%E5%BA%A6"><span class="toc-number">4.3.1.</span> <span class="toc-text">基于N-gram重叠度</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E8%AF%AD%E4%B9%89%E7%9B%B8%E4%BC%BC%E5%BA%A6"><span class="toc-number">4.3.2.</span> <span class="toc-text">基于语义相似度</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%8B%E5%AE%9E%E6%80%A7%E8%AF%84%E4%BC%B0-Factuality-Evaluation"><span class="toc-number">4.3.3.</span> <span class="toc-text">事实性评估 (Factuality Evaluation)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8F%90%E5%8D%87%E5%BF%A0%E5%AE%9E%E5%BA%A6%EF%BC%9A%E5%89%8D%E6%B2%BF%E6%8A%80%E6%9C%AF%E4%B8%8E%E7%AD%96%E7%95%A5"><span class="toc-number">5.</span> <span class="toc-text">提升忠实度：前沿技术与策略</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%B1%82%E9%9D%A2"><span class="toc-number">5.1.</span> <span class="toc-text">数据层面</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84%E5%B1%82%E9%9D%A2"><span class="toc-number">5.2.</span> <span class="toc-text">模型架构层面</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5%E5%B1%82%E9%9D%A2"><span class="toc-number">5.3.</span> <span class="toc-text">训练策略层面</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A3%E9%87%8A%E6%80%A7%E4%B8%8E%E5%8F%AF%E4%BF%A1%E5%BA%A6"><span class="toc-number">5.4.</span> <span class="toc-text">解释性与可信度</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA"><span class="toc-number">6.</span> <span class="toc-text">结论</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/26/hello-world/" title="Hello World">Hello World</a><time datetime="2025-07-26T07:43:24.714Z" title="发表于 2025-07-26 15:43:24">2025-07-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/26/%E5%8D%9A%E5%BC%88%E8%AE%BA%E5%9F%BA%E7%A1%80/" title="博弈论基础">博弈论基础</a><time datetime="2025-07-26T07:43:24.714Z" title="发表于 2025-07-26 15:43:24">2025-07-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/25/2025-07-26-074018/" title="微生物的代谢多样性：生命基石的无限变奏">微生物的代谢多样性：生命基石的无限变奏</a><time datetime="2025-07-25T23:40:18.000Z" title="发表于 2025-07-26 07:40:18">2025-07-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/25/2025-07-26-073926/" title="免疫系统的记忆与遗忘：生命演化中的信息管理与权衡">免疫系统的记忆与遗忘：生命演化中的信息管理与权衡</a><time datetime="2025-07-25T23:39:26.000Z" title="发表于 2025-07-26 07:39:26">2025-07-26</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/25/2025-07-26-073836/" title="决策的神经经济学：从理性模型到大脑深层机制的探索">决策的神经经济学：从理性模型到大脑深层机制的探索</a><time datetime="2025-07-25T23:38:36.000Z" title="发表于 2025-07-26 07:38:36">2025-07-26</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;2025 By qmwneb946</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.2</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css')
    if (true) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const getGiscusTheme = theme => theme === 'dark' ? 'dark' : 'light'

  const createScriptElement = config => {
    const ele = document.createElement('script')
    Object.entries(config).forEach(([key, value]) => {
      ele.setAttribute(key, value)
    })
    return ele
  }

  const loadGiscus = (el = document, key) => {
    const mappingConfig = isShuoshuo
      ? { 'data-mapping': 'specific', 'data-term': key }
      : { 'data-mapping': (option && option['data-mapping']) || 'pathname' }

    const giscusConfig = {
      src: 'https://giscus.app/client.js',
      'data-repo': 'qmwneb946/blog',
      'data-repo-id': 'R_kgDOPM6cWw',
      'data-category-id': 'DIC_kwDOPM6cW84CtEzo',
      'data-theme': getGiscusTheme(document.documentElement.getAttribute('data-theme')),
      'data-reactions-enabled': '1',
      crossorigin: 'anonymous',
      async: true,
      ...option,
      ...mappingConfig
    }

    const scriptElement = createScriptElement(giscusConfig)

    el.querySelector('#giscus-wrap').appendChild(scriptElement)

    if (isShuoshuo) {
      window.shuoshuoComment.destroyGiscus = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }
  }

  const changeGiscusTheme = theme => {
    const iframe = document.querySelector('#giscus-wrap iframe')
    if (iframe) {
      const message = {
        giscus: {
          setConfig: {
            theme: getGiscusTheme(theme)
          }
        }
      }
      iframe.contentWindow.postMessage(message, 'https://giscus.app')
    }
  }

  btf.addGlobalFn('themeChange', changeGiscusTheme, 'giscus')

  if (isShuoshuo) {
    'Giscus' === 'Giscus'
      ? window.shuoshuoComment = { loadComment: loadGiscus }
      : window.loadOtherComment = loadGiscus
    return
  }

  if ('Giscus' === 'Giscus' || !false) {
    if (false) btf.loadComment(document.getElementById('giscus-wrap'), loadGiscus)
    else loadGiscus()
  } else {
    window.loadOtherComment = loadGiscus
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>