<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>永不止步的探索：持续学习与灾难性遗忘的挑战与机遇 | qmwneb946 的博客</title><meta name="author" content="qmwneb946"><meta name="copyright" content="qmwneb946"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="你好，各位技术爱好者！我是 qmwneb946，今天我们一起深入探讨一个关于人工智能未来的核心议题：持续学习（Continual Learning，或称 Incremental Learning）以及它所面临的最大挑战——灾难性遗忘（Catastrophic Forgetting）。 设想一下，一个人工智能系统能够像人类一样，在日常经验中不断学习新技能、新知识，同时又不忘却过去所学。它可以在工厂中">
<meta property="og:type" content="article">
<meta property="og:title" content="永不止步的探索：持续学习与灾难性遗忘的挑战与机遇">
<meta property="og:url" content="https://qmwneb946.dpdns.org/2025/07/22/2025-07-22-222136/index.html">
<meta property="og:site_name" content="qmwneb946 的博客">
<meta property="og:description" content="你好，各位技术爱好者！我是 qmwneb946，今天我们一起深入探讨一个关于人工智能未来的核心议题：持续学习（Continual Learning，或称 Incremental Learning）以及它所面临的最大挑战——灾难性遗忘（Catastrophic Forgetting）。 设想一下，一个人工智能系统能够像人类一样，在日常经验中不断学习新技能、新知识，同时又不忘却过去所学。它可以在工厂中">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://qmwneb946.dpdns.org/img/icon.png">
<meta property="article:published_time" content="2025-07-22T14:21:36.000Z">
<meta property="article:modified_time" content="2025-07-22T22:25:12.343Z">
<meta property="article:author" content="qmwneb946">
<meta property="article:tag" content="2025">
<meta property="article:tag" content="数学">
<meta property="article:tag" content="持续学习与灾难性遗忘">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://qmwneb946.dpdns.org/img/icon.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "永不止步的探索：持续学习与灾难性遗忘的挑战与机遇",
  "url": "https://qmwneb946.dpdns.org/2025/07/22/2025-07-22-222136/",
  "image": "https://qmwneb946.dpdns.org/img/icon.png",
  "datePublished": "2025-07-22T14:21:36.000Z",
  "dateModified": "2025-07-22T22:25:12.343Z",
  "author": [
    {
      "@type": "Person",
      "name": "qmwneb946",
      "url": "https://github.com/qmwneb946"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://qmwneb946.dpdns.org/2025/07/22/2025-07-22-222136/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '永不止步的探索：持续学习与灾难性遗忘的挑战与机遇',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2845632165165414" crossorigin="anonymous"></script><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="qmwneb946 的博客" type="application/atom+xml">
</head><body><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">qmwneb946 的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">永不止步的探索：持续学习与灾难性遗忘的挑战与机遇</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">永不止步的探索：持续学习与灾难性遗忘的挑战与机遇<a class="post-edit-link" href="https://github.com/qmwneb946/blog/edit/main/source/_posts/2025-07-22-222136.md" title="编辑" target="_blank"><i class="fas fa-pencil-alt"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-07-22T14:21:36.000Z" title="发表于 2025-07-22 22:21:36">2025-07-22</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-07-22T22:25:12.343Z" title="更新于 2025-07-23 06:25:12">2025-07-23</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%95%B0%E5%AD%A6/">数学</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><p>你好，各位技术爱好者！我是 qmwneb946，今天我们一起深入探讨一个关于人工智能未来的核心议题：持续学习（Continual Learning，或称 Incremental Learning）以及它所面临的最大挑战——灾难性遗忘（Catastrophic Forgetting）。</p>
<p>设想一下，一个人工智能系统能够像人类一样，在日常经验中不断学习新技能、新知识，同时又不忘却过去所学。它可以在工厂中学习新的生产流程，在医院里掌握最新的疾病诊断标准，或者在自动驾驶汽车中适应不断变化的交通规则。这听起来是不是很令人兴奋？这正是持续学习所描绘的未来愿景。然而，与人类大脑的奇妙适应性形成鲜明对比的是，当前的深度学习模型往往“健忘”得惊人：在学习新任务时，它们会迅速且彻底地遗忘之前所掌握的知识。这种现象，正是我们今天要聚焦的“灾难性遗忘”。</p>
<p>传统的机器学习模型通常采用离线训练范式：收集大量数据，一次性训练模型，然后部署。一旦数据分布发生变化或出现新任务，我们就需要从头开始或在旧数据和新数据上共同微调模型。这种方式在很多场景下是不可持续的：数据可能无限增长，旧数据可能因隐私或存储限制而无法访问，而且每次从头训练都耗时巨大且计算资源开销惊人。持续学习正是为了打破这种僵局而生，旨在让AI系统具备像生命体一样“在流中学习”的能力。</p>
<p>在这篇文章中，我们将一起：</p>
<ul>
<li>深入理解持续学习的定义、必要性及不同范式。</li>
<li>揭示灾难性遗忘的本质、其背后的机制及为何它是持续学习的“阿喀琉斯之踵”。</li>
<li>探索当前学界与业界为克服灾难性遗忘所提出的各类创新策略，包括基于回放、正则化、架构调整等多种技术路径。</li>
<li>讨论如何科学地评估持续学习模型的性能。</li>
<li>展望持续学习在各个领域的广阔应用前景。</li>
</ul>
<p>准备好了吗？让我们一同踏上这段充满挑战与机遇的探索之旅。</p>
<h2 id="什么是持续学习？">什么是持续学习？</h2>
<p>持续学习，顾名思义，是指机器学习模型在面对连续不断的数据流时，能够逐步地、增量地学习新知识、新任务，同时有效地保留或利用之前学到的知识的能力。它旨在模拟人类智能的渐进式学习过程，是构建真正智能和自适应AI系统的关键一步。</p>
<h3 id="定义与愿景">定义与愿景</h3>
<p>从狭义上讲，持续学习是让模型能够在没有访问旧任务数据的情况下，学习一系列新任务，并保持在新旧任务上的高性能。从广义上讲，它更是通往通用人工智能（Artificial General Intelligence, AGI）的必经之路。</p>
<p><strong>核心愿景：</strong></p>
<ul>
<li><strong>终身学习 (Lifelong Learning)：</strong> 模型能够在其整个生命周期中持续学习和进化，无需停机或频繁重置。</li>
<li><strong>自适应性 (Adaptability)：</strong> 模型能够动态地适应不断变化的环境、新的数据模式和任务需求。</li>
<li><strong>资源效率 (Resource Efficiency)：</strong> 避免每次更新都进行大规模的重训练，节省计算资源和时间。</li>
</ul>
<p>持续学习的目标是构建一个能够不断积累知识、自我完善的AI实体，而非当前“训练-部署-过时-重训”的静态模式。</p>
<h3 id="持续学习的必要性">持续学习的必要性</h3>
<p>为什么持续学习在当前AI时代变得如此重要？</p>
<ul>
<li><strong>动态的现实世界：</strong> 我们所处的物理世界和数字世界都在不断变化。新的概念、新的趋势、新的威胁层出不穷。传统的静态模型部署后很快就会因为数据分布漂移（Data Drift）而性能下降。</li>
<li><strong>数据流的无限性：</strong> 真实世界的数据是连续不断生成的，例如摄像头捕获的图像、传感器读数、用户交互日志等。我们无法将所有数据一次性收集并训练。</li>
<li><strong>部署后模型的维护：</strong> 一旦AI系统投入实际使用，通常很难回溯到原始训练环境进行大规模修改。持续学习允许模型在部署后直接通过新的数据进行在线更新。</li>
<li><strong>隐私与存储限制：</strong> 在许多应用中，旧数据可能因隐私法规（如GDPR）或存储成本而无法长时间保留。持续学习可以在不依赖完整历史数据的情况下进行知识更新。</li>
<li><strong>走向AGI的阶梯：</strong> 如果AI要真正具备通用智能，它必须能够像人类一样，通过经验的积累和迭代来持续提升认知能力，而非简单地重复学习或重新启动。</li>
</ul>
<h3 id="持续学习的范式">持续学习的范式</h3>
<p>根据学习任务的粒度、数据可用性以及任务边界的定义，持续学习可以分为几种不同的范式：</p>
<h4 id="任务增量学习-Task-Incremental-Learning">任务增量学习 (Task Incremental Learning)</h4>
<p>这是最常见和研究最深入的范式。在这种设置下，模型一次只学习一个新任务，并且在学习每个任务时，模型知道当前正在学习的是哪个任务（例如，通过任务ID），并且在测试时也知道要测试的是哪个任务。旧任务的数据在学习新任务时通常是不可访问的。</p>
<ul>
<li><strong>特点：</strong> 任务边界明确，测试时任务信息已知。</li>
<li><strong>例子：</strong> 训练一个模型首先识别猫狗，然后学习识别鸟类和鱼类，之后再学习识别汽车。</li>
</ul>
<h4 id="域增量学习-Domain-Incremental-Learning">域增量学习 (Domain Incremental Learning)</h4>
<p>在这种范式下，任务保持不变（例如，始终是图像分类），但数据分布（域）随时间变化。模型需要适应新的数据领域，同时在旧领域上保持性能。</p>
<ul>
<li><strong>特点：</strong> 任务固定，数据分布变化。</li>
<li><strong>例子：</strong> 模型最初在晴天驾驶场景数据上训练，然后需要适应雨天、雾天或雪天等不同天气条件下的驾驶场景。</li>
</ul>
<h4 id="类增量学习-Class-Incremental-Learning">类增量学习 (Class Incremental Learning)</h4>
<p>这是比任务增量学习更具挑战性的范式。在每次增量学习中，模型会遇到新的类别，但它在训练和测试时并不知道当前是哪个任务或新旧类别。这意味着模型需要区分所有历史学习过的类别。</p>
<ul>
<li><strong>特点：</strong> 类别是增量的，任务边界不明确（在测试时，所有已学类别都在一个统一的任务下）。</li>
<li><strong>例子：</strong> 模型首先学习识别数字0-4，然后学习识别数字5-9。在测试时，模型需要识别0-9中的任何数字，且不知道数字是属于“0-4”任务还是“5-9”任务。这种范式下灾难性遗忘的问题尤为突出。</li>
</ul>
<h4 id="流式学习-Stream-Learning">流式学习 (Stream Learning)</h4>
<p>这是最接近真实世界场景的范式。数据以连续的、无边界的流形式到达，任务也可能随时间动态出现或变化。模型需要在线学习，并且只能访问当前数据点，不能对整个历史数据进行批处理。</p>
<ul>
<li><strong>特点：</strong> 数据连续到达，通常无法进行多次遍历，任务边界模糊，对计算和内存效率要求极高。</li>
<li><strong>例子：</strong> 推荐系统实时更新用户偏好，或网络入侵检测系统不断适应新的攻击模式。</li>
</ul>
<p>理解这些范式有助于我们更好地把握持续学习所面临的具体挑战和解决方案的适用性。</p>
<h2 id="灾难性遗忘：持续学习的阿喀琉斯之踵">灾难性遗忘：持续学习的阿喀琉斯之踵</h2>
<p>“灾难性遗忘”（Catastrophic Forgetting），又称“灾难性干扰”（Catastrophic Interference），是持续学习领域最核心、最难以克服的挑战。它形象地描述了当前深度学习模型在学习新知识时，迅速且彻底地遗忘旧知识的现象。这就像一个学生，每次学新课本，就会把之前所有课本的内容忘得一干二净。</p>
<h3 id="什么是灾难性遗忘？">什么是灾难性遗忘？</h3>
<p>灾难性遗忘是指一个神经网络模型在顺序学习多个任务时，在学习新任务的过程中，对旧任务的性能会急剧下降，甚至完全丧失。这种现象首次在20世纪80年代末期，当研究者试图让神经网络连续学习时被观察到。</p>
<p><strong>一个简单的例子：</strong><br>
假设我们有一个图像分类模型。</p>
<ol>
<li><strong>任务 A：</strong> 学习区分“猫”和“狗”。模型训练得很好，准确率很高。</li>
<li><strong>任务 B：</strong> 学习区分“鸟”和“鱼”。我们用任务B的数据在之前模型的参数基础上继续训练。</li>
<li><strong>结果：</strong> 模型现在可以很好地区分“鸟”和“鱼”，但当你再次给它看“猫”和“狗”的图片时，它的识别能力可能已经变得非常糟糕，甚至完全无法区分。</li>
</ol>
<p>这就是灾难性遗忘。模型在学习任务B时，其内部权重被严重修改，以至于服务于任务A的知识被“冲刷”掉了。</p>
<h3 id="灾难性遗忘的机制分析">灾难性遗忘的机制分析</h3>
<p>要解决灾难性遗忘，我们首先需要理解它为什么会发生。深度神经网络的特性是导致灾难性遗忘的根本原因。</p>
<h4 id="权重扰动-Weight-Perturbation">权重扰动 (Weight Perturbation)</h4>
<p>深度学习模型的核心是其大量的可训练参数（权重和偏置）。这些参数以复杂的方式编码了从训练数据中学习到的知识。当模型学习一个新任务时，其优化器（如梯度下降）会根据新任务的损失函数调整这些参数。</p>
<ul>
<li><strong>机制：</strong> 新任务的优化目标往往会驱动模型参数向一个新的状态移动，这个新状态可能与旧任务所需的参数状态显著不同。即使两个任务在概念上不冲突，参数的微小改变也可能对旧任务的性能产生巨大影响。</li>
<li><strong>直观理解：</strong> 想象一个复杂的锁，每个拨盘（参数）都必须在正确的位置（旧知识）才能打开。学习新知识就像重新调整了所有拨盘，结果旧的锁就打不开了。</li>
</ul>
<h4 id="表示漂移-Representation-Drift">表示漂移 (Representation Drift)</h4>
<p>深度神经网络通过逐层提取特征来构建高层抽象表示。例如，在图像分类任务中，底层可能提取边缘和纹理，中层提取形状和部件，高层则形成概念性的特征。</p>
<ul>
<li><strong>机制：</strong> 当模型在学习新任务时，它会调整其内部的特征提取器，以更好地服务于新任务的分类或回归目标。这种调整可能导致模型为旧任务学到的最优特征表示发生“漂移”或变得不那么有效。例如，一个特征提取器原来能很好地区分猫狗的毛发和体型特征，但在学习鸟类和鱼类的翅膀和鳞片特征后，可能就不再能很好地提取猫狗的辨别性特征了。</li>
<li><strong>直观理解：</strong> 学习新语言时，你可能不自觉地改变了母语的发音习惯，导致说母语时发音不那么标准了。</li>
</ul>
<h4 id="数据分布偏移-Data-Distribution-Shift">数据分布偏移 (Data Distribution Shift)</h4>
<p>持续学习的一个核心挑战是，每次学习新任务时，所接触到的数据分布与之前任务的数据分布是不同的。</p>
<ul>
<li><strong>机制：</strong> 传统深度学习假设训练数据是独立同分布（IID）的。然而，在持续学习中，这种假设被打破。模型在<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">T_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>上训练，然后在<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">T_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>上训练，这时模型只接触<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">T_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的数据。优化器试图在<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">T_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的数据分布上找到最优解，而不会考虑到<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">T_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>的数据分布。这使得模型在<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">T_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>上的泛化能力受损。</li>
<li><strong>直观理解：</strong> 你在一个说法语的国家学会了如何点餐，然后去了说德语的国家。当你需要再次点餐时，你的大脑会优先激活德语模式，而不是法语模式，甚至可能影响你回想法语词汇的能力。</li>
</ul>
<h4 id="神经元活性变化-Neuron-Activity-Changes">神经元活性变化 (Neuron Activity Changes)</h4>
<p>在神经网络中，特定的神经元或神经元组可能在处理特定任务或识别特定模式时扮演关键角色。</p>
<ul>
<li><strong>机制：</strong> 当学习新任务时，为了适应新的特征和决策边界，这些关键神经元的激活模式或其在网络中的功能可能会被重分配，从而服务于新任务。这可能导致它们对旧任务的响应变得不那么准确或被完全抑制。</li>
<li><strong>直观理解：</strong> 你的大脑中有一组神经元专门负责识别你爱人的面孔。如果突然要求这组神经元去识别成千上万种新的图案，它们可能会失去对你爱人面孔的敏感性。</li>
</ul>
<p>综上所述，灾难性遗忘是深度神经网络“可塑性与稳定性困境”的体现：网络需要足够的可塑性来学习新知识，但又需要足够的稳定性来保留旧知识。在持续学习中，找到这个平衡点是关键。</p>
<h2 id="应对灾难性遗忘的策略">应对灾难性遗忘的策略</h2>
<p>为了解决灾难性遗忘问题，研究者们提出了多种多样的策略。这些方法可以大致分为几大类，每种都有其独特的思想和适用场景。</p>
<h3 id="基于回放-重演的方法-Rehearsal-Replay-based-Methods">基于回放/重演的方法 (Rehearsal/Replay-based Methods)</h3>
<p><strong>核心思想：</strong> 这类方法试图通过存储并周期性地回放少量旧任务的数据（或其表示），来“提醒”模型旧知识，从而避免其在学习新任务时完全遗忘。</p>
<p><strong>优点：</strong></p>
<ul>
<li><strong>直观有效：</strong> 通过重新暴露模型于旧数据，可以显著缓解遗忘。</li>
<li><strong>通用性强：</strong> 理论上可以与任何模型架构和优化器结合。</li>
</ul>
<p><strong>挑战：</strong></p>
<ul>
<li><strong>存储限制：</strong> 需要存储旧数据，即便只是少量，在任务数量和数据维度增加时也可能成为瓶颈。</li>
<li><strong>隐私问题：</strong> 存储真实旧数据可能涉及隐私泄露风险。</li>
<li><strong>数据选择：</strong> 如何选择最具代表性、最能有效防止遗忘的旧数据样本是一个研究热点（例如，通过核心集选择）。</li>
</ul>
<h4 id="具体技术：">具体技术：</h4>
<h5 id="1-经验回放-Experience-Replay">1. 经验回放 (Experience Replay)</h5>
<p>这是强化学习（RL）中常用的技术，也被广泛应用于持续学习。</p>
<ul>
<li><strong>原理：</strong> 维护一个“经验缓冲区”（experience buffer），存储过去学习任务的少量样本。在训练新任务时，除了新任务的数据，还从缓冲区中随机抽取旧样本，一起用于模型训练。这使得模型在训练过程中能够同时优化新旧任务的损失，从而减轻遗忘。</li>
<li><strong>例子：</strong><br>
一个简单的基于经验回放的训练循环伪代码：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 假设模型 model，优化器 optimizer，损失函数 criterion</span></span><br><span class="line"><span class="comment"># 假设 experience_buffer 存储了旧任务的 (data, label)</span></span><br><span class="line"><span class="comment"># 假设 new_task_dataloader 提供新任务的数据</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="comment"># 训练新任务</span></span><br><span class="line">    <span class="keyword">for</span> new_data, new_labels <span class="keyword">in</span> new_task_dataloader:</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        new_outputs = model(new_data)</span><br><span class="line">        loss_new = criterion(new_outputs, new_labels)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 从经验缓冲区中采样旧数据进行回放</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(experience_buffer) &gt; <span class="number">0</span>:</span><br><span class="line">            old_data, old_labels = experience_buffer.sample(batch_size_replay)</span><br><span class="line">            old_outputs = model(old_data)</span><br><span class="line">            loss_old = criterion(old_outputs, old_labels)</span><br><span class="line">            total_loss = loss_new + loss_old <span class="comment"># 也可以加权</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            total_loss = loss_new</span><br><span class="line">        </span><br><span class="line">        total_loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 将当前任务的部分数据添加到经验缓冲区</span></span><br><span class="line">    <span class="comment"># (需要策略来选择哪些样本加入，以及何时移除旧样本)</span></span><br><span class="line">    <span class="comment"># 例如：experience_buffer.add_samples(new_task_data_subset)</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h5 id="2-生成式回放-Generative-Replay">2. 生成式回放 (Generative Replay)</h5>
<p>为了避免直接存储和访问原始旧数据，这类方法利用生成模型（如生成对抗网络 GAN、变分自编码器 VAE）来学习旧任务的数据分布。在学习新任务时，通过这些生成模型来合成“伪旧数据”进行回放。</p>
<ul>
<li><strong>原理：</strong> 在学习每个任务后，训练一个生成器来模仿该任务的数据分布。当学习新任务时，利用训练好的生成器生成旧任务的样本，与新任务的真实数据一起训练。</li>
<li><strong>优点：</strong> 解决了隐私和存储原始数据的限制。</li>
<li><strong>挑战：</strong> 生成模型的训练本身就很复杂，且生成的样本质量会影响回放效果。</li>
</ul>
<h5 id="3-伪回放-Pseudo-Replay">3. 伪回放 (Pseudo-Replay)</h5>
<p>与生成式回放类似，但伪回放不训练复杂的生成模型，而是利用当前学习到的模型或之前模型的输出来生成伪样本。例如，存储旧任务的少量样本，然后用当前模型对这些样本进行推断，得到“伪标签”，或者直接对随机噪声生成“伪样本”。</p>
<ul>
<li><strong>原理：</strong> 结合模型蒸馏的思想，让新模型在学习新任务的同时，也尝试拟合旧模型在旧数据上的输出分布。</li>
</ul>
<h3 id="基于正则化的方法-Regularization-based-Methods">基于正则化的方法 (Regularization-based Methods)</h3>
<p><strong>核心思想：</strong> 这类方法通过修改模型的损失函数，添加正则化项，来惩罚模型在学习新任务时对那些对旧任务重要的参数的改变。它们通常不需要存储旧任务的原始数据。</p>
<p><strong>优点：</strong></p>
<ul>
<li><strong>无需存储旧数据：</strong> 解决了隐私和存储瓶颈。</li>
<li><strong>概念上优雅：</strong> 直接作用于模型的学习过程。</li>
</ul>
<p><strong>挑战：</strong></p>
<ul>
<li><strong>参数重要性度量：</strong> 如何准确有效地衡量每个参数对旧任务的重要性是一个难点。</li>
<li><strong>超参数调整：</strong> 正则化项的权重通常需要仔细调整。</li>
<li><strong>效果限制：</strong> 当任务差异很大时，单纯依靠正则化可能不足以完全防止遗忘。</li>
</ul>
<h4 id="具体技术：-2">具体技术：</h4>
<h5 id="1-弹性权值巩固-Elastic-Weight-Consolidation-EWC">1. 弹性权值巩固 (Elastic Weight Consolidation, EWC)</h5>
<p>EWC是Hassabis团队在DeepMind提出的一种经典正则化方法，灵感来源于神经科学中突触巩固的原理。</p>
<ul>
<li><strong>原理：</strong> EWC通过计算Fisher信息矩阵来估计每个参数对旧任务的重要性。Fisher信息矩阵的对角线元素可以近似表示参数的“敏感度”或“贡献度”。在学习新任务时，对那些被认为对旧任务很重要的参数，施加更大的惩罚，限制它们的更新幅度。</li>
<li><strong>数学原理：</strong><br>
假设模型已学完任务 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span>，参数为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>θ</mi><mi>A</mi></msub></mrow><annotation encoding="application/x-tex">\theta_A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">A</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。现在要学习任务 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>，新的损失函数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mi>B</mi></msub><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L_B(\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span>。EWC 在 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mi>B</mi></msub><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L_B(\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span> 上添加一个正则化项，形成新的总损失 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>t</mi><mi>o</mi><mi>t</mi><mi>a</mi><mi>l</mi></mrow></msub><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L_{total}(\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span>：<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>L</mi><mrow><mi>t</mi><mi>o</mi><mi>t</mi><mi>a</mi><mi>l</mi></mrow></msub><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi>L</mi><mi>B</mi></msub><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo><mo>+</mo><munder><mo>∑</mo><mi>i</mi></munder><mfrac><mi>λ</mi><mn>2</mn></mfrac><msub><mi>F</mi><mi>i</mi></msub><mo stretchy="false">(</mo><msub><mi>θ</mi><mi>i</mi></msub><mo>−</mo><msub><mi>θ</mi><mrow><mi>A</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">L_{total}(\theta) = L_B(\theta) + \sum_i \frac{\lambda}{2} F_i (\theta_i - \theta_{A,i})^2
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right:0.01968em;">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:2.6491em;vertical-align:-1.2777em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">λ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1502em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">A</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></p>
其中：
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mi>B</mi></msub><mo stretchy="false">(</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">L_B(\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mclose">)</span></span></span></span> 是新任务的损失函数。</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>θ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\theta_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是当前模型的第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 个参数。</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>θ</mi><mrow><mi>A</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\theta_{A,i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">A</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 是模型在学习完任务 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> 时的第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span> 个参数值。</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">F_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是 Fisher 信息矩阵的对角线元素，表示参数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>θ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\theta_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 对任务 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> 的重要性。它通常通过对数似然函数关于参数的二阶导数期望的负值来计算，即 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>F</mi><mi>i</mi></msub><mo>=</mo><mi>E</mi><mrow><mo fence="true">[</mo><msup><mrow><mo fence="true">(</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>log</mi><mo>⁡</mo><mi>P</mi><mo stretchy="false">(</mo><mi>y</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo separator="true">;</mo><mi>θ</mi><mo stretchy="false">)</mo></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>θ</mi><mi>i</mi></msub></mrow></mfrac><mo fence="true">)</mo></mrow><mn>2</mn></msup><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">F_i = E \left[ \left( \frac{\partial \log P(y|x; \theta)}{\partial \theta_i} \right)^2 \right]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4em;vertical-align:-0.95em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">[</span></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0278em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mspace mtight" style="margin-right:0.1952em;"></span><span class="mop mtight"><span class="mtight">l</span><span class="mtight">o</span><span class="mtight" style="margin-right:0.01389em;">g</span></span><span class="mspace mtight" style="margin-right:0.1952em;"></span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">P</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">y</span><span class="mord mtight">∣</span><span class="mord mathnormal mtight">x</span><span class="mpunct mtight">;</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4451em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size2">)</span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.354em;"><span style="top:-3.6029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">]</span></span></span></span></span></span>。</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">λ</span></span></span></span> 是一个超参数，用于平衡新任务学习和旧知识保留的重要性。</li>
</ul>
</li>
<li><strong>优势：</strong> 数学上优雅，效果显著。</li>
<li><strong>局限：</strong> 计算Fisher信息矩阵可能耗时，且需要为每个任务存储其对应的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>θ</mi><mi>A</mi></msub></mrow><annotation encoding="application/x-tex">\theta_A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">A</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi></mrow><annotation encoding="application/x-tex">F</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span></span></span></span>。</li>
</ul>
<h5 id="2-Synaptic-Intelligence-SI">2. Synaptic Intelligence (SI)</h5>
<p>SI 旨在衡量每个参数在整个训练轨迹上对损失函数变化的贡献。</p>
<ul>
<li><strong>原理：</strong> SI 跟踪参数在梯度下降更新过程中的“步长”和“损失贡献”，以此来累积计算一个参数的重要性。重要性高的参数在后续学习中会被限制变化。</li>
</ul>
<h5 id="3-Memory-Aware-Synapses-MAS">3. Memory Aware Synapses (MAS)</h5>
<p>MAS 通过计算参数对模型输出变化的敏感度来衡量其重要性。</p>
<ul>
<li><strong>原理：</strong> 对于模型输出 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span>，参数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>θ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\theta_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的重要性 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">S_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 计算为对 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span> 的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 范数平方的梯度的平均值：<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>S</mi><mi>i</mi></msub><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mi mathvariant="normal">∥</mi><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>k</mi></msub><mo stretchy="false">)</mo></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>θ</mi><mi>i</mi></msub></mrow></mfrac><msubsup><mi mathvariant="normal">∥</mi><mn>2</mn><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">S_i = \frac{1}{N} \sum_{k=1}^N \| \frac{\partial f(x_k)}{\partial \theta_i} \|_2^2
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.1304em;vertical-align:-1.3021em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3021em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">∥</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.836em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord">∥</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span></span></p>
这个值越大，表示参数对模型输出的影响越大，因此越重要。</li>
</ul>
<h5 id="4-Learning-without-Forgetting-LwF">4. Learning without Forgetting (LwF)</h5>
<p>LwF 是一种基于知识蒸馏（Knowledge Distillation）的方法。</p>
<ul>
<li><strong>原理：</strong> 当学习新任务时，利用旧模型（在旧任务上训练好的模型）作为“教师模型”。新模型在训练新任务的同时，也通过知识蒸馏，模仿旧模型在旧任务数据上的输出（通常是软目标）。这样，新模型在学习新知识的同时，也被引导去保留旧模型的知识结构和决策边界。</li>
<li><strong>优势：</strong> 概念简单，实现相对容易。</li>
<li><strong>局限：</strong> 依赖于旧模型的能力，如果旧模型对旧任务的知识不够鲁棒，蒸馏效果会受限。</li>
</ul>
<h3 id="基于架构的方法-Architecture-based-Methods">基于架构的方法 (Architecture-based Methods)</h3>
<p><strong>核心思想：</strong> 这类方法通过动态调整或扩展神经网络的结构来适应新任务，为新旧知识分配独立的或部分独立的网络容量，从而物理地隔离或保护已学知识。</p>
<p><strong>优点：</strong></p>
<ul>
<li><strong>明确的知识隔离：</strong> 可以有效地防止新旧知识之间的干扰。</li>
<li><strong>潜在的无限容量：</strong> 理论上可以通过添加更多参数来适应更多任务。</li>
</ul>
<p><strong>挑战：</strong></p>
<ul>
<li><strong>模型增长：</strong> 随着任务数量的增加，模型的大小可能会变得非常庞大，导致计算和存储成本急剧上升。</li>
<li><strong>网络利用率：</strong> 可能会出现参数冗余或利用率不高的问题。</li>
<li><strong>架构选择与设计：</strong> 如何动态地决定何时、何地、如何扩展或调整网络结构是一个复杂问题。</li>
</ul>
<h4 id="具体技术：-3">具体技术：</h4>
<h5 id="1-渐进式神经网络-Progressive-Neural-Networks-PNNs">1. 渐进式神经网络 (Progressive Neural Networks, PNNs)</h5>
<p>PNNs 为每个新任务创建一个新的网络“列”（column），同时通过横向连接从之前任务的网络列中提取特征。</p>
<ul>
<li><strong>原理：</strong>
<ul>
<li>训练任务1时，构建一个标准神经网络 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">N_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。</li>
<li>训练任务2时，新建一个网络 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">N_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">N_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的每一层不仅接收来自 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">N_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 前一层的输入，还接收来自 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">N_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 所有层（经过适配层）的输入。这样，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">N_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 可以利用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">N_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 学习到的通用特征。</li>
<li>训练任务 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> 时，新建网络 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">N_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，并从 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>N</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>N</mi><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow></msub></mrow><annotation encoding="application/x-tex">N_1, \dots, N_{k-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8917em;vertical-align:-0.2083em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span></span></span></span> 中提取特征。</li>
</ul>
</li>
<li><strong>优势：</strong> 理论上完全避免了遗忘，因为旧网络参数被冻结。</li>
<li><strong>局限：</strong> 模型大小线性增长，推理时计算量大。</li>
</ul>
<h5 id="2-动态扩展网络-Dynamically-Expandable-Networks-DEN">2. 动态扩展网络 (Dynamically Expandable Networks, DEN)</h5>
<p>DEN 在学习新任务时，会选择性地扩展网络（增加神经元或层），并对冗余的神经元进行剪枝，从而在控制模型增长的同时提高容量。</p>
<ul>
<li><strong>原理：</strong> 检测模型在新任务上的性能瓶颈，通过添加新的神经元或层来增强能力。同时，识别并移除对现有任务不重要的冗余神经元或连接，以保持模型效率。</li>
</ul>
<h5 id="3-剪枝与连接-Pruning-and-Rewiring">3. 剪枝与连接 (Pruning and Rewiring)</h5>
<p>这类方法结合了神经网络剪枝和动态连接的思想。</p>
<ul>
<li><strong>原理：</strong> 在学习旧任务后，识别并“保护”对旧任务至关重要的连接（通过剪枝将其标记为不可移除）。在新任务上训练时，允许新连接的生长，同时修剪对新旧任务都不重要的连接。</li>
<li><strong>优势：</strong> 可能比完全新增网络更节省参数。</li>
<li><strong>挑战：</strong> 如何有效地识别和保护关键连接是一个难题。</li>
</ul>
<h5 id="4-基于掩码的方法-Mask-based-Methods">4. 基于掩码的方法 (Mask-based Methods)</h5>
<p>这类方法为每个任务学习一个二进制“掩码”，该掩码决定了在处理特定任务时，网络中的哪些神经元或连接是激活的，而其他则被“冻结”或禁用。</p>
<ul>
<li><strong>原理：</strong> 假设网络具有足够的过参数化能力。对于每个任务，通过一个任务特定的掩码来激活网络的不同子集。</li>
<li><strong>优势：</strong> 可以在一个共享网络中存储多个任务的知识，参数不线性增长。</li>
<li><strong>挑战：</strong> 掩码学习的复杂性，以及如何确保不同任务的掩码不冲突。</li>
</ul>
<h3 id="其他新兴方法-Other-Emerging-Methods">其他新兴方法 (Other Emerging Methods)</h3>
<p>除了上述三大类，还有一些更前沿、交叉学科的方法也在积极探索中：</p>
<h4 id="1-元学习-Meta-Learning">1. 元学习 (Meta-Learning)</h4>
<ul>
<li><strong>原理：</strong> 元学习旨在“学习如何学习”。在持续学习的语境下，元学习可以帮助模型学会一种更快的适应新任务的方式，并且这种适应方式能够最大限度地减少对旧知识的遗忘。例如，通过学习一个良好的初始化参数，使得模型在面对新任务时，只需要少量步数的梯度更新就能取得好结果，同时又不会严重影响旧任务性能。</li>
<li><strong>例子：</strong> MAML (Model-Agnostic Meta-Learning) 等算法可以被扩展应用于持续学习。</li>
</ul>
<h4 id="2-对比学习-自监督学习-Contrastive-Learning-Self-Supervised-Learning">2. 对比学习/自监督学习 (Contrastive Learning/Self-Supervised Learning)</h4>
<ul>
<li><strong>原理：</strong> 这类方法通过在大规模无标签数据上进行自监督预训练，学习到更鲁棒、更通用的特征表示。这些表示对后续任务的微调具有更好的稳定性，从而可能减轻遗忘。</li>
<li><strong>优势：</strong> 学习到的特征表示在面对任务变化时可能更不易漂移。</li>
</ul>
<h4 id="3-神经符号混合方法-Neuro-Symbolic-Hybrid-Methods">3. 神经符号混合方法 (Neuro-Symbolic Hybrid Methods)</h4>
<ul>
<li><strong>原理：</strong> 结合深度学习的模式识别能力和符号AI的显式知识表示与推理能力。符号知识图谱可以作为外部记忆库，显式地存储和管理结构化的知识，从而规避神经网络的遗忘问题。当神经网络遗忘时，可以从符号知识库中“回忆”或重构知识。</li>
<li><strong>优势：</strong> 有望提供更可解释、更稳定的知识存储。</li>
</ul>
<h4 id="4-可解释AI-Explainable-AI-XAI-与持续学习的结合">4. 可解释AI (Explainable AI, XAI) 与持续学习的结合</h4>
<ul>
<li><strong>原理：</strong> 通过理解模型在学习新任务时哪些部分被修改，以及这些修改如何影响旧任务的决策过程，可以为设计更有效的持续学习算法提供洞察。例如，定位对遗忘影响最大的神经元或连接，并针对性地进行保护。</li>
</ul>
<p>这些新兴方法代表了持续学习研究的前沿方向，它们往往结合了多个领域的先进思想，共同推动着人工智能向更智能、更接近人类学习方式的方向发展。</p>
<h2 id="评估持续学习模型">评估持续学习模型</h2>
<p>设计有效的持续学习算法固然重要，但如何客观、全面地评估它们的性能，同样是研究中的关键环节。持续学习的评估比传统机器学习更复杂，因为它不仅要衡量模型在新任务上的性能，还要考察它对旧知识的保留能力。</p>
<h3 id="关键指标">关键指标</h3>
<p>在评估持续学习模型时，我们通常关注以下几个核心指标：</p>
<h4 id="1-准确性-Accuracy">1. 准确性 (Accuracy)</h4>
<ul>
<li><strong>平均准确率 (Average Accuracy)：</strong> 模型在所有已学任务（包括当前任务和所有历史任务）上的平均性能。这是衡量模型整体表现的最直接指标。
<ul>
<li>例如，在学习了 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> 个任务后，平均准确率 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mi>N</mi></msub><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><msub><mi>P</mi><mrow><mi>N</mi><mo separator="true">,</mo><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">A_N = \frac{1}{N} \sum_{k=1}^N P_{N,k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.3262em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mrow><mi>N</mi><mo separator="true">,</mo><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">P_{N,k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 是在学完第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> 个任务后，模型在第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> 个任务上的准确率。</li>
</ul>
</li>
<li><strong>当前任务准确率 (Current Task Accuracy)：</strong> 模型在新学习任务上的性能。这衡量了模型学习新知识的能力。</li>
<li><strong>旧任务准确率 (Old Task Accuracy)：</strong> 模型在旧任务上的性能。这直接反映了遗忘的程度。</li>
</ul>
<h4 id="2-遗忘度-Forgetting">2. 遗忘度 (Forgetting)</h4>
<p>遗忘度是衡量模型在学习新任务后，其对旧任务性能下降程度的关键指标。</p>
<ul>
<li><strong>具体遗忘度 (Specific Forgetting)：</strong> 对于每个任务 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>&lt;</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">k &lt; N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7335em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span>)，当模型学完任务 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> 后，其在任务 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> 上的最高准确率 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mrow><mi>k</mi><mo separator="true">,</mo><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">P_{k,k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 与当前准确率 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mrow><mi>N</mi><mo separator="true">,</mo><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">P_{N,k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 之间的下降。<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>F</mi><mi>k</mi></msub><mo>=</mo><munder><mrow><mi>max</mi><mo>⁡</mo></mrow><mrow><mi>j</mi><mo>∈</mo><mo stretchy="false">{</mo><mi>k</mi><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><mi>N</mi><mo>−</mo><mn>1</mn><mo stretchy="false">}</mo></mrow></munder><mo stretchy="false">(</mo><msub><mi>P</mi><mrow><mi>j</mi><mo separator="true">,</mo><mi>k</mi></mrow></msub><mo stretchy="false">)</mo><mo>−</mo><msub><mi>P</mi><mrow><mi>N</mi><mo separator="true">,</mo><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">F_k = \max_{j \in \{k, \dots, N-1\}} (P_{j,k}) - P_{N,k}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.716em;vertical-align:-0.966em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.4306em;"><span style="top:-2.309em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">∈</span><span class="mopen mtight">{</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mpunct mtight">,</span><span class="minner mtight">…</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mclose mtight">}</span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.966em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span></span></p>
</li>
<li><strong>平均遗忘度 (Average Forgetting)：</strong> 所有旧任务遗忘度的平均值。理想情况下，我们希望遗忘度接近零。<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>F</mi><mi>N</mi></msub><mo>=</mo><mfrac><mn>1</mn><mrow><mi>N</mi><mo>−</mo><mn>1</mn></mrow></mfrac><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>N</mi><mo>−</mo><mn>1</mn></mrow></munderover><msub><mi>F</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">F_N = \frac{1}{N-1} \sum_{k=1}^{N-1} F_k
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.1304em;vertical-align:-1.3021em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord">1</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3021em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>
</li>
</ul>
<h4 id="3-前向迁移-Forward-Transfer">3. 前向迁移 (Forward Transfer)</h4>
<ul>
<li><strong>定义：</strong> 在学习一个新任务时，模型利用之前学到的知识来提升新任务性能的能力。如果模型从旧任务中学习到了有用的通用特征或知识，那么在新任务上的初始学习速度会更快，或最终性能会更高。</li>
<li><strong>衡量：</strong> 比较模型在有持续学习策略和无持续学习策略（从头训练或随机初始化）时在新任务上的性能差异。</li>
</ul>
<h4 id="4-反向迁移-Backward-Transfer">4. 反向迁移 (Backward Transfer)</h4>
<ul>
<li><strong>定义：</strong> 学习新任务后，旧任务性能是否意外地得到提升。虽然在大多数情况下，我们关心的是遗忘（负向反向迁移），但在某些情况下，新知识可能以一种促进老知识理解的方式整合，导致旧任务性能的提升。这通常是罕见且难以实现的。</li>
</ul>
<h4 id="5-模型容量-效率-Model-Capacity-Efficiency">5. 模型容量/效率 (Model Capacity/Efficiency)</h4>
<ul>
<li><strong>参数数量 (Number of Parameters)：</strong> 衡量模型的大小，尤其是在基于架构扩展的方法中，这是评估其可扩展性的重要指标。</li>
<li><strong>计算成本 (Computational Cost)：</strong> 训练和推理所需的计算资源（FLOPs、时间等）。</li>
<li><strong>存储需求 (Storage Requirements)：</strong> 模型参数、经验缓冲区等所需的内存或磁盘空间。</li>
</ul>
<h3 id="评估范式">评估范式</h3>
<p>持续学习的评估通常遵循特定的范式：</p>
<h4 id="1-顺序任务评估-Sequential-Task-Evaluation">1. 顺序任务评估 (Sequential Task Evaluation)</h4>
<p>这是最常见的评估方式，它模拟了持续学习的增量过程：</p>
<ol>
<li><strong>初始化：</strong> 模型在第一个任务上训练。</li>
<li><strong>增量学习：</strong> 学习完一个任务后，保存当前模型，然后加载下一个任务的数据进行训练。在训练过程中，模型不能访问之前任务的原始数据。</li>
<li><strong>最终评估：</strong> 在所有任务学习完毕后，使用一个包含所有已学任务测试集的统一测试集对模型进行评估，计算在每个任务上的准确率，并进而计算平均准确率和平均遗忘度。</li>
</ol>
<ul>
<li><strong>优势：</strong> 严格模拟了无旧数据访问的持续学习场景。</li>
</ul>
<h4 id="2-混合任务评估-Mixed-Task-Evaluation">2. 混合任务评估 (Mixed Task Evaluation)</h4>
<p>在某些情况下，尤其是在类增量学习或域增量学习中，测试时并不知道样本属于哪个任务或哪个类别。</p>
<ul>
<li><strong>过程：</strong> 模型学习一系列任务（或类别），但在最终评估时，所有已学类别的数据被混合在一起，模型需要识别任意一个已学类别。</li>
<li><strong>优势：</strong> 更贴近实际应用中任务边界不明确的场景。</li>
</ul>
<p><strong>重要的考虑：</strong></p>
<ul>
<li><strong>基线选择：</strong> 通常需要与以下基线进行比较：
<ul>
<li><strong>独立训练 (Independent Training)：</strong> 为每个任务单独训练一个模型。这通常具有最好的单任务性能，但无法实现持续学习。</li>
<li><strong>联合训练 (Joint Training / Oracle)：</strong> 将所有任务的数据汇集在一起，一次性训练一个模型。这代表了理论上的最佳性能（没有遗忘），但通常不切实际。</li>
</ul>
</li>
<li><strong>数据集：</strong> 常用的持续学习数据集包括 MNIST、CIFAR-100、ImageNet 的变体（如 Split MNIST, Split CIFAR-100, Permuted MNIST 等）。</li>
</ul>
<p>通过上述指标和评估范式，研究者们能够更全面、准确地衡量持续学习算法的有效性、鲁棒性以及资源效率。</p>
<h2 id="持续学习的应用前景">持续学习的应用前景</h2>
<p>持续学习并非仅仅是学术研究的兴趣点，它在众多实际应用领域都展现出巨大的潜力和必要性。它将使AI系统从静态的“工具”转变为动态的“伙伴”，能够与我们一同成长和进化。</p>
<h3 id="1-机器人学习-Robotics-Learning">1. 机器人学习 (Robotics Learning)</h3>
<ul>
<li><strong>场景：</strong> 机器人需要在不断变化的环境中执行各种任务。例如，家庭服务机器人需要学习识别新的物品、适应新的家具布局，或掌握新的家务技能。工厂机器人需要适应生产线上的新产品或新流程。</li>
<li><strong>挑战：</strong> 传统上，机器人需要大量预编程或在模拟环境中学习，然后才能部署。但现实世界充满了未知和变化。</li>
<li><strong>持续学习的价值：</strong>
<ul>
<li><strong>在线适应：</strong> 机器人可以在部署后通过与环境的交互实时学习和调整其行为策略。</li>
<li><strong>技能积累：</strong> 机器人可以累积和组合不同的技能，例如先学习抓取物体，再学习将物体放入特定容器中，而不会忘记抓取能力。</li>
<li><strong>泛化能力：</strong> 从少量新经验中快速泛化到类似但未曾见过的新任务。</li>
</ul>
</li>
</ul>
<h3 id="2-自动驾驶-Autonomous-Driving">2. 自动驾驶 (Autonomous Driving)</h3>
<ul>
<li><strong>场景：</strong> 自动驾驶汽车需要在各种复杂、动态的交通环境中运行，包括不同的天气条件、道路类型、交通规则、以及新的障碍物和事件。</li>
<li><strong>挑战：</strong> 无法在训练阶段穷尽所有可能的驾驶场景。数据不断产生，新的交通状况和异常事件层出不穷。</li>
<li><strong>持续学习的价值：</strong>
<ul>
<li><strong>适应新场景：</strong> 车辆可以学习识别新的路标、交通信号灯变体、应对极端天气条件（如大雾、暴雨）。</li>
<li><strong>学习新型驾驶行为：</strong> 适应不同国家或地区独特的交通习惯和规则。</li>
<li><strong>处理“长尾”事件：</strong> 那些极少发生但影响巨大的事件，通过持续学习可以逐步积累经验。</li>
</ul>
</li>
</ul>
<h3 id="3-医疗诊断-Medical-Diagnosis">3. 医疗诊断 (Medical Diagnosis)</h3>
<ul>
<li><strong>场景：</strong> 医疗领域的新研究、新疾病、新诊断标准、新的治疗方法层出不穷。AI辅助诊断系统需要及时更新其知识库。</li>
<li><strong>挑战：</strong> 医疗数据敏感且稀缺，难以进行大规模重训练。新疾病或罕见病的病例数据往往是增量出现的。</li>
<li><strong>持续学习的价值：</strong>
<ul>
<li><strong>知识更新：</strong> 模型可以不断吸收最新的医学文献、疾病指南和临床病例数据，提高诊断准确率。</li>
<li><strong>适应新疾病：</strong> 当出现新的流行病或变异病毒时，模型可以快速学习其特征并辅助诊断。</li>
<li><strong>个性化医疗：</strong> 根据患者的特定病史和治疗响应，模型可以持续优化诊断和治疗建议。</li>
</ul>
</li>
</ul>
<h3 id="4-自然语言处理-Natural-Language-Processing-NLP">4. 自然语言处理 (Natural Language Processing, NLP)</h3>
<ul>
<li><strong>场景：</strong> 语言本身就是动态变化的，新词汇、新表达、新俚语不断涌现。大型语言模型（LLMs）需要不断更新其对世界的理解和生成能力。</li>
<li><strong>挑战：</strong> LLMs 规模巨大，每次更新都需要巨大的计算资源；它们也容易出现“知识截止日期”问题。</li>
<li><strong>持续学习的价值：</strong>
<ul>
<li><strong>概念漂移：</strong> 适应新词汇、短语和俚语，保持对时事和文化趋势的敏感性。</li>
<li><strong>事实更新：</strong> 及时更新模型内部存储的事实性知识，例如政治事件、科学发现等。</li>
<li><strong>领域适应：</strong> 模型可以从通用领域知识逐步学习并适应特定行业（如法律、金融）的术语和语境。</li>
<li><strong>安全与伦理：</strong> 学习和适应新的安全指南和伦理规范，减少偏见和有害输出。</li>
</ul>
</li>
</ul>
<h3 id="5-个性化推荐系统-Personalized-Recommendation-Systems">5. 个性化推荐系统 (Personalized Recommendation Systems)</h3>
<ul>
<li><strong>场景：</strong> 用户兴趣、商品趋势、内容流行度都在实时变化。推荐系统需要快速响应这些变化。</li>
<li><strong>挑战：</strong> 用户行为数据是典型的流式数据，需要在线处理。</li>
<li><strong>持续学习的价值：</strong>
<ul>
<li><strong>实时更新：</strong> 根据用户最新的点击、购买、浏览行为实时调整推荐策略。</li>
<li><strong>适应趋势：</strong> 快速捕捉流行趋势和季节性变化，避免推荐过时或不相关的产品。</li>
<li><strong>新用户/新商品冷启动：</strong> 利用持续学习机制，更有效地处理新用户和新商品的数据，快速融入推荐系统。</li>
</ul>
</li>
</ul>
<h3 id="6-金融欺诈检测-Financial-Fraud-Detection">6. 金融欺诈检测 (Financial Fraud Detection)</h3>
<ul>
<li><strong>场景：</strong> 欺诈模式不断演变，欺诈者会不断发明新的攻击手段以规避现有检测系统。</li>
<li><strong>挑战：</strong> 欺诈数据通常是不平衡的，新欺诈模式的样本稀少。</li>
<li><strong>持续学习的价值：</strong>
<ul>
<li><strong>适应新模式：</strong> 模型能够快速学习并识别新型的欺诈交易模式或攻击向量，而不会遗忘对已知欺诈模式的识别能力。</li>
<li><strong>降低误报：</strong> 在学习新模式的同时，保持对正常交易的准确识别，减少误报。</li>
</ul>
</li>
</ul>
<p>总而言之，持续学习是构建未来智能系统的基石。它将使AI系统变得更加健壮、灵活、自主，并能够更好地服务于真实世界中那些动态、复杂且不断演进的应用场景。虽然灾难性遗忘仍然是一个巨大的挑战，但持续学习的广阔前景激励着全球的研究者们不断探索新的解决方案。</p>
<h2 id="结语">结语</h2>
<p>我们今天一起深入探讨了持续学习这一令人兴奋却又充满挑战的领域，并重点剖析了其“阿喀琉斯之踵”——灾难性遗忘。从定义和范式，到遗忘的内在机制，再到五花八门的应对策略，我们看到了学界和业界为实现真正意义上的“终身学习”AI所做出的不懈努力。</p>
<p>持续学习是通向通用人工智能的必经之路。它承诺让AI系统不再是静态的、需要频繁重置的工具，而是能够像人类一样，在经验的河流中不断积累知识、迭代升级的智能体。想象一下，一个能够自主学习、不断适应的机器人，一个永不“过时”的语言模型，一个能够应对所有未知驾驶场景的自动驾驶汽车，这些都离不开持续学习的突破。</p>
<p>我们已经了解，灾难性遗忘并非偶然，而是深度神经网络核心机制在特定学习范式下的必然结果。参数的扰动、特征表示的漂移以及数据分布的变化，都在无形中“冲刷”着模型对旧知识的记忆。</p>
<p>然而，面对这一挑战，研究者们并非束手无策。无论是通过巧妙地“温故而知新”的回放策略，还是通过“修旧如旧”的正则化方法来保护关键知识，亦或是通过“增添新衣”的架构调整来为新旧知识提供独立空间，以及如元学习、对比学习、神经符号混合等前沿方向的探索，都为我们提供了解决遗忘问题的宝贵思路。尽管目前还没有一个“万能药”能够彻底解决所有持续学习场景下的灾难性遗忘，但每一种方法的进步都让我们离目标更近一步。</p>
<p>评估指标的建立也至关重要，它帮助我们公正地衡量模型的学习能力、记忆保持能力以及在新旧任务之间的知识迁移能力，确保研究方向的正确性。</p>
<p>未来，持续学习的研究将更加注重多策略的融合与协同作用，例如将回放与正则化、架构调整相结合；同时，对模型可解释性的深入理解，也将为我们设计更有效的持续学习机制提供新的视角。我们还需要探索更高效的记忆管理策略，如何在有限的资源下存储和提取最具价值的旧知识，以及如何将符号推理与神经网络学习深度融合，以实现更鲁棒的知识表示和推理。</p>
<p>作为技术爱好者，我们正处于一个激动人心的时代。持续学习领域的每一次突破，都可能为我们带来下一代AI系统的革命性变革。我鼓励大家保持好奇心，继续关注这个领域的前沿进展，甚至投身其中，亲手去构建那些能够永不止步、持续进化的智能系统。</p>
<p>感谢您的阅读，希望这篇文章能为您对持续学习与灾难性遗忘的理解提供深度和广度。让我们一起期待并共同创造AI的辉煌未来！</p>
<p>—— qmwneb946</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a target="_blank" rel="noopener" href="https://github.com/qmwneb946">qmwneb946</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://qmwneb946.dpdns.org/2025/07/22/2025-07-22-222136/">https://qmwneb946.dpdns.org/2025/07/22/2025-07-22-222136/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://opensource.org/licenses/MIT" target="_blank">MIT License</a> 许可协议。转载请注明来源 <a href="https://qmwneb946.dpdns.org" target="_blank">qmwneb946 的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/2025/">2025</a><a class="post-meta__tags" href="/tags/%E6%95%B0%E5%AD%A6/">数学</a><a class="post-meta__tags" href="/tags/%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%81%BE%E9%9A%BE%E6%80%A7%E9%81%97%E5%BF%98/">持续学习与灾难性遗忘</a></div><div class="post-share"><div class="social-share" data-image="/img/icon.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/07/22/2025-07-22-222303/" title="深度剖析：文本风格迁移技术的奥秘与前沿"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">深度剖析：文本风格迁移技术的奥秘与前沿</div></div><div class="info-2"><div class="info-item-1">你好，各位技术与数学爱好者！我是 qmwneb946，今天我们将一同踏上一段激动人心的旅程，探索自然语言处理领域中一个既充满艺术气息又极具技术挑战的方向——文本风格迁移。 想象一下，你写了一段平实直白的文字，却希望它能瞬间变得幽默风趣，或者严谨正式，甚至像莎士比亚的诗句般充满韵律。这听起来像是魔法，但在人工智能的时代，它正逐渐变为现实。文本风格迁移技术，正是致力于将这种“魔法”带入我们的数字世界。 引言：语言的魔法与风格的魅力 语言是人类最精妙的创造之一。它不仅承载信息，更传递情感、态度和身份。同样的内容，以不同的风格呈现，其影响力会截然不同。比如，一篇充满激情的演讲稿，与一份严谨的学术报告，即使核心观点一致，其遣词造句、行文结构也大相径庭。正是这种“风格”的差异，赋予了语言无穷的魅力和多变性。 长期以来，改变文本风格是一项高度依赖人类经验和创造力的工作。作家、编辑、翻译家们凭借其深厚的语言功底，将内容与风格巧妙地融合或分离。然而，随着人工智能，特别是深度学习技术的飞速发展，我们开始尝试将这种人类独有的能力赋予机器。 文本风格迁移（Text Style Transfer），顾顾名...</div></div></div></a><a class="pagination-related" href="/2025/07/22/2025-07-22-222027/" title="微内核与宏内核之争：深入理解操作系统架构的权衡与选择"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">微内核与宏内核之争：深入理解操作系统架构的权衡与选择</div></div><div class="info-2"><div class="info-item-1">你好，各位技术爱好者和深度思考者！我是你们的老朋友 qmwneb946，一个热爱探索技术深层逻辑的博主。今天，我们将一同踏上一段激动人心的旅程，深入剖析计算机科学中最基础也最引人入胜的议题之一：操作系统的核心——内核架构。具体来说，我们将聚焦于两种截然不同但又各自承载着辉煌历史和广阔未来的范式：宏内核（Monolithic Kernel） 与 微内核（Microkernel）。 操作系统是计算机硬件与软件之间的桥梁，而内核则是操作系统的“心脏”，负责管理系统资源、调度任务、处理中断等最核心的功能。然而，这颗“心脏”的内部构造却可以大相径庭，宏内核与微内核正是其两种最主要的设计哲学。它们各自代表着对性能、安全性、可靠性、可扩展性以及开发复杂度的不同权衡。 这场围绕内核架构的“战争”从未真正停止，它塑造了我们今天使用的所有计算设备。从我们日常使用的智能手机、电脑，到支撑互联网的服务器，再到自动驾驶汽车、工业控制系统中的嵌入式设备，内核架构的选择无时无刻不在影响着它们的行为和表现。理解这两种架构的优劣，不仅能加深我们对操作系统原理的认识，更能帮助我们洞察未来技术发展的趋势。 那么，准备...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/07/18/2025-07-18-082519/" title="增强现实与工业维修：一场效率革命"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">增强现实与工业维修：一场效率革命</div></div><div class="info-2"><div class="info-item-1">增强现实 (AR) 技术正以前所未有的速度改变着我们的生活，而其在工业维修领域的应用更是展现出了巨大的潜力。不再局限于科幻电影中的场景，AR 如今已成为提升维修效率、降低维护成本、提高安全性的强大工具。本文将深入探讨 AR 如何与工业维修相结合，并分析其背后的技术和未来发展趋势。 引言：传统工业维修的挑战 传统的工业维修往往面临着诸多挑战：  信息获取困难: 维修人员需要查阅大量的纸质文档、图纸和视频，耗时费力，容易出错。 培训成本高昂:  熟练技工的培养需要漫长的学习过程和大量的实践经验，成本高昂。 安全风险较高:  一些复杂的设备维修存在高风险，例如高压电、高温部件等，容易发生意外事故。 维修效率低下:  由于缺乏实时信息和有效的指导，维修时间往往较长，导致生产停机时间增加，损失巨大。  AR 如何改变工业维修的游戏规则 AR 技术通过将数字信息叠加到现实世界中，为工业维修提供了全新的解决方案： 远程专家指导 通过 AR 眼镜或平板电脑，现场维修人员可以与远程专家实时互动。专家可以通过 AR 系统看到现场设备的实时图像，并利用虚拟标注、3D 模型等工具进行远程指导，大大缩短了...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082652/" title="纳米材料在靶向药物中的革命性应用"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">纳米材料在靶向药物中的革命性应用</div></div><div class="info-2"><div class="info-item-1">近年来，癌症等重大疾病的治疗面临着巨大的挑战，传统的化疗药物往往毒性大、副作用强，难以实现精准治疗。而纳米技术的兴起为解决这一难题提供了新的思路，特别是纳米材料在靶向药物递送系统中的应用，正引发一场医学革命。本文将深入探讨纳米材料如何提升靶向药物的疗效，降低其毒副作用。 纳米材料的特性及其在药物递送中的优势 纳米材料，是指至少在一个维度上尺寸小于100纳米的材料。这种极小的尺寸赋予了它们许多独特的物理和化学性质，使其在药物递送领域具有显著优势： 增强的药物溶解度和稳定性 许多药物具有较低的溶解度，限制了其在体内的吸收和生物利用度。纳米载体，例如脂质体、聚合物纳米颗粒和无机纳米颗粒（如金纳米颗粒、氧化铁纳米颗粒），可以显著提高药物的溶解度和稳定性，延长其在体内的循环时间。例如，将抗癌药物负载在聚合物纳米颗粒中，可以保护药物免受降解，并提高其在肿瘤组织中的积累。 靶向药物递送 纳米材料可以通过表面修饰，例如结合特异性配体（如抗体、肽或小分子），实现对特定细胞或组织的靶向递送。这种靶向递送可以最大限度地减少药物对健康组织的毒性，并提高药物在靶标部位的浓度，从而增强治疗效果。例如，修饰有...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082925/" title="生物化学中的蛋白质折叠问题：一个复杂而迷人的计算挑战"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">生物化学中的蛋白质折叠问题：一个复杂而迷人的计算挑战</div></div><div class="info-2"><div class="info-item-1">生命，这奇妙的现象，其本质很大程度上取决于蛋白质的精确三维结构。蛋白质是由氨基酸链组成的长链分子，但仅仅是氨基酸序列并不能完全决定其功能。蛋白质必须折叠成特定的三维结构（构象），才能发挥其生物学功能，例如催化酶促反应、运输分子或构建细胞结构。  而这个折叠过程，就是著名的“蛋白质折叠问题”。 蛋白质折叠：从线性序列到三维结构 蛋白质的氨基酸序列由基因编码决定，这是一个线性的一维结构。然而，这些氨基酸链并非随机地盘踞在一起，而是会遵循特定的物理和化学原理，自发地折叠成独特的、功能性的三维结构。这个折叠过程涉及到多种相互作用，包括： 疏水相互作用 蛋白质内部的疏水氨基酸残基倾向于聚集在一起，远离水性环境，形成蛋白质的核心区域。而亲水性氨基酸残基则倾向于暴露在蛋白质的表面，与水分子相互作用。 静电相互作用 带电荷的氨基酸残基之间会发生静电吸引或排斥作用，影响蛋白质的折叠。 氢键 氢键在维持蛋白质二级结构（例如α螺旋和β折叠）中起着关键作用。 二硫键 某些氨基酸残基（例如半胱氨酸）之间可以形成二硫键，进一步稳定蛋白质的三维结构。 这些相互作用共同决定了蛋白质的最终构象，这是一个极其复杂的...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-092536/" title="CRISPR基因编辑：技术的奇迹与伦理的挑战"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">CRISPR基因编辑：技术的奇迹与伦理的挑战</div></div><div class="info-2"><div class="info-item-1">大家好！我是你们的技术和数学博主，今天我们要深入探讨一个既令人兴奋又充满争议的话题：CRISPR-Cas9基因编辑技术及其伦理挑战。CRISPR技术以其精准性和效率，为治疗遗传疾病、改良作物等领域带来了革命性的变革，但与此同时，它也引发了诸多伦理难题，需要我们认真思考和谨慎应对。 CRISPR技术：一把双刃剑 CRISPR-Cas9系统，简单来说，就是一种可以精确地“剪切和粘贴”DNA的工具。它源自细菌的天然防御机制，利用向导RNA（gRNA）引导Cas9酶到基因组中的特定位置，从而进行基因的敲除、插入或替换。其操作简便、成本低廉、效率高，使其成为基因编辑领域的“明星”技术。 CRISPR的工作原理 CRISPR系统的工作机制可以概括为以下几个步骤：  设计gRNA:  根据目标基因序列设计相应的gRNA，使其能够特异性地结合目标DNA序列。 Cas9酶的结合: gRNA引导Cas9酶到目标DNA序列。 DNA双链断裂: Cas9酶在目标位点切割DNA双链，形成双链断裂（DSB）。 DNA修复: 细胞利用非同源末端连接（NHEJ）或同源定向修复（HDR）机制修复DSB。NHEJ修...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-094115/" title="免疫学与癌症免疫疗法：一场人体内部的战争与和平"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">免疫学与癌症免疫疗法：一场人体内部的战争与和平</div></div><div class="info-2"><div class="info-item-1">免疫系统，人体精妙的防御机制，日夜不停地抵御着病毒、细菌和其他有害物质的入侵。然而，当这套系统出现故障，对自身细胞发起攻击，或者无法有效清除癌细胞时，疾病便会发生，其中最可怕的莫过于癌症。近年来，癌症免疫疗法异军突起，为癌症治疗带来了新的希望，让我们深入探索这场人体内部的战争与和平。 免疫系统：人体精妙的防御网络 我们的免疫系统由先天免疫和适应性免疫两大支柱组成。 先天免疫：第一道防线 先天免疫是人体抵御病原体的第一道防线，它包含物理屏障（例如皮肤和黏膜）、化学屏障（例如胃酸和酶）以及细胞介导的免疫反应，例如巨噬细胞和自然杀伤细胞（NK细胞）的吞噬和杀伤作用。这些细胞能够识别并清除被感染的细胞或癌细胞，但其特异性较低。 适应性免疫：精准打击 适应性免疫系统则更为精细，它具有特异性和记忆性。T细胞和B细胞是适应性免疫的主角。T细胞负责细胞介导的免疫，其中细胞毒性T细胞（CTL）能够特异性识别并杀死靶细胞，例如被病毒感染的细胞或癌细胞。B细胞则负责体液免疫，产生抗体，中和病原体或标记癌细胞以便清除。  抗原呈递细胞（APC），例如树突状细胞，在将抗原信息呈递给T细胞，启动适应性免疫反...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-094141/" title="生态学中的生物多样性保护：一个复杂系统工程的视角"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">生态学中的生物多样性保护：一个复杂系统工程的视角</div></div><div class="info-2"><div class="info-item-1">大家好！今天我们要深入探讨一个既充满挑战又至关重要的话题：生态学中的生物多样性保护。  这不仅是环境保护的基石，也与我们人类的福祉息息相关。对技术爱好者来说，这更像是一个巨大的、复杂的系统工程，充满了需要解决的优化问题和值得探索的算法。 生物多样性的价值：超越简单的物种数量 我们通常将生物多样性理解为物种数量的多样性。但实际上，它是一个多层次的概念，包括：  遗传多样性 (Genetic Diversity):  同一物种内基因组的差异性，这决定了物种的适应性和进化潜力。  想象一下，一个抗旱基因的缺失可能导致整个小麦品种在干旱年份面临灭绝的风险。 物种多样性 (Species Diversity):  不同物种的数量及其相对丰度。 这通常用Shannon多样性指数 (H=−∑i=1Spilog⁡2piH = -\sum_{i=1}^{S} p_i \log_2 p_iH=−∑i=1S​pi​log2​pi​) 来衡量，其中 pip_ipi​ 是第 iii 个物种的比例，SSS 是物种总数。  更高的Shannon指数表示更高的物种多样性。 生态系统多样性 (Ecosystem ...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">qmwneb946</div><div class="author-info-description">一个专注于技术分享的个人博客，涵盖编程、算法、系统设计等内容</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">588</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">592</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/qmwneb946"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/qmwneb946" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:qmwneb946@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">代码与远方，技术与生活交织的篇章。</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0%EF%BC%9F"><span class="toc-number">1.</span> <span class="toc-text">什么是持续学习？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E4%B8%8E%E6%84%BF%E6%99%AF"><span class="toc-number">1.1.</span> <span class="toc-text">定义与愿景</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BF%85%E8%A6%81%E6%80%A7"><span class="toc-number">1.2.</span> <span class="toc-text">持续学习的必要性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%8C%83%E5%BC%8F"><span class="toc-number">1.3.</span> <span class="toc-text">持续学习的范式</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A1%E5%A2%9E%E9%87%8F%E5%AD%A6%E4%B9%A0-Task-Incremental-Learning"><span class="toc-number">1.3.1.</span> <span class="toc-text">任务增量学习 (Task Incremental Learning)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%9F%E5%A2%9E%E9%87%8F%E5%AD%A6%E4%B9%A0-Domain-Incremental-Learning"><span class="toc-number">1.3.2.</span> <span class="toc-text">域增量学习 (Domain Incremental Learning)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%B1%BB%E5%A2%9E%E9%87%8F%E5%AD%A6%E4%B9%A0-Class-Incremental-Learning"><span class="toc-number">1.3.3.</span> <span class="toc-text">类增量学习 (Class Incremental Learning)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B5%81%E5%BC%8F%E5%AD%A6%E4%B9%A0-Stream-Learning"><span class="toc-number">1.3.4.</span> <span class="toc-text">流式学习 (Stream Learning)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%81%BE%E9%9A%BE%E6%80%A7%E9%81%97%E5%BF%98%EF%BC%9A%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%98%BF%E5%96%80%E7%90%89%E6%96%AF%E4%B9%8B%E8%B8%B5"><span class="toc-number">2.</span> <span class="toc-text">灾难性遗忘：持续学习的阿喀琉斯之踵</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E7%81%BE%E9%9A%BE%E6%80%A7%E9%81%97%E5%BF%98%EF%BC%9F"><span class="toc-number">2.1.</span> <span class="toc-text">什么是灾难性遗忘？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%81%BE%E9%9A%BE%E6%80%A7%E9%81%97%E5%BF%98%E7%9A%84%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90"><span class="toc-number">2.2.</span> <span class="toc-text">灾难性遗忘的机制分析</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9D%83%E9%87%8D%E6%89%B0%E5%8A%A8-Weight-Perturbation"><span class="toc-number">2.2.1.</span> <span class="toc-text">权重扰动 (Weight Perturbation)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A1%A8%E7%A4%BA%E6%BC%82%E7%A7%BB-Representation-Drift"><span class="toc-number">2.2.2.</span> <span class="toc-text">表示漂移 (Representation Drift)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83%E5%81%8F%E7%A7%BB-Data-Distribution-Shift"><span class="toc-number">2.2.3.</span> <span class="toc-text">数据分布偏移 (Data Distribution Shift)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%A5%9E%E7%BB%8F%E5%85%83%E6%B4%BB%E6%80%A7%E5%8F%98%E5%8C%96-Neuron-Activity-Changes"><span class="toc-number">2.2.4.</span> <span class="toc-text">神经元活性变化 (Neuron Activity Changes)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BA%94%E5%AF%B9%E7%81%BE%E9%9A%BE%E6%80%A7%E9%81%97%E5%BF%98%E7%9A%84%E7%AD%96%E7%95%A5"><span class="toc-number">3.</span> <span class="toc-text">应对灾难性遗忘的策略</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%9B%9E%E6%94%BE-%E9%87%8D%E6%BC%94%E7%9A%84%E6%96%B9%E6%B3%95-Rehearsal-Replay-based-Methods"><span class="toc-number">3.1.</span> <span class="toc-text">基于回放&#x2F;重演的方法 (Rehearsal&#x2F;Replay-based Methods)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B7%E4%BD%93%E6%8A%80%E6%9C%AF%EF%BC%9A"><span class="toc-number">3.1.1.</span> <span class="toc-text">具体技术：</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E7%BB%8F%E9%AA%8C%E5%9B%9E%E6%94%BE-Experience-Replay"><span class="toc-number">3.1.1.1.</span> <span class="toc-text">1. 经验回放 (Experience Replay)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E7%94%9F%E6%88%90%E5%BC%8F%E5%9B%9E%E6%94%BE-Generative-Replay"><span class="toc-number">3.1.1.2.</span> <span class="toc-text">2. 生成式回放 (Generative Replay)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-%E4%BC%AA%E5%9B%9E%E6%94%BE-Pseudo-Replay"><span class="toc-number">3.1.1.3.</span> <span class="toc-text">3. 伪回放 (Pseudo-Replay)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E6%AD%A3%E5%88%99%E5%8C%96%E7%9A%84%E6%96%B9%E6%B3%95-Regularization-based-Methods"><span class="toc-number">3.2.</span> <span class="toc-text">基于正则化的方法 (Regularization-based Methods)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B7%E4%BD%93%E6%8A%80%E6%9C%AF%EF%BC%9A-2"><span class="toc-number">3.2.1.</span> <span class="toc-text">具体技术：</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E5%BC%B9%E6%80%A7%E6%9D%83%E5%80%BC%E5%B7%A9%E5%9B%BA-Elastic-Weight-Consolidation-EWC"><span class="toc-number">3.2.1.1.</span> <span class="toc-text">1. 弹性权值巩固 (Elastic Weight Consolidation, EWC)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-Synaptic-Intelligence-SI"><span class="toc-number">3.2.1.2.</span> <span class="toc-text">2. Synaptic Intelligence (SI)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-Memory-Aware-Synapses-MAS"><span class="toc-number">3.2.1.3.</span> <span class="toc-text">3. Memory Aware Synapses (MAS)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-Learning-without-Forgetting-LwF"><span class="toc-number">3.2.1.4.</span> <span class="toc-text">4. Learning without Forgetting (LwF)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E6%9E%B6%E6%9E%84%E7%9A%84%E6%96%B9%E6%B3%95-Architecture-based-Methods"><span class="toc-number">3.3.</span> <span class="toc-text">基于架构的方法 (Architecture-based Methods)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B7%E4%BD%93%E6%8A%80%E6%9C%AF%EF%BC%9A-3"><span class="toc-number">3.3.1.</span> <span class="toc-text">具体技术：</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E6%B8%90%E8%BF%9B%E5%BC%8F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-Progressive-Neural-Networks-PNNs"><span class="toc-number">3.3.1.1.</span> <span class="toc-text">1. 渐进式神经网络 (Progressive Neural Networks, PNNs)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E5%8A%A8%E6%80%81%E6%89%A9%E5%B1%95%E7%BD%91%E7%BB%9C-Dynamically-Expandable-Networks-DEN"><span class="toc-number">3.3.1.2.</span> <span class="toc-text">2. 动态扩展网络 (Dynamically Expandable Networks, DEN)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-%E5%89%AA%E6%9E%9D%E4%B8%8E%E8%BF%9E%E6%8E%A5-Pruning-and-Rewiring"><span class="toc-number">3.3.1.3.</span> <span class="toc-text">3. 剪枝与连接 (Pruning and Rewiring)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-%E5%9F%BA%E4%BA%8E%E6%8E%A9%E7%A0%81%E7%9A%84%E6%96%B9%E6%B3%95-Mask-based-Methods"><span class="toc-number">3.3.1.4.</span> <span class="toc-text">4. 基于掩码的方法 (Mask-based Methods)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E6%96%B0%E5%85%B4%E6%96%B9%E6%B3%95-Other-Emerging-Methods"><span class="toc-number">3.4.</span> <span class="toc-text">其他新兴方法 (Other Emerging Methods)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E5%85%83%E5%AD%A6%E4%B9%A0-Meta-Learning"><span class="toc-number">3.4.1.</span> <span class="toc-text">1. 元学习 (Meta-Learning)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0-%E8%87%AA%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-Contrastive-Learning-Self-Supervised-Learning"><span class="toc-number">3.4.2.</span> <span class="toc-text">2. 对比学习&#x2F;自监督学习 (Contrastive Learning&#x2F;Self-Supervised Learning)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E7%A5%9E%E7%BB%8F%E7%AC%A6%E5%8F%B7%E6%B7%B7%E5%90%88%E6%96%B9%E6%B3%95-Neuro-Symbolic-Hybrid-Methods"><span class="toc-number">3.4.3.</span> <span class="toc-text">3. 神经符号混合方法 (Neuro-Symbolic Hybrid Methods)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-%E5%8F%AF%E8%A7%A3%E9%87%8AAI-Explainable-AI-XAI-%E4%B8%8E%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%BB%93%E5%90%88"><span class="toc-number">3.4.4.</span> <span class="toc-text">4. 可解释AI (Explainable AI, XAI) 与持续学习的结合</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%84%E4%BC%B0%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.</span> <span class="toc-text">评估持续学习模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E6%8C%87%E6%A0%87"><span class="toc-number">4.1.</span> <span class="toc-text">关键指标</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E5%87%86%E7%A1%AE%E6%80%A7-Accuracy"><span class="toc-number">4.1.1.</span> <span class="toc-text">1. 准确性 (Accuracy)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E9%81%97%E5%BF%98%E5%BA%A6-Forgetting"><span class="toc-number">4.1.2.</span> <span class="toc-text">2. 遗忘度 (Forgetting)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E5%89%8D%E5%90%91%E8%BF%81%E7%A7%BB-Forward-Transfer"><span class="toc-number">4.1.3.</span> <span class="toc-text">3. 前向迁移 (Forward Transfer)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-%E5%8F%8D%E5%90%91%E8%BF%81%E7%A7%BB-Backward-Transfer"><span class="toc-number">4.1.4.</span> <span class="toc-text">4. 反向迁移 (Backward Transfer)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-%E6%A8%A1%E5%9E%8B%E5%AE%B9%E9%87%8F-%E6%95%88%E7%8E%87-Model-Capacity-Efficiency"><span class="toc-number">4.1.5.</span> <span class="toc-text">5. 模型容量&#x2F;效率 (Model Capacity&#x2F;Efficiency)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%84%E4%BC%B0%E8%8C%83%E5%BC%8F"><span class="toc-number">4.2.</span> <span class="toc-text">评估范式</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E9%A1%BA%E5%BA%8F%E4%BB%BB%E5%8A%A1%E8%AF%84%E4%BC%B0-Sequential-Task-Evaluation"><span class="toc-number">4.2.1.</span> <span class="toc-text">1. 顺序任务评估 (Sequential Task Evaluation)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E6%B7%B7%E5%90%88%E4%BB%BB%E5%8A%A1%E8%AF%84%E4%BC%B0-Mixed-Task-Evaluation"><span class="toc-number">4.2.2.</span> <span class="toc-text">2. 混合任务评估 (Mixed Task Evaluation)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8C%81%E7%BB%AD%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%BA%94%E7%94%A8%E5%89%8D%E6%99%AF"><span class="toc-number">5.</span> <span class="toc-text">持续学习的应用前景</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%AD%A6%E4%B9%A0-Robotics-Learning"><span class="toc-number">5.1.</span> <span class="toc-text">1. 机器人学习 (Robotics Learning)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6-Autonomous-Driving"><span class="toc-number">5.2.</span> <span class="toc-text">2. 自动驾驶 (Autonomous Driving)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%8C%BB%E7%96%97%E8%AF%8A%E6%96%AD-Medical-Diagnosis"><span class="toc-number">5.3.</span> <span class="toc-text">3. 医疗诊断 (Medical Diagnosis)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86-Natural-Language-Processing-NLP"><span class="toc-number">5.4.</span> <span class="toc-text">4. 自然语言处理 (Natural Language Processing, NLP)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E4%B8%AA%E6%80%A7%E5%8C%96%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F-Personalized-Recommendation-Systems"><span class="toc-number">5.5.</span> <span class="toc-text">5. 个性化推荐系统 (Personalized Recommendation Systems)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E9%87%91%E8%9E%8D%E6%AC%BA%E8%AF%88%E6%A3%80%E6%B5%8B-Financial-Fraud-Detection"><span class="toc-number">5.6.</span> <span class="toc-text">6. 金融欺诈检测 (Financial Fraud Detection)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E8%AF%AD"><span class="toc-number">6.</span> <span class="toc-text">结语</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/22/hello-world/" title="Hello World">Hello World</a><time datetime="2025-07-22T22:25:10.320Z" title="发表于 2025-07-23 06:25:10">2025-07-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/22/%E5%8D%9A%E5%BC%88%E8%AE%BA%E5%9F%BA%E7%A1%80/" title="博弈论基础">博弈论基础</a><time datetime="2025-07-22T22:25:10.320Z" title="发表于 2025-07-23 06:25:10">2025-07-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/22/2025-07-22-222303/" title="深度剖析：文本风格迁移技术的奥秘与前沿">深度剖析：文本风格迁移技术的奥秘与前沿</a><time datetime="2025-07-22T14:23:03.000Z" title="发表于 2025-07-22 22:23:03">2025-07-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/22/2025-07-22-222136/" title="永不止步的探索：持续学习与灾难性遗忘的挑战与机遇">永不止步的探索：持续学习与灾难性遗忘的挑战与机遇</a><time datetime="2025-07-22T14:21:36.000Z" title="发表于 2025-07-22 22:21:36">2025-07-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/22/2025-07-22-222027/" title="微内核与宏内核之争：深入理解操作系统架构的权衡与选择">微内核与宏内核之争：深入理解操作系统架构的权衡与选择</a><time datetime="2025-07-22T14:20:27.000Z" title="发表于 2025-07-22 22:20:27">2025-07-22</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;2025 By qmwneb946</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.2</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css')
    if (true) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const getGiscusTheme = theme => theme === 'dark' ? 'dark' : 'light'

  const createScriptElement = config => {
    const ele = document.createElement('script')
    Object.entries(config).forEach(([key, value]) => {
      ele.setAttribute(key, value)
    })
    return ele
  }

  const loadGiscus = (el = document, key) => {
    const mappingConfig = isShuoshuo
      ? { 'data-mapping': 'specific', 'data-term': key }
      : { 'data-mapping': (option && option['data-mapping']) || 'pathname' }

    const giscusConfig = {
      src: 'https://giscus.app/client.js',
      'data-repo': 'qmwneb946/blog',
      'data-repo-id': 'R_kgDOPM6cWw',
      'data-category-id': 'DIC_kwDOPM6cW84CtEzo',
      'data-theme': getGiscusTheme(document.documentElement.getAttribute('data-theme')),
      'data-reactions-enabled': '1',
      crossorigin: 'anonymous',
      async: true,
      ...option,
      ...mappingConfig
    }

    const scriptElement = createScriptElement(giscusConfig)

    el.querySelector('#giscus-wrap').appendChild(scriptElement)

    if (isShuoshuo) {
      window.shuoshuoComment.destroyGiscus = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }
  }

  const changeGiscusTheme = theme => {
    const iframe = document.querySelector('#giscus-wrap iframe')
    if (iframe) {
      const message = {
        giscus: {
          setConfig: {
            theme: getGiscusTheme(theme)
          }
        }
      }
      iframe.contentWindow.postMessage(message, 'https://giscus.app')
    }
  }

  btf.addGlobalFn('themeChange', changeGiscusTheme, 'giscus')

  if (isShuoshuo) {
    'Giscus' === 'Giscus'
      ? window.shuoshuoComment = { loadComment: loadGiscus }
      : window.loadOtherComment = loadGiscus
    return
  }

  if ('Giscus' === 'Giscus' || !false) {
    if (false) btf.loadComment(document.getElementById('giscus-wrap'), loadGiscus)
    else loadGiscus()
  } else {
    window.loadOtherComment = loadGiscus
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>