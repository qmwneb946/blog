<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>深入探索文本摘要：抽取式与生成式方法的奥秘 | qmwneb946 的博客</title><meta name="author" content="qmwneb946"><meta name="copyright" content="qmwneb946"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="你好，各位技术和数学爱好者！我是qmwneb946，今天我们将一同踏上一段关于文本摘要技术，特别是其两大核心范式——抽取式（Extractive）与生成式（Abstractive）方法的深度探索之旅。在这个信息爆炸的时代，我们每天被海量的文本数据所淹没，无论是新闻文章、研究论文、报告，还是社交媒体动态。如何在有限的时间内高效获取这些信息的核心要义，成为了一个迫切的需求。文本摘要技术正是为了解决这一">
<meta property="og:type" content="article">
<meta property="og:title" content="深入探索文本摘要：抽取式与生成式方法的奥秘">
<meta property="og:url" content="https://qmwneb946.dpdns.org/2025/07/22/2025-07-22-132623/index.html">
<meta property="og:site_name" content="qmwneb946 的博客">
<meta property="og:description" content="你好，各位技术和数学爱好者！我是qmwneb946，今天我们将一同踏上一段关于文本摘要技术，特别是其两大核心范式——抽取式（Extractive）与生成式（Abstractive）方法的深度探索之旅。在这个信息爆炸的时代，我们每天被海量的文本数据所淹没，无论是新闻文章、研究论文、报告，还是社交媒体动态。如何在有限的时间内高效获取这些信息的核心要义，成为了一个迫切的需求。文本摘要技术正是为了解决这一">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://qmwneb946.dpdns.org/img/icon.png">
<meta property="article:published_time" content="2025-07-22T05:26:23.000Z">
<meta property="article:modified_time" content="2025-07-23T11:46:17.179Z">
<meta property="article:author" content="qmwneb946">
<meta property="article:tag" content="2025">
<meta property="article:tag" content="技术">
<meta property="article:tag" content="文本摘要的抽取式与生成式方法">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://qmwneb946.dpdns.org/img/icon.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "深入探索文本摘要：抽取式与生成式方法的奥秘",
  "url": "https://qmwneb946.dpdns.org/2025/07/22/2025-07-22-132623/",
  "image": "https://qmwneb946.dpdns.org/img/icon.png",
  "datePublished": "2025-07-22T05:26:23.000Z",
  "dateModified": "2025-07-23T11:46:17.179Z",
  "author": [
    {
      "@type": "Person",
      "name": "qmwneb946",
      "url": "https://github.com/qmwneb946"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://qmwneb946.dpdns.org/2025/07/22/2025-07-22-132623/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '深入探索文本摘要：抽取式与生成式方法的奥秘',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2845632165165414" crossorigin="anonymous"></script><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="qmwneb946 的博客" type="application/atom+xml">
</head><body><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">qmwneb946 的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">深入探索文本摘要：抽取式与生成式方法的奥秘</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">深入探索文本摘要：抽取式与生成式方法的奥秘<a class="post-edit-link" href="https://github.com/qmwneb946/blog/edit/main/source/_posts/2025-07-22-132623.md" title="编辑" target="_blank"><i class="fas fa-pencil-alt"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-07-22T05:26:23.000Z" title="发表于 2025-07-22 13:26:23">2025-07-22</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-07-23T11:46:17.179Z" title="更新于 2025-07-23 19:46:17">2025-07-23</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%8A%80%E6%9C%AF/">技术</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><p>你好，各位技术和数学爱好者！我是qmwneb946，今天我们将一同踏上一段关于文本摘要技术，特别是其两大核心范式——抽取式（Extractive）与生成式（Abstractive）方法的深度探索之旅。在这个信息爆炸的时代，我们每天被海量的文本数据所淹没，无论是新闻文章、研究论文、报告，还是社交媒体动态。如何在有限的时间内高效获取这些信息的核心要义，成为了一个迫切的需求。文本摘要技术正是为了解决这一挑战而生，它旨在将冗长复杂的文本浓缩为简洁而富有信息量的短篇摘要。</p>
<p>本文将从文本摘要的基本概念出发，深入剖析抽取式与生成式摘要各自的原理、经典算法、优缺点、面临的挑战以及它们在现实世界中的应用。我们还将探讨评估摘要质量的方法，以及随着深度学习和大型语言模型（LLMs）的兴起，文本摘要技术所经历的革命性变革和未来的发展趋势。准备好了吗？让我们一起揭开文本摘要技术的神秘面纱！</p>
<h2 id="第一部分：文本摘要的基石">第一部分：文本摘要的基石</h2>
<h3 id="什么是文本摘要？">什么是文本摘要？</h3>
<p>文本摘要（Text Summarization）是自然语言处理（NLP）领域的一个核心任务，其目标是从一篇或多篇原文中自动生成一个简短、连贯且信息密度高的新文本，该新文本能够捕捉原文的核心思想，并取代原文进行信息传达。简单来说，它就像是为冗长文章制作的“精华版”或“浓缩咖啡”。</p>
<p>文本摘要的最终目标是帮助用户快速理解文档内容，从而节省阅读时间、提高信息获取效率。它在新闻媒体、搜索引擎、学术研究、智能客服、商业智能等诸多领域都有着广泛而重要的应用。</p>
<h3 id="摘要的类型与挑战">摘要的类型与挑战</h3>
<p>根据输入文档的数量，文本摘要可分为：</p>
<ul>
<li><strong>单文档摘要（Single-document Summarization）：</strong> 从一篇文档中生成摘要。</li>
<li><strong>多文档摘要（Multi-document Summarization）：</strong> 从多篇相关文档中生成一篇融合了所有关键信息的摘要，这需要解决信息冗余和冲突的问题。</li>
</ul>
<p>根据摘要的输出形式，文本摘要可以分为我们今天将要深入探讨的两种主要范式：<strong>抽取式摘要</strong> 和 <strong>生成式摘要</strong>。</p>
<p>尽管文本摘要的应用前景广阔，但它也面临着多方面的挑战：</p>
<ol>
<li><strong>信息保留与压缩比：</strong> 如何在显著压缩文本长度的同时，最大限度地保留原文的关键信息。</li>
<li><strong>连贯性与流畅性：</strong> 摘要必须像人类撰写的一样，在逻辑上连贯，在语言上流畅自然，避免生硬的拼接感。</li>
<li><strong>准确性与事实性：</strong> 摘要中的信息必须与原文事实保持一致，避免误报或“幻觉”（即生成原文中不存在但听起来合理的信息）。</li>
<li><strong>可控性：</strong> 如何根据用户需求（如指定长度、关键词、风格）生成定制化的摘要。</li>
<li><strong>领域适应性：</strong> 针对不同领域（如法律、医学、新闻）的文本，可能需要不同的摘要策略和模型。</li>
</ol>
<h2 id="第二部分：抽取式文本摘要">第二部分：抽取式文本摘要</h2>
<p>抽取式文本摘要（Extractive Text Summarization）是文本摘要领域中历史最悠久、原理相对直观的一种方法。它的核心思想是：<strong>从原始文本中识别并直接提取最重要的句子、短语或关键词，然后将它们组合起来形成摘要</strong>。这个过程就像是使用荧光笔在文章中高亮出关键语句，然后把这些语句按顺序排列起来。</p>
<h3 id="基本原理">基本原理</h3>
<p>抽取式摘要不生成任何新的词语或句子，它的输出完全由原文中的片段构成。这意味着摘要的语言表达、语法结构都直接继承自原文，从而保证了其忠实性和可解释性。通常，抽取式方法会给原文中的每个句子打分，分数最高的句子被认为是“最重要的”，然后根据预设的长度限制选择排名前 N 的句子构成摘要。</p>
<h3 id="经典方法">经典方法</h3>
<p>抽取式摘要方法大致可以分为以下几类：</p>
<h4 id="基于统计学的方法">基于统计学的方法</h4>
<p>这类方法通过分析文本的统计特征来判断句子或词语的重要性。</p>
<ul>
<li>
<p><strong>词频与逆文档频率 (TF-IDF)：</strong><br>
高频词通常被认为是重要的，但一些通用词（如“的”、“是”）即使频率很高也可能不重要。TF-IDF 结合了词频（Term Frequency, TF）和逆文档频率（Inverse Document Frequency, IDF）来衡量一个词在文档中的重要性。一个词的 TF-IDF 值越高，它在文档中的重要性越大。在句子层面，可以计算句子中所有词的 TF-IDF 值之和或平均值，以此作为句子的重要性得分。</p>
<p>TF-IDF 计算公式：<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>F</mi><mo stretchy="false">(</mo><mi>t</mi><mo separator="true">,</mo><mi>d</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mtext>词t在文档d中出现的次数</mtext><mtext>文档d中词的总数</mtext></mfrac></mrow><annotation encoding="application/x-tex">TF(t, d) = \frac{\text{词t在文档d中出现的次数}}{\text{文档d中词的总数}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">TF</span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">d</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2251em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord cjk_fallback mtight">文档</span><span class="mord mtight">d</span><span class="mord cjk_fallback mtight">中词的总数</span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord cjk_fallback mtight">词</span><span class="mord mtight">t</span><span class="mord cjk_fallback mtight">在文档</span><span class="mord mtight">d</span><span class="mord cjk_fallback mtight">中出现的次数</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mi>D</mi><mi>F</mi><mo stretchy="false">(</mo><mi>t</mi><mo separator="true">,</mo><mi>D</mi><mo stretchy="false">)</mo><mo>=</mo><mi>log</mi><mo>⁡</mo><mfrac><mtext>文档集D中的文档总数</mtext><mrow><mtext>包含词t的文档数量</mtext><mo>+</mo><mn>1</mn></mrow></mfrac></mrow><annotation encoding="application/x-tex">IDF(t, D) = \log \frac{\text{文档集D中的文档总数}}{\text{包含词t的文档数量} + 1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2757em;vertical-align:-0.4033em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord cjk_fallback mtight">包含词</span><span class="mord mtight">t</span><span class="mord cjk_fallback mtight">的文档数量</span></span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord cjk_fallback mtight">文档集</span><span class="mord mtight">D</span><span class="mord cjk_fallback mtight">中的文档总数</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>F</mi><mi>I</mi><mi>D</mi><mi>F</mi><mo stretchy="false">(</mo><mi>t</mi><mo separator="true">,</mo><mi>d</mi><mo separator="true">,</mo><mi>D</mi><mo stretchy="false">)</mo><mo>=</mo><mi>T</mi><mi>F</mi><mo stretchy="false">(</mo><mi>t</mi><mo separator="true">,</mo><mi>d</mi><mo stretchy="false">)</mo><mo>×</mo><mi>I</mi><mi>D</mi><mi>F</mi><mo stretchy="false">(</mo><mi>t</mi><mo separator="true">,</mo><mi>D</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">TFIDF(t, d, D) = TF(t, d) \times IDF(t, D)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">TF</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">d</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">TF</span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">d</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mopen">(</span><span class="mord mathnormal">t</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mclose">)</span></span></span></span></p>
</li>
<li>
<p><strong>基于句子的特征：</strong></p>
<ul>
<li><strong>句子位置：</strong> 人们发现文章的首句和末句通常包含重要信息。</li>
<li><strong>句子长度：</strong> 过短或过长的句子可能信息量不足。</li>
<li><strong>关键词密度：</strong> 包含更多关键词的句子可能更重要。</li>
<li><strong>指示词：</strong> 包含“因此”、“总之”、“研究表明”等指示性词语的句子往往是结论性或概括性的。</li>
<li><strong>命名实体：</strong> 包含更多命名实体（人名、地名、组织名）的句子可能更具信息量。</li>
</ul>
</li>
</ul>
<h4 id="基于图的方法">基于图的方法</h4>
<p>图模型在抽取式摘要中表现出色，其中最著名的就是 TextRank 和 LexRank。这些方法将文档中的句子视为图的节点，句子之间的相似度作为边的权重，然后利用图排序算法（如 PageRank）来评估节点（句子）的重要性。</p>
<ul>
<li>
<p><strong>TextRank 算法：</strong><br>
TextRank 是 PageRank 算法在文本领域的应用。PageRank 最初用于评估网页的重要性，而 TextRank 则用于评估句子或关键词的重要性。</p>
<p><strong>工作原理：</strong></p>
<ol>
<li><strong>构建图：</strong> 将文档中的每个句子表示为一个节点。</li>
<li><strong>计算边权重：</strong> 计算任意两个句子之间的相似度作为它们之间边的权重。相似度通常通过计算词语重叠（如 Jaccard 相似度、余弦相似度）或语义相似度（如词向量余弦相似度）来获得。</li>
<li><strong>迭代排序：</strong> 类似于 PageRank，节点的重要性得分根据其连接的其他节点的重要性以及连接它们的边的权重迭代计算。得分高的句子被认为是更重要的。</li>
</ol>
<p>TextRank 的迭代计算公式（简化版，针对句子 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">V_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>）：<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo stretchy="false">(</mo><msub><mi>V</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>d</mi><mo stretchy="false">)</mo><mo>+</mo><mi>d</mi><msub><mo>∑</mo><mrow><msub><mi>V</mi><mi>j</mi></msub><mo>∈</mo><mi>I</mi><mi>n</mi><mo stretchy="false">(</mo><msub><mi>V</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></msub><mfrac><msub><mi>w</mi><mrow><mi>j</mi><mi>i</mi></mrow></msub><mrow><msub><mo>∑</mo><mrow><msub><mi>V</mi><mi>k</mi></msub><mo>∈</mo><mi>O</mi><mi>u</mi><mi>t</mi><mo stretchy="false">(</mo><msub><mi>V</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow></msub><msub><mi>w</mi><mrow><mi>j</mi><mi>k</mi></mrow></msub></mrow></mfrac><mi>S</mi><mo stretchy="false">(</mo><msub><mi>V</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">S(V_i) = (1-d) + d \sum_{V_j \in In(V_i)} \frac{w_{ji}}{\sum_{V_k \in Out(V_j)} w_{jk}} S(V_j)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.6333em;vertical-align:-0.8246em;"></span><span class="mord mathnormal">d</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2253em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.2222em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em;"><span></span></span></span></span></span></span><span class="mrel mtight">∈</span><span class="mord mathnormal mtight" style="margin-right:0.07847em;">I</span><span class="mord mathnormal mtight">n</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.2222em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.497em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8087em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2143em;"><span style="top:-2.2143em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5357em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3448em;margin-left:-0.2222em;margin-right:0.1em;"><span class="pstrut" style="height:2.6944em;"></span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3496em;"><span></span></span></span></span></span></span><span class="mrel mtight">∈</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">O</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3448em;margin-left:-0.2222em;margin-right:0.1em;"><span class="pstrut" style="height:2.6595em;"></span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5092em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.6851em;"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.1952em;"></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:-0.0269em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">jk</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2901em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.5073em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0269em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ji</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8246em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><br>
其中：</p>
<ul>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi><mo stretchy="false">(</mo><msub><mi>V</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">S(V_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 是句子 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">V_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的重要性得分。</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">d</span></span></span></span> 是阻尼系数（通常设为 0.85），表示随机跳转到其他节点的概率。</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>I</mi><mi>n</mi><mo stretchy="false">(</mo><msub><mi>V</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">In(V_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal">n</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 是指向 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">V_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的所有句子集合。</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mi>u</mi><mi>t</mi><mo stretchy="false">(</mo><msub><mi>V</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Out(V_j)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 是从 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">V_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 指向的所有句子集合。</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mi>j</mi><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{ji}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ji</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 是从 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">V_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">V_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的边的权重（即句子 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">V_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">V_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的相似度）。</li>
<li>当计算无向图时，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mrow><mi>j</mi><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">w_{ji}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0269em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ji</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 只是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">V_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">V_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 的相似度，分母是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>V</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">V_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 的总连接强度。</li>
</ul>
<p><strong>示例伪代码 (概念性)：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">textrank_summarize</span>(<span class="params">text, num_sentences</span>):</span><br><span class="line">    <span class="comment"># 1. 句子切分</span></span><br><span class="line">    sentences = split_into_sentences(text)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2. 构建相似度矩阵 (图的邻接矩阵)</span></span><br><span class="line">    similarity_matrix = calculate_sentence_similarity(sentences)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 3. 初始化句子得分</span></span><br><span class="line">    scores = &#123;i: <span class="number">1.0</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(sentences))&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 4. 迭代计算得分 (PageRank算法核心)</span></span><br><span class="line">    damping_factor = <span class="number">0.85</span></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(max_iterations):</span><br><span class="line">        new_scores = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> i, sentence_i <span class="keyword">in</span> <span class="built_in">enumerate</span>(sentences):</span><br><span class="line">            rank_score = (<span class="number">1</span> - damping_factor)</span><br><span class="line">            <span class="keyword">for</span> j, sentence_j <span class="keyword">in</span> <span class="built_in">enumerate</span>(sentences):</span><br><span class="line">                <span class="keyword">if</span> i != j:</span><br><span class="line">                    <span class="comment"># 边权重 / (出度之和) * 对方分数</span></span><br><span class="line">                    <span class="keyword">if</span> <span class="built_in">sum</span>(similarity_matrix[j]) &gt; <span class="number">0</span>: <span class="comment"># 避免除以零</span></span><br><span class="line">                        rank_score += damping_factor * (similarity_matrix[j][i] / <span class="built_in">sum</span>(similarity_matrix[j])) * scores[j]</span><br><span class="line">            new_scores[i] = rank_score</span><br><span class="line">        scores = new_scores <span class="comment"># 更新得分</span></span><br><span class="line">        <span class="comment"># 可以添加收敛判断</span></span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 5. 根据得分排序并选择最重要的N个句子</span></span><br><span class="line">    ranked_sentences = <span class="built_in">sorted</span>(((scores[i], s) <span class="keyword">for</span> i, s <span class="keyword">in</span> <span class="built_in">enumerate</span>(sentences)), reverse=<span class="literal">True</span>)</span><br><span class="line">    summary_sentences = [s <span class="keyword">for</span> score, s <span class="keyword">in</span> ranked_sentences[:num_sentences]]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 6. 按照原文顺序重新排列摘要句子</span></span><br><span class="line">    summary = sort_sentences_by_original_order(summary_sentences, original_sentences)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot; &quot;</span>.join(summary)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="基于机器学习的方法">基于机器学习的方法</h4>
<p>更复杂的抽取式方法会利用机器学习模型，将摘要任务视为一个分类问题：对于原文中的每一个句子，模型预测它是否应该被包含在摘要中（二分类）。</p>
<ul>
<li><strong>特征工程：</strong> 需要手动提取大量特征，包括：
<ul>
<li><strong>位置特征：</strong> 句子在文档中的相对位置。</li>
<li><strong>内容特征：</strong> TF-IDF、词性、命名实体密度、句子长度。</li>
<li><strong>句法特征：</strong> 句子是否是完整句、是否包含特定句法结构。</li>
<li><strong>主题特征：</strong> 句子与文档主题的相关性。</li>
</ul>
</li>
<li><strong>模型选择：</strong> 早期常用模型包括支持向量机（SVM）、条件随机场（CRF）、决策树等。</li>
<li><strong>监督学习：</strong> 需要大量已有人工摘要的文档作为训练数据，将人工摘要中的句子标记为“重要”，原文中未被选中的句子标记为“不重要”。</li>
</ul>
<h3 id="优点">优点</h3>
<ol>
<li><strong>忠实于原文：</strong> 由于直接提取原文片段，摘要内容与原文高度一致，不易出现事实性错误或“幻觉”现象。</li>
<li><strong>可解释性强：</strong> 摘要中的每个句子都可以追溯到原文，用户可以清楚地知道摘要是如何形成的。</li>
<li><strong>计算成本相对较低：</strong> 相较于生成式方法，抽取式通常不需要复杂的神经网络结构和庞大的训练数据，计算资源需求较低。</li>
<li><strong>避免语法错误：</strong> 直接使用原文的句子，保证了摘要的语法正确性。</li>
</ol>
<h3 id="缺点">缺点</h3>
<ol>
<li><strong>连贯性与流畅性差：</strong> 提取的句子可能在上下文衔接上不自然，导致摘要读起来像是一系列不相关的句子拼接。</li>
<li><strong>冗余性：</strong> 不同的句子可能表达相同或相似的信息，导致摘要中存在冗余。</li>
<li><strong>无法概括和生成新信息：</strong> 无法对原文信息进行重新组织、概括或推断，也无法生成原文中没有出现过的词语或句子。这意味着它在处理需要高度抽象或总结的任务时表现不佳。</li>
<li><strong>摘要长度不易控制：</strong> 只能通过选择句子的数量来控制长度，可能无法精确达到预设的字符或词数限制。</li>
</ol>
<h3 id="应用场景">应用场景</h3>
<p>抽取式摘要因其高忠实度和相对较低的计算成本，在许多对精确性要求较高的场景中仍有广泛应用：</p>
<ul>
<li><strong>新闻摘要：</strong> 快速生成新闻稿的摘要，用户可以一目了然地获取新闻要点。</li>
<li><strong>文档预览：</strong> 为用户提供长篇文档（如报告、论文）的快速预览，帮助判断是否值得深入阅读。</li>
<li><strong>搜索引擎结果摘要：</strong> 在搜索结果页面展示的摘要通常是抽取式的，直接从网页中提取相关片段。</li>
<li><strong>法律文档摘要：</strong> 确保摘要不偏离原文，维护法律严谨性。</li>
</ul>
<h2 id="第三部分：生成式文本摘要">第三部分：生成式文本摘要</h2>
<p>生成式文本摘要（Abstractive Text Summarization）是文本摘要领域更具挑战性也更符合人类认知模式的一种方法。它不简单地从原文中复制粘贴，而是<strong>在理解原文内容的基础上，利用自然语言生成（NLG）技术，用全新的语言和表述来重写摘要</strong>。这个过程更像是人类阅读完一篇文章后，用自己的话概括其主要内容。</p>
<h3 id="基本原理-2">基本原理</h3>
<p>生成式摘要的核心在于模型对原文的“理解”和“重构”能力。它需要能够识别原文中的关键信息，去除冗余，然后以更简洁、流畅、连贯的方式重新表达这些信息，甚至可以引入原文中没有出现过的新词语或句式。</p>
<h3 id="发展历程与模型">发展历程与模型</h3>
<p>生成式摘要技术的发展与深度学习尤其是神经网络模型的进步密不可分。</p>
<h4 id="早期尝试">早期尝试</h4>
<p>在深度学习兴起之前，生成式摘要的尝试非常有限且效果不佳。主要包括：</p>
<ul>
<li><strong>基于规则的方法：</strong> 依赖于专家设计的语法和语义规则，难以覆盖语言的复杂性和多样性。</li>
<li><strong>基于语义解析的方法：</strong> 尝试将文本解析成语义表示（如逻辑形式），然后从语义表示中生成摘要。但语义解析本身就是NLP领域的难题。</li>
</ul>
<p>这些早期方法由于语言的复杂性和泛化能力的不足，未能大规模应用。</p>
<h4 id="基于序列到序列模型-Sequence-to-Sequence-Models">基于序列到序列模型 (Sequence-to-Sequence Models)</h4>
<p>生成式摘要的真正突破始于2014年 Seq2Seq 模型的提出。Seq2Seq 模型是一种通用的编码器-解码器（Encoder-Decoder）架构，非常适合处理输入序列到输出序列的转换任务，如机器翻译、文本摘要等。</p>
<ul>
<li>
<p><strong>Encoder-Decoder 架构：</strong></p>
<ul>
<li><strong>编码器（Encoder）：</strong> 读取原文，将其编码为一个固定长度的“上下文向量”或“语义表示”，这个向量包含了原文的核心信息。</li>
<li><strong>解码器（Decoder）：</strong> 接收编码器生成的上下文向量，并逐步生成摘要中的每一个词，直到生成结束标志。</li>
</ul>
</li>
<li>
<p><strong>循环神经网络（RNN）及其变体：</strong> 早期 Seq2Seq 模型通常使用循环神经网络（RNN）、长短时记忆网络（LSTM）或门控循环单元（GRU）作为编码器和解码器的基本单元。</p>
<ul>
<li>RNN 能够处理序列数据，但存在长期依赖问题（梯度消失/爆炸）。</li>
<li>LSTM 和 GRU 通过引入门控机制，有效缓解了长期依赖问题，使得模型能够处理更长的文本序列。</li>
</ul>
</li>
<li>
<p><strong>注意力机制（Attention Mechanism）：</strong><br>
虽然 LSTM/GRU 缓解了长期依赖问题，但单一的上下文向量在处理长文本时仍然面临信息瓶颈。注意力机制（2015年提出）解决了这一问题。<br>
<strong>工作原理：</strong> 在解码器生成每个词时，它不再仅仅依赖于一个固定的上下文向量，而是会“关注”编码器不同部分的输出。这意味着解码器在生成摘要的某一部分时，可以动态地选择关注原文的哪个部分。</p>
<p>注意力机制的计算通常包括：</p>
<ol>
<li><strong>计算对齐分数（Alignment Score）：</strong> 将解码器当前隐藏状态 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">s_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 与编码器每个时间步的隐藏状态 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">h_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 进行匹配，得到一个分数，表示 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">s_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 对 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">h_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 的关注程度。<br>
例如，点积注意力：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><msubsup><mi>s</mi><mi>i</mi><mi>T</mi></msubsup><msub><mi>h</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">e_{ij} = s_i^T h_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1274em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-2.4413em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2587em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span><br>
或加性注意力：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><msubsup><mi>v</mi><mi>a</mi><mi>T</mi></msubsup><mi>tanh</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>W</mi><mi>s</mi></msub><msub><mi>s</mi><mi>i</mi></msub><mo>+</mo><msub><mi>W</mi><mi>h</mi></msub><msub><mi>h</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">e_{ij} = v_a^T \tanh(W_s s_i + W_h h_j)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0913em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-2.453em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">a</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">tanh</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></li>
<li><strong>归一化：</strong> 对对齐分数进行 softmax 归一化，得到注意力权重 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\alpha_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span>。<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>e</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">)</mo></mrow><mrow><msubsup><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>T</mi><mi>x</mi></msub></msubsup><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>e</mi><mrow><mi>i</mi><mi>k</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\alpha_{ij} = \frac{\exp(e_{ij})}{\sum_{k=1}^{T_x} \exp(e_{ik})}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.7684em;vertical-align:-0.7361em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0323em;"><span style="top:-2.507em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9757em;"><span style="top:-2.1528em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-2.9877em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2306em;"><span style="top:-2.3em;margin-left:-0.1389em;margin-right:0.1em;"><span class="pstrut" style="height:2.5em;"></span><span class="mord mathnormal mtight">x</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3472em;"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.1952em;"></span><span class="mop mtight"><span class="mtight">e</span><span class="mtight">x</span><span class="mtight">p</span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">ik</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.5073em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mtight">e</span><span class="mtight">x</span><span class="mtight">p</span></span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7361em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></li>
<li><strong>加权求和：</strong> 将编码器隐藏状态 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">h_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 根据注意力权重 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\alpha_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 加权求和，得到一个动态的上下文向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>c</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">c_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>c</mi><mi>i</mi></msub><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>T</mi><mi>x</mi></msub></msubsup><msub><mi>α</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><msub><mi>h</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">c_i = \sum_{j=1}^{T_x} \alpha_{ij} h_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.417em;vertical-align:-0.4358em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em;"><span style="top:-2.357em;margin-left:-0.1389em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span><br>
这个上下文向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>c</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">c_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 会作为解码器下一步生成词的输入。</li>
</ol>
<p>注意力机制极大地提升了 Seq2Seq 模型在长文本处理任务上的表现，成为后来所有先进神经网络模型的基础。</p>
</li>
</ul>
<h4 id="基于-Transformer-的模型">基于 Transformer 的模型</h4>
<p>Transformer 模型（2017年提出）彻底改变了序列建模的范式，取代了 RNN/LSTM 成为主流。它的核心是<strong>自注意力机制（Self-Attention）</strong>，它允许模型在编码或解码过程中并行地关注序列中所有位置的信息，极大地提高了训练效率和模型表达能力。</p>
<ul>
<li>
<p><strong>自注意力（Self-Attention）：</strong><br>
每个词的表示都是通过关注序列中所有其他词（包括自身）的加权和来计算的。这种机制使得模型能够捕捉到任意距离的词之间的依赖关系。</p>
<p>Scaled Dot-Product Attention 公式：<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo stretchy="false">)</mo><mi>V</mi></mrow><annotation encoding="application/x-tex">Attention(Q, K, V) = softmax(\frac{QK^T}{\sqrt{d_k}})V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">A</span><span class="mord mathnormal">tt</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.6275em;vertical-align:-0.538em;"></span><span class="mord mathnormal">so</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0895em;"><span style="top:-2.5864em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8622em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mtight" style="padding-left:0.833em;"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span></span></span><span style="top:-2.8222em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail mtight" style="min-width:0.853em;height:1.08em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1778em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4461em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">Q</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9191em;"><span style="top:-2.931em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.538em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span><br>
其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span>（Query）、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span>（Key）、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span>（Value）是输入矩阵通过线性变换得到的三个矩阵，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">d_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是键向量的维度，用于缩放点积。</p>
</li>
<li>
<p><strong>多头注意力（Multi-Head Attention）：</strong><br>
通过并行运行多个自注意力机制，并将它们的输出拼接起来，模型可以在不同的“表示子空间”中学习不同的注意力模式，从而捕捉更丰富的语义信息。</p>
</li>
<li>
<p><strong>预训练语言模型（Pre-trained Language Models, PLMs）：</strong><br>
基于 Transformer 的大规模预训练语言模型，如 BERT、GPT 系列、T5、BART 等，在文本摘要任务上取得了革命性的进展。</p>
<ul>
<li><strong>BERT (Bidirectional Encoder Representations from Transformers):</strong> 主要作为编码器，通过掩码语言模型（MLM）和下一句预测（NSP）进行预训练，擅长文本理解。</li>
<li><strong>GPT (Generative Pre-trained Transformer):</strong> 采用纯解码器架构，通过单向语言模型进行预训练，擅长文本生成。</li>
<li><strong>T5 (Text-to-Text Transfer Transformer):</strong> 将所有NLP任务统一为“文本到文本”的任务，双向编码器-解码器架构，在摘要等多种任务上表现出色。</li>
<li><strong>BART (Bidirectional and Auto-Regressive Transformers):</strong> 结合了 BERT 的双向编码器和 GPT 的自回归解码器，通过去噪自编码器（denoising autoencoder）进行预训练，特别适合生成任务。</li>
</ul>
<p>这些预训练模型在海量无标注文本上学习了丰富的语言知识和语义模式，只需在特定摘要数据集上进行<strong>微调（fine-tuning）</strong>，就能达到SOTA（State-Of-The-Art）性能。微调过程通常是将原文作为输入，摘要作为目标输出，训练模型生成与目标摘要尽可能接近的文本。</p>
</li>
</ul>
<h3 id="训练策略与挑战">训练策略与挑战</h3>
<h4 id="数据">数据</h4>
<p>生成式摘要模型的训练需要大规模的<strong>高质量、配对的（原文-摘要）数据集</strong>。常见的公开数据集包括：</p>
<ul>
<li><strong>CNN/Daily Mail：</strong> 包含大量新闻文章及其对应的子弹点式摘要。</li>
<li><strong>XSum (Extreme Summarization)：</strong> 包含BBC新闻文章和单句高度抽象的摘要，挑战性更高。</li>
<li><strong>PubMed/ArXiv：</strong> 包含科学论文及其摘要。</li>
</ul>
<p>数据的质量和规模对模型性能至关重要。</p>
<h4 id="评估指标">评估指标</h4>
<p>评估生成式摘要的质量比抽取式更复杂，因为需要衡量其流畅性、连贯性、信息量以及是否忠实于原文。最常用的自动评估指标是 <strong>ROUGE (Recall-Oriented Understudy for Gisting Evaluation)</strong>。</p>
<ul>
<li>
<p><strong>ROUGE 原理：</strong> 通过计算模型生成的摘要（candidate summary）与人工撰写的参考摘要（reference summary）之间的词语重叠度来评估。它关注“召回率”（Recall），即参考摘要中的多少内容被模型摘要捕获。</p>
</li>
<li>
<p><strong>ROUGE-N：</strong> 基于 N-gram 重叠。<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mi>O</mi><mi>U</mi><mi>G</mi><mi>E</mi><mo>−</mo><mi>N</mi><mo>=</mo><mfrac><mrow><msub><mo>∑</mo><mrow><mi>S</mi><mo>∈</mo><mo stretchy="false">{</mo><mtext>参考摘要</mtext><mo stretchy="false">}</mo></mrow></msub><msub><mo>∑</mo><mrow><mi>n</mi><mi>g</mi><mi>r</mi><mi>a</mi><mi>m</mi><mo>∈</mo><mi>S</mi></mrow></msub><mtext>Count</mtext><mo stretchy="false">(</mo><mi>n</mi><mi>g</mi><mi>r</mi><mi>a</mi><mi>m</mi><mo stretchy="false">)</mo></mrow><mrow><msub><mo>∑</mo><mrow><mi>S</mi><mo>∈</mo><mo stretchy="false">{</mo><mtext>参考摘要</mtext><mo stretchy="false">}</mo></mrow></msub><msub><mo>∑</mo><mrow><mi>n</mi><mi>g</mi><mi>r</mi><mi>a</mi><mi>m</mi><mo>∈</mo><mi>S</mi></mrow></msub><msub><mtext>Count</mtext><mtext>ref</mtext></msub><mo stretchy="false">(</mo><mi>n</mi><mi>g</mi><mi>r</mi><mi>a</mi><mi>m</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">ROUGE-N = \frac{\sum_{S \in \{\text{参考摘要}\}} \sum_{ngram \in S} \text{Count}(ngram)}{\sum_{S \in \{\text{参考摘要}\}} \sum_{ngram \in S} \text{Count}_{\text{ref}}(ngram)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">RO</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mord mathnormal" style="margin-right:0.05764em;">GE</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.88em;vertical-align:-0.695em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.185em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2143em;"><span style="top:-2.2143em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5357em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span><span class="mrel mtight">∈</span><span class="mopen mtight">{</span><span class="mord text mtight"><span class="mord cjk_fallback mtight">参考摘要</span></span><span class="mclose mtight">}</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5em;"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.1952em;"></span><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1667em;"><span style="top:-2.1786em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">am</span><span class="mrel mtight">∈</span><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4603em;"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.1952em;"></span><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">Count</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">ref</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1512em;"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">am</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.66em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2143em;"><span style="top:-2.2143em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5357em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span><span class="mrel mtight">∈</span><span class="mopen mtight">{</span><span class="mord text mtight"><span class="mord cjk_fallback mtight">参考摘要</span></span><span class="mclose mtight">}</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5em;"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.1952em;"></span><span class="mop mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1667em;"><span style="top:-2.1786em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">am</span><span class="mrel mtight">∈</span><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4603em;"><span></span></span></span></span></span></span><span class="mspace mtight" style="margin-right:0.1952em;"></span><span class="mord text mtight"><span class="mord mtight">Count</span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">g</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">am</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.695em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><br>
其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mi>o</mi><mi>u</mi><mi>n</mi><mi>t</mi><mo stretchy="false">(</mo><mi>n</mi><mi>g</mi><mi>r</mi><mi>a</mi><mi>m</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Count(ngram)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">am</span><span class="mclose">)</span></span></span></span> 是模型摘要和参考摘要共有的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>g</mi><mi>r</mi><mi>a</mi><mi>m</mi></mrow><annotation encoding="application/x-tex">ngram</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">am</span></span></span></span> 数量，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mi>o</mi><mi>u</mi><mi>n</mi><msub><mi>t</mi><mtext>ref</mtext></msub><mo stretchy="false">(</mo><mi>n</mi><mi>g</mi><mi>r</mi><mi>a</mi><mi>m</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Count_{\text{ref}}(ngram)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">n</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">ref</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">am</span><span class="mclose">)</span></span></span></span> 是参考摘要中的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>g</mi><mi>r</mi><mi>a</mi><mi>m</mi></mrow><annotation encoding="application/x-tex">ngram</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">am</span></span></span></span> 数量。</p>
<ul>
<li><strong>ROUGE-1：</strong> 基于单词（unigram）重叠，衡量摘要的信息覆盖度。</li>
<li><strong>ROUGE-2：</strong> 基于双词（bigram）重叠，衡量摘要的流畅性和局部连贯性。</li>
</ul>
</li>
<li>
<p><strong>ROUGE-L：</strong> 基于最长公共子序列（Longest Common Subsequence, LCS）。它能捕捉句子的整体结构相似性，而无需考虑 N-gram 的连续性。<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mi>O</mi><mi>U</mi><mi>G</mi><mi>E</mi><mo>−</mo><mi>L</mi><mo>=</mo><mfrac><mrow><mi>L</mi><mi>C</mi><mi>S</mi><mo stretchy="false">(</mo><mtext>candidate</mtext><mo separator="true">,</mo><mtext>reference</mtext><mo stretchy="false">)</mo></mrow><mrow><mtext>length</mtext><mo stretchy="false">(</mo><mtext>reference</mtext><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">ROUGE-L = \frac{LCS(\text{candidate}, \text{reference})}{\text{length}(\text{reference})}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">RO</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mord mathnormal" style="margin-right:0.05764em;">GE</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.53em;vertical-align:-0.52em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">length</span></span><span class="mopen mtight">(</span><span class="mord text mtight"><span class="mord mtight">reference</span></span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">L</span><span class="mord mathnormal mtight" style="margin-right:0.05764em;">CS</span><span class="mopen mtight">(</span><span class="mord text mtight"><span class="mord mtight">candidate</span></span><span class="mpunct mtight">,</span><span class="mord text mtight"><span class="mord mtight">reference</span></span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> (通常报告 F1 分数)</p>
</li>
<li>
<p><strong>ROUGE-S：</strong> 基于跳跃二元组（Skip-Bigram）重叠，允许 N-gram 之间存在跳跃。</p>
</li>
</ul>
<p><strong>ROUGE 的局限性：</strong></p>
<ul>
<li><strong>偏爱抽取式摘要：</strong> 由于基于词语重叠，ROUGE 更倾向于那些直接从原文中提取词语的摘要，对生成了大量新词的生成式摘要评估不准确。</li>
<li><strong>无法衡量流畅性与连贯性：</strong> 尽管 ROUGE-2 和 ROUGE-L 试图捕捉结构信息，但它们仍不能完全评估摘要的语法正确性、逻辑连贯性和自然流畅度。</li>
<li><strong>不考虑语义：</strong> 仅仅是词语重叠，无法判断语义是否相同但表达方式不同。</li>
<li><strong>无法衡量事实准确性：</strong> ROUGE 无法检测摘要中是否存在“幻觉”或不符合原文事实的信息。</li>
</ul>
<p>因此，除了 ROUGE，<strong>人工评估</strong>仍然是衡量摘要质量的黄金标准。此外，一些新的自动评估指标如 <strong>BERTScore</strong> 开始流行，它基于预训练语言模型计算摘要与参考摘要之间的语义相似度，而非简单的词语重叠。</p>
<h4 id="挑战">挑战</h4>
<ol>
<li><strong>幻觉问题（Hallucination）：</strong> 生成式摘要最大的挑战之一是“幻觉”，即模型生成了原文中不存在但听起来合理的信息，或者生成了与原文事实相悖的信息。这严重影响了摘要的可靠性和可信度。</li>
<li><strong>事实准确性：</strong> 如何确保模型生成的摘要与原文事实完全一致，尤其是在处理需要高度精确的信息（如医疗、法律文档）时。</li>
<li><strong>连贯性与流畅性：</strong> 尽管 Transformer 模型有所改善，但在长文本摘要中，如何保持生成的摘要在逻辑上严密、语言上流畅自然，仍然是一个难题。</li>
<li><strong>长文本处理：</strong> 尽管 Transformer 模型打破了 RNN 的序列长度限制，但其计算复杂度（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>L</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(L^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，L为序列长度）使得处理超长文档（如书籍、多文档集合）依然面临内存和计算瓶颈。</li>
<li><strong>可控性：</strong> 如何让模型根据用户的特定指令（如生成指定长度、风格、强调特定方面）来生成摘要。</li>
<li><strong>计算资源：</strong> 训练和部署大型生成式摘要模型需要庞大的计算资源（GPU、内存）。</li>
</ol>
<h3 id="优点-2">优点</h3>
<ol>
<li><strong>摘要更自然、流畅、简洁：</strong> 能够重组句子，使用更简洁的表达，读起来更像人类撰写。</li>
<li><strong>能够概括和生成新信息：</strong> 可以对原文内容进行提炼、抽象和推理，甚至生成原文中没有出现过的新词语或表达，提供更深层次的总结。</li>
<li><strong>更强的压缩比：</strong> 在相同信息量下，生成式摘要通常能达到更高的压缩比。</li>
<li><strong>适应性强：</strong> 理论上可以处理各种类型的文本，只要有足够的训练数据。</li>
</ol>
<h3 id="缺点-2">缺点</h3>
<ol>
<li><strong>训练数据需求大：</strong> 需要大量的、高质量的（原文-摘要）配对数据集。</li>
<li><strong>计算成本高：</strong> 训练和推理大型生成模型需要大量的计算资源。</li>
<li><strong>易产生幻觉：</strong> 最大的问题，摘要可能包含与原文事实不符的信息。</li>
<li><strong>可解释性差：</strong> 作为“黑箱”模型，难以理解模型为何生成特定的词语或句子。</li>
<li><strong>事实准确性难以保证：</strong> 需要额外的机制来验证生成摘要的准确性。</li>
</ol>
<h3 id="应用场景-2">应用场景</h3>
<p>生成式摘要因其能够提供更智能、更人性化的总结，在许多领域展现出巨大潜力：</p>
<ul>
<li><strong>智能客服与问答系统：</strong> 对用户咨询或对话记录进行总结，快速提取关键信息。</li>
<li><strong>新闻快讯与报告生成：</strong> 自动生成新闻简报、会议纪要或商业报告的摘要。</li>
<li><strong>内容创作辅助：</strong> 帮助作者快速生成文章草稿、段落总结或大纲。</li>
<li><strong>学术论文摘要：</strong> 自动生成论文的摘要或引言部分。</li>
<li><strong>智能助手：</strong> 为用户提供网页、邮件、文档的快速概览。</li>
</ul>
<h2 id="第四部分：抽取式与生成式：对比与融合">第四部分：抽取式与生成式：对比与融合</h2>
<p>在理解了抽取式和生成式摘要各自的原理与特点后，我们来系统地对比它们的核心差异，并探讨如何将两者的优势结合起来，形成混合式摘要方法。</p>
<h3 id="核心差异对比">核心差异对比</h3>
<table>
<thead>
<tr>
<th style="text-align:left">特征</th>
<th style="text-align:left">抽取式文本摘要 (Extractive)</th>
<th style="text-align:left">生成式文本摘要 (Abstractive)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>生成方式</strong></td>
<td style="text-align:left">从原文中选择并拼接关键句子或短语</td>
<td style="text-align:left">理解原文内容，然后用新的语言重写摘要</td>
</tr>
<tr>
<td style="text-align:left"><strong>信息来源</strong></td>
<td style="text-align:left">完全来自原文</td>
<td style="text-align:left">源于对原文的理解，可重构或创造新表达</td>
</tr>
<tr>
<td style="text-align:left"><strong>忠实度</strong></td>
<td style="text-align:left">高，直接引用原文，保证事实准确</td>
<td style="text-align:left">较低，易产生“幻觉”，需要额外验证</td>
</tr>
<tr>
<td style="text-align:left"><strong>流畅性与连贯性</strong></td>
<td style="text-align:left">较低，可能存在跳跃和生硬感</td>
<td style="text-align:left">高，摘要更自然、流畅、符合语法</td>
</tr>
<tr>
<td style="text-align:left"><strong>可解释性</strong></td>
<td style="text-align:left">强，每个句子都可追溯到原文</td>
<td style="text-align:left">弱，作为“黑箱”模型，难以追溯生成过程</td>
</tr>
<tr>
<td style="text-align:left"><strong>压缩比</strong></td>
<td style="text-align:left">相对较低，受句子结构限制</td>
<td style="text-align:left">较高，可进行高度概括和精简</td>
</tr>
<tr>
<td style="text-align:left"><strong>新信息生成</strong></td>
<td style="text-align:left">无，无法概括、推理或引入原文外信息</td>
<td style="text-align:left">有，能概括、推理，甚至生成原文中不存在的词语或句式</td>
</tr>
<tr>
<td style="text-align:left"><strong>训练难度</strong></td>
<td style="text-align:left">相对较低，通常无需大量标注数据（无监督/弱监督）</td>
<td style="text-align:left">较高，需要大量高质量的（原文-摘要）配对数据，计算资源需求大</td>
</tr>
<tr>
<td style="text-align:left"><strong>错误类型</strong></td>
<td style="text-align:left">主要为信息冗余、连贯性差</td>
<td style="text-align:left">主要为“幻觉”、事实性错误、语法错误</td>
</tr>
</tbody>
</table>
<h3 id="混合式方法">混合式方法</h3>
<p>鉴于抽取式和生成式摘要各自的优缺点，研究人员开始探索将两者结合的<strong>混合式（Hybrid）方法</strong>，旨在发挥抽取式摘要的忠实性和可解释性，同时利用生成式摘要的流畅性和概括能力。</p>
<p>混合式方法通常有以下几种策略：</p>
<ol>
<li>
<p><strong>先抽取后生成（Extract-then-Abstract）：</strong></p>
<ul>
<li><strong>阶段一（抽取）：</strong> 首先使用抽取式方法（如 TextRank 或基于分类的模型）从原文中识别出最重要的句子或关键片段。</li>
<li><strong>阶段二（生成）：</strong> 将这些抽取出的片段作为输入，喂给一个生成式模型。生成式模型对这些关键片段进行重写、概括和润色，以生成流畅、连贯的最终摘要。</li>
<li><strong>优势：</strong> 这种方法可以显著减少生成式模型处理的输入长度，降低计算复杂度，并帮助模型专注于关键信息，从而减少幻觉的风险。</li>
</ul>
</li>
<li>
<p><strong>带有抽取约束的生成（Abstractive with Extractive Constraints/Guidance）：</strong></p>
<ul>
<li>在生成式模型的训练或推理过程中，引入额外的机制来鼓励或强制模型生成与原文中关键短语或概念相关的摘要。</li>
<li><strong>指针-生成网络（Pointer-Generator Networks）：</strong> 这是一种经典的混合模型，它在标准 Seq2Seq 模型的基础上增加了“复制机制”（copy mechanism）或“指针机制”（pointer mechanism）。在生成词语时，模型既可以从词汇表中生成新词，也可以直接从原文中“复制”一个词过来。这有助于生成重要实体或关键词，并减少 OOV（out-of-vocabulary）问题。</li>
<li><strong>基于内容选择的生成：</strong> 模型首先识别原文中的关键内容单元（如主题词、实体），然后在生成摘要时优先使用或确保包含这些内容单元。</li>
<li><strong>优势：</strong> 这种方法在保留生成式摘要流畅性的同时，通过引入抽取元素的约束，提高了摘要的事实准确性和忠实度。</li>
</ul>
</li>
<li>
<p><strong>多任务学习：</strong></p>
<ul>
<li>将抽取式摘要和生成式摘要视为两个相关任务，通过多任务学习框架共同训练模型。例如，模型可能同时学习预测哪些句子是关键的，并生成摘要。这种共享参数的方式有助于模型学习更鲁棒的文本表示。</li>
</ul>
</li>
</ol>
<h3 id="评估指标的局限性与新方向">评估指标的局限性与新方向</h3>
<p>正如之前提到的，ROUGE 指标在评估生成式摘要时存在局限性，特别是在衡量语义相似度和事实准确性方面。为了更全面地评估摘要质量，研究界正在探索新的评估方法：</p>
<ul>
<li>
<p><strong>基于语义相似度指标：</strong></p>
<ul>
<li><strong>BERTScore：</strong> 利用预训练的 BERT 模型计算生成摘要与参考摘要之间每个词的上下文嵌入向量的相似度，然后进行加权平均。它能够捕捉到同义词、近义词的语义相似性，比 ROUGE 更能反映生成式摘要的质量。</li>
<li><strong>MoverScore：</strong> 基于 Word Mover’s Distance，计算从一个文本中“移动”词语到另一个文本所需的最小成本，以衡量语义距离。</li>
</ul>
</li>
<li>
<p><strong>事实一致性评估：</strong></p>
<ul>
<li>由于幻觉问题日益突出，专门用于评估摘要事实准确性的指标和数据集应运而生。这通常涉及构建问答对、自然语言推理（NLI）或人工标注的方式来判断摘要中的陈述是否与原文事实一致。</li>
<li>例如，可以训练一个独立的模型（Fact-checking Model）来判断摘要中的每一个句子是否能在原文中找到支持。</li>
</ul>
</li>
<li>
<p><strong>人工评估的重要性：</strong><br>
尽管自动化指标不断进步，但人工评估（Human Evaluation）仍是衡量摘要质量最可靠的方法。专家评审员可以从多个维度（如流畅性、连贯性、信息量、简洁性、事实准确性等）对摘要进行打分和排名。然而，人工评估成本高昂且耗时。</p>
</li>
</ul>
<h2 id="第五部分：最新进展与未来展望">第五部分：最新进展与未来展望</h2>
<p>文本摘要领域正经历着前所未有的快速发展，特别是随着大型语言模型（LLMs）的崛起，许多以往的挑战正在被重新审视和解决。</p>
<h3 id="大型语言模型（LLMs）对摘要的影响">大型语言模型（LLMs）对摘要的影响</h3>
<p>大型语言模型，如 GPT-3/4、ChatGPT、Bard、Claude 等，由于其庞大的参数量、在海量数据上的预训练以及强大的泛化能力，对文本摘要任务产生了颠覆性影响。</p>
<ol>
<li>
<p><strong>零样本/少样本摘要（Zero-shot/Few-shot Summarization）：</strong><br>
LLMs 展现出令人惊叹的零样本（不提供任何示例）和少样本（提供少量示例）学习能力。这意味着我们可以直接通过自然语言指令（Prompt）来引导 LLM 生成摘要，而无需进行传统的模型微调。例如，可以直接对 GPT-4 说：“请总结以下文章的核心内容，限制在100字以内。”<br>
这种能力极大地降低了摘要任务的门槛，使得非专业用户也能轻松使用高质量的摘要服务。</p>
</li>
<li>
<p><strong>指令微调（Instruction Tuning）与强化学习（RLHF）：</strong><br>
通过对 LLMs 进行指令微调（使其更好地遵循人类指令）和基于人类反馈的强化学习（RLHF），模型的摘要质量和对用户意图的理解能力得到了显著提升。它们能更好地理解“生成一篇简洁摘要”、“列出关键要点”、“将语气改为轻松幽默”等复杂指令。</p>
</li>
<li>
<p><strong>多功能性与可控性：</strong><br>
LLMs 不仅能生成摘要，还能在同一个模型中实现多种摘要变体：</p>
<ul>
<li><strong>可控长度摘要：</strong> 精确控制摘要的字数或句子数。</li>
<li><strong>特定视角摘要：</strong> 从特定角色（如学生、专家）或特定目的（如商业分析、技术报告）出发生成摘要。</li>
<li><strong>多语言摘要：</strong> 直接生成不同语言的摘要。</li>
<li><strong>问答式摘要：</strong> 用户通过提问获取摘要中的具体信息。</li>
</ul>
</li>
<li>
<p><strong>挑战：成本与可靠性：</strong></p>
<ul>
<li><strong>计算成本：</strong> LLMs 的推理成本依然很高，对于大规模实时摘要场景可能不适用。</li>
<li><strong>“幻觉”问题：</strong> 尽管 LLMs 在语言连贯性和流畅性上表现卓越，但它们仍然存在“幻觉”问题，尤其是在不确定或信息不足时。确保 LLM 生成摘要的事实准确性是当前研究的重点。</li>
<li><strong>数据隐私与安全：</strong> 将敏感文本输入到第三方 LLM 服务中进行摘要可能带来数据隐私和安全问题。</li>
</ul>
</li>
</ol>
<h3 id="可控摘要（Controllable-Summarization）">可控摘要（Controllable Summarization）</h3>
<p>随着对摘要质量要求提升，用户对摘要的定制化需求也日益增加。可控摘要旨在让用户能够通过参数、指令或示例来引导模型生成满足特定要求的摘要，例如：</p>
<ul>
<li><strong>长度控制：</strong> 生成指定字数、句子数或压缩比的摘要。</li>
<li><strong>风格控制：</strong> 生成正式、非正式、幽默、严肃等不同风格的摘要。</li>
<li><strong>关键词控制：</strong> 确保摘要包含某些指定关键词或短语。</li>
<li><strong>视角控制：</strong> 从特定实体或主题的角度生成摘要。</li>
<li><strong>粒度控制：</strong> 生成高层次概括性摘要或详细的要点列表。</li>
</ul>
<p>实现可控摘要通常通过在模型架构中引入条件变量、在训练过程中加入特定损失函数、或者在推理时使用 Prompt Engineering 等方法。</p>
<h3 id="多模态摘要（Multimodal-Summarization）">多模态摘要（Multimodal Summarization）</h3>
<p>现代信息不再局限于纯文本。新闻报道可能包含图片，视频会议有语音和画面，社交媒体有文本和表情包。多模态摘要的目标是综合分析多种模态的信息（如文本、图像、视频、音频），然后生成一个整合了这些模态关键内容的多模态或文本摘要。例如，从一个新闻视频中提取关键视频片段和对应的文本解说，生成一个简洁的视频摘要。</p>
<h3 id="事实准确性与可信度（Factual-Accuracy-and-Trustworthiness）">事实准确性与可信度（Factual Accuracy and Trustworthiness）</h3>
<p>这是当前生成式摘要领域最核心的研究热点之一。为了应对幻觉问题，研究者们正在探索：</p>
<ul>
<li><strong>事实验证模块：</strong> 在摘要生成后，使用独立的事实验证模型来检查摘要中的陈述是否与原文或其他可靠信息源一致。</li>
<li><strong>可解释性与溯源：</strong> 设计能够指明摘要中每个信息来源的生成模型，让用户可以追溯到原文的具体位置。</li>
<li><strong>检索增强生成（Retrieval-Augmented Generation, RAG）：</strong> 将大语言模型与外部知识库或原文检索系统结合，在生成摘要时从可靠来源获取信息，以减少幻觉。</li>
<li><strong>特定领域微调：</strong> 在特定领域数据上进行更精细的微调，让模型学习该领域特有的事实知识和表达习惯。</li>
</ul>
<h3 id="挑战与机遇">挑战与机遇</h3>
<p><strong>挑战：</strong></p>
<ul>
<li><strong>计算资源限制：</strong> 训练和部署超大型模型依然是巨大的挑战。</li>
<li><strong>数据偏见：</strong> 训练数据中存在的偏见可能导致摘要带有歧视性或不公平。</li>
<li><strong>伦理问题：</strong> 自动化摘要可能被用于传播虚假信息或进行恶意宣传。</li>
<li><strong>长文本的深层理解：</strong> 对于数万字甚至数十万字的长篇文档，如何高效准确地进行深层语义理解和概括，仍需突破。</li>
<li><strong>幻觉的根治：</strong> 尽管有多种缓解策略，彻底消除生成式摘要的幻觉问题仍然是一个开放性难题。</li>
</ul>
<p><strong>机遇：</strong></p>
<ul>
<li><strong>个性化和适应性摘要：</strong> 根据用户需求、阅读习惯和领域知识生成高度定制化的摘要。</li>
<li><strong>多语言和跨语言摘要：</strong> 促进全球信息流通和理解。</li>
<li><strong>交互式摘要：</strong> 用户可以与摘要系统进行对话，逐步细化或拓展摘要内容。</li>
<li><strong>融合多模态信息：</strong> 创造更丰富、更全面的信息概览体验。</li>
<li><strong>与领域专家系统结合：</strong> 在垂直领域（如医疗、金融、法律）发挥更大价值，提高专业信息处理效率。</li>
</ul>
<h2 id="结论">结论</h2>
<p>文本摘要技术，无论是其早期的抽取式方法，还是得益于深度学习而蓬勃发展的生成式方法，都在不断演进，以满足我们日益增长的信息处理需求。抽取式摘要因其忠实于原文、可解释性强而继续在特定场景下发挥作用；而生成式摘要则凭借其出色的流畅性和概括能力，正成为摘要领域的主流发展方向。</p>
<p>回顾历史，从基于统计的 TextRank 到基于注意力机制的 Seq2Seq，再到如今由 Transformer 架构和大型语言模型主导的时代，文本摘要技术取得了里程碑式的进步。特别是 LLMs 的出现，使得生成高质量、多功能、甚至零样本的摘要成为可能，极大地拓展了摘要技术的应用边界。</p>
<p>然而，我们也清醒地认识到，幻觉问题、事实准确性、可解释性以及庞大的计算资源需求，仍然是当前文本摘要技术，尤其是生成式摘要所面临的核心挑战。未来的研究将围绕如何增强模型的事实一致性、提升摘要的可控性、降低计算成本、并实现真正的人机协作摘要体验而展开。</p>
<p>抽取式与生成式并非互斥，而是互补的。混合式方法和基于检索增强的生成策略，正成为结合两者优势、克服各自缺点的有效途径。随着技术的不断进步，我们有理由相信，未来的文本摘要系统将更加智能、可靠、高效，成为我们获取知识、理解世界的强大工具。</p>
<p>希望这篇深入的探讨能为您带来对文本摘要领域更全面、更深刻的理解。感谢您的阅读，期待在技术探索的道路上与您再次相遇！</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a target="_blank" rel="noopener" href="https://github.com/qmwneb946">qmwneb946</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://qmwneb946.dpdns.org/2025/07/22/2025-07-22-132623/">https://qmwneb946.dpdns.org/2025/07/22/2025-07-22-132623/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://opensource.org/licenses/MIT" target="_blank">MIT License</a> 许可协议。转载请注明来源 <a href="https://qmwneb946.dpdns.org" target="_blank">qmwneb946 的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/2025/">2025</a><a class="post-meta__tags" href="/tags/%E6%8A%80%E6%9C%AF/">技术</a><a class="post-meta__tags" href="/tags/%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81%E7%9A%84%E6%8A%BD%E5%8F%96%E5%BC%8F%E4%B8%8E%E7%94%9F%E6%88%90%E5%BC%8F%E6%96%B9%E6%B3%95/">文本摘要的抽取式与生成式方法</a></div><div class="post-share"><div class="social-share" data-image="/img/icon.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/07/22/2025-07-22-132738/" title="探索深海之眼：水下无线光通信技术的奥秘与未来"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">探索深海之眼：水下无线光通信技术的奥秘与未来</div></div><div class="info-2"><div class="info-item-1">作者: qmwneb946 引言 浩瀚的海洋占据了地球表面积的70%以上，蕴藏着无数未知的奥秘和宝贵的资源。从深海采矿到海洋环境监测，从海底地震预警到水下机器人集群协作，我们对海洋的探索和利用正日益深入。然而，要实现这些目标，一个高效、可靠的水下通信系统是不可或缺的基石。 长期以来，水声通信是水下最主要的通信方式。声波在水下传播距离远，但在带宽、延迟和安全性方面存在显著局限性——其数据速率通常只能达到几十kbps，且传播延迟高、易受环境噪声干扰。射频（RF）无线电波在水下则面临严重的吸收衰减，仅能在极短距离内（几米）实现通信。为了突破这些瓶颈，科学家们将目光投向了光：水下无线光通信（Underwater Wireless Optical Communication, UWOC）。 UWOC 利用蓝绿波段的光波作为信息载体，在水下介质中进行无线传输。相较于传统的水声通信，UWOC 具有超高带宽、极低延迟、高安全性以及抗电磁干扰能力强等显著优势。它能够提供兆比特甚至千兆比特每秒的数据速率，为水下高清视频传输、高速数据回传以及实时控制等高级应用提供了可能。 然而，水下光学信道是一个极其...</div></div></div></a><a class="pagination-related" href="/2025/07/22/2025-07-22-124155/" title="零样本学习：跨越未知疆界的智能之光"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">零样本学习：跨越未知疆界的智能之光</div></div><div class="info-2"><div class="info-item-1">大家好，我是你们的老朋友 qmwneb946，一个对技术和数学充满热情的博主。今天，我们将深入探讨一个令人兴奋且极具挑战性的机器学习前沿领域——零样本学习（Zero-Shot Learning, ZSL）。想象一下，一个孩子从未见过“长颈鹿”，但通过你的描述（“很高”、“脖子很长”、“身上有斑点”），当他第一次看到长颈鹿的照片时，竟然能准确地认出来。这听起来像是科幻，但零样本学习正是努力让机器具备这种超越经验的智能。 引言：为什么我们需要零样本学习？ 在传统机器学习范式中，我们训练模型识别的类别必须在训练数据中出现过。这就像一个学生，只有学习过“猫”的照片，才能识别“猫”。这种模式在许多应用中工作得很好，比如人脸识别、垃圾邮件检测等。然而，世界是无限的，新概念、新类别层出不穷。我们不可能为每一个新出现的物体、物种或概念都收集大量的标注数据来训练模型。 想象一下：  稀有物种识别：很多物种极其罕见，根本没有足够的数据。 新产品上市：一款全新的手机型号发布，如何让AI立刻识别它？ 医疗影像诊断：罕见疾病的样本极少，甚至没有。  这些场景揭示了传统机器学习的局限性：它们是“数据饥渴型”...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/07/18/2025-07-18-082448/" title="数据挖掘在金融风控的应用：从算法到实践"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">数据挖掘在金融风控的应用：从算法到实践</div></div><div class="info-2"><div class="info-item-1">大家好，我是你们的技术博主，今天我们来深入探讨一个与我们日常生活息息相关，却又充满技术挑战的领域：金融风控。在这个领域中，数据挖掘技术发挥着越来越重要的作用，它帮助金融机构有效识别和管理风险，保障金融体系的稳定运行。本文将从多个角度深入探讨数据挖掘在金融风控中的应用，并结合实际案例进行分析。 数据挖掘在金融风控中的关键作用 金融风控的目标是识别、评估和控制各种金融风险，例如信用风险、欺诈风险、操作风险等。传统的风控方法往往依赖于人工审核和简单的统计模型，效率低、准确率不高。而数据挖掘技术的出现，为金融风控带来了革命性的变革。它能够从海量数据中提取有价值的信息，建立更精确的风险模型，从而提高风控效率和准确性。 具体来说，数据挖掘在金融风控中主要发挥以下作用： 欺诈检测 欺诈行为日益猖獗，给金融机构造成巨大的经济损失。数据挖掘技术，特别是异常检测算法，能够有效识别出可疑交易行为。例如，基于机器学习的异常检测模型可以学习正常交易的模式，然后识别偏离该模式的异常交易，从而有效识别潜在的欺诈行为。常用的算法包括：  孤立森林 (Isolation Forest): 通过随机分割数据来隔离异...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082509/" title="虚拟现实技术的沉浸式体验：从感知到认知"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">虚拟现实技术的沉浸式体验：从感知到认知</div></div><div class="info-2"><div class="info-item-1">虚拟现实（VR）技术不再是科幻小说中的幻想，它已经逐渐融入我们的生活，并正在深刻地改变着我们与世界互动的方式。本文将深入探讨VR技术的沉浸式体验，从技术原理到感知机制，再到其潜在的应用和未来发展方向，为技术爱好者提供一个全面的视角。 沉浸式体验的奥秘：技术层面 VR技术能够创造出令人信服的沉浸式体验，这依赖于多项关键技术的协同作用。 显示技术与图像渲染 高质量的图像渲染是VR体验的关键。高分辨率、高刷新率的显示器能够有效减少画面延迟和模糊感，提升视觉舒适度。目前主流的VR头显大多采用OLED或LCD屏幕，并通过透镜系统将图像投射到用户的视网膜上，模拟真实世界的视觉体验。  为了实现更广阔的视野（FOV），厂商们也在不断改进透镜设计和显示面板技术。 空间音频技术 除了视觉，听觉在构建沉浸式环境中也扮演着至关重要的角色。空间音频技术通过模拟声音在三维空间中的传播，让用户能够准确感知声音的方位和距离，增强临场感。例如，头部追踪技术配合精密的算法，可以根据用户头部姿态实时调整声音的输出，使声音效果更加逼真。 追踪技术与交互方式 精确的追踪技术是VR体验流畅的关键。目前常用的追踪技术包括：...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082730/" title="有机合成中的手性催化技术：构建分子世界的精巧艺术"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">有机合成中的手性催化技术：构建分子世界的精巧艺术</div></div><div class="info-2"><div class="info-item-1">有机合成，这门将简单的化学物质转化为复杂分子的艺术，正因手性分子的存在而变得更加精妙和挑战性。手性分子如同左右手一样，结构互为镜像，但性质却可能大相径庭。在药物研发、材料科学等领域，获得特定手性的分子至关重要，而手性催化技术正是实现这一目标的关键。本文将深入探讨有机合成中的手性催化技术，揭示其背后的原理和应用。 手性与手性催化：从镜像到精准控制 手性，源于希腊语“cheir”（手），指的是分子不能与其镜像重合的特性。这种结构差异导致手性分子具有不同的物理性质和生物活性。例如，一种药物的左旋体可能具有疗效，而其右旋体则可能无效甚至有害。因此，精准控制手性合成至关重要。 手性催化技术利用手性催化剂来控制反应的立体选择性，即优先生成特定手性的产物。催化剂本身是手性的，它通过与反应物形成短暂的超分子复合物，影响反应路径，从而引导反应朝特定立体异构体方向进行。这就好比一个熟练的工匠，用巧妙的手法引导反应物“组装”成预期的分子结构。 手性催化剂的类型及作用机制 目前，广泛应用的手性催化剂主要包括： 过渡金属配合物催化剂 这类催化剂通常含有手性配体与过渡金属中心（如铑、钌、钯等）结合而成。配体...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082852/" title="光谱分析技术在环境监测的应用：从原理到实践"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">光谱分析技术在环境监测的应用：从原理到实践</div></div><div class="info-2"><div class="info-item-1">大家好，我是你们的技术博主 DataWhisperer！今天我们来聊一个既高大上又贴近生活的技术领域：光谱分析技术在环境监测中的应用。  这可不是简单的“看看颜色”就能搞定的，它背后蕴含着丰富的物理学、化学和数学原理，并且在保护我们的环境方面发挥着越来越重要的作用。 引言：光谱分析 – 环境监测的“火眼金睛” 环境监测的目标是及时、准确地获取环境污染物的信息，为环境保护和管理提供科学依据。传统监测方法往往费时费力，且灵敏度有限。而光谱分析技术，凭借其快速、灵敏、多组分同时检测等优点，成为了环境监测领域的一匹黑马。  它利用物质与电磁辐射相互作用的特性，分析物质的成分和结构，从而实现对环境污染物的精准识别和定量分析。 光谱分析技术的种类及原理 光谱分析技术涵盖多种方法，根据所用电磁波的波长范围不同，可以分为： 紫外-可见光谱法 (UV-Vis) UV-Vis 光谱法利用物质对紫外和可见光区域电磁波的吸收特性进行分析。  不同物质具有独特的吸收光谱，通过测量吸收光谱的特征峰，可以确定物质的种类和浓度。  这在水质监测中应用广泛，例如检测重金属离子、有机污染物等。  其原理基于朗伯-比...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082903/" title="计算化学模拟分子间相互作用：从经典力场到量子力学"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">计算化学模拟分子间相互作用：从经典力场到量子力学</div></div><div class="info-2"><div class="info-item-1">引言 分子间相互作用是化学和生物学领域的核心概念，它支配着物质的物理和化学性质，例如溶解度、沸点、蛋白质折叠等等。精确地模拟这些相互作用对于理解和预测分子行为至关重要。计算化学为我们提供了一套强大的工具来研究分子间相互作用，从经典的力场方法到复杂的量子力学计算，本文将深入探讨这些方法及其应用。 经典力场方法 经典力场方法基于牛顿力学，将分子简化为一系列原子，并通过经验参数化的势能函数来描述原子间的相互作用。这种方法计算效率高，适用于模拟大量的原子和分子，例如蛋白质、DNA和材料科学中的大分子体系。 势能函数 经典力场通常包含以下几种类型的相互作用项：  键伸缩 (Bond Stretching): 描述键长偏离平衡键长的能量变化，通常用谐振势能函数表示：Ebond=12kb(r−r0)2E_{bond} = \frac{1}{2}k_b(r - r_0)^2Ebond​=21​kb​(r−r0​)2，其中 kbk_bkb​ 是力常数，rrr 是键长，r0r_0r0​ 是平衡键长。 键角弯曲 (Angle Bending): 描述键角偏离平衡键角的能量变化，通常也用谐振势能函数表示...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082912/" title="绿色化学与可持续发展目标：技术与未来的融合"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">绿色化学与可持续发展目标：技术与未来的融合</div></div><div class="info-2"><div class="info-item-1">近年来，可持续发展已成为全球关注的焦点，联合国提出的17个可持续发展目标 (SDGs) 为全球共同努力提供了蓝图。其中，许多目标都与化学工业息息相关，而绿色化学作为一种旨在减少或消除有害物质使用的化学方法，扮演着至关重要的角色。本文将探讨绿色化学如何为实现可持续发展目标做出贡献，并从技术角度深入分析其应用。 绿色化学的十二原则：通向可持续未来的基石 绿色化学的核心是其十二项原则，这些原则指导着化学家的研究和工业生产，力求最大限度地减少环境影响。这些原则并非相互独立，而是相互关联，共同构成了一个整体的框架。 预防原则 这是绿色化学的首要原则，强调在化学反应的设计阶段就应避免产生有害物质，而非在产生后进行处理。这需要化学家们从根本上重新思考化学反应的设计和工艺流程。 原子经济性 理想情况下，所有反应物原子都应转化为最终产物，没有任何浪费。原子经济性是衡量化学反应效率的重要指标，其计算公式为： 原子经济性=目标产物的分子量所有反应物的分子量总和×100%原子经济性 = \frac{目标产物的分子量}{所有反应物的分子量总和} \times 100\%原子经济性=所有反应物的分子量总和目...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">qmwneb946</div><div class="author-info-description">一个专注于技术分享的个人博客，涵盖编程、算法、系统设计等内容</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">703</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">707</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/qmwneb946"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/qmwneb946" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:qmwneb946@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">代码与远方，技术与生活交织的篇章。</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%EF%BC%9A%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81%E7%9A%84%E5%9F%BA%E7%9F%B3"><span class="toc-number">1.</span> <span class="toc-text">第一部分：文本摘要的基石</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81%EF%BC%9F"><span class="toc-number">1.1.</span> <span class="toc-text">什么是文本摘要？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%91%98%E8%A6%81%E7%9A%84%E7%B1%BB%E5%9E%8B%E4%B8%8E%E6%8C%91%E6%88%98"><span class="toc-number">1.2.</span> <span class="toc-text">摘要的类型与挑战</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86%EF%BC%9A%E6%8A%BD%E5%8F%96%E5%BC%8F%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81"><span class="toc-number">2.</span> <span class="toc-text">第二部分：抽取式文本摘要</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86"><span class="toc-number">2.1.</span> <span class="toc-text">基本原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%8F%E5%85%B8%E6%96%B9%E6%B3%95"><span class="toc-number">2.2.</span> <span class="toc-text">经典方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E7%BB%9F%E8%AE%A1%E5%AD%A6%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">2.2.1.</span> <span class="toc-text">基于统计学的方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%9B%BE%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">2.2.2.</span> <span class="toc-text">基于图的方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">2.2.3.</span> <span class="toc-text">基于机器学习的方法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%98%E7%82%B9"><span class="toc-number">2.3.</span> <span class="toc-text">优点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%BA%E7%82%B9"><span class="toc-number">2.4.</span> <span class="toc-text">缺点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">2.5.</span> <span class="toc-text">应用场景</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%EF%BC%9A%E7%94%9F%E6%88%90%E5%BC%8F%E6%96%87%E6%9C%AC%E6%91%98%E8%A6%81"><span class="toc-number">3.</span> <span class="toc-text">第三部分：生成式文本摘要</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86-2"><span class="toc-number">3.1.</span> <span class="toc-text">基本原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%91%E5%B1%95%E5%8E%86%E7%A8%8B%E4%B8%8E%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.2.</span> <span class="toc-text">发展历程与模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%97%A9%E6%9C%9F%E5%B0%9D%E8%AF%95"><span class="toc-number">3.2.1.</span> <span class="toc-text">早期尝试</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%BA%8F%E5%88%97%E5%88%B0%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B-Sequence-to-Sequence-Models"><span class="toc-number">3.2.2.</span> <span class="toc-text">基于序列到序列模型 (Sequence-to-Sequence Models)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E-Transformer-%E7%9A%84%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.2.3.</span> <span class="toc-text">基于 Transformer 的模型</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E7%AD%96%E7%95%A5%E4%B8%8E%E6%8C%91%E6%88%98"><span class="toc-number">3.3.</span> <span class="toc-text">训练策略与挑战</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE"><span class="toc-number">3.3.1.</span> <span class="toc-text">数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87"><span class="toc-number">3.3.2.</span> <span class="toc-text">评估指标</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8C%91%E6%88%98"><span class="toc-number">3.3.3.</span> <span class="toc-text">挑战</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%98%E7%82%B9-2"><span class="toc-number">3.4.</span> <span class="toc-text">优点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%BA%E7%82%B9-2"><span class="toc-number">3.5.</span> <span class="toc-text">缺点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF-2"><span class="toc-number">3.6.</span> <span class="toc-text">应用场景</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%EF%BC%9A%E6%8A%BD%E5%8F%96%E5%BC%8F%E4%B8%8E%E7%94%9F%E6%88%90%E5%BC%8F%EF%BC%9A%E5%AF%B9%E6%AF%94%E4%B8%8E%E8%9E%8D%E5%90%88"><span class="toc-number">4.</span> <span class="toc-text">第四部分：抽取式与生成式：对比与融合</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E5%B7%AE%E5%BC%82%E5%AF%B9%E6%AF%94"><span class="toc-number">4.1.</span> <span class="toc-text">核心差异对比</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B7%B7%E5%90%88%E5%BC%8F%E6%96%B9%E6%B3%95"><span class="toc-number">4.2.</span> <span class="toc-text">混合式方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87%E7%9A%84%E5%B1%80%E9%99%90%E6%80%A7%E4%B8%8E%E6%96%B0%E6%96%B9%E5%90%91"><span class="toc-number">4.3.</span> <span class="toc-text">评估指标的局限性与新方向</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%EF%BC%9A%E6%9C%80%E6%96%B0%E8%BF%9B%E5%B1%95%E4%B8%8E%E6%9C%AA%E6%9D%A5%E5%B1%95%E6%9C%9B"><span class="toc-number">5.</span> <span class="toc-text">第五部分：最新进展与未来展望</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%EF%BC%88LLMs%EF%BC%89%E5%AF%B9%E6%91%98%E8%A6%81%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-number">5.1.</span> <span class="toc-text">大型语言模型（LLMs）对摘要的影响</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%AF%E6%8E%A7%E6%91%98%E8%A6%81%EF%BC%88Controllable-Summarization%EF%BC%89"><span class="toc-number">5.2.</span> <span class="toc-text">可控摘要（Controllable Summarization）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E6%A8%A1%E6%80%81%E6%91%98%E8%A6%81%EF%BC%88Multimodal-Summarization%EF%BC%89"><span class="toc-number">5.3.</span> <span class="toc-text">多模态摘要（Multimodal Summarization）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8B%E5%AE%9E%E5%87%86%E7%A1%AE%E6%80%A7%E4%B8%8E%E5%8F%AF%E4%BF%A1%E5%BA%A6%EF%BC%88Factual-Accuracy-and-Trustworthiness%EF%BC%89"><span class="toc-number">5.4.</span> <span class="toc-text">事实准确性与可信度（Factual Accuracy and Trustworthiness）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%91%E6%88%98%E4%B8%8E%E6%9C%BA%E9%81%87"><span class="toc-number">5.5.</span> <span class="toc-text">挑战与机遇</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA"><span class="toc-number">6.</span> <span class="toc-text">结论</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/23/%E5%8D%9A%E5%BC%88%E8%AE%BA%E5%9F%BA%E7%A1%80/" title="博弈论基础">博弈论基础</a><time datetime="2025-07-23T11:46:17.225Z" title="发表于 2025-07-23 19:46:17">2025-07-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/23/hello-world/" title="Hello World">Hello World</a><time datetime="2025-07-23T11:46:17.224Z" title="发表于 2025-07-23 19:46:17">2025-07-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/23/2025-07-23-114340/" title="数字孪生在城市规划中的革命性应用：构建智能城市的未来">数字孪生在城市规划中的革命性应用：构建智能城市的未来</a><time datetime="2025-07-23T03:43:40.000Z" title="发表于 2025-07-23 11:43:40">2025-07-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/23/2025-07-23-114234/" title="天地一体化信息网络：构建未来全域智能连接的终极蓝图">天地一体化信息网络：构建未来全域智能连接的终极蓝图</a><time datetime="2025-07-23T03:42:34.000Z" title="发表于 2025-07-23 11:42:34">2025-07-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/23/2025-07-23-114105/" title="掌控语言的魔力：深度探索文本生成的可控性研究">掌控语言的魔力：深度探索文本生成的可控性研究</a><time datetime="2025-07-23T03:41:05.000Z" title="发表于 2025-07-23 11:41:05">2025-07-23</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;2025 By qmwneb946</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.2</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css')
    if (true) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const getGiscusTheme = theme => theme === 'dark' ? 'dark' : 'light'

  const createScriptElement = config => {
    const ele = document.createElement('script')
    Object.entries(config).forEach(([key, value]) => {
      ele.setAttribute(key, value)
    })
    return ele
  }

  const loadGiscus = (el = document, key) => {
    const mappingConfig = isShuoshuo
      ? { 'data-mapping': 'specific', 'data-term': key }
      : { 'data-mapping': (option && option['data-mapping']) || 'pathname' }

    const giscusConfig = {
      src: 'https://giscus.app/client.js',
      'data-repo': 'qmwneb946/blog',
      'data-repo-id': 'R_kgDOPM6cWw',
      'data-category-id': 'DIC_kwDOPM6cW84CtEzo',
      'data-theme': getGiscusTheme(document.documentElement.getAttribute('data-theme')),
      'data-reactions-enabled': '1',
      crossorigin: 'anonymous',
      async: true,
      ...option,
      ...mappingConfig
    }

    const scriptElement = createScriptElement(giscusConfig)

    el.querySelector('#giscus-wrap').appendChild(scriptElement)

    if (isShuoshuo) {
      window.shuoshuoComment.destroyGiscus = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }
  }

  const changeGiscusTheme = theme => {
    const iframe = document.querySelector('#giscus-wrap iframe')
    if (iframe) {
      const message = {
        giscus: {
          setConfig: {
            theme: getGiscusTheme(theme)
          }
        }
      }
      iframe.contentWindow.postMessage(message, 'https://giscus.app')
    }
  }

  btf.addGlobalFn('themeChange', changeGiscusTheme, 'giscus')

  if (isShuoshuo) {
    'Giscus' === 'Giscus'
      ? window.shuoshuoComment = { loadComment: loadGiscus }
      : window.loadOtherComment = loadGiscus
    return
  }

  if ('Giscus' === 'Giscus' || !false) {
    if (false) btf.loadComment(document.getElementById('giscus-wrap'), loadGiscus)
    else loadGiscus()
  } else {
    window.loadOtherComment = loadGiscus
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>