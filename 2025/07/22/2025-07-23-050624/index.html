<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>自编码器与数据降维：从理论到实践的深度探索 | qmwneb946 的博客</title><meta name="author" content="qmwneb946"><meta name="copyright" content="qmwneb946"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="你好，各位技术与数学爱好者！我是qmwneb946。今天，我们将一同踏上一段深度学习的奇妙旅程，探索一个既经典又充满活力的主题——自编码器 (Autoencoders)。在当今数据爆炸的时代，我们每天都面临着海量、高维度的数据。如何有效地处理、理解乃至利用这些复杂数据，成为了一个核心挑战。维度灾难（Curse of Dimensionality）随之而来：数据维度越高，数据变得越稀疏，模型训练越困">
<meta property="og:type" content="article">
<meta property="og:title" content="自编码器与数据降维：从理论到实践的深度探索">
<meta property="og:url" content="https://qmwneb946.dpdns.org/2025/07/22/2025-07-23-050624/index.html">
<meta property="og:site_name" content="qmwneb946 的博客">
<meta property="og:description" content="你好，各位技术与数学爱好者！我是qmwneb946。今天，我们将一同踏上一段深度学习的奇妙旅程，探索一个既经典又充满活力的主题——自编码器 (Autoencoders)。在当今数据爆炸的时代，我们每天都面临着海量、高维度的数据。如何有效地处理、理解乃至利用这些复杂数据，成为了一个核心挑战。维度灾难（Curse of Dimensionality）随之而来：数据维度越高，数据变得越稀疏，模型训练越困">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://qmwneb946.dpdns.org/img/icon.png">
<meta property="article:published_time" content="2025-07-22T21:06:24.000Z">
<meta property="article:modified_time" content="2025-07-23T09:07:47.561Z">
<meta property="article:author" content="qmwneb946">
<meta property="article:tag" content="科技前沿">
<meta property="article:tag" content="2025">
<meta property="article:tag" content="自编码器与数据降维">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://qmwneb946.dpdns.org/img/icon.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "自编码器与数据降维：从理论到实践的深度探索",
  "url": "https://qmwneb946.dpdns.org/2025/07/22/2025-07-23-050624/",
  "image": "https://qmwneb946.dpdns.org/img/icon.png",
  "datePublished": "2025-07-22T21:06:24.000Z",
  "dateModified": "2025-07-23T09:07:47.561Z",
  "author": [
    {
      "@type": "Person",
      "name": "qmwneb946",
      "url": "https://github.com/qmwneb946"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://qmwneb946.dpdns.org/2025/07/22/2025-07-23-050624/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '自编码器与数据降维：从理论到实践的深度探索',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2845632165165414" crossorigin="anonymous"></script><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="qmwneb946 的博客" type="application/atom+xml">
</head><body><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">qmwneb946 的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">自编码器与数据降维：从理论到实践的深度探索</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">自编码器与数据降维：从理论到实践的深度探索<a class="post-edit-link" href="https://github.com/qmwneb946/blog/edit/main/source/_posts/2025-07-23-050624.md" title="编辑" target="_blank"><i class="fas fa-pencil-alt"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-07-22T21:06:24.000Z" title="发表于 2025-07-23 05:06:24">2025-07-23</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-07-23T09:07:47.561Z" title="更新于 2025-07-23 17:07:47">2025-07-23</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%A7%91%E6%8A%80%E5%89%8D%E6%B2%BF/">科技前沿</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><p>你好，各位技术与数学爱好者！我是qmwneb946。今天，我们将一同踏上一段深度学习的奇妙旅程，探索一个既经典又充满活力的主题——<strong>自编码器 (Autoencoders)</strong>。在当今数据爆炸的时代，我们每天都面临着海量、高维度的数据。如何有效地处理、理解乃至利用这些复杂数据，成为了一个核心挑战。维度灾难（Curse of Dimensionality）随之而来：数据维度越高，数据变得越稀疏，模型训练越困难，计算成本也急剧增加。</p>
<p>正是在这样的背景下，数据降维技术应运而生。它旨在将高维度数据映射到低维度空间，同时尽可能保留原始数据中的重要信息。而自编码器，作为一种特殊的神经网络架构，以其无监督学习的特性和强大的非线性映射能力，成为了数据降维领域的一颗璀璨明星。</p>
<p>在这篇博客中，我将带你从零开始，深入剖析自编码器的理论基础、工作原理，探究其各种迷人的变体，并展示如何在实际项目中应用它们。无论你是初学者还是经验丰富的开发者，我相信你都能从中获得新的启发和深刻的理解。</p>
<hr>
<h2 id="1-降维的必要性与传统方法回顾">1. 降维的必要性与传统方法回顾</h2>
<p>在深入探讨自编码器之前，我们首先需要理解为什么数据降维如此重要，以及在自编码器出现之前，人们是如何处理高维度数据的。</p>
<h3 id="1-1-维度灾难-Curse-of-Dimensionality">1.1 维度灾难 (Curse of Dimensionality)</h3>
<p>“维度灾难”是机器学习和数据挖掘领域的一个核心概念。简单来说，随着数据特征维度的增加，数据空间会变得异常稀疏，从而带来一系列问题：</p>
<ul>
<li><strong>计算效率下降</strong>: 训练模型所需的计算资源呈指数级增长。</li>
<li><strong>存储成本增加</strong>: 高维数据需要更多的存储空间。</li>
<li><strong>模型过拟合风险</strong>: 在稀疏空间中，模型更容易记住噪声而非学习真实模式。</li>
<li><strong>可视化困难</strong>: 超过三维的数据几乎无法直观展示。</li>
<li><strong>距离度量失效</strong>: 在高维空间中，所有数据点之间的距离差异变得不那么显著。</li>
</ul>
<p>降维技术正是为了应对这些挑战而诞生的。通过将数据投影到更低的维度空间，我们可以更有效地进行数据处理、分析和可视化，同时可能提升模型的泛化能力。</p>
<h3 id="1-2-传统降维方法">1.2 传统降维方法</h3>
<p>在神经网络时代之前，统计学和机器学习领域已经发展出了一系列经典的降维方法：</p>
<h4 id="主成分分析-Principal-Component-Analysis-PCA">主成分分析 (Principal Component Analysis - PCA)</h4>
<p>PCA 是最常用也是最经典的线性降维方法。它的核心思想是找到一个线性投影，使得投影后的数据在新的坐标轴上具有最大的方差，从而尽可能保留原始数据的信息。</p>
<p><strong>工作原理</strong>:</p>
<ol>
<li><strong>计算协方差矩阵</strong>: 衡量不同特征之间的线性关系。<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mi>o</mi><mi>v</mi><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><mover accent="true"><mi>x</mi><mo>ˉ</mo></mover><mo stretchy="false">)</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><mover accent="true"><mi>x</mi><mo>ˉ</mo></mover><msup><mo stretchy="false">)</mo><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">Cov(X) = \frac{1}{n-1} \sum_{i=1}^n (x_i - \bar{x})(x_i - \bar{x})^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2484em;vertical-align:-0.4033em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8043em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.5678em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">ˉ</span></span></span></span></span></span></span><span class="mclose">)</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0913em;vertical-align:-0.25em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.5678em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">ˉ</span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span></li>
<li><strong>特征值分解</strong>: 对协方差矩阵进行特征值分解，得到特征值（表示方差大小）和对应的特征向量（表示主成分方向）。<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>v</mi><mo>=</mo><mi>λ</mi><mi>v</mi></mrow><annotation encoding="application/x-tex">A v = \lambda v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">λ</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span><br>
其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span> 是协方差矩阵，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span></span></span></span> 是特征向量，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">λ</span></span></span></span> 是特征值。</li>
<li><strong>选择主成分</strong>: 选择最大的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> 个特征值对应的特征向量，它们就是新的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span> 个主成分。</li>
<li><strong>数据投影</strong>: 将原始数据投影到这些选定的主成分上，得到降维后的数据。</li>
</ol>
<p><strong>优点</strong>: 简单、高效、结果易于解释。<br>
<strong>缺点</strong>: 只能捕获线性关系，无法处理数据中复杂的非线性结构。</p>
<h4 id="线性判别分析-Linear-Discriminant-Analysis-LDA">线性判别分析 (Linear Discriminant Analysis - LDA)</h4>
<p>与 PCA 不同，LDA 是一种<strong>有监督</strong>的降维方法。它的目标是找到一个投影方向，使得投影后不同类别的数据尽可能分开（类间方差最大化），同时同一类别的数据尽可能聚集（类内方差最小化）。LDA 在分类任务中表现良好。</p>
<p><strong>核心思想</strong>: 最大化类间散度矩阵与类内散度矩阵的比值。</p>
<h4 id="t-SNE-t-distributed-Stochastic-Neighbor-Embedding">t-SNE (t-distributed Stochastic Neighbor Embedding)</h4>
<p>t-SNE 是一种强大的<strong>非线性</strong>降维方法，特别适用于高维数据的可视化。它通过在高维和低维空间中构建数据点之间的概率分布，并最小化这两个分布之间的 Kullback-Leibler (KL) 散度来工作。</p>
<p><strong>优点</strong>: 能够揭示数据中复杂的局部结构和簇。<br>
<strong>缺点</strong>: 计算成本高昂，不适合作为特征提取的通用方法，主要用于可视化。</p>
<h4 id="UMAP-Uniform-Manifold-Approximation-and-Projection">UMAP (Uniform Manifold Approximation and Projection)</h4>
<p>UMAP 是一种比 t-SNE 更快的非线性降维算法，在许多方面能够达到相似甚至更好的可视化效果。它的理论基础是黎曼几何和代数拓扑。</p>
<p>这些传统方法在各自的领域都取得了成功，但随着深度学习的兴起，神经网络为降维问题提供了全新的视角和更强大的非线性建模能力，其中最引人注目的就是——自编码器。</p>
<hr>
<h2 id="2-自编码器：核心概念与工作原理">2. 自编码器：核心概念与工作原理</h2>
<p>现在，让我们把焦点转向自编码器。它是一种独特而迷人的神经网络架构，为无监督学习和数据降维带来了革命性的改变。</p>
<h3 id="2-1-什么是自编码器？">2.1 什么是自编码器？</h3>
<p>自编码器 (Autoencoder, AE) 是一种无监督神经网络，其主要目标是学习一个关于输入数据的<strong>高效编码</strong>（或表示）。它通过尝试<strong>重构其输入</strong>来实现这一目标。听起来有点像“照镜子”，对吧？网络接收一个输入，然后试图在输出层复制这个输入。</p>
<p>一个典型的自编码器由两部分组成：</p>
<ol>
<li><strong>编码器 (Encoder)</strong>：负责将输入数据 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> 映射到一个低维的<strong>潜在空间 (Latent Space)</strong> 表示 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span></span>。这个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span></span> 通常被称为<strong>编码 (Code)</strong>、<strong>潜在表示 (Latent Representation)</strong> 或<strong>瓶颈特征 (Bottleneck Feature)</strong>。<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>=</mo><msub><mi>f</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">z = f_\theta(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span><br>
其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>θ</mi></msub></mrow><annotation encoding="application/x-tex">f_\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是编码器网络，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span> 是其权重参数。</li>
<li><strong>解码器 (Decoder)</strong>：负责将潜在空间中的编码 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span></span> 映射回原始数据空间，生成重构的输出 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>x</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span></span></span></span></span></span></span>。<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>x</mi><mo>^</mo></mover><mo>=</mo><msub><mi>g</mi><mi>ϕ</mi></msub><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\hat{x} = g_\phi(z)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)</span></span></span></span><br>
其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>g</mi><mi>ϕ</mi></msub></mrow><annotation encoding="application/x-tex">g_\phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 是解码器网络，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϕ</mi></mrow><annotation encoding="application/x-tex">\phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">ϕ</span></span></span></span> 是其权重参数。</li>
</ol>
<p>整个自编码器的前向传播可以表示为：<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>x</mi><mo>^</mo></mover><mo>=</mo><msub><mi>g</mi><mi>ϕ</mi></msub><mo stretchy="false">(</mo><msub><mi>f</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\hat{x} = g_\phi(f_\theta(x))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">))</span></span></span></span></p>
<h3 id="2-2-潜在空间-Latent-Space-的意义">2.2 潜在空间 (Latent Space) 的意义</h3>
<p>潜在空间是自编码器最核心的概念之一。它是数据经过编码器压缩后的低维表示。这个低维表示捕捉了原始数据中最重要的、最具区分性的特征。</p>
<ul>
<li><strong>数据压缩</strong>: 如果我们能够从低维的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span></span> 准确地重构出高维的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span>，说明 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span></span> 有效地压缩了 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> 的信息。</li>
<li><strong>特征提取</strong>: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span></span> 可以被视为原始数据的抽象特征。这些特征往往比原始像素值或原始特征更具语义性，也更适合下游的机器学习任务。</li>
<li><strong>降维</strong>: 当潜在空间的维度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mi>i</mi><mi>m</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">dim(z)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">im</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)</span></span></span></span> 远小于输入数据的维度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mi>i</mi><mi>m</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">dim(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">im</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span> 时，自编码器就实现了数据的降维。</li>
</ul>
<h3 id="2-3-损失函数-Loss-Function">2.3 损失函数 (Loss Function)</h3>
<p>自编码器的训练目标是使重构的输出 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>x</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span></span></span></span></span></span></span> 尽可能地接近原始输入 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span>。为了量化这种“接近程度”，我们使用<strong>重构误差 (Reconstruction Error)</strong> 作为损失函数。</p>
<p>对于连续型数据（如图像像素值），常用的损失函数是<strong>均方误差 (Mean Squared Error, MSE)</strong>：<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">L</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mover accent="true"><mi>x</mi><mo>^</mo></mover><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><msub><mover accent="true"><mi>x</mi><mo>^</mo></mover><mi>i</mi></msub><mi mathvariant="normal">∣</mi><msup><mi mathvariant="normal">∣</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\mathcal{L}(x, \hat{x}) = \frac{1}{N} \sum_{i=1}^N ||x_i - \hat{x}_i||^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathcal">L</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.3262em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">∣∣</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span><br>
其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> 是样本数量。</p>
<p>对于二值数据（如伯努利分布的像素值），常用的损失函数是<strong>二元交叉熵 (Binary Cross-Entropy)</strong>：<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">L</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mover accent="true"><mi>x</mi><mo>^</mo></mover><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>D</mi></msubsup><mo stretchy="false">[</mo><msub><mi>x</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mover accent="true"><mi>x</mi><mo>^</mo></mover><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msub><mi>x</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">)</mo><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msub><mover accent="true"><mi>x</mi><mo>^</mo></mover><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\mathcal{L}(x, \hat{x}) = -\frac{1}{N} \sum_{i=1}^N \sum_{j=1}^D [x_{ij} \log(\hat{x}_{ij}) + (1 - x_{ij}) \log(1 - \hat{x}_{ij})]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathcal">L</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.417em;vertical-align:-0.4358em;"></span><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mopen">(</span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)]</span></span></span></span><br>
其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span></span></span> 是输入数据的维度。</p>
<p>训练过程就是通过反向传播和梯度下降优化器（如 Adam, RMSprop 等）来最小化这个重构误差，从而不断调整编码器和解码器的权重 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϕ</mi></mrow><annotation encoding="application/x-tex">\phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">ϕ</span></span></span></span>。</p>
<h3 id="2-4-自编码器与降维">2.4 自编码器与降维</h3>
<p>自编码器之所以能用于降维，关键在于其<strong>瓶颈层 (Bottleneck Layer)</strong>。当编码器网络的中间层维度（即潜在空间的维度）小于输入数据的维度时，这个中间层就形成了一个信息瓶颈。网络被迫学习如何将高维数据压缩成一个低维表示，同时保留足够的信息以供解码器重构原始数据。</p>
<p>这个经过压缩的低维表示 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span></span> 就是我们想要的降维结果。它不仅是非线性的（因为神经网络通常包含非线性激活函数），而且是在数据自身的基础上学习到的最优表示，而非像 PCA 那样仅仅是线性变换。</p>
<p><strong>训练流程总结</strong>:</p>
<ol>
<li>输入数据 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> 经过编码器 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mi>θ</mi></msub></mrow><annotation encoding="application/x-tex">f_\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 得到低维编码 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span></span>。</li>
<li>编码 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span></span> 经过解码器 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>g</mi><mi>ϕ</mi></msub></mrow><annotation encoding="application/x-tex">g_\phi</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 得到重构数据 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>x</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span></span></span></span></span></span></span>。</li>
<li>计算 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>x</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span></span></span></span></span></span></span> 之间的重构误差。</li>
<li>通过反向传播算法更新编码器和解码器的权重，以最小化重构误差。</li>
<li>重复以上步骤直到模型收敛。</li>
</ol>
<p>完成训练后，我们就可以丢弃解码器，只保留编码器作为特征提取器或降维工具。对于任何新的输入数据，我们都可以通过编码器获得其低维、有意义的表示。</p>
<hr>
<h2 id="3-自编码器的变体与发展">3. 自编码器的变体与发展</h2>
<p>标准自编码器虽然强大，但在特定场景下可能存在一些局限性，例如容易学习恒等映射（简单地复制输入到输出），或者在潜在空间中缺乏良好的结构。为了解决这些问题，研究人员开发了多种自编码器的变体，它们在学习更鲁棒、更有意义的表示方面表现出色。</p>
<h3 id="3-1-稀疏自编码器-Sparse-Autoencoders-SAE">3.1 稀疏自编码器 (Sparse Autoencoders - SAE)</h3>
<p><strong>问题</strong>: 如果编码器的隐藏层神经元数量足够多，自编码器可能会简单地学习一个恒等映射，而不真正提取有意义的特征。这就像它只是把输入“复制粘贴”到了输出，没有进行任何有效的压缩或学习。</p>
<p><strong>解决方案</strong>: 稀疏自编码器引入了<strong>稀疏性惩罚</strong>。它要求编码器中的隐藏层神经元在给定时间只激活少数几个，而大多数神经元处于不活跃状态（输出接近于零）。这强制网络学习更具区分性的特征，每个特征只在特定输入模式下被激活。</p>
<p><strong>实现方式</strong>:<br>
在损失函数中添加一个稀疏性惩罚项，通常是基于 KL 散度（Kullback-Leibler Divergence）或 L1 正则化。</p>
<ul>
<li><strong>KL 散度惩罚</strong>: 我们希望隐藏层神经元 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span> 的平均激活度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>ρ</mi><mo>^</mo></mover><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\hat{\rho}_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">ρ</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 接近一个预设的稀疏性参数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ρ</mi></mrow><annotation encoding="application/x-tex">\rho</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">ρ</span></span></span></span>（一个很小的值，如 0.01）。<br>
惩罚项为：<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mrow><mi>s</mi><mi>p</mi><mi>a</mi><mi>r</mi><mi>s</mi><mi>e</mi></mrow></msub><mo>=</mo><mi>β</mi><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><msub><mi>s</mi><mn>2</mn></msub></msubsup><mi>K</mi><mi>L</mi><mo stretchy="false">(</mo><mi>ρ</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><msub><mover accent="true"><mi>ρ</mi><mo>^</mo></mover><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P_{sparse} = \beta \sum_{j=1}^{s_2} KL(\rho || \hat{\rho}_j)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">rse</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2401em;vertical-align:-0.4358em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8043em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord mathnormal">ρ</span><span class="mord">∣∣</span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">ρ</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><br>
其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">s_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是隐藏层神经元的数量，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05278em;">β</span></span></span></span> 是稀疏性惩罚的权重。<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mi>L</mi><mo stretchy="false">(</mo><mi>ρ</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><msub><mover accent="true"><mi>ρ</mi><mo>^</mo></mover><mi>j</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi>ρ</mi><mi>log</mi><mo>⁡</mo><mfrac><mi>ρ</mi><msub><mover accent="true"><mi>ρ</mi><mo>^</mo></mover><mi>j</mi></msub></mfrac><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>ρ</mi><mo stretchy="false">)</mo><mi>log</mi><mo>⁡</mo><mfrac><mrow><mn>1</mn><mo>−</mo><mi>ρ</mi></mrow><mrow><mn>1</mn><mo>−</mo><msub><mover accent="true"><mi>ρ</mi><mo>^</mo></mover><mi>j</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">KL(\rho || \hat{\rho}_j) = \rho \log \frac{\rho}{\hat{\rho}_j} + (1-\rho) \log \frac{1-\rho}{1-\hat{\rho}_j}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord mathnormal">ρ</span><span class="mord">∣∣</span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">ρ</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2898em;vertical-align:-0.5423em;"></span><span class="mord mathnormal">ρ</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7475em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord accent mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="mord mathnormal mtight">ρ</span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord mtight">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4461em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ρ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5423em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.4395em;vertical-align:-0.5423em;"></span><span class="mord mathnormal">ρ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8972em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord accent mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="mord mathnormal mtight">ρ</span></span><span style="top:-2.7em;"><span class="pstrut" style="height:2.7em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord mtight">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4461em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">ρ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5423em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>ρ</mi><mo>^</mo></mover><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\hat{\rho}_j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9805em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">ρ</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1667em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span></span></span></span> 是神经元 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span> 在训练批次中的平均激活度。</li>
</ul>
<p><strong>优点</strong>:</p>
<ul>
<li>学习到更稀疏、更具解释性的特征。</li>
<li>有助于防止过拟合。</li>
<li>在特征选择和去噪方面表现良好。</li>
</ul>
<h3 id="3-2-去噪自编码器-Denoising-Autoencoders-DAE">3.2 去噪自编码器 (Denoising Autoencoders - DAE)</h3>
<p><strong>问题</strong>: 标准自编码器在面对包含噪声或损坏的输入数据时，可能会直接学习到输入数据的恒等映射，而无法提取出数据本身的鲁棒特征。</p>
<p><strong>解决方案</strong>: 去噪自编码器通过在输入数据中<strong>人为地引入噪声或损坏</strong>来解决这个问题。然后，它被训练去<strong>从损坏的输入中重构原始、干净的输入</strong>。</p>
<p><strong>工作原理</strong>:</p>
<ol>
<li>给定原始输入 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span>。</li>
<li>通过某种噪声函数（如随机将部分像素置零，或添加高斯噪声）生成损坏的输入 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>x</mi><mo>~</mo></mover></mrow><annotation encoding="application/x-tex">\tilde{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6679em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3.35em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">~</span></span></span></span></span></span></span></span></span></span>。</li>
<li>编码器接收 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>x</mi><mo>~</mo></mover></mrow><annotation encoding="application/x-tex">\tilde{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6679em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3.35em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">~</span></span></span></span></span></span></span></span></span></span> 并生成编码 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>=</mo><msub><mi>f</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mover accent="true"><mi>x</mi><mo>~</mo></mover><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">z = f_\theta(\tilde{x})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.1076em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6679em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3.35em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">~</span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>。</li>
<li>解码器接收 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span></span> 并生成重构输出 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>x</mi><mo>^</mo></mover><mo>=</mo><msub><mi>g</mi><mi>ϕ</mi></msub><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\hat{x} = g_\phi(z)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)</span></span></span></span>。</li>
<li>损失函数计算的是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>x</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span></span></span></span></span></span></span> 与<strong>原始干净输入</strong> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> 之间的重构误差。</li>
</ol>
<p><strong>优点</strong>:</p>
<ul>
<li>学习到更鲁棒的特征表示，对输入噪声不敏感。</li>
<li>作为一种强大的去噪工具。</li>
<li>强制模型学习数据内在的结构，而非简单的复制。</li>
</ul>
<h3 id="3-3-栈式自编码器-Stacked-Autoencoders-SAE">3.3 栈式自编码器 (Stacked Autoencoders - SAE)</h3>
<p><strong>概念</strong>: 栈式自编码器是将多个自编码器堆叠起来，形成一个深度神经网络。每个自编码器的输出作为下一个自编码器的输入。</p>
<p><strong>训练方式</strong>:<br>
传统的训练方式是<strong>逐层预训练 (Greedy Layer-wise Pre-training)</strong>：</p>
<ol>
<li><strong>第一层</strong>: 训练一个自编码器，使其重构原始输入数据 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span>，得到第一层隐藏表示 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">h_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。</li>
<li><strong>第二层</strong>: 将训练好的第一个自编码器的编码器部分的输出 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">h_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 作为第二个自编码器的输入，训练第二个自编码器，得到第二层隐藏表示 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>h</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">h_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。</li>
<li><strong>依此类推</strong>: 重复此过程，直到所有层都训练完毕。</li>
</ol>
<p><strong>微调 (Fine-tuning)</strong>:<br>
在所有层都预训练完毕后，通常会在网络的顶部添加一个分类器（如 softmax 层），然后使用有标签数据对整个堆叠网络进行<strong>端到端（end-to-end）的微调</strong>。预训练的权重提供了一个很好的初始点，有助于避免深度网络的梯度消失/爆炸问题，并加速训练。</p>
<p><strong>优点</strong>:</p>
<ul>
<li>能够学习到更深层次、更抽象的特征表示。</li>
<li>在数据标签稀缺时，可以通过无监督预训练来利用大量无标签数据。</li>
<li>为深度学习模型提供良好的初始化，有助于克服深度网络训练的挑战。</li>
</ul>
<h3 id="3-4-变分自编码器-Variational-Autoencoders-VAE">3.4 变分自编码器 (Variational Autoencoders - VAE)</h3>
<p><strong>概念</strong>: VAE 是自编码器家族中最具创新性的成员之一，它不仅仅用于降维，更是一种强大的<strong>生成模型 (Generative Model)</strong>。与传统自编码器直接学习数据的确定性编码不同，VAE 学习的是数据在潜在空间中的<strong>概率分布</strong>。</p>
<p><strong>核心思想</strong>:</p>
<ul>
<li>编码器不是输出一个单一的潜在向量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span></span>，而是输出表示潜在变量分布的<strong>均值</strong> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">μ</span></span></span></span> 和<strong>方差</strong> <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>σ</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\sigma^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>（或 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>log</mi><mo>⁡</mo><msup><mi>σ</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\log \sigma^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>）。</li>
<li>假设潜在空间 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span></span> 服从标准正态分布 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>∼</mo><mi mathvariant="script">N</mi><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mi>I</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(z) \sim \mathcal{N}(0, I)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathcal" style="margin-right:0.14736em;">N</span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mclose">)</span></span></span></span>。编码器学习的分布 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mi>ϕ</mi></msub><mo stretchy="false">(</mo><mi>z</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">q_\phi(z|x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord">∣</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span> 应该尽可能接近这个先验分布。</li>
<li>通过<strong>重参数化技巧 (Reparameterization Trick)</strong>，我们可以从这个分布中采样一个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span></span>，然后将其传递给解码器。<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi><mo>=</mo><mi>μ</mi><mo>+</mo><mi>σ</mi><mo>⊙</mo><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">z = \mu + \sigma \odot \epsilon</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">μ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⊙</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">ϵ</span></span></span></span><br>
其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϵ</mi><mo>∼</mo><mi mathvariant="script">N</mi><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mi>I</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\epsilon \sim \mathcal{N}(0, I)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">ϵ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathcal" style="margin-right:0.14736em;">N</span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mclose">)</span></span></span></span>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⊙</mo></mrow><annotation encoding="application/x-tex">\odot</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="mord">⊙</span></span></span></span> 是逐元素乘法。这个技巧使得采样过程变得可微分，从而能够通过反向传播训练。</li>
</ul>
<p><strong>损失函数</strong>: VAE 的损失函数由两部分组成：</p>
<ol>
<li><strong>重构损失 (Reconstruction Loss)</strong>：与标准自编码器相同，衡量重构输出 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>x</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal">x</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.2222em;"><span class="mord">^</span></span></span></span></span></span></span></span></span></span> 与原始输入 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> 之间的差异。<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>E</mi><mrow><msub><mi>q</mi><mi>ϕ</mi></msub><mo stretchy="false">(</mo><mi>z</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">[</mo><mi>log</mi><mo>⁡</mo><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mi mathvariant="normal">∣</mi><mi>z</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">E_{q_\phi(z|x)}[\log p_\theta(x|z)]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1333em;vertical-align:-0.3833em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:-0.0359em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2901em;"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span><span class="mord mtight">∣</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3833em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)]</span></span></span></span> （通常使用 MSE 或交叉熵）</li>
<li><strong>KL 散度损失 (KL Divergence Loss)</strong>：作为正则化项，衡量编码器输出的潜在分布 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>q</mi><mi>ϕ</mi></msub><mo stretchy="false">(</mo><mi>z</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">q_\phi(z|x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord">∣</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span> 与标准正态分布 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(z)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)</span></span></span></span> 之间的距离。这确保了潜在空间具有良好的结构，例如连续性和可插值性。<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>D</mi><mrow><mi>K</mi><mi>L</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>q</mi><mi>ϕ</mi></msub><mo stretchy="false">(</mo><mi>z</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo stretchy="false">)</mo><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi>p</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">D_{KL}(q_\phi(z|x) || p(z))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord">∣</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mord">∣∣</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">))</span></span></span></span><br>
对于高斯分布，KL 散度有闭式解：<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>D</mi><mrow><mi>K</mi><mi>L</mi></mrow></msub><mo stretchy="false">(</mo><mi mathvariant="script">N</mi><mo stretchy="false">(</mo><mi>μ</mi><mo separator="true">,</mo><msup><mi>σ</mi><mn>2</mn></msup><mo stretchy="false">)</mo><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi mathvariant="script">N</mi><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mi>I</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>D</mi></msubsup><mo stretchy="false">(</mo><msubsup><mi>σ</mi><mi>i</mi><mn>2</mn></msubsup><mo>+</mo><msubsup><mi>μ</mi><mi>i</mi><mn>2</mn></msubsup><mo>−</mo><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><msubsup><mi>σ</mi><mi>i</mi><mn>2</mn></msubsup><mo stretchy="false">)</mo><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">D_{KL}(\mathcal{N}(\mu, \sigma^2) || \mathcal{N}(0, I)) = \frac{1}{2} \sum_{i=1}^D (\sigma_i^2 + \mu_i^2 - \log(\sigma_i^2) - 1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathcal" style="margin-right:0.14736em;">N</span><span class="mopen">(</span><span class="mord mathnormal">μ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord">∣∣</span><span class="mord mathcal" style="margin-right:0.14736em;">N</span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mclose">))</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.3262em;vertical-align:-0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-2.4413em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2587em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0728em;vertical-align:-0.2587em;"></span><span class="mord"><span class="mord mathnormal">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-2.4413em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2587em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0728em;vertical-align:-0.2587em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-2.4413em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2587em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span></li>
</ol>
<p><strong>总损失</strong>:<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">L</mi><mo stretchy="false">(</mo><mi>θ</mi><mo separator="true">,</mo><mi>ϕ</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi>E</mi><mrow><msub><mi>q</mi><mi>ϕ</mi></msub><mo stretchy="false">(</mo><mi>z</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo stretchy="false">)</mo></mrow></msub><mo stretchy="false">[</mo><mi>log</mi><mo>⁡</mo><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mi mathvariant="normal">∣</mi><mi>z</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>−</mo><msub><mi>D</mi><mrow><mi>K</mi><mi>L</mi></mrow></msub><mo stretchy="false">(</mo><msub><mi>q</mi><mi>ϕ</mi></msub><mo stretchy="false">(</mo><mi>z</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo stretchy="false">)</mo><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi>p</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathcal{L}(\theta, \phi) = E_{q_\phi(z|x)}[\log p_\theta(x|z)] - D_{KL}(q_\phi(z|x) || p(z))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathcal">L</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">θ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">ϕ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1333em;vertical-align:-0.3833em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.5198em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3488em;margin-left:-0.0359em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2901em;"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span><span class="mord mtight">∣</span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3833em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)]</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ϕ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mord">∣</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mord">∣∣</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">))</span></span></span></span><br>
负号是因为我们希望最小化负对数似然和 KL 散度。</p>
<p><strong>优点</strong>:</p>
<ul>
<li><strong>生成能力</strong>: VAE 可以通过从潜在空间采样 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>z</mi></mrow><annotation encoding="application/x-tex">z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span></span></span></span> 并将其输入解码器来生成新的、从未见过的数据样本。</li>
<li><strong>潜在空间结构</strong>: 潜在空间是连续且平滑的，这意味着潜在空间中的插值可以生成有意义的中间样本。</li>
<li><strong>正则化</strong>: KL 散度项强制潜在空间具有良好的结构，防止过拟合。</li>
</ul>
<p><strong>应用</strong>: 图像生成、数据增强、异常检测、半监督学习。</p>
<h3 id="3-5-收缩自编码器-Contractive-Autoencoders-CAE">3.5 收缩自编码器 (Contractive Autoencoders - CAE)</h3>
<p><strong>概念</strong>: 收缩自编码器旨在学习一个<strong>对输入微小扰动不敏感</strong>的鲁棒特征表示。它通过在损失函数中添加一个惩罚项来实现，该惩罚项衡量编码器输出（隐藏层激活）对输入变化的敏感度。</p>
<p><strong>惩罚项</strong>: 惩罚项是编码器隐藏层激活函数对输入求导的 Jacobian 矩阵的 Frobenius 范数。<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>t</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi></mrow></msub><mo>=</mo><mi>λ</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>h</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>x</mi></mrow></mfrac><mi mathvariant="normal">∣</mi><msubsup><mi mathvariant="normal">∣</mi><mi>F</mi><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">P_{contractive} = \lambda ||\frac{\partial h}{\partial x}||_F^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">co</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right:0.03588em;">v</span><span class="mord mathnormal mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.2251em;vertical-align:-0.345em;"></span><span class="mord mathnormal">λ</span><span class="mord">∣∣</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8801em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal mtight">x</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:0.05556em;">∂</span><span class="mord mathnormal mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord">∣</span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-2.4247em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">F</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2753em;"><span></span></span></span></span></span></span></span></span></span><br>
其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">h</span></span></span></span> 是隐藏层的激活，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span> 是输入，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mo>⋅</mo><mi mathvariant="normal">∣</mi><msub><mi mathvariant="normal">∣</mi><mi>F</mi></msub></mrow><annotation encoding="application/x-tex">||\cdot||_F</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣∣</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣</span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">F</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 是 Frobenius 范数，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">λ</span></span></span></span> 是惩罚权重。</p>
<p><strong>优点</strong>:</p>
<ul>
<li>学习到更鲁棒的特征，对输入中的噪声或微小变化具有不变性。</li>
<li>有助于防止过拟合。</li>
</ul>
<hr>
<h2 id="4-自编码器的应用场景">4. 自编码器的应用场景</h2>
<p>自编码器及其变体在众多领域都展现了强大的能力，从数据预处理到复杂的生成任务，无所不能。</p>
<h3 id="4-1-数据降维与可视化">4.1 数据降维与可视化</h3>
<p>这是自编码器最直接的应用。通过将高维数据映射到 2D 或 3D 潜在空间，我们可以直观地观察数据的内在结构、簇分布以及异常点。例如，在分析基因表达数据、图像特征或文本嵌入时，自编码器可以将成千上万维的数据压缩到可视图的维度，帮助科学家发现模式或聚类。</p>
<h3 id="4-2-特征学习与表示">4.2 特征学习与表示</h3>
<p>自编码器能够学习到数据的低维、密集且语义丰富的特征表示。这些表示可以作为下游机器学习任务（如分类、聚类）的输入，替代原始高维数据，从而：</p>
<ul>
<li><strong>提高模型性能</strong>: 学习到的特征通常比原始特征更具判别力。</li>
<li><strong>加速训练</strong>: 低维特征减少了模型的复杂性。</li>
<li><strong>处理非线性</strong>: AE 能够捕获数据中的非线性关系，这优于 PCA 等线性方法。</li>
</ul>
<p>例如，在图像识别中，一个预训练好的自编码器可以提取图像的边缘、纹理等特征，然后将这些特征输入到传统的分类器中。</p>
<h3 id="4-3-异常检测-Anomaly-Detection">4.3 异常检测 (Anomaly Detection)</h3>
<p>自编码器在异常检测中表现出色，尤其适用于无标签的异常数据检测场景。<br>
<strong>原理</strong>:</p>
<ol>
<li>自编码器在大量“正常”数据上进行训练，学习如何有效地重构这些正常数据。</li>
<li>当遇到“异常”数据时，由于这些数据与训练时的正常数据模式不符，自编码器将难以准确重构它们，导致重构误差（reconstruction error）显著升高。</li>
<li>通过设置一个重构误差阈值，我们可以将重构误差超过阈值的数据点标记为异常。</li>
</ol>
<p>这种方法在网络入侵检测、设备故障预测、欺诈检测等领域有广泛应用。</p>
<h3 id="4-4-数据去噪-Data-Denoising">4.4 数据去噪 (Data Denoising)</h3>
<p>去噪自编码器 (DAE) 的设计初衷就是为了从损坏的输入中恢复原始干净的数据。这在处理包含传感器噪声、图像模糊、缺失数据等实际问题时非常有用。它通过学习数据底层的真实分布，有效地滤除噪声，生成更清晰、完整的数据。</p>
<h3 id="4-5-信息检索">4.5 信息检索</h3>
<p>自编码器可以用于学习文档、图像或其他媒体的低维嵌入（embeddings）。这些嵌入可以用来计算不同项目之间的相似性，从而实现高效的信息检索。例如，通过自编码器学习到的文档向量可以用于语义搜索，即使查询中不包含关键词，也能找到相关文档。</p>
<h3 id="4-6-推荐系统">4.6 推荐系统</h3>
<p>在推荐系统中，自编码器可以学习用户-物品交互的潜在特征。例如，一个自编码器可以接收用户对物品的评分矩阵作为输入，学习用户的偏好和物品的特性。通过解码器重构缺失的评分，可以预测用户对未评分物品的喜好，从而生成推荐。</p>
<h3 id="4-7-生成模型-Generative-Models">4.7 生成模型 (Generative Models)</h3>
<p>变分自编码器 (VAE) 是重要的生成模型。它们不仅能将数据降维，还能通过从学习到的潜在分布中采样来生成全新的、与训练数据类似的数据。这在艺术创作（生成新图像）、数据增强、半监督学习以及探索数据流形结构等方面有巨大潜力。</p>
<hr>
<h2 id="5-实践：使用Python和TensorFlow-Keras构建自编码器">5. 实践：使用Python和TensorFlow/Keras构建自编码器</h2>
<p>理论学习再多，不如亲自动手实践一番。本节将带你使用 Python 和 TensorFlow/Keras 框架构建几种常见的自编码器，并观察它们在数据降维和重构上的效果。</p>
<h3 id="5-1-环境准备">5.1 环境准备</h3>
<p>确保你已经安装了 Python 和 TensorFlow/Keras。如果没有，可以通过 pip 安装：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install tensorflow matplotlib numpy</span><br></pre></td></tr></table></figure>
<h3 id="5-2-数据集选择">5.2 数据集选择</h3>
<p>我们将使用 <strong>Fashion-MNIST</strong> 数据集，它包含 70,000 张 28x28 灰度图像，10 个类别（例如T恤、裤子、运动鞋等），比 MNIST 更具挑战性，也更能体现自编码器的特征学习能力。</p>
<h3 id="5-3-简单的全连接自编码器">5.3 简单的全连接自编码器</h3>
<p>我们首先构建一个简单的全连接（Dense）自编码器来对 Fashion-MNIST 图像进行降维和重构。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers, models</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.3.1 数据加载与预处理</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Loading and preprocessing Fashion-MNIST dataset...&quot;</span>)</span><br><span class="line">(x_train, _), (x_test, _) = tf.keras.datasets.fashion_mnist.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 归一化像素值到 [0, 1]</span></span><br><span class="line">x_train = x_train.astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255.0</span></span><br><span class="line">x_test = x_test.astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将图像展平为向量</span></span><br><span class="line">x_train_flat = x_train.reshape((<span class="built_in">len</span>(x_train), np.prod(x_train.shape[<span class="number">1</span>:])))</span><br><span class="line">x_test_flat = x_test.reshape((<span class="built_in">len</span>(x_test), np.prod(x_test.shape[<span class="number">1</span>:])))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Original image shape: <span class="subst">&#123;x_train.shape[<span class="number">1</span>:]&#125;</span>&quot;</span>) <span class="comment"># (28, 28)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Flattened image shape: <span class="subst">&#123;x_train_flat.shape[<span class="number">1</span>:]&#125;</span>&quot;</span>) <span class="comment"># (784,)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.3.2 模型架构</span></span><br><span class="line">input_dim = x_train_flat.shape[<span class="number">1</span>] <span class="comment"># 784</span></span><br><span class="line">latent_dim = <span class="number">32</span> <span class="comment"># 潜在空间的维度，用于降维</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 编码器</span></span><br><span class="line">encoder = models.Sequential([</span><br><span class="line">    layers.Input(shape=(input_dim,)),</span><br><span class="line">    layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    layers.Dense(latent_dim, activation=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&#x27;encoder_output&#x27;</span>) <span class="comment"># 瓶颈层/潜在空间</span></span><br><span class="line">], name=<span class="string">&#x27;encoder&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解码器</span></span><br><span class="line">decoder = models.Sequential([</span><br><span class="line">    layers.Input(shape=(latent_dim,)),</span><br><span class="line">    layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    layers.Dense(input_dim, activation=<span class="string">&#x27;sigmoid&#x27;</span>) <span class="comment"># 输出层激活函数通常是sigmoid或tanh</span></span><br><span class="line">], name=<span class="string">&#x27;decoder&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 组合自编码器</span></span><br><span class="line">autoencoder = models.Model(inputs=encoder.<span class="built_in">input</span>, outputs=decoder(encoder.output), name=<span class="string">&#x27;autoencoder&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.3.3 编译与训练</span></span><br><span class="line">autoencoder.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;mse&#x27;</span>) <span class="comment"># 使用均方误差作为损失函数</span></span><br><span class="line">autoencoder.summary()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nTraining the Autoencoder...&quot;</span>)</span><br><span class="line">history = autoencoder.fit(x_train_flat, x_train_flat,</span><br><span class="line">                          epochs=<span class="number">50</span>,</span><br><span class="line">                          batch_size=<span class="number">256</span>,</span><br><span class="line">                          shuffle=<span class="literal">True</span>,</span><br><span class="line">                          validation_data=(x_test_flat, x_test_flat))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制训练损失</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;loss&#x27;</span>], label=<span class="string">&#x27;Train Loss&#x27;</span>)</span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;val_loss&#x27;</span>], label=<span class="string">&#x27;Validation Loss&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Autoencoder Loss History&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.3.4 可视化重构结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nVisualizing reconstruction results...&quot;</span>)</span><br><span class="line">encoded_imgs = encoder.predict(x_test_flat)</span><br><span class="line">decoded_imgs = decoder.predict(encoded_imgs)</span><br><span class="line"></span><br><span class="line">n = <span class="number">10</span> <span class="comment"># 显示10张图片</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">4</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    <span class="comment"># 原始图像</span></span><br><span class="line">    ax = plt.subplot(<span class="number">2</span>, n, i + <span class="number">1</span>)</span><br><span class="line">    plt.imshow(x_test_flat[i].reshape(<span class="number">28</span>, <span class="number">28</span>))</span><br><span class="line">    plt.gray()</span><br><span class="line">    ax.get_xaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line">    ax.get_yaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">        ax.set_title(<span class="string">&quot;Original&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 重构图像</span></span><br><span class="line">    ax = plt.subplot(<span class="number">2</span>, n, i + <span class="number">1</span> + n)</span><br><span class="line">    plt.imshow(decoded_imgs[i].reshape(<span class="number">28</span>, <span class="number">28</span>))</span><br><span class="line">    plt.gray()</span><br><span class="line">    ax.get_xaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line">    ax.get_yaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">        ax.set_title(<span class="string">&quot;Reconstructed&quot;</span>)</span><br><span class="line">plt.suptitle(<span class="string">&#x27;Original vs Reconstructed Images (Fully Connected Autoencoder)&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.3.5 可视化潜在空间 (降维结果)</span></span><br><span class="line"><span class="comment"># 假设我们只想可视化前几维，或者将它进一步降维到2D进行展示</span></span><br><span class="line"><span class="comment"># 这里直接使用编码器输出的32维结果，如果想可视化2D，需要把latent_dim设为2</span></span><br><span class="line"><span class="comment"># 或者使用 t-SNE 进一步降维 encoded_imgs</span></span><br><span class="line"><span class="keyword">if</span> latent_dim == <span class="number">2</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\nVisualizing 2D latent space...&quot;</span>)</span><br><span class="line">    encoded_test_imgs = encoder.predict(x_test_flat)</span><br><span class="line">    plt.figure(figsize=(<span class="number">10</span>, <span class="number">8</span>))</span><br><span class="line">    plt.scatter(encoded_test_imgs[:, <span class="number">0</span>], encoded_test_imgs[:, <span class="number">1</span>], cmap=<span class="string">&#x27;viridis&#x27;</span>, s=<span class="number">5</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">    plt.colorbar(label=<span class="string">&#x27;Feature 2&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Feature 1&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Feature 2&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;2D Latent Space Visualization&#x27;</span>)</span><br><span class="line">    plt.grid(<span class="literal">True</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\nLatent space is <span class="subst">&#123;latent_dim&#125;</span>-dimensional. Cannot directly visualize in 2D/3D.&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Consider using t-SNE or UMAP on &#x27;encoded_imgs&#x27; for 2D visualization if needed.&quot;</span>)</span><br></pre></td></tr></table></figure>
<p><strong>代码解释</strong>:</p>
<ul>
<li><strong>数据预处理</strong>: Fashion-MNIST 图像是 28x28 像素的，首先将像素值归一化到 0-1 范围，然后展平为 784 维的向量，作为全连接网络的输入。</li>
<li><strong>编码器</strong>: 包含多个 Dense 层，逐渐将 784 维的数据压缩到 <code>latent_dim</code> (这里是 32) 维。</li>
<li><strong>解码器</strong>: 镜像编码器的结构，将 <code>latent_dim</code> 维的数据重新扩展到 784 维。输出层使用 <code>sigmoid</code> 激活函数，因为像素值在 0-1 之间。</li>
<li><strong>编译与训练</strong>: 优化器选择 <code>adam</code>，损失函数选择 <code>mse</code>（均方误差）。训练时，输入和目标都是 <code>x_train_flat</code>，因为自编码器要重构自身。</li>
<li><strong>可视化</strong>: 训练后，我们通过编码器得到测试集的潜在表示，再通过解码器重构图像，并与原始图像进行对比，直观地评估重构效果。</li>
</ul>
<h3 id="5-4-使用卷积自编码器进行图像降维">5.4 使用卷积自编码器进行图像降维</h3>
<p>对于图像数据，卷积神经网络（CNN）通常比全连接网络表现更好，因为它们能更好地捕获局部空间特征。我们来构建一个卷积自编码器。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers, models</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.4.1 数据加载与预处理</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nLoading and preprocessing Fashion-MNIST dataset for CNN...&quot;</span>)</span><br><span class="line">(x_train, _), (x_test, _) = tf.keras.datasets.fashion_mnist.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 归一化像素值到 [0, 1]</span></span><br><span class="line">x_train = x_train.astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255.0</span></span><br><span class="line">x_test = x_test.astype(<span class="string">&#x27;float32&#x27;</span>) / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 为CNN添加通道维度 (28, 28) -&gt; (28, 28, 1)</span></span><br><span class="line">x_train_cnn = np.expand_dims(x_train, axis=-<span class="number">1</span>)</span><br><span class="line">x_test_cnn = np.expand_dims(x_test, axis=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;CNN input shape: <span class="subst">&#123;x_train_cnn.shape[<span class="number">1</span>:]&#125;</span>&quot;</span>) <span class="comment"># (28, 28, 1)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.4.2 模型架构 (卷积自编码器)</span></span><br><span class="line">input_shape = x_train_cnn.shape[<span class="number">1</span>:] <span class="comment"># (28, 28, 1)</span></span><br><span class="line">latent_dim_cnn = <span class="number">32</span> <span class="comment"># 潜在空间的维度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 编码器 (使用 Conv2D 和 MaxPooling2D)</span></span><br><span class="line">encoder_cnn = models.Sequential([</span><br><span class="line">    layers.Input(shape=input_shape),</span><br><span class="line">    layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, padding=<span class="string">&#x27;same&#x27;</span>),</span><br><span class="line">    layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>), padding=<span class="string">&#x27;same&#x27;</span>), <span class="comment"># Output: (14, 14, 32)</span></span><br><span class="line">    layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, padding=<span class="string">&#x27;same&#x27;</span>),</span><br><span class="line">    layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>), padding=<span class="string">&#x27;same&#x27;</span>), <span class="comment"># Output: (7, 7, 64)</span></span><br><span class="line">    layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, padding=<span class="string">&#x27;same&#x27;</span>),</span><br><span class="line">    layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>), padding=<span class="string">&#x27;same&#x27;</span>), <span class="comment"># Output: (4, 4, 128) - 原始28x28图像变为4x4x128的特征图</span></span><br><span class="line">    layers.Flatten(), <span class="comment"># 展平为向量</span></span><br><span class="line">    layers.Dense(latent_dim_cnn, activation=<span class="string">&#x27;relu&#x27;</span>, name=<span class="string">&#x27;encoder_output&#x27;</span>) <span class="comment"># 潜在空间</span></span><br><span class="line">], name=<span class="string">&#x27;encoder_cnn&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解码器 (使用 Conv2DTranspose / UpSampling2D)</span></span><br><span class="line">decoder_cnn = models.Sequential([</span><br><span class="line">    layers.Input(shape=(latent_dim_cnn,)),</span><br><span class="line">    layers.Dense(<span class="number">4</span> * <span class="number">4</span> * <span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>), <span class="comment"># 重新变为展平前的维度</span></span><br><span class="line">    layers.Reshape((<span class="number">4</span>, <span class="number">4</span>, <span class="number">128</span>)), <span class="comment"># 重塑为特征图</span></span><br><span class="line">    layers.Conv2DTranspose(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, padding=<span class="string">&#x27;same&#x27;</span>),</span><br><span class="line">    layers.UpSampling2D((<span class="number">2</span>, <span class="number">2</span>)), <span class="comment"># Output: (8, 8, 128) - 这里需要注意尺寸调整</span></span><br><span class="line">    layers.Conv2DTranspose(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, padding=<span class="string">&#x27;same&#x27;</span>),</span><br><span class="line">    layers.UpSampling2D((<span class="number">2</span>, <span class="number">2</span>)), <span class="comment"># Output: (16, 16, 64)</span></span><br><span class="line">    layers.Conv2DTranspose(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, padding=<span class="string">&#x27;same&#x27;</span>),</span><br><span class="line">    layers.UpSampling2D((<span class="number">2</span>, <span class="number">2</span>)), <span class="comment"># Output: (32, 32, 32) - 接近原始尺寸</span></span><br><span class="line">    layers.Cropping2D(((<span class="number">2</span>,<span class="number">2</span>),(<span class="number">2</span>,<span class="number">2</span>))), <span class="comment"># 将32x32裁剪回28x28 (如果padding=&#x27;same&#x27;在某些层导致尺寸变化)</span></span><br><span class="line">    layers.Conv2D(<span class="number">1</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;sigmoid&#x27;</span>, padding=<span class="string">&#x27;same&#x27;</span>) <span class="comment"># 输出1个通道的图像</span></span><br><span class="line">], name=<span class="string">&#x27;decoder_cnn&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 组合自编码器</span></span><br><span class="line">autoencoder_cnn = models.Model(inputs=encoder_cnn.<span class="built_in">input</span>, outputs=decoder_cnn(encoder_cnn.output), name=<span class="string">&#x27;autoencoder_cnn&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.4.3 编译与训练</span></span><br><span class="line">autoencoder_cnn.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;mse&#x27;</span>)</span><br><span class="line">autoencoder_cnn.summary()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nTraining the Convolutional Autoencoder...&quot;</span>)</span><br><span class="line">history_cnn = autoencoder_cnn.fit(x_train_cnn, x_train_cnn,</span><br><span class="line">                                  epochs=<span class="number">50</span>,</span><br><span class="line">                                  batch_size=<span class="number">256</span>,</span><br><span class="line">                                  shuffle=<span class="literal">True</span>,</span><br><span class="line">                                  validation_data=(x_test_cnn, x_test_cnn))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制训练损失</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">plt.plot(history_cnn.history[<span class="string">&#x27;loss&#x27;</span>], label=<span class="string">&#x27;Train Loss&#x27;</span>)</span><br><span class="line">plt.plot(history_cnn.history[<span class="string">&#x27;val_loss&#x27;</span>], label=<span class="string">&#x27;Validation Loss&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Convolutional Autoencoder Loss History&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.4.4 可视化重构结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\nVisualizing convolutional reconstruction results...&quot;</span>)</span><br><span class="line">encoded_imgs_cnn = encoder_cnn.predict(x_test_cnn)</span><br><span class="line">decoded_imgs_cnn = decoder_cnn.predict(encoded_imgs_cnn)</span><br><span class="line"></span><br><span class="line">n = <span class="number">10</span> <span class="comment"># 显示10张图片</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">4</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    <span class="comment"># 原始图像</span></span><br><span class="line">    ax = plt.subplot(<span class="number">2</span>, n, i + <span class="number">1</span>)</span><br><span class="line">    plt.imshow(x_test_cnn[i].reshape(<span class="number">28</span>, <span class="number">28</span>))</span><br><span class="line">    plt.gray()</span><br><span class="line">    ax.get_xaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line">    ax.get_yaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">        ax.set_title(<span class="string">&quot;Original&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 重构图像</span></span><br><span class="line">    ax = plt.subplot(<span class="number">2</span>, n, i + <span class="number">1</span> + n)</span><br><span class="line">    plt.imshow(decoded_imgs_cnn[i].reshape(<span class="number">28</span>, <span class="number">28</span>))</span><br><span class="line">    plt.gray()</span><br><span class="line">    ax.get_xaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line">    ax.get_yaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">        ax.set_title(<span class="string">&quot;Reconstructed&quot;</span>)</span><br><span class="line">plt.suptitle(<span class="string">&#x27;Original vs Reconstructed Images (Convolutional Autoencoder)&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以通过 encoder_cnn.predict(x_test_cnn) 获取降维后的特征</span></span><br><span class="line"><span class="comment"># encoded_features_cnn = encoder_cnn.predict(x_test_cnn)</span></span><br><span class="line"><span class="comment"># print(f&quot;Shape of encoded features: &#123;encoded_features_cnn.shape&#125;&quot;)</span></span><br></pre></td></tr></table></figure>
<p><strong>代码解释</strong>:</p>
<ul>
<li><strong>数据预处理</strong>: 图像需要保留其空间维度 <code>(28, 28, 1)</code>，以便于卷积层处理。</li>
<li><strong>编码器</strong>: 使用 <code>Conv2D</code> 进行特征提取和 <code>MaxPooling2D</code> 进行下采样（降维）。最后使用 <code>Flatten</code> 将特征图展平，再通过一个 <code>Dense</code> 层得到潜在向量。</li>
<li><strong>解码器</strong>: 使用 <code>Dense</code> 层将潜在向量恢复到展平前的维度，然后使用 <code>Reshape</code> 恢复为特征图。接着使用 <code>Conv2DTranspose</code>（转置卷积，也称作反卷积或去卷积）和 <code>UpSampling2D</code> 进行上采样，逐步恢复图像的空间分辨率。<code>Cropping2D</code> 用于处理因 <code>padding='same'</code> 导致的轻微尺寸偏差，确保最终输出为 28x28。</li>
<li><strong>训练与可视化</strong>: 与全连接自编码器类似。</li>
</ul>
<p>通过对比两种自编码器的重构效果，你会发现卷积自编码器在处理图像数据时通常能生成更清晰、细节更丰富的重构图像，因为它更好地利用了图像的局部性和空间相关性。</p>
<hr>
<h2 id="6-结论">6. 结论</h2>
<p>在本次深度探索中，我们全面剖析了自编码器这一强大的无监督学习工具。从理解“维度灾难”的困扰，到回顾 PCA 等传统降维方法的局限性，我们看到了自编码器作为一种能够学习<strong>非线性、高层次特征表示</strong>的深度学习模型所带来的革命性突破。</p>
<p>我们深入学习了自编码器的核心工作原理——通过编码器将数据压缩到低维潜在空间，再通过解码器重构数据，并利用重构误差进行训练。更进一步，我们探讨了其各种强大的变体：</p>
<ul>
<li><strong>稀疏自编码器</strong>强制学习稀疏而富有意义的特征。</li>
<li><strong>去噪自编码器</strong>通过处理噪声输入提升模型的鲁棒性。</li>
<li><strong>栈式自编码器</strong>构建深度模型以学习层次化特征。</li>
<li><strong>变分自编码器</strong>将潜在空间建模为概率分布，开启了强大的生成能力。</li>
<li><strong>收缩自编码器</strong>则专注于学习对输入扰动不敏感的特征。</li>
</ul>
<p>最后，我们通过实际的 Python 和 Keras 代码，动手构建了全连接和卷积自编码器，直观地展示了它们在图像数据降维和重构方面的应用。这些实践案例帮助我们巩固了理论知识，并体会到自编码器在数据预处理、特征工程、异常检测乃至生成新数据方面的巨大潜力。</p>
<p>自编码器是深度学习领域一个持续活跃的研究方向，尤其在表示学习和生成模型方面，它为我们理解和处理复杂数据提供了强大的工具和全新的视角。希望这篇博客能为你打开一扇窗，激发你对深度学习和数据降维更深层次的探索兴趣。</p>
<p>感谢你的阅读，期待在未来的技术旅程中与你再次相遇！</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a target="_blank" rel="noopener" href="https://github.com/qmwneb946">qmwneb946</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://qmwneb946.dpdns.org/2025/07/22/2025-07-23-050624/">https://qmwneb946.dpdns.org/2025/07/22/2025-07-23-050624/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://opensource.org/licenses/MIT" target="_blank">MIT License</a> 许可协议。转载请注明来源 <a href="https://qmwneb946.dpdns.org" target="_blank">qmwneb946 的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%A7%91%E6%8A%80%E5%89%8D%E6%B2%BF/">科技前沿</a><a class="post-meta__tags" href="/tags/2025/">2025</a><a class="post-meta__tags" href="/tags/%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8%E4%B8%8E%E6%95%B0%E6%8D%AE%E9%99%8D%E7%BB%B4/">自编码器与数据降维</a></div><div class="post-share"><div class="social-share" data-image="/img/icon.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/07/22/2025-07-23-050731/" title="智能合约的形式化验证：构建可信赖的数字基石"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">智能合约的形式化验证：构建可信赖的数字基石</div></div><div class="info-2"><div class="info-item-1">你好，技术爱好者们！我是 qmwneb946，你们的数字世界探索者。今天，我们将一同深入区块链技术的核心，探讨一个至关重要却又充满挑战的领域——智能合约的形式化验证。 自比特币诞生以来，区块链技术以其去中心化、透明和不可篡改的特性，重塑了我们对信任的理解。而智能合约，作为区块链上的可编程协议，更是将这种信任从简单的价值转移扩展到了复杂的业务逻辑。它们是无需中介、自动执行的“数字协议”，为去中心化金融（DeFi）、非同质化代币（NFTs）、去中心化自治组织（DAOs）等创新应用奠定了基石。 然而，正是这种“代码即法律”的特性，也带来了前所未有的安全挑战。智能合约一旦部署，其行为便难以更改。一个微小的逻辑错误或安全漏洞，可能导致数百万甚至数十亿美元的资产损失，或是协议的永久性失效。DAO 事件、Parity 多签钱包漏洞、以及各种闪贷攻击，都以血的教训警示我们：智能合约的安全绝非儿戏。 传统的软件测试方法，如单元测试、集成测试和模糊测试，虽然重要，但在面对智能合约的复杂性、确定性执行和高价值资产时，往往力不从心。它们只能证明代码在特定条件下“没有错误”，却无法证明在所有可能条件下“没...</div></div></div></a><a class="pagination-related" href="/2025/07/22/2025-07-23-044012/" title="探索禁忌：深入禁忌搜索算法的奥秘"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">探索禁忌：深入禁忌搜索算法的奥秘</div></div><div class="info-2"><div class="info-item-1">您好，各位技术爱好者和数学探险家！我是你们的老朋友 qmwneb946。今天，我们将踏上一段激动人心的旅程，深入探索一种巧妙而强大的优化算法——禁忌搜索（Tabu Search，简称 TS）。在面对那些令人头疼的 NP-hard 问题时，禁忌搜索就像一位经验丰富的向导，帮助我们巧妙地避开局部最优的陷阱，寻找更接近全局最优的解决方案。 在当今世界，从复杂的生产调度到精密的物流路线规划，从机器学习模型的超参数调优到生物信息学中的序列比对，优化问题无处不在。然而，许多这类问题都属于 NP-hard 范畴，这意味着我们无法在合理的时间内找到其精确的最优解。这时，元启发式算法（Metaheuristics）就成为了我们的救星。它们不保证找到全局最优解，但能在可接受的时间内找到高质量的近似解。禁忌搜索正是元启发式家族中的一颗璀璨明珠。 在本文中，我将带您：  理解优化问题的基本挑战和传统局部搜索的局限性。 深入剖析禁忌搜索的核心思想，包括禁忌列表、抱负准则等关键概念。 详细解读禁忌搜索算法的运作流程。 探讨影响算法性能的关键参数及其调优策略。 通过一个经典的案例——旅行商问题（TSP）——来...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/07/18/2025-07-18-082408/" title="人工智能在医疗诊断中的应用：机遇与挑战"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">人工智能在医疗诊断中的应用：机遇与挑战</div></div><div class="info-2"><div class="info-item-1">大家好，我是你们的技术和数学博主！今天，我们来深入探讨一个激动人心的领域：人工智能 (AI) 在医疗诊断中的应用。AI 的快速发展正在彻底改变医疗行业，为更精准、高效的诊断提供了前所未有的可能性。但同时，我们也需要审慎地看待其挑战和局限性。 引言：AI 赋能医疗诊断 医疗诊断是一个复杂的过程，需要医生具备丰富的知识、经验和判断力。然而，人类医生可能会受到主观偏差、疲劳以及信息过载的影响。AI 的介入，则为提高诊断准确性和效率提供了新的途径。通过分析大量的医学影像数据、病历记录和基因组信息，AI 算法可以学习识别疾病模式，辅助医生进行诊断，甚至在某些情况下独立完成初步诊断。 AI 在医疗诊断中的核心技术 深度学习在医学影像分析中的应用 深度学习，特别是卷积神经网络 (CNN)，在医学影像分析中取得了显著的成功。CNN 可以从大量的医学影像数据（例如 X 光片、CT 扫描、MRI 图像）中学习特征，并识别出细微的病变，例如肺癌结节、脑瘤或心血管疾病。 例如，一个训练良好的 CNN 模型可以比人类放射科医生更早地检测出肺癌，从而提高早期诊断率和治疗成功率。  这其中的关键在于大量的标注...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082643/" title="高分子化学与可降解塑料：迈向可持续未来的关键"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">高分子化学与可降解塑料：迈向可持续未来的关键</div></div><div class="info-2"><div class="info-item-1">近年来，塑料污染已成为全球性环境问题。传统塑料由于其难以降解的特性，对环境造成了巨大的压力。而可降解塑料的出现，为解决这一问题提供了一条可行的途径。本文将深入探讨高分子化学在可降解塑料研发中的关键作用，并介绍几种主要的降解机制和材料。 高分子化学：可降解塑料的基础 可降解塑料并非简单的“可被分解的塑料”，其核心在于高分子材料的分子结构设计。高分子化学为我们提供了理解和操纵聚合物结构的工具，从而设计出具有特定降解性能的材料。传统塑料通常由难以断裂的强共价键连接而成，而可降解塑料则通过引入特定的化学键或结构单元，使其在特定条件下能够断裂，从而实现降解。  这需要对聚合物的合成方法、分子量分布、链结构以及结晶度等进行精细的控制。 常见的可降解塑料聚合物 目前，市场上常见的可降解塑料主要包括以下几种：   聚乳酸 (PLA):  PLA 是一种生物基聚合物，由可再生资源（例如玉米淀粉）制成。其降解过程主要依靠水解反应，在特定条件下（例如堆肥环境）可以被微生物降解。PLA 的机械性能较好，但耐热性相对较差。   聚羟基脂肪酸酯 (PHAs): PHAs 是一类由微生物合成的聚酯。它们具有良...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-082805/" title="电化学储能技术的新进展：迈向更清洁、更持久的能源未来"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">电化学储能技术的新进展：迈向更清洁、更持久的能源未来</div></div><div class="info-2"><div class="info-item-1">电化学储能技术作为解决可再生能源间歇性问题的关键技术，近年来取得了显著进展。从电动汽车到智能电网，电化学储能系统正深刻地改变着我们的生活。本文将深入探讨电化学储能技术的最新突破，涵盖不同类型的储能技术及其面临的挑战与机遇。 电化学储能技术的类型 目前，市场上主要的电化学储能技术包括： 锂离子电池 锂离子电池凭借其高能量密度、长循环寿命和相对较低的成本，占据了当前电化学储能市场的主导地位。然而，锂资源的有限性和安全性问题仍然是制约其发展的瓶颈。  近年来，研究者们致力于开发高能量密度锂离子电池，例如：  固态锂电池:  固态电解质的采用可以显著提高电池的安全性，并有望实现更高的能量密度。然而，固态电解质的离子电导率和界面接触仍然是需要克服的挑战。 锂硫电池:  锂硫电池具有极高的理论能量密度，但其循环寿命和硫的穿梭效应仍然是需要解决的关键问题。  研究者们正在探索各种改性策略来提高锂硫电池的性能。 锂空气电池:  锂空气电池拥有理论上最高的能量密度，但其反应动力学缓慢，副反应多，循环寿命短等问题限制了其商业化应用。  钠离子电池 作为锂离子的潜在替代品，钠离子电池具有成本低、资源丰...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-092352/" title="材料科学与新型半导体材料：摩尔定律的未来"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">材料科学与新型半导体材料：摩尔定律的未来</div></div><div class="info-2"><div class="info-item-1">引言 摩尔定律，即集成电路上的晶体管数量每隔两年翻一番，几十年来一直驱动着信息技术产业的飞速发展。然而，随着晶体管尺寸逼近物理极限，摩尔定律的持续性受到了挑战。为了维持这种指数级增长，我们需要探索新型半导体材料，突破硅基技术的瓶颈。本文将深入探讨材料科学在新型半导体材料研发中的关键作用，并介绍一些具有前景的候选材料。 新型半导体材料的需求 硅作为半导体材料的主力，其优势在于成本低、工艺成熟。但其固有的物理特性限制了其在更高频率、更高功率和更低功耗方面的性能提升。例如，硅的载流子迁移率相对较低，导致能量损耗增加，尤其是在高频应用中。因此，我们需要寻找具有更高载流子迁移率、更宽禁带宽度、更高饱和电子漂移速度等优异特性的材料。 性能瓶颈及解决方案 硅基技术的性能瓶颈主要体现在以下几个方面：  漏电流:  随着晶体管尺寸的缩小，漏电流问题日益严重，导致功耗增加和性能下降。 热耗散: 高频运行会导致晶体管产生大量热量，影响器件稳定性和可靠性。 开关速度: 硅的载流子迁移率限制了晶体管的开关速度，限制了处理器的运行频率。  为了解决这些问题，研究人员正在积极探索各种新型半导体材料，例如：  ...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-092411/" title="弦理论中的额外维度探索：超越我们感知的宇宙"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">弦理论中的额外维度探索：超越我们感知的宇宙</div></div><div class="info-2"><div class="info-item-1">引言 我们生活在一个看似三维的空间中，加上时间构成四维时空。然而，弦理论，这个试图统一所有基本力的优雅理论，却预言了额外维度的存在。这些额外维度并非我们日常经验所能感知，它们蜷缩在比原子尺度还要小得多的空间里。本文将深入探讨弦理论中额外维度的概念，并解释科学家们如何尝试探测这些隐藏的宇宙维度。 弦理论与额外维度：一个必要的假设 弦理论的核心思想是将基本粒子视为微小的振动弦，不同振动模式对应不同的粒子。为了使理论自洽，并消除量子场论中的一些困扰，弦理论需要引入额外空间维度。最初的弦理论版本需要 26 个维度，而超弦理论则将维度数量缩减到 10 个（或 11 个，在 M 理论中）。这多出来的 6 个（或 7 个）维度是如何隐藏起来的呢？ 卡拉比-丘空间：卷曲的维度 弦理论提出，额外维度并非不存在，而是以紧致化的形式存在，就像一根细细的管子卷曲得非常紧密，以至于在宏观尺度上无法被察觉。这些紧致化的额外维度通常被描述为卡拉比-丘空间，这是一类复杂的六维流形，具有独特的几何性质。卡拉比-丘空间的形状和大小直接影响了我们观察到的粒子物理学特性，例如粒子质量和相互作用强度。 R6R^6R6 表...</div></div></div></a><a class="pagination-related" href="/2025/07/18/2025-07-18-092451/" title="粒子物理学的标准模型之外：探索宇宙未解之谜"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">粒子物理学的标准模型之外：探索宇宙未解之谜</div></div><div class="info-2"><div class="info-item-1">我们生活在一个由基本粒子及其相互作用组成的宇宙中。粒子物理学的标准模型，如同一个精妙的乐章，成功地描述了已知的基本粒子及其三种基本作用力（电磁力、弱力和强力），并准确预测了许多实验结果。然而，这个模型并非完美无缺，它留下了许多未解之谜，指引着我们向标准模型之外的更广阔领域探索。 标准模型的局限性 标准模型尽管取得了巨大的成功，但它并不能解释宇宙中的一切现象。一些关键的不足之处包括： 暗物质与暗能量 宇宙学观测表明，宇宙中存在大量的暗物质和暗能量，它们构成了宇宙质量能量的大部分，但标准模型中却无法解释它们的本质。暗物质不参与电磁相互作用，因此我们无法直接观测到它，只能通过其引力效应间接探测。暗能量则是一种神秘的能量形式，导致宇宙加速膨胀。它们的发现暗示着标准模型之外存在着新的物理学。 中微子质量 标准模型最初假设中微子是无质量的。然而，实验观测表明中微子具有微小的质量，这与标准模型的预言相矛盾。中微子的质量之谜需要新的物理机制来解释，例如 seesaw 机制。 质子衰变 标准模型预言质子是稳定的，然而，一些大统一理论（GUTs）预测质子会发生极其缓慢的衰变。虽然到目前为止还没有观测...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">qmwneb946</div><div class="author-info-description">一个专注于技术分享的个人博客，涵盖编程、算法、系统设计等内容</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">673</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">677</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/qmwneb946"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/qmwneb946" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:qmwneb946@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">代码与远方，技术与生活交织的篇章。</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E9%99%8D%E7%BB%B4%E7%9A%84%E5%BF%85%E8%A6%81%E6%80%A7%E4%B8%8E%E4%BC%A0%E7%BB%9F%E6%96%B9%E6%B3%95%E5%9B%9E%E9%A1%BE"><span class="toc-number">1.</span> <span class="toc-text">1. 降维的必要性与传统方法回顾</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-%E7%BB%B4%E5%BA%A6%E7%81%BE%E9%9A%BE-Curse-of-Dimensionality"><span class="toc-number">1.1.</span> <span class="toc-text">1.1 维度灾难 (Curse of Dimensionality)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-%E4%BC%A0%E7%BB%9F%E9%99%8D%E7%BB%B4%E6%96%B9%E6%B3%95"><span class="toc-number">1.2.</span> <span class="toc-text">1.2 传统降维方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90-Principal-Component-Analysis-PCA"><span class="toc-number">1.2.1.</span> <span class="toc-text">主成分分析 (Principal Component Analysis - PCA)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90-Linear-Discriminant-Analysis-LDA"><span class="toc-number">1.2.2.</span> <span class="toc-text">线性判别分析 (Linear Discriminant Analysis - LDA)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#t-SNE-t-distributed-Stochastic-Neighbor-Embedding"><span class="toc-number">1.2.3.</span> <span class="toc-text">t-SNE (t-distributed Stochastic Neighbor Embedding)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#UMAP-Uniform-Manifold-Approximation-and-Projection"><span class="toc-number">1.2.4.</span> <span class="toc-text">UMAP (Uniform Manifold Approximation and Projection)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8%EF%BC%9A%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E4%B8%8E%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="toc-number">2.</span> <span class="toc-text">2. 自编码器：核心概念与工作原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E4%BB%80%E4%B9%88%E6%98%AF%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8%EF%BC%9F"><span class="toc-number">2.1.</span> <span class="toc-text">2.1 什么是自编码器？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E6%BD%9C%E5%9C%A8%E7%A9%BA%E9%97%B4-Latent-Space-%E7%9A%84%E6%84%8F%E4%B9%89"><span class="toc-number">2.2.</span> <span class="toc-text">2.2 潜在空间 (Latent Space) 的意义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0-Loss-Function"><span class="toc-number">2.3.</span> <span class="toc-text">2.3 损失函数 (Loss Function)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8%E4%B8%8E%E9%99%8D%E7%BB%B4"><span class="toc-number">2.4.</span> <span class="toc-text">2.4 自编码器与降维</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8%E7%9A%84%E5%8F%98%E4%BD%93%E4%B8%8E%E5%8F%91%E5%B1%95"><span class="toc-number">3.</span> <span class="toc-text">3. 自编码器的变体与发展</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E7%A8%80%E7%96%8F%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8-Sparse-Autoencoders-SAE"><span class="toc-number">3.1.</span> <span class="toc-text">3.1 稀疏自编码器 (Sparse Autoencoders - SAE)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E5%8E%BB%E5%99%AA%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8-Denoising-Autoencoders-DAE"><span class="toc-number">3.2.</span> <span class="toc-text">3.2 去噪自编码器 (Denoising Autoencoders - DAE)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E6%A0%88%E5%BC%8F%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8-Stacked-Autoencoders-SAE"><span class="toc-number">3.3.</span> <span class="toc-text">3.3 栈式自编码器 (Stacked Autoencoders - SAE)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8-Variational-Autoencoders-VAE"><span class="toc-number">3.4.</span> <span class="toc-text">3.4 变分自编码器 (Variational Autoencoders - VAE)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-5-%E6%94%B6%E7%BC%A9%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8-Contractive-Autoencoders-CAE"><span class="toc-number">3.5.</span> <span class="toc-text">3.5 收缩自编码器 (Contractive Autoencoders - CAE)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8%E7%9A%84%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">4.</span> <span class="toc-text">4. 自编码器的应用场景</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-%E6%95%B0%E6%8D%AE%E9%99%8D%E7%BB%B4%E4%B8%8E%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="toc-number">4.1.</span> <span class="toc-text">4.1 数据降维与可视化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-%E7%89%B9%E5%BE%81%E5%AD%A6%E4%B9%A0%E4%B8%8E%E8%A1%A8%E7%A4%BA"><span class="toc-number">4.2.</span> <span class="toc-text">4.2 特征学习与表示</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B-Anomaly-Detection"><span class="toc-number">4.3.</span> <span class="toc-text">4.3 异常检测 (Anomaly Detection)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-%E6%95%B0%E6%8D%AE%E5%8E%BB%E5%99%AA-Data-Denoising"><span class="toc-number">4.4.</span> <span class="toc-text">4.4 数据去噪 (Data Denoising)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-5-%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2"><span class="toc-number">4.5.</span> <span class="toc-text">4.5 信息检索</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-6-%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F"><span class="toc-number">4.6.</span> <span class="toc-text">4.6 推荐系统</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-7-%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B-Generative-Models"><span class="toc-number">4.7.</span> <span class="toc-text">4.7 生成模型 (Generative Models)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E5%AE%9E%E8%B7%B5%EF%BC%9A%E4%BD%BF%E7%94%A8Python%E5%92%8CTensorFlow-Keras%E6%9E%84%E5%BB%BA%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8"><span class="toc-number">5.</span> <span class="toc-text">5. 实践：使用Python和TensorFlow&#x2F;Keras构建自编码器</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87"><span class="toc-number">5.1.</span> <span class="toc-text">5.1 环境准备</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-%E6%95%B0%E6%8D%AE%E9%9B%86%E9%80%89%E6%8B%A9"><span class="toc-number">5.2.</span> <span class="toc-text">5.2 数据集选择</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-%E7%AE%80%E5%8D%95%E7%9A%84%E5%85%A8%E8%BF%9E%E6%8E%A5%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8"><span class="toc-number">5.3.</span> <span class="toc-text">5.3 简单的全连接自编码器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-%E4%BD%BF%E7%94%A8%E5%8D%B7%E7%A7%AF%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8%E8%BF%9B%E8%A1%8C%E5%9B%BE%E5%83%8F%E9%99%8D%E7%BB%B4"><span class="toc-number">5.4.</span> <span class="toc-text">5.4 使用卷积自编码器进行图像降维</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-%E7%BB%93%E8%AE%BA"><span class="toc-number">6.</span> <span class="toc-text">6. 结论</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/23/hello-world/" title="Hello World">Hello World</a><time datetime="2025-07-23T09:07:47.569Z" title="发表于 2025-07-23 17:07:47">2025-07-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/23/%E5%8D%9A%E5%BC%88%E8%AE%BA%E5%9F%BA%E7%A1%80/" title="博弈论基础">博弈论基础</a><time datetime="2025-07-23T09:07:47.569Z" title="发表于 2025-07-23 17:07:47">2025-07-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/23/2025-07-23-090513/" title="人类泛基因组计划：超越单一参考，解码生命多样性的宏伟蓝图">人类泛基因组计划：超越单一参考，解码生命多样性的宏伟蓝图</a><time datetime="2025-07-23T01:05:13.000Z" title="发表于 2025-07-23 09:05:13">2025-07-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/23/2025-07-23-090421/" title="细胞力学与细胞行为：微观世界的宏观奥秘">细胞力学与细胞行为：微观世界的宏观奥秘</a><time datetime="2025-07-23T01:04:21.000Z" title="发表于 2025-07-23 09:04:21">2025-07-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/23/2025-07-23-090324/" title="解锁生命密码的起始之钥：转录起始的精妙调控">解锁生命密码的起始之钥：转录起始的精妙调控</a><time datetime="2025-07-23T01:03:24.000Z" title="发表于 2025-07-23 09:03:24">2025-07-23</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;2025 By qmwneb946</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.2</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css')
    if (true) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const getGiscusTheme = theme => theme === 'dark' ? 'dark' : 'light'

  const createScriptElement = config => {
    const ele = document.createElement('script')
    Object.entries(config).forEach(([key, value]) => {
      ele.setAttribute(key, value)
    })
    return ele
  }

  const loadGiscus = (el = document, key) => {
    const mappingConfig = isShuoshuo
      ? { 'data-mapping': 'specific', 'data-term': key }
      : { 'data-mapping': (option && option['data-mapping']) || 'pathname' }

    const giscusConfig = {
      src: 'https://giscus.app/client.js',
      'data-repo': 'qmwneb946/blog',
      'data-repo-id': 'R_kgDOPM6cWw',
      'data-category-id': 'DIC_kwDOPM6cW84CtEzo',
      'data-theme': getGiscusTheme(document.documentElement.getAttribute('data-theme')),
      'data-reactions-enabled': '1',
      crossorigin: 'anonymous',
      async: true,
      ...option,
      ...mappingConfig
    }

    const scriptElement = createScriptElement(giscusConfig)

    el.querySelector('#giscus-wrap').appendChild(scriptElement)

    if (isShuoshuo) {
      window.shuoshuoComment.destroyGiscus = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }
  }

  const changeGiscusTheme = theme => {
    const iframe = document.querySelector('#giscus-wrap iframe')
    if (iframe) {
      const message = {
        giscus: {
          setConfig: {
            theme: getGiscusTheme(theme)
          }
        }
      }
      iframe.contentWindow.postMessage(message, 'https://giscus.app')
    }
  }

  btf.addGlobalFn('themeChange', changeGiscusTheme, 'giscus')

  if (isShuoshuo) {
    'Giscus' === 'Giscus'
      ? window.shuoshuoComment = { loadComment: loadGiscus }
      : window.loadOtherComment = loadGiscus
    return
  }

  if ('Giscus' === 'Giscus' || !false) {
    if (false) btf.loadComment(document.getElementById('giscus-wrap'), loadGiscus)
    else loadGiscus()
  } else {
    window.loadOtherComment = loadGiscus
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>