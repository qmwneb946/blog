<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>机器学习算法概述：从原理到实践的深度剖析 | qmwneb946 的博客</title><meta name="author" content="qmwneb946"><meta name="copyright" content="qmwneb946"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="引言：人工智能的引擎——机器学习 在当今数字驱动的世界里，“人工智能”和“机器学习”已不再是遥远的科幻概念，而是深刻地融入了我们生活的方方面面：从智能手机的面部识别解锁，到电商平台的个性化商品推荐，从自动驾驶汽车的路径规划，到医疗领域的疾病诊断辅助。机器学习，作为人工智能的核心引擎，正是赋予机器从数据中学习并做出决策能力的科学。 它本质上是一种通过数据而非显式编程来让计算机获得学习能力的范式。想">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习算法概述：从原理到实践的深度剖析">
<meta property="og:url" content="https://blog.qmwneb946.dpdns.org/2025/07/17/2025-07-17-182902/index.html">
<meta property="og:site_name" content="qmwneb946 的博客">
<meta property="og:description" content="引言：人工智能的引擎——机器学习 在当今数字驱动的世界里，“人工智能”和“机器学习”已不再是遥远的科幻概念，而是深刻地融入了我们生活的方方面面：从智能手机的面部识别解锁，到电商平台的个性化商品推荐，从自动驾驶汽车的路径规划，到医疗领域的疾病诊断辅助。机器学习，作为人工智能的核心引擎，正是赋予机器从数据中学习并做出决策能力的科学。 它本质上是一种通过数据而非显式编程来让计算机获得学习能力的范式。想">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://blog.qmwneb946.dpdns.org/img/icon.png">
<meta property="article:published_time" content="2025-07-17T10:29:02.000Z">
<meta property="article:modified_time" content="2025-07-18T05:32:14.812Z">
<meta property="article:author" content="qmwneb946">
<meta property="article:tag" content="2025">
<meta property="article:tag" content="数学">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://blog.qmwneb946.dpdns.org/img/icon.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "机器学习算法概述：从原理到实践的深度剖析",
  "url": "https://blog.qmwneb946.dpdns.org/2025/07/17/2025-07-17-182902/",
  "image": "https://blog.qmwneb946.dpdns.org/img/icon.png",
  "datePublished": "2025-07-17T10:29:02.000Z",
  "dateModified": "2025-07-18T05:32:14.812Z",
  "author": [
    {
      "@type": "Person",
      "name": "qmwneb946",
      "url": "https://github.com/qmwneb946"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://blog.qmwneb946.dpdns.org/2025/07/17/2025-07-17-182902/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '机器学习算法概述：从原理到实践的深度剖析',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="qmwneb946 的博客" type="application/atom+xml">
</head><body><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">qmwneb946 的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">机器学习算法概述：从原理到实践的深度剖析</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">机器学习算法概述：从原理到实践的深度剖析<a class="post-edit-link" href="https://github.com/qmwneb946/blog/edit/main/source/_posts/2025-07-17-182902.md" title="编辑" target="_blank"><i class="fas fa-pencil-alt"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-07-17T10:29:02.000Z" title="发表于 2025-07-17 18:29:02">2025-07-17</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-07-18T05:32:14.812Z" title="更新于 2025-07-18 13:32:14">2025-07-18</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%95%B0%E5%AD%A6/">数学</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><hr>
<h2 id="引言：人工智能的引擎——机器学习">引言：人工智能的引擎——机器学习</h2>
<p>在当今数字驱动的世界里，“人工智能”和“机器学习”已不再是遥远的科幻概念，而是深刻地融入了我们生活的方方面面：从智能手机的面部识别解锁，到电商平台的个性化商品推荐，从自动驾驶汽车的路径规划，到医疗领域的疾病诊断辅助。机器学习，作为人工智能的核心引擎，正是赋予机器从数据中学习并做出决策能力的科学。</p>
<p>它本质上是一种通过数据而非显式编程来让计算机获得学习能力的范式。想象一下，你无需一步步告诉计算机如何识别猫，而是向它展示成千上万张猫的图片，它便能自己归纳出“猫”的特征。这便是机器学习的魔力。</p>
<p>本文旨在为技术爱好者提供一份高质量、有深度的机器学习算法概述。我们将深入探讨机器学习的三大主要范式，并详细介绍每个范畴下的核心算法，理解它们的原理、应用场景以及优缺点。让我们一起踏上这场探索之旅，揭开机器学习算法的神秘面纱。</p>
<h2 id="机器学习的基石：三大核心学习范式">机器学习的基石：三大核心学习范式</h2>
<p>机器学习算法通常根据其学习方式和数据类型分为以下三大类：监督学习、无监督学习和强化学习。理解这三种范式是理解所有机器学习算法的基础。</p>
<h3 id="1-监督学习-Supervised-Learning">1. 监督学习 (Supervised Learning)</h3>
<p><strong>核心思想：</strong> 从<strong>有标签</strong>的数据中学习。这意味着训练数据集中的每个输入都与一个已知的正确输出（标签）相关联。算法的目标是学习一个映射函数，将输入映射到输出，以便对新的、未见过的数据进行准确预测。</p>
<p><strong>应用场景：</strong> 当我们有历史数据和对应的结果时，例如预测房价（结果是具体数值）或识别邮件是否为垃圾邮件（结果是类别）。</p>
<p>监督学习主要分为两大类问题：</p>
<h4 id="a-回归-Regression">a. 回归 (Regression)</h4>
<p><strong>目标：</strong> 预测一个<strong>连续的数值输出</strong>。</p>
<p><strong>示例：</strong> 预测房价、股票价格、气温、销售额等。</p>
<p><strong>常用算法：</strong></p>
<ul>
<li>
<p><strong>线性回归 (Linear Regression):</strong> 最基础的回归算法，通过找到最佳拟合直线（或超平面）来建模输入特征和连续输出之间的关系。</p>
<ul>
<li><strong>原理：</strong> 假设特征与目标之间存在线性关系。对于单变量线性回归，模型表示为：<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>y</mi><mo>=</mo><msub><mi>β</mi><mn>0</mn></msub><mo>+</mo><msub><mi>β</mi><mn>1</mn></msub><mi>x</mi><mo>+</mo><mi>ϵ</mi></mrow><annotation encoding="application/x-tex">y = \beta_0 + \beta_1 x + \epsilon 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0528em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0528em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">ϵ</span></span></span></span></span></p>
其中 ( y ) 是预测值，( x ) 是输入特征，( \beta_0 ) 是截距，( \beta_1 ) 是斜率（系数），( \epsilon ) 是误差项。算法通过最小化残差平方和（即真实值与预测值之差的平方和，也称为均方误差 MSE）来找到最优的 ( \beta_0 ) 和 ( \beta_1 )。</li>
<li><strong>优点：</strong> 简单、快速、易于解释。</li>
<li><strong>缺点：</strong> 假设线性关系，对异常值敏感。</li>
</ul>
</li>
<li>
<p><strong>多项式回归 (Polynomial Regression):</strong> 当数据是非线性关系时，通过引入特征的幂次项来拟合曲线。</p>
</li>
<li>
<p><strong>支持向量回归 (Support Vector Regression, SVR):</strong> 支持向量机在回归问题上的应用，旨在找到一个能够容忍一定误差的超平面。</p>
</li>
<li>
<p><strong>决策树回归 (Decision Tree Regressor):</strong> 通过一系列的条件判断，将数据分割成更小的子集，最终在叶节点给出预测值。</p>
</li>
<li>
<p><strong>随机森林回归 (Random Forest Regressor):</strong> 集合了多棵决策树的集成学习方法，通过多棵树的平均预测值来提高准确性和鲁棒性。</p>
</li>
<li>
<p><strong>梯度提升机 (Gradient Boosting Machines, GBM) / XGBoost / LightGBM:</strong> 强大的集成学习方法，通过迭代训练弱学习器（通常是决策树）并逐步纠正前一个学习器的错误来提高性能。</p>
</li>
</ul>
<p><strong>代码示例（概念性：使用 scikit-learn 进行线性回归）:</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设有一些房屋面积和价格数据</span></span><br><span class="line"><span class="comment"># X: 房屋面积 (特征)</span></span><br><span class="line"><span class="comment"># y: 房屋价格 (标签)</span></span><br><span class="line">X = np.array([<span class="number">50</span>, <span class="number">75</span>, <span class="number">100</span>, <span class="number">120</span>, <span class="number">150</span>, <span class="number">170</span>, <span class="number">200</span>]).reshape(-<span class="number">1</span>, <span class="number">1</span>) <span class="comment"># 特征需要是二维数组</span></span><br><span class="line">y = np.array([<span class="number">150</span>, <span class="number">200</span>, <span class="number">250</span>, <span class="number">290</span>, <span class="number">350</span>, <span class="number">380</span>, <span class="number">420</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分训练集和测试集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建线性回归模型</span></span><br><span class="line">model = LinearRegression()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行预测</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 评估模型</span></span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;模型的系数: <span class="subst">&#123;model.coef_[<span class="number">0</span>]:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;模型的截距: <span class="subst">&#123;model.intercept_:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;测试集上的均方误差 (MSE): <span class="subst">&#123;mse:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测一个新房子的价格 (例如，面积110平米)</span></span><br><span class="line">new_house_area = np.array([[<span class="number">110</span>]])</span><br><span class="line">predicted_price = model.predict(new_house_area)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;预测面积为110平米的房屋价格: <span class="subst">&#123;predicted_price[<span class="number">0</span>]:<span class="number">.2</span>f&#125;</span> 万元&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="b-分类-Classification">b. 分类 (Classification)</h4>
<p><strong>目标：</strong> 预测一个<strong>离散的类别标签</strong>。</p>
<p><strong>示例：</strong> 判断邮件是否为垃圾邮件（是/否）、识别图片中的动物种类（猫/狗/鸟）、疾病诊断（阳性/阴性）等。</p>
<p><strong>常用算法：</strong></p>
<ul>
<li>
<p><strong>逻辑回归 (Logistic Regression):</strong> 尽管名字有“回归”，但它是一种广泛用于二分类问题的分类算法。它通过 Sigmoid 函数将线性模型的输出映射到 (0, 1) 区间，表示属于某一类别的概率。</p>
<ul>
<li><strong>原理：</strong> 基于线性模型的输出 ( z = \beta_0 + \beta_1 x )，通过 Sigmoid 函数将其转化为概率：<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>Y</mi><mo>=</mo><mn>1</mn><mi mathvariant="normal">∣</mi><mi>X</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>z</mi></mrow></msup></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><mo stretchy="false">(</mo><msub><mi>β</mi><mn>0</mn></msub><mo>+</mo><msub><mi>β</mi><mn>1</mn></msub><mi>x</mi><mo stretchy="false">)</mo></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">P(Y=1|X) = \frac{1}{1 + e^{-z}} = \frac{1}{1 + e^{-(\beta_0 + \beta_1 x)}} 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.22222em;">Y</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1∣</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.0908em;vertical-align:-0.7693em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6973em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.1088em;vertical-align:-0.7873em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.296em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.814em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mopen mtight">(</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.0528em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.0528em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mord mathnormal mtight">x</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7873em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
然后根据设定的阈值（通常是0.5）将概率转换为类别。</li>
<li><strong>优点：</strong> 简单、快速、易于解释、输出概率。</li>
<li><strong>缺点：</strong> 假设特征与目标之间存在线性决策边界。</li>
</ul>
</li>
<li>
<p><strong>K近邻 (K-Nearest Neighbors, k-NN):</strong> 基于实例的学习，通过测量距离来找到与新数据点最接近的 K 个训练样本，并根据这些近邻的类别进行投票决定新数据点的类别。</p>
</li>
<li>
<p><strong>支持向量机 (Support Vector Machine, SVM):</strong> 旨在找到一个最优的超平面，以最大化不同类别数据点之间的间隔。在处理高维数据和非线性问题时表现出色（通过核技巧）。</p>
</li>
<li>
<p><strong>决策树分类 (Decision Tree Classifier):</strong> 同回归树，但叶节点输出类别标签。</p>
</li>
<li>
<p><strong>朴素贝叶斯 (Naive Bayes):</strong> 基于贝叶斯定理和特征条件独立性假设的概率分类器。适用于文本分类等。</p>
</li>
<li>
<p><strong>神经网络 (Neural Networks):</strong> 受到人脑结构启发，通过多层神经元处理复杂模式，是深度学习的基础。适用于图像识别、语音识别等复杂任务。</p>
</li>
</ul>
<p><strong>代码示例（概念性：使用 scikit-learn 进行逻辑回归分类）:</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设有一些学习时间和是否通过考试的数据</span></span><br><span class="line"><span class="comment"># X: 学习时间 (特征)</span></span><br><span class="line"><span class="comment"># y: 是否通过考试 (0: 未通过, 1: 通过)</span></span><br><span class="line">X = np.array([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">y = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分训练集和测试集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建逻辑回归模型</span></span><br><span class="line">model = LogisticRegression()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行预测</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 评估模型</span></span><br><span class="line">accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;测试集上的准确率: <span class="subst">&#123;accuracy:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测一个新学生的通过概率 (例如，学习时间5.5小时)</span></span><br><span class="line">new_student_hours = np.array([[<span class="number">5.5</span>]])</span><br><span class="line">predicted_proba = model.predict_proba(new_student_hours)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;学习5.5小时的学生通过考试的概率: <span class="subst">&#123;predicted_proba[<span class="number">0</span>][<span class="number">1</span>]:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="2-无监督学习-Unsupervised-Learning">2. 无监督学习 (Unsupervised Learning)</h3>
<p><strong>核心思想：</strong> 从<strong>无标签</strong>的数据中学习。算法的任务是发现数据中隐藏的结构、模式或关联，而不是预测特定的输出。</p>
<p><strong>应用场景：</strong> 当我们只有数据但没有明确的“答案”时，例如客户细分、数据降维、异常检测等。</p>
<p>无监督学习主要包括：</p>
<h4 id="a-聚类-Clustering">a. 聚类 (Clustering)</h4>
<p><strong>目标：</strong> 将数据点分组，使得同组内的数据点相似度高，不同组间的数据点相似度低。</p>
<p><strong>示例：</strong> 客户细分、图片像素聚类、文档主题发现。</p>
<p><strong>常用算法：</strong></p>
<ul>
<li>
<p><strong>K均值 (K-Means):</strong> 最流行的聚类算法之一。</p>
<ul>
<li><strong>原理：</strong> 预先指定聚类的数量 K。算法随机选择 K 个初始质心（簇的中心），然后迭代地执行两个步骤：
<ol>
<li><strong>分配步：</strong> 将每个数据点分配到最近的质心所在的簇。</li>
<li><strong>更新步：</strong> 重新计算每个簇的质心（该簇所有数据点的平均值）。<br>
这个过程重复直到质心不再显著移动或达到最大迭代次数。其目标是最小化簇内平方和（Within-Cluster Sum of Squares, WCSS）。</li>
</ol>
</li>
<li><strong>优点：</strong> 简单、高效、易于实现。</li>
<li><strong>缺点：</strong> 需要预设 K 值，对初始质心和异常值敏感，只适用于球形簇。</li>
</ul>
</li>
<li>
<p><strong>DBSCAN (Density-Based Spatial Clustering of Applications with Noise):</strong> 基于密度的聚类算法，能够发现任意形状的簇，并有效识别噪声点。</p>
</li>
<li>
<p><strong>层次聚类 (Hierarchical Clustering):</strong> 构建一个簇的层次结构（树状图），可以自下而上（凝聚式）或自上而下（分裂式）。</p>
</li>
<li>
<p><strong>高斯混合模型 (Gaussian Mixture Models, GMM):</strong> 假设数据点来自多个高斯分布的混合，通过期望最大化（EM）算法来估计每个分布的参数和每个数据点属于每个分布的概率。</p>
</li>
</ul>
<p><strong>代码示例（概念性：使用 scikit-learn 进行 K-Means 聚类）:</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设有一些客户的消费金额和访问次数数据</span></span><br><span class="line"><span class="comment"># X: 客户数据 (两个特征)</span></span><br><span class="line">X = np.array([</span><br><span class="line">    [<span class="number">100</span>, <span class="number">5</span>], [<span class="number">120</span>, <span class="number">6</span>], [<span class="number">90</span>, <span class="number">4</span>], [<span class="number">300</span>, <span class="number">15</span>], [<span class="number">320</span>, <span class="number">14</span>],</span><br><span class="line">    [<span class="number">280</span>, <span class="number">13</span>], [<span class="number">50</span>, <span class="number">2</span>], [<span class="number">60</span>, <span class="number">3</span>], [<span class="number">250</span>, <span class="number">11</span>]</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据标准化（对于聚类很重要）</span></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X_scaled = scaler.fit_transform(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 K-Means 模型，假设我们想分为3个簇</span></span><br><span class="line">kmeans = KMeans(n_clusters=<span class="number">3</span>, random_state=<span class="number">42</span>, n_init=<span class="number">10</span>) <span class="comment"># n_init ensures robustness</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">kmeans.fit(X_scaled)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取每个数据点的簇标签</span></span><br><span class="line">labels = kmeans.labels_</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取簇中心</span></span><br><span class="line">centers = kmeans.cluster_centers_</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;每个数据点的簇标签:&quot;</span>, labels)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;簇中心 (标准化后):\n&quot;</span>, centers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化聚类结果 (简化，实际需要逆标准化中心点或直接画原始数据)</span></span><br><span class="line">plt.scatter(X_scaled[:, <span class="number">0</span>], X_scaled[:, <span class="number">1</span>], c=labels, cmap=<span class="string">&#x27;viridis&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, s=<span class="number">100</span>, alpha=<span class="number">0.8</span>)</span><br><span class="line">plt.scatter(centers[:, <span class="number">0</span>], centers[:, <span class="number">1</span>], c=<span class="string">&#x27;red&#x27;</span>, marker=<span class="string">&#x27;X&#x27;</span>, s=<span class="number">200</span>, label=<span class="string">&#x27;Cluster Centers&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;K-Means Clustering (Standardized Data)&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Scaled Feature 1 (Consumption)&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Scaled Feature 2 (Visits)&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h4 id="b-降维-Dimensionality-Reduction">b. 降维 (Dimensionality Reduction)</h4>
<p><strong>目标：</strong> 减少数据集的特征数量，同时尽可能保留数据中的重要信息。</p>
<p><strong>示例：</strong> 数据可视化、特征工程、去除冗余信息。</p>
<p><strong>常用算法：</strong></p>
<ul>
<li>
<p><strong>主成分分析 (Principal Component Analysis, PCA):</strong></p>
<ul>
<li><strong>原理：</strong> 是一种线性降维技术。它通过正交变换将原始数据投影到新的坐标系上，新坐标系由主成分组成，这些主成分是原始特征的线性组合。第一个主成分捕获数据中最大的方差，第二个主成分捕获次大的方差，以此类推。从而可以在较低维度上表示数据，同时保留大部分信息。</li>
<li><strong>优点：</strong> 降低维度、去除冗余特征、提高模型效率、有助于可视化。</li>
<li><strong>缺点：</strong> 丢失一些信息，主成分的解释性可能不强。</li>
</ul>
</li>
<li>
<p><strong>t-SNE (t-Distributed Stochastic Neighbor Embedding):</strong> 一种非线性降维算法，特别适用于高维数据的可视化，它旨在保留数据点之间的局部结构。</p>
</li>
<li>
<p><strong>奇异值分解 (Singular Value Decomposition, SVD):</strong> 广泛应用于降维、矩阵分解等。</p>
</li>
</ul>
<h4 id="c-关联规则学习-Association-Rule-Learning">c. 关联规则学习 (Association Rule Learning)</h4>
<p><strong>目标：</strong> 发现数据集中项集之间的有趣关系，通常以“如果发生X，则可能发生Y”的形式表示。</p>
<p><strong>示例：</strong> 购物篮分析（“购买了牛奶和面包的顾客也倾向于购买鸡蛋”）。</p>
<p><strong>常用算法：</strong></p>
<ul>
<li><strong>Apriori 算法:</strong> 经典的关联规则挖掘算法，通过迭代地生成候选项集并剪枝，发现频繁项集和关联规则。</li>
</ul>
<h3 id="3-强化学习-Reinforcement-Learning-RL">3. 强化学习 (Reinforcement Learning, RL)</h3>
<p><strong>核心思想：</strong> 智能体 (Agent) 通过与环境 (Environment) 的交互来学习，目标是最大化累积奖励 (Cumulative Reward)。它不像监督学习那样有明确的标签，也不像无监督学习那样寻找数据结构，而是通过“试错”来学习最优行为策略。</p>
<p><strong>应用场景：</strong> 游戏AI（AlphaGo）、机器人控制、自动驾驶、资源管理、推荐系统等。</p>
<p><strong>核心要素：</strong></p>
<ul>
<li><strong>智能体 (Agent):</strong> 学习者和决策者。</li>
<li><strong>环境 (Environment):</strong> 智能体所处的外部世界。</li>
<li><strong>状态 (State):</strong> 环境的当前情况。</li>
<li><strong>动作 (Action):</strong> 智能体在给定状态下可以采取的行为。</li>
<li><strong>奖励 (Reward):</strong> 智能体采取某个动作后，环境给予的反馈信号（可以是正或负）。</li>
<li><strong>策略 (Policy):</strong> 智能体从状态到动作的映射，决定了在给定状态下采取什么动作。</li>
<li><strong>价值函数 (Value Function):</strong> 评估在某个状态下或采取某个动作后未来累积奖励的期望。</li>
</ul>
<p><strong>常用算法/方法：</strong></p>
<ul>
<li><strong>Q-Learning:</strong> 一种基于值函数的离策略 (Off-policy) 学习算法，通过更新 Q 值（表示在某个状态下采取某个动作的预期未来奖励）来找到最优策略。
<ul>
<li><strong>Q值更新公式（贝尔曼方程的离散形式）:</strong><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>Q</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo><mo>←</mo><mi>Q</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo><mo>+</mo><mi>α</mi><mo stretchy="false">[</mo><mi>r</mi><mo>+</mo><mi>γ</mi><munder><mrow><mi>max</mi><mo>⁡</mo></mrow><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></munder><mi>Q</mi><mo stretchy="false">(</mo><msup><mi>s</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo separator="true">,</mo><msup><mi>a</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo stretchy="false">)</mo><mo>−</mo><mi>Q</mi><mo stretchy="false">(</mo><mi>s</mi><mo separator="true">,</mo><mi>a</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">Q(s, a) \leftarrow Q(s, a) + \alpha [r + \gamma \max_{a&#x27;} Q(s&#x27;, a&#x27;) - Q(s, a)] 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.5459em;vertical-align:-0.744em;"></span><span class="mord mathnormal" style="margin-right:0.05556em;">γ</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.4306em;"><span style="top:-2.356em;margin-left:0em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6828em;"><span style="top:-2.786em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span><span class="mop">max</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.744em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8019em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">Q</span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">a</span><span class="mclose">)]</span></span></span></span></span></p>
其中 ( s ) 是当前状态，( a ) 是当前动作，( r ) 是即时奖励，( s’ ) 是新状态，( a’ ) 是新状态下的最优动作，( \alpha ) 是学习率，( \gamma ) 是折扣因子。</li>
</ul>
</li>
<li><strong>SARSA (State-Action-Reward-State-Action):</strong> 一种基于值函数的在策略 (On-policy) 学习算法，与 Q-Learning 类似，但它根据当前策略选择下一个动作来更新 Q 值。</li>
<li><strong>深度Q网络 (Deep Q-Networks, DQN):</strong> 将深度学习（神经网络）与 Q-Learning 结合，解决了 Q-Learning 难以处理高维状态空间的问题。</li>
<li><strong>策略梯度 (Policy Gradients):</strong> 直接学习最优策略，而不是通过值函数间接学习。</li>
</ul>
<p><strong>强化学习的挑战：</strong> 探索与利用的平衡、奖励稀疏性、高维状态空间。</p>
<h2 id="算法选择与评估：如何量体裁衣？">算法选择与评估：如何量体裁衣？</h2>
<p>选择合适的机器学习算法并非易事，它取决于多种因素：</p>
<ol>
<li><strong>问题类型：</strong> 是监督学习（回归/分类）、无监督学习（聚类/降维）还是强化学习？</li>
<li><strong>数据特征：</strong> 数据量、数据维度、特征类型（数值/类别）、是否存在缺失值或异常值。</li>
<li><strong>模型解释性要求：</strong> 有些场景要求模型能被人类理解（如线性回归、决策树），而有些场景更注重性能（如深度学习、集成方法）。</li>
<li><strong>计算资源：</strong> 算法的训练和预测时间、内存消耗。</li>
<li><strong>性能要求：</strong> 对准确率、召回率、延迟等指标的具体要求。</li>
</ol>
<h3 id="常用评估指标">常用评估指标</h3>
<p>不同的机器学习任务需要不同的评估指标来衡量模型的好坏：</p>
<ul>
<li>
<p><strong>回归问题：</strong></p>
<ul>
<li><strong>均方误差 (Mean Squared Error, MSE):</strong> ( \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 )</li>
<li><strong>均方根误差 (Root Mean Squared Error, RMSE):</strong> ( \sqrt{\text{MSE}} )</li>
<li><strong>平均绝对误差 (Mean Absolute Error, MAE):</strong> ( \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i| )</li>
<li><strong>R平方 (R-squared, (R^2)):</strong> 表示模型解释了因变量变异的百分比。</li>
</ul>
</li>
<li>
<p><strong>分类问题：</strong></p>
<ul>
<li><strong>准确率 (Accuracy):</strong> ( \frac{\text{正确预测的数量}}{\text{总样本数}} )</li>
<li><strong>精确率 (Precision):</strong> ( \frac{\text{真阳性}}{\text{真阳性} + \text{假阳性}} ) (预测为正的样本中真正为正的比例)</li>
<li><strong>召回率 (Recall / Sensitivity):</strong> ( \frac{\text{真阳性}}{\text{真阳性} + \text{假阴性}} ) (所有真正为正的样本中被正确识别的比例)</li>
<li><strong>F1-Score:</strong> 精确率和召回率的调和平均值，当类不平衡时比准确率更具参考价值。</li>
<li><strong>混淆矩阵 (Confusion Matrix):</strong> 直观展示真阳性、真阴性、假阳性、假阴性。</li>
<li><strong>ROC曲线和AUC值 (Receiver Operating Characteristic &amp; Area Under the Curve):</strong> 衡量分类器在不同阈值下的性能，尤其适用于不平衡数据集。</li>
</ul>
</li>
<li>
<p><strong>聚类问题：</strong></p>
<ul>
<li><strong>轮廓系数 (Silhouette Score):</strong> 衡量簇内紧密度和簇间离散度，值越高表示聚类效果越好。</li>
<li><strong>Davies-Bouldin Index (DBI):</strong> 衡量簇的紧凑性和分离度，值越低表示聚类效果越好。</li>
</ul>
</li>
</ul>
<h3 id="过拟合与欠拟合">过拟合与欠拟合</h3>
<p>在模型训练过程中，我们常会遇到两个核心问题：</p>
<ul>
<li><strong>欠拟合 (Underfitting):</strong> 模型未能充分捕捉数据中的模式，表现为在训练集和测试集上都表现不佳。</li>
<li><strong>过拟合 (Overfitting):</strong> 模型过度学习了训练数据中的噪声和特有模式，导致在训练集上表现很好，但在测试集上表现很差。</li>
</ul>
<p>为了避免这两个问题，常用的技术包括：<strong>交叉验证 (Cross-validation)</strong>、正则化、增加数据量、特征选择、集成学习等。</p>
<h2 id="结论：机器学习的持续演进">结论：机器学习的持续演进</h2>
<p>我们已经概述了机器学习的三大核心范式——监督学习、无监督学习和强化学习，并深入探讨了它们各自领域内的代表性算法。从预测连续数值的回归模型，到分类离散类别的分类器；从发现数据隐藏结构的聚类和降维算法，到通过试错学习最优策略的强化学习，每一种算法都有其独特的数学原理和适用场景。</p>
<p>机器学习是一个持续演进的领域。新的算法不断涌现，现有算法也在不断优化。理解这些算法的原理是基础，而如何根据实际问题选择、训练和评估模型，更是从理论走向实践的关键。</p>
<p>作为技术爱好者，掌握这些基础知识只是开始。更重要的是动手实践，通过实际项目去应用这些算法，去面对真实世界中的数据挑战。愿这篇概述能为您在机器学习的旅程中点亮一盏明灯，激发您继续深入探索的热情。未来的智能世界，正等待着我们去创造！</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a target="_blank" rel="noopener" href="https://github.com/qmwneb946">qmwneb946</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://blog.qmwneb946.dpdns.org/2025/07/17/2025-07-17-182902/">https://blog.qmwneb946.dpdns.org/2025/07/17/2025-07-17-182902/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://opensource.org/licenses/MIT" target="_blank">MIT License</a> 许可协议。转载请注明来源 <a href="https://blog.qmwneb946.dpdns.org" target="_blank">qmwneb946 的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/2025/">2025</a><a class="post-meta__tags" href="/tags/%E6%95%B0%E5%AD%A6/">数学</a></div><div class="post-share"><div class="social-share" data-image="/img/icon.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/07/17/2025-07-17-191728/" title="图论入门：连接世界的数学之美"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">图论入门：连接世界的数学之美</div></div><div class="info-2"><div class="info-item-1">引言 想象一下现代生活中的各种互联系统：社交网络中的好友关系，城市中错综复杂的道路，互联网上的信息流，甚至是生物体内的蛋白质相互作用网络。这些看似不同的系统，背后却隐藏着一个共同且强大的数学框架——图论。 图论（Graph Theory）是数学的一个分支，它研究的是点（顶点或节点）与点之间连接（边）的结构。它提供了一种抽象而直观的方式来建模和分析各种关系和连接问题。从计算机科学到运筹学，从物理学到生物学，图论都扮演着不可或缺的角色。 作为一名技术爱好者，掌握图论的基础知识，不仅能帮助你更好地理解各种算法背后的逻辑，还能为解决复杂的实际问题提供全新的视角。本文将带你步入图论的大门，从基本概念讲起，深入探讨图的表示方法、经典算法，并展望其在现实世界中的广泛应用。 图论的基础概念 在图论中，我们使用“图”来表示对象之间的关系。一个图 (G) 通常由两个集合定义：顶点集合 (V) 和边集合 (E)。 G=(V,E)G = (V, E)  G=(V,E)  顶点（Vertex / Node）：集合 (V) 中的元素，代表了我们要建模的实体或对象。例如，社交网络中的用户、城市中的十字路口。 ...</div></div></div></a><a class="pagination-related" href="/2025/07/17/2025-07-17-171904/" title="深入理解区块链技术：从零到一的硬核解析"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">深入理解区块链技术：从零到一的硬核解析</div></div><div class="info-2"><div class="info-item-1">在数字化浪潮席卷全球的今天，区块链技术无疑是其中最引人注目且最具颠覆潜力的创新之一。它不仅仅是比特币的底层支撑，更被誉为构建未来数字经济基础设施的基石。然而，对于许多人来说，“区块链”这个词汇依旧带着一层神秘的面纱，它究竟是如何运作的？其背后的数学和计算机科学原理又是什么？ 作为一名热衷于技术与数学的博主，我将在这篇文章中，以深入浅出的方式，带你揭开区块链的神秘面纱，从核心组件到运作机制，再到实际应用，进行一场全面的硬核解析。无论你是编程新手、数据科学家，还是对未来技术充满好奇的普通读者，这篇文章都将为你提供理解区块链的坚实基础。 什么是区块链？核心概念速览 简单来说，区块链（Blockchain）是一种去中心化的、分布式账本技术（Distributed Ledger Technology, DLT）。它将数据以“块”（Block）的形式进行打包，并以密码学方式链接起来，形成一个不可篡改的“链”（Chain）。 想象一下，你不再需要一个银行或中央服务器来记录所有交易，而是每个人都有一个账本副本，并且这些账本会自动同步和验证。这就是区块链的核心思想：去中心化、不可篡改、公开透明和安...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/07/17/2025-07-17-141851/" title="机器学习算法概述：从原理到实践的探索"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-17</div><div class="info-item-2">机器学习算法概述：从原理到实践的探索</div></div><div class="info-2"><div class="info-item-1">在当今数字驱动的世界里，机器学习（Machine Learning, ML）已不再是科幻小说中的概念，而是深入到我们生活的方方面面，从智能推荐系统、自动驾驶到医疗诊断和金融风控。它像一位无形的设计师，悄然重塑着我们的体验和效率。但机器学习究竟是什么？它背后的“魔力”源于何处？ 本文旨在为技术爱好者们提供一份高质量、有深度的机器学习算法概述。我们将深入探讨机器学习的核心范式，剖析各类经典算法的原理与应用，并揭示其背后的数学美学。无论您是初学者还是希望系统化知识的实践者，本文都将为您打开机器学习的精彩大门。 机器学习的基石：四大核心学习范式 机器学习的核心思想是让计算机系统通过数据“学习”，从而无需明确编程就能执行特定任务。根据数据类型和学习目标的不同，机器学习通常被划分为以下四大范式： 1. 监督学习 (Supervised Learning) 监督学习是机器学习中最常见、应用最广泛的一种范式。它的核心在于**“有监督”**，即模型通过带有标签（已知答案）的数据进行训练。你可以将其想象成一个学生，在老师（标签）的指导下，通过大量的练习（数据）来学习如何解决问题。 目标：从输入数据和...</div></div></div></a><a class="pagination-related" href="/2025/07/17/2025-07-17-152148/" title="无服务器架构解析：从概念到实践的深度探索"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-17</div><div class="info-item-2">无服务器架构解析：从概念到实践的深度探索</div></div><div class="info-2"><div class="info-item-1">在云计算的演进浪潮中，有一种架构范式正以其独特的魅力改变着我们开发和部署应用的方式，它就是“无服务器架构”（Serverless Architecture）。这个名字听起来有些反直觉——毕竟，没有服务器，应用程序又如何在空中运行呢？作为一名技术和数学的博主，我将带你深入探索无服务器架构的奥秘，从它的核心概念、组成部件，到其优势与挑战，并结合数学视角分析其成本效益，最终展望其未来。 引言：云计算的“终极抽象”之旅 回望软件开发的历史，我们经历了从物理机到虚拟机，再到容器化的演进。每一次变革都旨在提高资源利用率、简化部署和管理。  物理机时代：你拥有并维护自己的硬件，一切从零开始。 IaaS (Infrastructure as a Service)：云服务商提供虚拟机，你依然需要管理操作系统和运行时。 PaaS (Platform as a Service)：云服务商提供完整的运行时环境，你只需部署代码，但仍需关心平台配置和伸缩。 容器化 (Containerization)：如Docker和Kubernetes，提供了标准化的部署单元和强大的编排能力，但集群管理依然复杂。  而无...</div></div></div></a><a class="pagination-related" href="/2025/07/17/2025-07-17-191728/" title="图论入门：连接世界的数学之美"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-17</div><div class="info-item-2">图论入门：连接世界的数学之美</div></div><div class="info-2"><div class="info-item-1">引言 想象一下现代生活中的各种互联系统：社交网络中的好友关系，城市中错综复杂的道路，互联网上的信息流，甚至是生物体内的蛋白质相互作用网络。这些看似不同的系统，背后却隐藏着一个共同且强大的数学框架——图论。 图论（Graph Theory）是数学的一个分支，它研究的是点（顶点或节点）与点之间连接（边）的结构。它提供了一种抽象而直观的方式来建模和分析各种关系和连接问题。从计算机科学到运筹学，从物理学到生物学，图论都扮演着不可或缺的角色。 作为一名技术爱好者，掌握图论的基础知识，不仅能帮助你更好地理解各种算法背后的逻辑，还能为解决复杂的实际问题提供全新的视角。本文将带你步入图论的大门，从基本概念讲起，深入探讨图的表示方法、经典算法，并展望其在现实世界中的广泛应用。 图论的基础概念 在图论中，我们使用“图”来表示对象之间的关系。一个图 (G) 通常由两个集合定义：顶点集合 (V) 和边集合 (E)。 G=(V,E)G = (V, E)  G=(V,E)  顶点（Vertex / Node）：集合 (V) 中的元素，代表了我们要建模的实体或对象。例如，社交网络中的用户、城市中的十字路口。 ...</div></div></div></a><a class="pagination-related" href="/2025/07/17/2025-07-17-211854/" title="机器学习算法概述：从原理到应用的全景探索"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-17</div><div class="info-item-2">机器学习算法概述：从原理到应用的全景探索</div></div><div class="info-2"><div class="info-item-1">机器学习 (Machine Learning, ML) 作为人工智能领域的核心分支，正以前所未有的速度改变着我们的世界。从智能推荐系统、自动驾驶到疾病诊断，机器学习算法无处不在。但这些神奇的功能背后，究竟是哪些“魔法”在运作？作为一名技术和数学爱好者，深入理解机器学习算法的原理至关重要。 本文将带领大家系统地探索机器学习算法的广阔图景。我们将从算法的学习方式出发，将其划分为几个主要范畴：监督学习、无监督学习、半监督学习和强化学习，并对每个范畴内的核心算法进行深入浅出的介绍。 1. 机器学习的基石：学习范式概览 机器学习的本质是让计算机通过数据而不是明确的编程来学习。根据数据类型和学习目标的不同，机器学习算法通常被分为以下几大类： 1.1 监督学习 (Supervised Learning) 核心思想： 从带有标签（即已知输入和对应输出）的数据中学习一个映射函数。目标是预测新输入数据对应的输出。 常见任务：  回归 (Regression): 预测连续值输出，例如房价、股票价格。 分类 (Classification): 预测离散的类别标签，例如邮件是否为垃圾邮件、图片中是猫还是狗...</div></div></div></a><a class="pagination-related" href="/2025/07/17/2025-07-17-221929/" title="深入探讨神经网络：从原理到实践的探索"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-17</div><div class="info-item-2">深入探讨神经网络：从原理到实践的探索</div></div><div class="info-2"><div class="info-item-1">引言 在当今科技浪潮中，“人工智能”无疑是最激动人心的词汇之一。从智能推荐系统到自动驾驶汽车，从疾病诊断到自然语言处理，AI正以前所未有的速度改变着我们的世界。而在这场变革的核心，隐藏着一个精妙且强大的计算模型——神经网络。 对于许多技术爱好者而言，神经网络似乎是一个神秘的“黑箱”。它如何学习？为何能做出如此复杂的决策？本文旨在揭开神经网络的神秘面纱，带您从最基本的神经元开始，逐步深入理解其内部机制、训练过程以及面临的挑战，最终展望其未来的发展。无论您是初学者还是有一定基础的开发者，都将从这次深度探索中获益。 1. 神经网络的基石：神经元 要理解神经网络，我们必须从其最基本的组成单位——神经元（Neuron）或称为感知机（Perceptron）——开始。它受到生物神经元的启发，尽管其数学模型远比生物神经元简单，但已足够强大。 一个人工神经元接收来自其他神经元的输入信号，每个信号都有一个权重（Weight），表示该输入的重要性。所有加权输入会被求和，并加上一个**偏置（Bias）项。最后，这个和会通过一个激活函数（Activation Function）**来产生神经元的输出。 数...</div></div></div></a><a class="pagination-related" href="/2025/07/17/2025-07-17-231957/" title="P vs NP 问题：计算世界的终极谜团"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-17</div><div class="info-item-2">P vs NP 问题：计算世界的终极谜团</div></div><div class="info-2"><div class="info-item-1"> 引言：百万美元的计算之谜 在计算机科学和数学的殿堂中，P vs NP 问题无疑是最耀眼、最深刻的未解之谜之一。它被克莱数学研究所列为七个“千禧年大奖问题”之一，悬赏一百万美元征求任何一个正确的解答。但这不仅仅是金钱的诱惑，这个问题的答案将彻底改变我们对计算能力的理解，甚至颠覆我们世界的运作方式。 P vs NP 问题，简而言之，就是在问一个直观的问题：如果一个问题的解决方案可以被快速验证（即，如果你被提供一个答案，你能很快确认它是否正确），那么这个问题的解决方案是否也能被快速找到？这个问题触及了计算的本质，它的答案将对密码学、人工智能、优化理论、药物发现乃至哲学产生深远影响。 本文将深入探讨 P 类问题和 NP 类问题的定义，剖析 P vs NP 问题的核心，介绍 NP-完全性这一关键概念，并展望如果 P=NP 或 P!=NP，世界将发生怎样的变化。 什么是P类问题？ P，代表“多项式时间”（Polynomial Time）。P 类问题指的是那些可以在多项式时间内被确定性图灵机解决的问题。 定义： 一个问题属于 P 类，意味着存在一个算法，其运行时间可以被输入规模 (n) 的多...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">qmwneb946</div><div class="author-info-description">一个专注于技术分享的个人博客，涵盖编程、算法、系统设计等内容</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">18</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/qmwneb946"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">代码与远方，技术与生活交织的篇章。</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%95%E8%A8%80%EF%BC%9A%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E5%BC%95%E6%93%8E%E2%80%94%E2%80%94%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.</span> <span class="toc-text">引言：人工智能的引擎——机器学习</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%9F%BA%E7%9F%B3%EF%BC%9A%E4%B8%89%E5%A4%A7%E6%A0%B8%E5%BF%83%E5%AD%A6%E4%B9%A0%E8%8C%83%E5%BC%8F"><span class="toc-number">2.</span> <span class="toc-text">机器学习的基石：三大核心学习范式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-Supervised-Learning"><span class="toc-number">2.1.</span> <span class="toc-text">1. 监督学习 (Supervised Learning)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#a-%E5%9B%9E%E5%BD%92-Regression"><span class="toc-number">2.1.1.</span> <span class="toc-text">a. 回归 (Regression)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#b-%E5%88%86%E7%B1%BB-Classification"><span class="toc-number">2.1.2.</span> <span class="toc-text">b. 分类 (Classification)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-Unsupervised-Learning"><span class="toc-number">2.2.</span> <span class="toc-text">2. 无监督学习 (Unsupervised Learning)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#a-%E8%81%9A%E7%B1%BB-Clustering"><span class="toc-number">2.2.1.</span> <span class="toc-text">a. 聚类 (Clustering)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#b-%E9%99%8D%E7%BB%B4-Dimensionality-Reduction"><span class="toc-number">2.2.2.</span> <span class="toc-text">b. 降维 (Dimensionality Reduction)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#c-%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E5%AD%A6%E4%B9%A0-Association-Rule-Learning"><span class="toc-number">2.2.3.</span> <span class="toc-text">c. 关联规则学习 (Association Rule Learning)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-Reinforcement-Learning-RL"><span class="toc-number">2.3.</span> <span class="toc-text">3. 强化学习 (Reinforcement Learning, RL)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AE%97%E6%B3%95%E9%80%89%E6%8B%A9%E4%B8%8E%E8%AF%84%E4%BC%B0%EF%BC%9A%E5%A6%82%E4%BD%95%E9%87%8F%E4%BD%93%E8%A3%81%E8%A1%A3%EF%BC%9F"><span class="toc-number">3.</span> <span class="toc-text">算法选择与评估：如何量体裁衣？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87"><span class="toc-number">3.1.</span> <span class="toc-text">常用评估指标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%87%E6%8B%9F%E5%90%88%E4%B8%8E%E6%AC%A0%E6%8B%9F%E5%90%88"><span class="toc-number">3.2.</span> <span class="toc-text">过拟合与欠拟合</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA%EF%BC%9A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%8C%81%E7%BB%AD%E6%BC%94%E8%BF%9B"><span class="toc-number">4.</span> <span class="toc-text">结论：机器学习的持续演进</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/18/hello-world/" title="Hello World">Hello World</a><time datetime="2025-07-18T05:32:14.814Z" title="发表于 2025-07-18 13:32:14">2025-07-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/17/2025-07-18-052537/" title="P vs NP：计算机科学的千年之问与未解之谜">P vs NP：计算机科学的千年之问与未解之谜</a><time datetime="2025-07-17T21:25:37.000Z" title="发表于 2025-07-18 05:25:37">2025-07-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/17/2025-07-18-043836/" title="揭秘代码的炼金术：编译器是如何工作的？">揭秘代码的炼金术：编译器是如何工作的？</a><time datetime="2025-07-17T20:38:36.000Z" title="发表于 2025-07-18 04:38:36">2025-07-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/17/2025-07-18-032828/" title="赋能与变革：人工智能在软件开发中的深远作用">赋能与变革：人工智能在软件开发中的深远作用</a><time datetime="2025-07-17T19:28:28.000Z" title="发表于 2025-07-18 03:28:28">2025-07-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/17/2025-07-18-014322/" title="欧拉恒等式的优雅：数学与美的终极融合">欧拉恒等式的优雅：数学与美的终极融合</a><time datetime="2025-07-17T17:43:22.000Z" title="发表于 2025-07-18 01:43:22">2025-07-18</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;2025 By qmwneb946</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.2</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css')
    if (true) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const getGiscusTheme = theme => theme === 'dark' ? 'dark' : 'light'

  const createScriptElement = config => {
    const ele = document.createElement('script')
    Object.entries(config).forEach(([key, value]) => {
      ele.setAttribute(key, value)
    })
    return ele
  }

  const loadGiscus = (el = document, key) => {
    const mappingConfig = isShuoshuo
      ? { 'data-mapping': 'specific', 'data-term': key }
      : { 'data-mapping': (option && option['data-mapping']) || 'pathname' }

    const giscusConfig = {
      src: 'https://giscus.app/client.js',
      'data-repo': 'qmwneb946/blog',
      'data-repo-id': 'R_kgDOPM6cWw',
      'data-category-id': 'DIC_kwDOPM6cW84CtEzo',
      'data-theme': getGiscusTheme(document.documentElement.getAttribute('data-theme')),
      'data-reactions-enabled': '1',
      crossorigin: 'anonymous',
      async: true,
      ...option,
      ...mappingConfig
    }

    const scriptElement = createScriptElement(giscusConfig)

    el.querySelector('#giscus-wrap').appendChild(scriptElement)

    if (isShuoshuo) {
      window.shuoshuoComment.destroyGiscus = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }
  }

  const changeGiscusTheme = theme => {
    const iframe = document.querySelector('#giscus-wrap iframe')
    if (iframe) {
      const message = {
        giscus: {
          setConfig: {
            theme: getGiscusTheme(theme)
          }
        }
      }
      iframe.contentWindow.postMessage(message, 'https://giscus.app')
    }
  }

  btf.addGlobalFn('themeChange', changeGiscusTheme, 'giscus')

  if (isShuoshuo) {
    'Giscus' === 'Giscus'
      ? window.shuoshuoComment = { loadComment: loadGiscus }
      : window.loadOtherComment = loadGiscus
    return
  }

  if ('Giscus' === 'Giscus' || !false) {
    if (false) btf.loadComment(document.getElementById('giscus-wrap'), loadGiscus)
    else loadGiscus()
  } else {
    window.loadOtherComment = loadGiscus
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>