<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>机器学习算法概述：从原理到应用的全景探索 | qmwneb946 的博客</title><meta name="author" content="qmwneb946"><meta name="copyright" content="qmwneb946"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="机器学习 (Machine Learning, ML) 作为人工智能领域的核心分支，正以前所未有的速度改变着我们的世界。从智能推荐系统、自动驾驶到疾病诊断，机器学习算法无处不在。但这些神奇的功能背后，究竟是哪些“魔法”在运作？作为一名技术和数学爱好者，深入理解机器学习算法的原理至关重要。 本文将带领大家系统地探索机器学习算法的广阔图景。我们将从算法的学习方式出发，将其划分为几个主要范畴：监督学习、">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习算法概述：从原理到应用的全景探索">
<meta property="og:url" content="https://blog.qmwneb946.dpdns.org/2025/07/17/2025-07-17-211854/index.html">
<meta property="og:site_name" content="qmwneb946 的博客">
<meta property="og:description" content="机器学习 (Machine Learning, ML) 作为人工智能领域的核心分支，正以前所未有的速度改变着我们的世界。从智能推荐系统、自动驾驶到疾病诊断，机器学习算法无处不在。但这些神奇的功能背后，究竟是哪些“魔法”在运作？作为一名技术和数学爱好者，深入理解机器学习算法的原理至关重要。 本文将带领大家系统地探索机器学习算法的广阔图景。我们将从算法的学习方式出发，将其划分为几个主要范畴：监督学习、">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://blog.qmwneb946.dpdns.org/img/icon.png">
<meta property="article:published_time" content="2025-07-17T13:18:54.000Z">
<meta property="article:modified_time" content="2025-07-18T05:34:17.399Z">
<meta property="article:author" content="qmwneb946">
<meta property="article:tag" content="2025">
<meta property="article:tag" content="数学">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://blog.qmwneb946.dpdns.org/img/icon.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "机器学习算法概述：从原理到应用的全景探索",
  "url": "https://blog.qmwneb946.dpdns.org/2025/07/17/2025-07-17-211854/",
  "image": "https://blog.qmwneb946.dpdns.org/img/icon.png",
  "datePublished": "2025-07-17T13:18:54.000Z",
  "dateModified": "2025-07-18T05:34:17.399Z",
  "author": [
    {
      "@type": "Person",
      "name": "qmwneb946",
      "url": "https://github.com/qmwneb946"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://blog.qmwneb946.dpdns.org/2025/07/17/2025-07-17-211854/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '机器学习算法概述：从原理到应用的全景探索',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="qmwneb946 的博客" type="application/atom+xml">
</head><body><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">qmwneb946 的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">机器学习算法概述：从原理到应用的全景探索</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">机器学习算法概述：从原理到应用的全景探索<a class="post-edit-link" href="https://github.com/qmwneb946/blog/edit/main/source/_posts/2025-07-17-211854.md" title="编辑" target="_blank"><i class="fas fa-pencil-alt"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-07-17T13:18:54.000Z" title="发表于 2025-07-17 21:18:54">2025-07-17</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-07-18T05:34:17.399Z" title="更新于 2025-07-18 13:34:17">2025-07-18</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%95%B0%E5%AD%A6/">数学</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><p>机器学习 (Machine Learning, ML) 作为人工智能领域的核心分支，正以前所未有的速度改变着我们的世界。从智能推荐系统、自动驾驶到疾病诊断，机器学习算法无处不在。但这些神奇的功能背后，究竟是哪些“魔法”在运作？作为一名技术和数学爱好者，深入理解机器学习算法的原理至关重要。</p>
<p>本文将带领大家系统地探索机器学习算法的广阔图景。我们将从算法的学习方式出发，将其划分为几个主要范畴：监督学习、无监督学习、半监督学习和强化学习，并对每个范畴内的核心算法进行深入浅出的介绍。</p>
<h2 id="1-机器学习的基石：学习范式概览">1. 机器学习的基石：学习范式概览</h2>
<p>机器学习的本质是让计算机通过数据而不是明确的编程来学习。根据数据类型和学习目标的不同，机器学习算法通常被分为以下几大类：</p>
<h3 id="1-1-监督学习-Supervised-Learning">1.1 监督学习 (Supervised Learning)</h3>
<p><strong>核心思想：</strong> 从带有标签（即已知输入和对应输出）的数据中学习一个映射函数。目标是预测新输入数据对应的输出。</p>
<p><strong>常见任务：</strong></p>
<ul>
<li><strong>回归 (Regression):</strong> 预测连续值输出，例如房价、股票价格。</li>
<li><strong>分类 (Classification):</strong> 预测离散的类别标签，例如邮件是否为垃圾邮件、图片中是猫还是狗。</li>
</ul>
<p><strong>关键概念：</strong></p>
<ul>
<li><strong>训练集 (Training Set):</strong> 用于训练模型的数据。</li>
<li><strong>测试集 (Test Set):</strong> 用于评估模型性能的独立数据。</li>
<li><strong>损失函数 (Loss Function):</strong> 度量模型预测值与真实值之间差异的函数。例如，均方误差 (Mean Squared Error, MSE) 适用于回归问题：<br>
( MSE = \frac{1}{N} \sum_{i=1}^N (y_i - \hat{y}_i)^2 )<br>
其中 ( N ) 是样本数量，( y_i ) 是真实值，( \hat{y}_i ) 是预测值。</li>
<li><strong>优化器 (Optimizer):</strong> 调整模型参数以最小化损失函数的算法，如梯度下降 (Gradient Descent)。</li>
</ul>
<h4 id="1-1-1-线性回归-Linear-Regression">1.1.1 线性回归 (Linear Regression)</h4>
<p>线性回归是最简单也最基础的回归算法，它尝试找到一个线性函数来最好地拟合输入特征和输出变量之间的关系。</p>
<p><strong>模型表示：</strong><br>
对于单变量，模型为 ( y = wx + b )<br>
对于多变量，模型为 ( y = \mathbf{w}^T \mathbf{x} + b )<br>
其中 ( \mathbf{w} ) 是权重向量，( b ) 是偏置项，( \mathbf{x} ) 是输入特征向量。</p>
<p><strong>示例代码片段 (概念性预测):</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 假设 X 是特征矩阵，w 是权重向量，b 是偏置项</span></span><br><span class="line"><span class="comment"># y_pred = X @ w + b</span></span><br><span class="line"><span class="comment"># 这是线性模型预测的核心，通过矩阵乘法实现多特征加权求和</span></span><br></pre></td></tr></table></figure>
<h4 id="1-1-2-逻辑回归-Logistic-Regression">1.1.2 逻辑回归 (Logistic Regression)</h4>
<p>尽管名字中带有“回归”，但逻辑回归是一种广泛用于<strong>二分类问题</strong>的算法。它通过 Sigmoid 函数将线性模型的输出映射到 ( (0, 1) ) 区间，代表属于某一类别的概率。</p>
<p><strong>Sigmoid 函数：</strong><br>
( \sigma(z) = \frac{1}{1 + e^{-z}} )<br>
其中 ( z = \mathbf{w}^T \mathbf{x} + b )。</p>
<p><strong>预测概率：</strong><br>
( P(y=1|\mathbf{x}) = \sigma(\mathbf{w}^T \mathbf{x} + b) )</p>
<h4 id="1-1-3-支持向量机-Support-Vector-Machines-SVM">1.1.3 支持向量机 (Support Vector Machines, SVM)</h4>
<p>SVM 是一种强大的分类算法，其目标是找到一个最优的超平面 (hyperplane) 来最大化不同类别之间的间隔 (margin)。它特别适用于处理高维数据和非线性可分问题（通过核技巧 Kernel Trick）。</p>
<h4 id="1-1-4-决策树-Decision-Trees-与-随机森林-Random-Forests">1.1.4 决策树 (Decision Trees) 与 随机森林 (Random Forests)</h4>
<ul>
<li><strong>决策树：</strong> 通过一系列决策规则进行分类或回归。它将数据集递归地分割成越来越小的子集，直到每个子集都包含同质的样本。易于理解和解释。</li>
<li><strong>随机森林：</strong> 是一种集成学习 (Ensemble Learning) 方法，通过构建大量的决策树并聚合它们的预测来提高模型的准确性和鲁棒性。它能有效减少决策树的过拟合风险。</li>
</ul>
<h4 id="1-1-5-K-近邻算法-K-Nearest-Neighbors-KNN">1.1.5 K-近邻算法 (K-Nearest Neighbors, KNN)</h4>
<p>KNN 是一种惰性学习 (Lazy Learning) 算法，它不显式地从训练数据中学习模型，而是在预测时才进行计算。对于一个新的数据点，它会找出训练集中与其最近的 K 个邻居，并根据这些邻居的类别（分类）或平均值（回归）来决定自己的类别或值。距离度量通常使用欧氏距离。</p>
<h2 id="2-从数据中发现结构：无监督学习-Unsupervised-Learning">2. 从数据中发现结构：无监督学习 (Unsupervised Learning)</h2>
<p><strong>核心思想：</strong> 在没有标签的数据中发现隐藏的模式、结构或关系。</p>
<p><strong>常见任务：</strong></p>
<ul>
<li><strong>聚类 (Clustering):</strong> 将相似的数据点分组成簇。</li>
<li><strong>降维 (Dimensionality Reduction):</strong> 减少数据的特征数量，同时尽量保留数据中的重要信息。</li>
<li><strong>关联规则学习 (Association Rule Learning):</strong> 发现数据集中项之间的有趣关系。</li>
</ul>
<h4 id="2-1-1-K-均值聚类-K-Means-Clustering">2.1.1 K-均值聚类 (K-Means Clustering)</h4>
<p>K-Means 是一种简单且常用的聚类算法。它将数据点划分为 K 个簇，使得每个数据点都属于离它最近的均值（簇中心点）所在的簇。</p>
<p><strong>目标函数：</strong> 最小化簇内平方和 (Within-Cluster Sum of Squares, WCSS)：<br>
( J = \sum_{j=1}^k \sum_{\mathbf{x} \in C_j} ||\mathbf{x} - \mu_j||^2 )<br>
其中 ( k ) 是簇的数量，( C_j ) 是第 ( j ) 个簇，( \mu_j ) 是第 ( j ) 个簇的中心。</p>
<h4 id="2-1-2-主成分分析-Principal-Component-Analysis-PCA">2.1.2 主成分分析 (Principal Component Analysis, PCA)</h4>
<p>PCA 是一种常用的线性降维技术。它通过正交变换将数据投影到一组新的正交基上，这些基被称为主成分，它们是数据方差最大的方向。PCA 旨在保留数据中最重要的信息（方差最大的方向），同时去除冗余信息。</p>
<h2 id="3-标签稀缺时的策略：半监督学习-Semi-Supervised-Learning">3. 标签稀缺时的策略：半监督学习 (Semi-Supervised Learning)</h2>
<p><strong>核心思想：</strong> 结合了监督学习和无监督学习的特点。当只有少量有标签数据和大量无标签数据时，半监督学习能利用无标签数据来提高模型的性能。</p>
<p><strong>应用场景：</strong> 数据标注成本高昂，但无标签数据易于获取的情况。例如，图片分类中只有少量图片被手动标注，但有大量未标注图片可供利用。</p>
<h2 id="4-从互动中学习：强化学习-Reinforcement-Learning-RL">4. 从互动中学习：强化学习 (Reinforcement Learning, RL)</h2>
<p><strong>核心思想：</strong> 智能体 (Agent) 通过与环境 (Environment) 交互，根据从环境中获得的奖励 (Reward) 信号来学习最优行为策略。目标是最大化长期累积奖励。</p>
<p><strong>核心要素：</strong></p>
<ul>
<li><strong>智能体 (Agent):</strong> 学习者和决策者。</li>
<li><strong>环境 (Environment):</strong> 智能体所处的外部世界。</li>
<li><strong>状态 (State):</strong> 对环境当前情况的描述。</li>
<li><strong>动作 (Action):</strong> 智能体在给定状态下可以采取的行为。</li>
<li><strong>奖励 (Reward):</strong> 环境对智能体行为的即时反馈信号。</li>
<li><strong>策略 (Policy):</strong> 智能体从状态到动作的映射，决定了智能体在特定状态下采取何种动作。</li>
<li><strong>价值函数 (Value Function):</strong> 衡量在某个状态或某个状态-动作对下，遵循某一策略所能获得的未来累积奖励的期望。</li>
</ul>
<p><strong>典型算法：</strong></p>
<ul>
<li><strong>Q-Learning:</strong> 一种基于值函数 (Value-based) 的强化学习算法，它学习一个 Q 值表，表示在给定状态下采取某个动作所能获得的最大未来奖励。</li>
</ul>
<p>强化学习在游戏（如 AlphaGo）、机器人控制、推荐系统等领域取得了突破性进展。</p>
<h2 id="5-如何选择合适的算法？">5. 如何选择合适的算法？</h2>
<p>选择合适的机器学习算法并非易事，它通常取决于以下几个因素：</p>
<ol>
<li><strong>数据类型和规模：</strong> 是结构化数据还是非结构化数据？数据集的大小如何？</li>
<li><strong>任务类型：</strong> 是分类、回归、聚类还是其他？</li>
<li><strong>模型复杂度与可解释性需求：</strong> 需要一个简单易懂的模型还是可以接受黑箱模型？</li>
<li><strong>计算资源：</strong> 是否有足够的计算能力来训练复杂的模型？</li>
<li><strong>领域知识：</strong> 对问题领域的理解有助于选择更合适的特征和模型。</li>
</ol>
<p>通常，在实践中，会尝试多种算法，并通过交叉验证 (Cross-validation) 等技术来评估它们的性能，最终选择在特定问题上表现最优的算法。</p>
<h2 id="结论">结论</h2>
<p>本文对机器学习算法进行了全面的概述，从监督学习的预测能力、无监督学习的模式发现、半监督学习的标签利用效率，到强化学习的交互式学习范式，我们见证了机器学习的广阔和多样性。每种算法都有其独特的优势和适用场景。</p>
<p>理解这些核心算法的原理，是掌握机器学习的关键一步。随着数据科学的不断发展，新的算法和技术将层出不穷，但万变不离其宗。希望本文能为您在机器学习的探索之旅中点亮一盏明灯，激发您继续深入学习和实践的热情。未来的智能世界，离不开我们对这些算法的理解和应用！</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a target="_blank" rel="noopener" href="https://github.com/qmwneb946">qmwneb946</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://blog.qmwneb946.dpdns.org/2025/07/17/2025-07-17-211854/">https://blog.qmwneb946.dpdns.org/2025/07/17/2025-07-17-211854/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://opensource.org/licenses/MIT" target="_blank">MIT License</a> 许可协议。转载请注明来源 <a href="https://blog.qmwneb946.dpdns.org" target="_blank">qmwneb946 的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/2025/">2025</a><a class="post-meta__tags" href="/tags/%E6%95%B0%E5%AD%A6/">数学</a></div><div class="post-share"><div class="social-share" data-image="/img/icon.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/07/17/2025-07-17-221929/" title="深入探讨神经网络：从原理到实践的探索"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">深入探讨神经网络：从原理到实践的探索</div></div><div class="info-2"><div class="info-item-1">引言 在当今科技浪潮中，“人工智能”无疑是最激动人心的词汇之一。从智能推荐系统到自动驾驶汽车，从疾病诊断到自然语言处理，AI正以前所未有的速度改变着我们的世界。而在这场变革的核心，隐藏着一个精妙且强大的计算模型——神经网络。 对于许多技术爱好者而言，神经网络似乎是一个神秘的“黑箱”。它如何学习？为何能做出如此复杂的决策？本文旨在揭开神经网络的神秘面纱，带您从最基本的神经元开始，逐步深入理解其内部机制、训练过程以及面临的挑战，最终展望其未来的发展。无论您是初学者还是有一定基础的开发者，都将从这次深度探索中获益。 1. 神经网络的基石：神经元 要理解神经网络，我们必须从其最基本的组成单位——神经元（Neuron）或称为感知机（Perceptron）——开始。它受到生物神经元的启发，尽管其数学模型远比生物神经元简单，但已足够强大。 一个人工神经元接收来自其他神经元的输入信号，每个信号都有一个权重（Weight），表示该输入的重要性。所有加权输入会被求和，并加上一个**偏置（Bias）项。最后，这个和会通过一个激活函数（Activation Function）**来产生神经元的输出。 数...</div></div></div></a><a class="pagination-related" href="/2025/07/17/2025-07-17-202210/" title="探索斐波那契数列：自然界、数学与算法的永恒旋律"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">探索斐波那契数列：自然界、数学与算法的永恒旋律</div></div><div class="info-2"><div class="info-item-1"> 引言：宇宙间无处不在的神秘数字序列 你是否曾仰望向日葵的螺旋花盘，惊叹于松果鳞片的排列，或是凝视鹦鹉螺的完美螺线？在这些看似随机却又充满秩序的自然现象背后，隐藏着一个简单却又异常深刻的数学序列——斐波那契数列。它不仅是数学家们探索不尽的宝藏，也是计算机科学家们优化算法的灵感来源，更是艺术家们追求和谐与美的秘密武器。 今天，我们将一起踏上探索斐波那契数列的旅程。从它的基本定义出发，深入剖析其令人着迷的数学性质，探讨高效的计算方法，并最终领略它在自然、科学乃至艺术领域中的广泛应用。准备好了吗？让我们一起揭开这个古老数列的神秘面纱！ 斐波那契数列的定义与基础 斐波那契数列（Fibonacci Sequence），以意大利数学家列奥纳多·斐波那契（Leonardo Fibonacci）命名，最早出现在他1202年出版的《算盘书》（Liber Abaci）中，用来解决一个理想化的兔子繁殖问题。 其定义非常简洁：数列中的每一个数字都是前两个数字的和。我们通常从 ( F_0 = 0 ) 和 ( F_1 = 1 ) 开始。 数学定义： 对于 ( n \ge 2 )，斐波那契数列 ( F_n )...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/07/17/2025-07-17-141851/" title="机器学习算法概述：从原理到实践的探索"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-17</div><div class="info-item-2">机器学习算法概述：从原理到实践的探索</div></div><div class="info-2"><div class="info-item-1">在当今数字驱动的世界里，机器学习（Machine Learning, ML）已不再是科幻小说中的概念，而是深入到我们生活的方方面面，从智能推荐系统、自动驾驶到医疗诊断和金融风控。它像一位无形的设计师，悄然重塑着我们的体验和效率。但机器学习究竟是什么？它背后的“魔力”源于何处？ 本文旨在为技术爱好者们提供一份高质量、有深度的机器学习算法概述。我们将深入探讨机器学习的核心范式，剖析各类经典算法的原理与应用，并揭示其背后的数学美学。无论您是初学者还是希望系统化知识的实践者，本文都将为您打开机器学习的精彩大门。 机器学习的基石：四大核心学习范式 机器学习的核心思想是让计算机系统通过数据“学习”，从而无需明确编程就能执行特定任务。根据数据类型和学习目标的不同，机器学习通常被划分为以下四大范式： 1. 监督学习 (Supervised Learning) 监督学习是机器学习中最常见、应用最广泛的一种范式。它的核心在于**“有监督”**，即模型通过带有标签（已知答案）的数据进行训练。你可以将其想象成一个学生，在老师（标签）的指导下，通过大量的练习（数据）来学习如何解决问题。 目标：从输入数据和...</div></div></div></a><a class="pagination-related" href="/2025/07/17/2025-07-17-152148/" title="无服务器架构解析：从概念到实践的深度探索"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-17</div><div class="info-item-2">无服务器架构解析：从概念到实践的深度探索</div></div><div class="info-2"><div class="info-item-1">在云计算的演进浪潮中，有一种架构范式正以其独特的魅力改变着我们开发和部署应用的方式，它就是“无服务器架构”（Serverless Architecture）。这个名字听起来有些反直觉——毕竟，没有服务器，应用程序又如何在空中运行呢？作为一名技术和数学的博主，我将带你深入探索无服务器架构的奥秘，从它的核心概念、组成部件，到其优势与挑战，并结合数学视角分析其成本效益，最终展望其未来。 引言：云计算的“终极抽象”之旅 回望软件开发的历史，我们经历了从物理机到虚拟机，再到容器化的演进。每一次变革都旨在提高资源利用率、简化部署和管理。  物理机时代：你拥有并维护自己的硬件，一切从零开始。 IaaS (Infrastructure as a Service)：云服务商提供虚拟机，你依然需要管理操作系统和运行时。 PaaS (Platform as a Service)：云服务商提供完整的运行时环境，你只需部署代码，但仍需关心平台配置和伸缩。 容器化 (Containerization)：如Docker和Kubernetes，提供了标准化的部署单元和强大的编排能力，但集群管理依然复杂。  而无...</div></div></div></a><a class="pagination-related" href="/2025/07/17/2025-07-17-182902/" title="机器学习算法概述：从原理到实践的深度剖析"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-17</div><div class="info-item-2">机器学习算法概述：从原理到实践的深度剖析</div></div><div class="info-2"><div class="info-item-1"> 引言：人工智能的引擎——机器学习 在当今数字驱动的世界里，“人工智能”和“机器学习”已不再是遥远的科幻概念，而是深刻地融入了我们生活的方方面面：从智能手机的面部识别解锁，到电商平台的个性化商品推荐，从自动驾驶汽车的路径规划，到医疗领域的疾病诊断辅助。机器学习，作为人工智能的核心引擎，正是赋予机器从数据中学习并做出决策能力的科学。 它本质上是一种通过数据而非显式编程来让计算机获得学习能力的范式。想象一下，你无需一步步告诉计算机如何识别猫，而是向它展示成千上万张猫的图片，它便能自己归纳出“猫”的特征。这便是机器学习的魔力。 本文旨在为技术爱好者提供一份高质量、有深度的机器学习算法概述。我们将深入探讨机器学习的三大主要范式，并详细介绍每个范畴下的核心算法，理解它们的原理、应用场景以及优缺点。让我们一起踏上这场探索之旅，揭开机器学习算法的神秘面纱。 机器学习的基石：三大核心学习范式 机器学习算法通常根据其学习方式和数据类型分为以下三大类：监督学习、无监督学习和强化学习。理解这三种范式是理解所有机器学习算法的基础。 1. 监督学习 (Supervised Learning) 核心思想： ...</div></div></div></a><a class="pagination-related" href="/2025/07/17/2025-07-17-191728/" title="图论入门：连接世界的数学之美"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-17</div><div class="info-item-2">图论入门：连接世界的数学之美</div></div><div class="info-2"><div class="info-item-1">引言 想象一下现代生活中的各种互联系统：社交网络中的好友关系，城市中错综复杂的道路，互联网上的信息流，甚至是生物体内的蛋白质相互作用网络。这些看似不同的系统，背后却隐藏着一个共同且强大的数学框架——图论。 图论（Graph Theory）是数学的一个分支，它研究的是点（顶点或节点）与点之间连接（边）的结构。它提供了一种抽象而直观的方式来建模和分析各种关系和连接问题。从计算机科学到运筹学，从物理学到生物学，图论都扮演着不可或缺的角色。 作为一名技术爱好者，掌握图论的基础知识，不仅能帮助你更好地理解各种算法背后的逻辑，还能为解决复杂的实际问题提供全新的视角。本文将带你步入图论的大门，从基本概念讲起，深入探讨图的表示方法、经典算法，并展望其在现实世界中的广泛应用。 图论的基础概念 在图论中，我们使用“图”来表示对象之间的关系。一个图 (G) 通常由两个集合定义：顶点集合 (V) 和边集合 (E)。 G=(V,E)G = (V, E)  G=(V,E)  顶点（Vertex / Node）：集合 (V) 中的元素，代表了我们要建模的实体或对象。例如，社交网络中的用户、城市中的十字路口。 ...</div></div></div></a><a class="pagination-related" href="/2025/07/17/2025-07-17-221929/" title="深入探讨神经网络：从原理到实践的探索"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-17</div><div class="info-item-2">深入探讨神经网络：从原理到实践的探索</div></div><div class="info-2"><div class="info-item-1">引言 在当今科技浪潮中，“人工智能”无疑是最激动人心的词汇之一。从智能推荐系统到自动驾驶汽车，从疾病诊断到自然语言处理，AI正以前所未有的速度改变着我们的世界。而在这场变革的核心，隐藏着一个精妙且强大的计算模型——神经网络。 对于许多技术爱好者而言，神经网络似乎是一个神秘的“黑箱”。它如何学习？为何能做出如此复杂的决策？本文旨在揭开神经网络的神秘面纱，带您从最基本的神经元开始，逐步深入理解其内部机制、训练过程以及面临的挑战，最终展望其未来的发展。无论您是初学者还是有一定基础的开发者，都将从这次深度探索中获益。 1. 神经网络的基石：神经元 要理解神经网络，我们必须从其最基本的组成单位——神经元（Neuron）或称为感知机（Perceptron）——开始。它受到生物神经元的启发，尽管其数学模型远比生物神经元简单，但已足够强大。 一个人工神经元接收来自其他神经元的输入信号，每个信号都有一个权重（Weight），表示该输入的重要性。所有加权输入会被求和，并加上一个**偏置（Bias）项。最后，这个和会通过一个激活函数（Activation Function）**来产生神经元的输出。 数...</div></div></div></a><a class="pagination-related" href="/2025/07/17/2025-07-17-231957/" title="P vs NP 问题：计算世界的终极谜团"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-17</div><div class="info-item-2">P vs NP 问题：计算世界的终极谜团</div></div><div class="info-2"><div class="info-item-1"> 引言：百万美元的计算之谜 在计算机科学和数学的殿堂中，P vs NP 问题无疑是最耀眼、最深刻的未解之谜之一。它被克莱数学研究所列为七个“千禧年大奖问题”之一，悬赏一百万美元征求任何一个正确的解答。但这不仅仅是金钱的诱惑，这个问题的答案将彻底改变我们对计算能力的理解，甚至颠覆我们世界的运作方式。 P vs NP 问题，简而言之，就是在问一个直观的问题：如果一个问题的解决方案可以被快速验证（即，如果你被提供一个答案，你能很快确认它是否正确），那么这个问题的解决方案是否也能被快速找到？这个问题触及了计算的本质，它的答案将对密码学、人工智能、优化理论、药物发现乃至哲学产生深远影响。 本文将深入探讨 P 类问题和 NP 类问题的定义，剖析 P vs NP 问题的核心，介绍 NP-完全性这一关键概念，并展望如果 P=NP 或 P!=NP，世界将发生怎样的变化。 什么是P类问题？ P，代表“多项式时间”（Polynomial Time）。P 类问题指的是那些可以在多项式时间内被确定性图灵机解决的问题。 定义： 一个问题属于 P 类，意味着存在一个算法，其运行时间可以被输入规模 (n) 的多...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">qmwneb946</div><div class="author-info-description">一个专注于技术分享的个人博客，涵盖编程、算法、系统设计等内容</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">18</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/qmwneb946"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">代码与远方，技术与生活交织的篇章。</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%9F%BA%E7%9F%B3%EF%BC%9A%E5%AD%A6%E4%B9%A0%E8%8C%83%E5%BC%8F%E6%A6%82%E8%A7%88"><span class="toc-number">1.</span> <span class="toc-text">1. 机器学习的基石：学习范式概览</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-Supervised-Learning"><span class="toc-number">1.1.</span> <span class="toc-text">1.1 监督学习 (Supervised Learning)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-1-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92-Linear-Regression"><span class="toc-number">1.1.1.</span> <span class="toc-text">1.1.1 线性回归 (Linear Regression)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-2-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92-Logistic-Regression"><span class="toc-number">1.1.2.</span> <span class="toc-text">1.1.2 逻辑回归 (Logistic Regression)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-3-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA-Support-Vector-Machines-SVM"><span class="toc-number">1.1.3.</span> <span class="toc-text">1.1.3 支持向量机 (Support Vector Machines, SVM)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-4-%E5%86%B3%E7%AD%96%E6%A0%91-Decision-Trees-%E4%B8%8E-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97-Random-Forests"><span class="toc-number">1.1.4.</span> <span class="toc-text">1.1.4 决策树 (Decision Trees) 与 随机森林 (Random Forests)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-5-K-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95-K-Nearest-Neighbors-KNN"><span class="toc-number">1.1.5.</span> <span class="toc-text">1.1.5 K-近邻算法 (K-Nearest Neighbors, KNN)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E4%BB%8E%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%8F%91%E7%8E%B0%E7%BB%93%E6%9E%84%EF%BC%9A%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-Unsupervised-Learning"><span class="toc-number">2.</span> <span class="toc-text">2. 从数据中发现结构：无监督学习 (Unsupervised Learning)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-1-K-%E5%9D%87%E5%80%BC%E8%81%9A%E7%B1%BB-K-Means-Clustering"><span class="toc-number">2.0.1.</span> <span class="toc-text">2.1.1 K-均值聚类 (K-Means Clustering)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-2-%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90-Principal-Component-Analysis-PCA"><span class="toc-number">2.0.2.</span> <span class="toc-text">2.1.2 主成分分析 (Principal Component Analysis, PCA)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E6%A0%87%E7%AD%BE%E7%A8%80%E7%BC%BA%E6%97%B6%E7%9A%84%E7%AD%96%E7%95%A5%EF%BC%9A%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-Semi-Supervised-Learning"><span class="toc-number">3.</span> <span class="toc-text">3. 标签稀缺时的策略：半监督学习 (Semi-Supervised Learning)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E4%BB%8E%E4%BA%92%E5%8A%A8%E4%B8%AD%E5%AD%A6%E4%B9%A0%EF%BC%9A%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0-Reinforcement-Learning-RL"><span class="toc-number">4.</span> <span class="toc-text">4. 从互动中学习：强化学习 (Reinforcement Learning, RL)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82%E7%9A%84%E7%AE%97%E6%B3%95%EF%BC%9F"><span class="toc-number">5.</span> <span class="toc-text">5. 如何选择合适的算法？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA"><span class="toc-number">6.</span> <span class="toc-text">结论</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/18/hello-world/" title="Hello World">Hello World</a><time datetime="2025-07-18T05:34:17.401Z" title="发表于 2025-07-18 13:34:17">2025-07-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/17/2025-07-18-052537/" title="P vs NP：计算机科学的千年之问与未解之谜">P vs NP：计算机科学的千年之问与未解之谜</a><time datetime="2025-07-17T21:25:37.000Z" title="发表于 2025-07-18 05:25:37">2025-07-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/17/2025-07-18-043836/" title="揭秘代码的炼金术：编译器是如何工作的？">揭秘代码的炼金术：编译器是如何工作的？</a><time datetime="2025-07-17T20:38:36.000Z" title="发表于 2025-07-18 04:38:36">2025-07-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/17/2025-07-18-032828/" title="赋能与变革：人工智能在软件开发中的深远作用">赋能与变革：人工智能在软件开发中的深远作用</a><time datetime="2025-07-17T19:28:28.000Z" title="发表于 2025-07-18 03:28:28">2025-07-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/17/2025-07-18-014322/" title="欧拉恒等式的优雅：数学与美的终极融合">欧拉恒等式的优雅：数学与美的终极融合</a><time datetime="2025-07-17T17:43:22.000Z" title="发表于 2025-07-18 01:43:22">2025-07-18</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;2025 By qmwneb946</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.2</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css')
    if (true) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const getGiscusTheme = theme => theme === 'dark' ? 'dark' : 'light'

  const createScriptElement = config => {
    const ele = document.createElement('script')
    Object.entries(config).forEach(([key, value]) => {
      ele.setAttribute(key, value)
    })
    return ele
  }

  const loadGiscus = (el = document, key) => {
    const mappingConfig = isShuoshuo
      ? { 'data-mapping': 'specific', 'data-term': key }
      : { 'data-mapping': (option && option['data-mapping']) || 'pathname' }

    const giscusConfig = {
      src: 'https://giscus.app/client.js',
      'data-repo': 'qmwneb946/blog',
      'data-repo-id': 'R_kgDOPM6cWw',
      'data-category-id': 'DIC_kwDOPM6cW84CtEzo',
      'data-theme': getGiscusTheme(document.documentElement.getAttribute('data-theme')),
      'data-reactions-enabled': '1',
      crossorigin: 'anonymous',
      async: true,
      ...option,
      ...mappingConfig
    }

    const scriptElement = createScriptElement(giscusConfig)

    el.querySelector('#giscus-wrap').appendChild(scriptElement)

    if (isShuoshuo) {
      window.shuoshuoComment.destroyGiscus = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }
  }

  const changeGiscusTheme = theme => {
    const iframe = document.querySelector('#giscus-wrap iframe')
    if (iframe) {
      const message = {
        giscus: {
          setConfig: {
            theme: getGiscusTheme(theme)
          }
        }
      }
      iframe.contentWindow.postMessage(message, 'https://giscus.app')
    }
  }

  btf.addGlobalFn('themeChange', changeGiscusTheme, 'giscus')

  if (isShuoshuo) {
    'Giscus' === 'Giscus'
      ? window.shuoshuoComment = { loadComment: loadGiscus }
      : window.loadOtherComment = loadGiscus
    return
  }

  if ('Giscus' === 'Giscus' || !false) {
    if (false) btf.loadComment(document.getElementById('giscus-wrap'), loadGiscus)
    else loadGiscus()
  } else {
    window.loadOtherComment = loadGiscus
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>