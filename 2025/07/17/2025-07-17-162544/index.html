<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>机器学习算法概述：核心原理与应用洞察 | qmwneb946 的博客</title><meta name="author" content="qmwneb946"><meta name="copyright" content="qmwneb946"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="引言：通往智能未来的基石 在当今数据爆炸的时代，机器学习（Machine Learning, ML）已不再是一个陌生的概念。它正悄然改变着我们生活的方方面面，从智能手机的面部识别解锁，到电商平台的个性化推荐，再到自动驾驶汽车的智能导航，无一不闪耀着机器学习算法的光芒。简单来说，机器学习是一种让计算机无需被明确编程就能从数据中“学习”的能力。它赋予机器从经验中改进自身性能，从而执行特定任务的潜力。">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习算法概述：核心原理与应用洞察">
<meta property="og:url" content="https://blog.qmwneb946.dpdns.org/2025/07/17/2025-07-17-162544/index.html">
<meta property="og:site_name" content="qmwneb946 的博客">
<meta property="og:description" content="引言：通往智能未来的基石 在当今数据爆炸的时代，机器学习（Machine Learning, ML）已不再是一个陌生的概念。它正悄然改变着我们生活的方方面面，从智能手机的面部识别解锁，到电商平台的个性化推荐，再到自动驾驶汽车的智能导航，无一不闪耀着机器学习算法的光芒。简单来说，机器学习是一种让计算机无需被明确编程就能从数据中“学习”的能力。它赋予机器从经验中改进自身性能，从而执行特定任务的潜力。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://blog.qmwneb946.dpdns.org/img/icon.png">
<meta property="article:published_time" content="2025-07-17T08:25:44.000Z">
<meta property="article:modified_time" content="2025-07-18T05:34:17.398Z">
<meta property="article:author" content="qmwneb946">
<meta property="article:tag" content="技术">
<meta property="article:tag" content="2025">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://blog.qmwneb946.dpdns.org/img/icon.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "机器学习算法概述：核心原理与应用洞察",
  "url": "https://blog.qmwneb946.dpdns.org/2025/07/17/2025-07-17-162544/",
  "image": "https://blog.qmwneb946.dpdns.org/img/icon.png",
  "datePublished": "2025-07-17T08:25:44.000Z",
  "dateModified": "2025-07-18T05:34:17.398Z",
  "author": [
    {
      "@type": "Person",
      "name": "qmwneb946",
      "url": "https://github.com/qmwneb946"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://blog.qmwneb946.dpdns.org/2025/07/17/2025-07-17-162544/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '机器学习算法概述：核心原理与应用洞察',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="qmwneb946 的博客" type="application/atom+xml">
</head><body><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">qmwneb946 的博客</span></a><a class="nav-page-title" href="/"><span class="site-name">机器学习算法概述：核心原理与应用洞察</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">机器学习算法概述：核心原理与应用洞察<a class="post-edit-link" href="https://github.com/qmwneb946/blog/edit/main/source/_posts/2025-07-17-162544.md" title="编辑" target="_blank"><i class="fas fa-pencil-alt"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-07-17T08:25:44.000Z" title="发表于 2025-07-17 16:25:44">2025-07-17</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-07-18T05:34:17.398Z" title="更新于 2025-07-18 13:34:17">2025-07-18</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%8A%80%E6%9C%AF/">技术</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="container post-content" id="article-container"><h2 id="引言：通往智能未来的基石">引言：通往智能未来的基石</h2>
<p>在当今数据爆炸的时代，机器学习（Machine Learning, ML）已不再是一个陌生的概念。它正悄然改变着我们生活的方方面面，从智能手机的面部识别解锁，到电商平台的个性化推荐，再到自动驾驶汽车的智能导航，无一不闪耀着机器学习算法的光芒。简单来说，机器学习是一种让计算机无需被明确编程就能从数据中“学习”的能力。它赋予机器从经验中改进自身性能，从而执行特定任务的潜力。</p>
<p>但机器学习的“学习”并非魔法，而是基于精密的数学原理和巧妙的算法设计。对于技术爱好者、有志于投身数据科学的探索者而言，理解这些算法的运作机制，是掌握这门强大技术的关键。本文将深入浅出地为您揭示机器学习算法的广阔图景，从其基本分类入手，逐一剖析各类算法的核心原理、典型应用及其背后的数学之美，并辅以代码示例，助您构建对机器学习世界的系统认知。</p>
<h2 id="机器学习算法的宏观分类">机器学习算法的宏观分类</h2>
<p>机器学习算法通常根据其学习方式和处理的数据类型被划分为几个主要范畴。最常见的分类包括：</p>
<ol>
<li><strong>监督学习 (Supervised Learning)</strong>：从带有标签（即已知正确答案）的数据中学习。</li>
<li><strong>无监督学习 (Unsupervised Learning)</strong>：从无标签的数据中发现隐藏的模式或结构。</li>
<li><strong>强化学习 (Reinforcement Learning)</strong>：通过与环境互动，从试错中学习最优行为策略。</li>
<li><strong>半监督学习 (Semi-Supervised Learning)</strong>：结合了有标签和无标签数据进行学习。</li>
<li><strong>深度学习 (Deep Learning)</strong>：实际上是机器学习的一个子领域，特指使用多层神经网络进行学习的方法。</li>
</ol>
<p>接下来，我们将逐一深入探讨这些主要分类。</p>
<h2 id="一、监督学习：从已知中学习预测">一、监督学习：从已知中学习预测</h2>
<p>监督学习是机器学习中最常见、应用最广泛的一类。其核心思想是：给定一组输入-输出对（即训练数据，其中输入数据是特征，输出数据是标签），算法通过学习这些已知的映射关系，从而能够对新的、未见过的数据进行准确的预测。</p>
<p>根据输出变量的类型，监督学习任务可以进一步分为两类：</p>
<h3 id="1-1-回归-Regression-：预测连续值">1.1 回归 (Regression)：预测连续值</h3>
<p>回归任务旨在预测一个连续的数值输出。例如，预测房价、股票价格、气温等。</p>
<h4 id="1-1-1-线性回归-Linear-Regression">1.1.1 线性回归 (Linear Regression)</h4>
<p>线性回归是最简单也最基础的回归模型。它假设输入特征与输出变量之间存在线性关系。模型的目标是找到一条最佳拟合直线（或超平面），使得预测值与真实值之间的误差最小。</p>
<p>数学表达式为：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mover accent="true"><mi>y</mi><mo>^</mo></mover><mo>=</mo><msub><mi>β</mi><mn>0</mn></msub><mo>+</mo><msub><mi>β</mi><mn>1</mn></msub><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>β</mi><mn>2</mn></msub><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><mo>⋯</mo><mo>+</mo><msub><mi>β</mi><mi>n</mi></msub><msub><mi>x</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">\hat{y} = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_n x_n 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0528em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0528em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0528em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em;"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05278em;">β</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0528em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p>其中，( \hat{y} ) 是预测值，( x_i ) 是第 ( i ) 个特征，( \beta_0 ) 是截距项，( \beta_i ) 是第 ( i ) 个特征的系数（权重）。</p>
<p>模型通常通过最小化均方误差（Mean Squared Error, MSE）来学习参数 ( \beta )：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>MSE</mtext><mo>=</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mo stretchy="false">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><msub><mover accent="true"><mi>y</mi><mo>^</mo></mover><mi>i</mi></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\text{MSE} = \frac{1}{N} \sum_{i=1}^N (y_i - \hat{y}_i)^2 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord text"><span class="mord">MSE</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.106em;vertical-align:-1.2777em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.1944em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1944em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>其中，( N ) 是样本数量，( y_i ) 是真实值，( \hat{y}_i ) 是预测值。</p>
<p><strong>示例代码（使用 Scikit-learn 的线性回归）：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 准备数据</span></span><br><span class="line"><span class="comment"># 假设我们有一些简单的房屋面积和价格数据</span></span><br><span class="line"><span class="comment"># 面积 (X): 平方米</span></span><br><span class="line"><span class="comment"># 价格 (y): 万元</span></span><br><span class="line">X = np.array([[<span class="number">50</span>], [<span class="number">70</span>], [<span class="number">80</span>], [<span class="number">100</span>], [<span class="number">120</span>], [<span class="number">150</span>], [<span class="number">180</span>], [<span class="number">200</span>]])</span><br><span class="line">y = np.array([<span class="number">150</span>, <span class="number">200</span>, <span class="number">220</span>, <span class="number">280</span>, <span class="number">320</span>, <span class="number">380</span>, <span class="number">450</span>, <span class="number">500</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 划分训练集和测试集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 创建并训练模型</span></span><br><span class="line">model = LinearRegression()</span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 进行预测</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 评估模型</span></span><br><span class="line">mse = mean_squared_error(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;模型的截距项 (Intercept): <span class="subst">&#123;model.intercept_:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;模型的系数 (Coefficient): <span class="subst">&#123;model.coef_[<span class="number">0</span>]:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;测试集上的均方误差 (MSE): <span class="subst">&#123;mse:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测一个新面积的房价</span></span><br><span class="line">new_area = np.array([[<span class="number">95</span>]])</span><br><span class="line">predicted_price = model.predict(new_area)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;预测面积为 <span class="subst">&#123;new_area[<span class="number">0</span>][<span class="number">0</span>]&#125;</span> 平方米的房价: <span class="subst">&#123;predicted_price[<span class="number">0</span>]:<span class="number">.2</span>f&#125;</span> 万元&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="1-1-2-其他回归算法">1.1.2 其他回归算法</h4>
<ul>
<li><strong>多项式回归 (Polynomial Regression)</strong>：通过引入特征的高阶项来拟合非线性关系。</li>
<li><strong>支持向量回归 (Support Vector Regression, SVR)</strong>：支持向量机在回归问题上的扩展。</li>
<li><strong>决策树回归 (Decision Tree Regressor)</strong>：通过一系列决策规则进行预测。</li>
<li><strong>随机森林回归 (Random Forest Regressor)</strong>：集成学习方法，结合多棵决策树进行预测。</li>
</ul>
<h3 id="1-2-分类-Classification-：预测离散类别">1.2 分类 (Classification)：预测离散类别</h3>
<p>分类任务旨在预测数据点所属的离散类别。例如，判断邮件是否为垃圾邮件、识别图片中的物体、诊断疾病等。</p>
<h4 id="1-2-1-逻辑回归-Logistic-Regression">1.2.1 逻辑回归 (Logistic Regression)</h4>
<p>尽管名字中包含“回归”，但逻辑回归是广泛用于二分类问题的算法。它通过 Sigmoid 函数将线性模型的输出压缩到 (0, 1) 区间，表示属于某一类别的概率。</p>
<p>Sigmoid 函数：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>σ</mi><mo stretchy="false">(</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>z</mi></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\sigma(z) = \frac{1}{1 + e^{-z}} 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.0908em;vertical-align:-0.7693em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6973em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>其中 ( z = \beta_0 + \beta_1 x_1 + \dots + \beta_n x_n )。如果 ( \sigma(z) &gt; 0.5 )，则判为正类；否则判为负类。</p>
<p><strong>示例代码（使用 Scikit-learn 的逻辑回归）：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, classification_report</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 准备数据</span></span><br><span class="line"><span class="comment"># 使用鸢尾花数据集作为分类示例</span></span><br><span class="line">iris = load_iris()</span><br><span class="line">X, y = iris.data, iris.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 为了简化，我们只做二分类（将类别0和类别1合并为一类，类别2为另一类）</span></span><br><span class="line"><span class="comment"># 实际中通常是多分类，但逻辑回归也可以通过One-vs-Rest等策略实现多分类</span></span><br><span class="line">X = X[y != <span class="number">2</span>] <span class="comment"># 移除第三个类别</span></span><br><span class="line">y = y[y != <span class="number">2</span>] <span class="comment"># 移除第三个类别</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 划分训练集和测试集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 创建并训练模型</span></span><br><span class="line"><span class="comment"># solver=&#x27;liblinear&#x27; 是一个小数据集的常用优化器</span></span><br><span class="line">model = LogisticRegression(solver=<span class="string">&#x27;liblinear&#x27;</span>, random_state=<span class="number">42</span>)</span><br><span class="line">model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 进行预测</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 评估模型</span></span><br><span class="line">accuracy = accuracy_score(y_test, y_pred)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;测试集上的准确率 (Accuracy): <span class="subst">&#123;accuracy:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n分类报告 (Classification Report):&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test, y_pred, target_names=iris.target_names[:<span class="number">2</span>])) <span class="comment"># 注意这里只显示前两个类别名</span></span><br></pre></td></tr></table></figure>
<h4 id="1-2-2-其他分类算法">1.2.2 其他分类算法</h4>
<ul>
<li><strong>支持向量机 (Support Vector Machine, SVM)</strong>：寻找最佳超平面以最大化不同类别之间的间隔。</li>
<li><strong>决策树 (Decision Tree)</strong>：通过树形结构进行决策，易于理解。</li>
<li><strong>随机森林 (Random Forest)</strong>：集成多棵决策树，提高分类精度和鲁棒性。</li>
<li><strong>K近邻 (K-Nearest Neighbors, KNN)</strong>：根据K个最近邻居的类别进行投票决定。</li>
<li><strong>朴素贝叶斯 (Naive Bayes)</strong>：基于贝叶斯定理和特征条件独立性假设的概率分类器。</li>
</ul>
<h2 id="二、无监督学习：从数据中发现模式">二、无监督学习：从数据中发现模式</h2>
<p>无监督学习处理的是没有标签的数据。它的目标不是预测，而是发现数据中隐藏的结构、模式或关系。这在数据标注成本高昂或根本无法获得标签的情况下尤其有用。</p>
<h3 id="2-1-聚类-Clustering-：物以类聚">2.1 聚类 (Clustering)：物以类聚</h3>
<p>聚类是将数据点分组，使得同一组内的数据点彼此相似，而不同组间的数据点差异较大。</p>
<h4 id="2-1-1-K-Means-聚类">2.1.1 K-Means 聚类</h4>
<p>K-Means 是最流行、最简单的聚类算法之一。它将数据分成 ( K ) 个簇，每个簇由其质心（中心点）代表。算法通过迭代地将数据点分配给最近的质心，然后更新质心位置，直到收敛。</p>
<p>距离度量（通常是欧几里得距离）：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>d</mi><mo stretchy="false">(</mo><mi mathvariant="bold">p</mi><mo separator="true">,</mo><mi mathvariant="bold">q</mi><mo stretchy="false">)</mo><mo>=</mo><msqrt><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo stretchy="false">(</mo><msub><mi>p</mi><mi>i</mi></msub><mo>−</mo><msub><mi>q</mi><mi>i</mi></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow></msqrt></mrow><annotation encoding="application/x-tex">d(\mathbf{p}, \mathbf{q}) = \sqrt{\sum_{i=1}^n (p_i - q_i)^2} 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord mathbf">p</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathbf">q</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.1568em;vertical-align:-1.2777em;"></span><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8791em;"><span class="svg-align" style="top:-5.1168em;"><span class="pstrut" style="height:5.1168em;"></span><span class="mord" style="padding-left:1.056em;"><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6514em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7401em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span><span style="top:-3.8391em;"><span class="pstrut" style="height:5.1168em;"></span><span class="hide-tail" style="min-width:0.742em;height:3.1968em;"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="3.1968em" viewBox="0 0 400000 3196" preserveAspectRatio="xMinYMin slice"><path d="M702 80H40000040
H742v3062l-4 4-4 4c-.667.7 -2 1.5-4 2.5s-4.167 1.833-6.5 2.5-5.5 1-9.5 1
h-12l-28-84c-16.667-52-96.667 -294.333-240-727l-212 -643 -85 170
c-4-3.333-8.333-7.667-13 -13l-13-13l77-155 77-156c66 199.333 139 419.667
219 661 l218 661zM702 80H400000v40H742z"/></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span></span></span></span></span></p>
<p><strong>示例代码（使用 Scikit-learn 的 K-Means）：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs <span class="comment"># 用于生成聚类数据</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns <span class="comment"># 美化图表</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 准备数据</span></span><br><span class="line"><span class="comment"># 生成一些模拟的二维数据，包含3个明显的簇</span></span><br><span class="line">X, y = make_blobs(n_samples=<span class="number">300</span>, centers=<span class="number">3</span>, cluster_std=<span class="number">0.60</span>, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 创建并训练 K-Means 模型</span></span><br><span class="line"><span class="comment"># 假设我们知道有3个簇</span></span><br><span class="line">kmeans = KMeans(n_clusters=<span class="number">3</span>, random_state=<span class="number">0</span>, n_init=<span class="number">10</span>) <span class="comment"># n_init: 运行K-Means算法的次数，取最好的结果</span></span><br><span class="line">kmeans.fit(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 获取聚类结果</span></span><br><span class="line">labels = kmeans.labels_ <span class="comment"># 每个数据点所属的簇</span></span><br><span class="line">centroids = kmeans.cluster_centers_ <span class="comment"># 每个簇的质心</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 可视化结果</span></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line">sns.scatterplot(x=X[:, <span class="number">0</span>], y=X[:, <span class="number">1</span>], hue=labels, palette=<span class="string">&#x27;viridis&#x27;</span>, legend=<span class="string">&#x27;full&#x27;</span>, s=<span class="number">100</span>, alpha=<span class="number">0.8</span>)</span><br><span class="line">plt.scatter(centroids[:, <span class="number">0</span>], centroids[:, <span class="number">1</span>], marker=<span class="string">&#x27;X&#x27;</span>, s=<span class="number">200</span>, color=<span class="string">&#x27;red&#x27;</span>, label=<span class="string">&#x27;Centroids&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;K-Means Clustering Results&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Feature 1&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Feature 2&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid(<span class="literal">True</span>, linestyle=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.6</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;簇质心 (Centroids):\n<span class="subst">&#123;centroids&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="2-1-2-其他聚类算法">2.1.2 其他聚类算法</h4>
<ul>
<li><strong>DBSCAN (Density-Based Spatial Clustering of Applications with Noise)</strong>：基于密度的聚类，能发现任意形状的簇，并识别噪声点。</li>
<li><strong>层次聚类 (Hierarchical Clustering)</strong>：通过合并或分裂簇来构建嵌套的簇结构。</li>
</ul>
<h3 id="2-2-降维-Dimensionality-Reduction-：简化复杂性">2.2 降维 (Dimensionality Reduction)：简化复杂性</h3>
<p>降维是指减少数据集中特征（维度）的数量，同时尽可能保留数据的重要信息。这有助于可视化高维数据、减少计算复杂度、消除冗余特征以及缓解“维度灾难”。</p>
<h4 id="2-2-1-主成分分析-Principal-Component-Analysis-PCA">2.2.1 主成分分析 (Principal Component Analysis, PCA)</h4>
<p>PCA 是一种线性降维技术。它通过正交变换将原始数据投影到新的坐标系上，新坐标系的轴称为主成分，它们是原始数据方差最大的方向。第一个主成分捕获了数据中最大的方差，第二个主成分捕获了剩余方差中最大的部分，以此类推。</p>
<p>PCA 旨在找到一个低维子空间，使得数据点在该子空间上的投影能够最大化地保留原始数据的方差。</p>
<h4 id="2-2-2-其他降维算法">2.2.2 其他降维算法</h4>
<ul>
<li><strong>t-SNE (t-Distributed Stochastic Neighbor Embedding)</strong>：非线性降维技术，特别适用于高维数据的可视化。</li>
<li><strong>线性判别分析 (Linear Discriminant Analysis, LDA)</strong>：一种有监督的降维方法，旨在最大化类别间的分离。</li>
</ul>
<h2 id="三、强化学习：从互动中学习策略">三、强化学习：从互动中学习策略</h2>
<p>强化学习（Reinforcement Learning, RL）的灵感来源于心理学中的行为主义，即通过“奖励”和“惩罚”来学习。在RL中，一个“智能体”（Agent）通过与“环境”（Environment）不断互动来学习。智能体执行“动作”（Action），环境根据动作返回“状态”（State）和“奖励”（Reward）。智能体的目标是学习一个最优的“策略”（Policy），以最大化其长期累积奖励。</p>
<p><strong>核心要素：</strong></p>
<ul>
<li><strong>智能体 (Agent)</strong>：学习者或决策者。</li>
<li><strong>环境 (Environment)</strong>：智能体所处的外部世界。</li>
<li><strong>状态 (State)</strong>：环境在某一时刻的描述。</li>
<li><strong>动作 (Action)</strong>：智能体在某一状态下可以执行的操作。</li>
<li><strong>奖励 (Reward)</strong>：环境对智能体动作的即时反馈。</li>
<li><strong>策略 (Policy)</strong>：从状态到动作的映射，决定智能体如何行动。</li>
<li><strong>价值函数 (Value Function)</strong>：衡量某一状态或某一状态-动作对的长期价值。</li>
</ul>
<p><strong>典型算法：</strong></p>
<ul>
<li><strong>Q-learning</strong>：一种值迭代算法，通过更新Q值（状态-动作对的长期奖励）来学习最优策略。</li>
<li><strong>SARSA (State-Action-Reward-State-Action)</strong>：与Q-learning类似，但其Q值更新基于当前策略下实际执行的下一个动作。</li>
<li><strong>深度Q网络 (Deep Q-Network, DQN)</strong>：结合了深度学习和Q-learning，用神经网络近似Q值函数，在Atari游戏中取得了显著成功。</li>
<li><strong>策略梯度 (Policy Gradients)</strong>：直接优化策略函数，使其输出的动作能够最大化奖励。</li>
</ul>
<p>强化学习在机器人控制、自动驾驶、游戏AI（如AlphaGo）等领域展现出巨大潜力。</p>
<h2 id="四、半监督学习与深度学习的崛起">四、半监督学习与深度学习的崛起</h2>
<h3 id="4-1-半监督学习-Semi-Supervised-Learning">4.1 半监督学习 (Semi-Supervised Learning)</h3>
<p>在许多实际场景中，获取大量有标签数据成本高昂，而无标签数据却相对容易获取。半监督学习正是为解决这一问题而生。它结合了监督学习和无监督学习的优势，利用少量有标签数据和大量无标签数据进行学习，以提高模型的性能。</p>
<p>常见策略包括：自训练（Self-training）、协同训练（Co-training）、半监督SVM等。</p>
<h3 id="4-2-深度学习-Deep-Learning">4.2 深度学习 (Deep Learning)</h3>
<p>深度学习是机器学习的一个子集，特指利用包含多个隐藏层的神经网络（即“深度”神经网络）进行学习的方法。深度学习的出现，极大地推动了机器学习在图像识别、自然语言处理、语音识别等领域的突破。</p>
<p><strong>关键的深度学习架构包括：</strong></p>
<ul>
<li><strong>卷积神经网络 (Convolutional Neural Networks, CNN)</strong>：在图像处理领域表现卓越，通过卷积层自动提取特征。</li>
<li><strong>循环神经网络 (Recurrent Neural Networks, RNN) / 长短期记忆网络 (Long Short-Term Memory, LSTM)</strong>：适用于处理序列数据，如文本、语音。</li>
<li><strong>生成对抗网络 (Generative Adversarial Networks, GAN)</strong>：由一个生成器和一个判别器组成，用于生成逼真的数据（图像、文本等）。</li>
<li><strong>Transformer</strong>：在自然语言处理领域掀起革命性变革的架构，其自注意力机制使其能够高效处理长序列依赖。</li>
</ul>
<p>虽然深度学习的内部机制更为复杂，但其在许多复杂任务中表现出的强大能力，使其成为当今人工智能研究的核心焦点。</p>
<h2 id="机器学习算法选择与实践考量">机器学习算法选择与实践考量</h2>
<p>在选择和应用机器学习算法时，需要综合考虑以下因素：</p>
<ol>
<li><strong>数据类型与规模</strong>：是结构化数据还是非结构化数据？数据集的大小如何？</li>
<li><strong>问题类型</strong>：是回归、分类、聚类还是其他？</li>
<li><strong>模型复杂度与解释性</strong>：是否需要一个可解释的模型？对模型复杂度的接受程度如何？</li>
<li><strong>计算资源</strong>：可用的CPU/GPU、内存资源。</li>
<li><strong>性能要求</strong>：对模型精度、速度和鲁棒性的要求。</li>
<li><strong>特征工程</strong>：预处理和选择合适的特征对任何机器学习项目的成功至关重要。</li>
<li><strong>模型评估</strong>：选择合适的评估指标（如准确率、精确率、召回率、F1分数、MSE、MAE等）对模型进行客观评估。</li>
<li><strong>过拟合与欠拟合</strong>：理解偏差-方差权衡，并采取正则化、交叉验证等技术来缓解过拟合和欠拟合问题。</li>
</ol>
<h2 id="结论：机器学习的无限可能">结论：机器学习的无限可能</h2>
<p>从线性回归的简洁优雅，到深度神经网络的宏大复杂，机器学习算法构成了现代人工智能的基石。它们各有侧重，共同支撑着我们构建智能系统的能力。本文仅是机器学习算法浩瀚世界的一个概览，旨在为您勾勒出其主要脉络。</p>
<p>掌握机器学习并非一蹴而就，它需要理论知识、编程实践和持续学习的结合。随着数据量和计算能力的飞速增长，以及算法研究的不断深入，机器学习的未来充满无限可能。愿这篇概述能点燃您对机器学习的兴趣，激励您在数据驱动的时代中，开启探索智能的旅程！</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a target="_blank" rel="noopener" href="https://github.com/qmwneb946">qmwneb946</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://blog.qmwneb946.dpdns.org/2025/07/17/2025-07-17-162544/">https://blog.qmwneb946.dpdns.org/2025/07/17/2025-07-17-162544/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://opensource.org/licenses/MIT" target="_blank">MIT License</a> 许可协议。转载请注明来源 <a href="https://blog.qmwneb946.dpdns.org" target="_blank">qmwneb946 的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%8A%80%E6%9C%AF/">技术</a><a class="post-meta__tags" href="/tags/2025/">2025</a></div><div class="post-share"><div class="social-share" data-image="/img/icon.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/07/17/2025-07-17-171904/" title="深入理解区块链技术：从零到一的硬核解析"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">深入理解区块链技术：从零到一的硬核解析</div></div><div class="info-2"><div class="info-item-1">在数字化浪潮席卷全球的今天，区块链技术无疑是其中最引人注目且最具颠覆潜力的创新之一。它不仅仅是比特币的底层支撑，更被誉为构建未来数字经济基础设施的基石。然而，对于许多人来说，“区块链”这个词汇依旧带着一层神秘的面纱，它究竟是如何运作的？其背后的数学和计算机科学原理又是什么？ 作为一名热衷于技术与数学的博主，我将在这篇文章中，以深入浅出的方式，带你揭开区块链的神秘面纱，从核心组件到运作机制，再到实际应用，进行一场全面的硬核解析。无论你是编程新手、数据科学家，还是对未来技术充满好奇的普通读者，这篇文章都将为你提供理解区块链的坚实基础。 什么是区块链？核心概念速览 简单来说，区块链（Blockchain）是一种去中心化的、分布式账本技术（Distributed Ledger Technology, DLT）。它将数据以“块”（Block）的形式进行打包，并以密码学方式链接起来，形成一个不可篡改的“链”（Chain）。 想象一下，你不再需要一个银行或中央服务器来记录所有交易，而是每个人都有一个账本副本，并且这些账本会自动同步和验证。这就是区块链的核心思想：去中心化、不可篡改、公开透明和安...</div></div></div></a><a class="pagination-related" href="/2025/07/17/2025-07-17-152148/" title="无服务器架构解析：从概念到实践的深度探索"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">无服务器架构解析：从概念到实践的深度探索</div></div><div class="info-2"><div class="info-item-1">在云计算的演进浪潮中，有一种架构范式正以其独特的魅力改变着我们开发和部署应用的方式，它就是“无服务器架构”（Serverless Architecture）。这个名字听起来有些反直觉——毕竟，没有服务器，应用程序又如何在空中运行呢？作为一名技术和数学的博主，我将带你深入探索无服务器架构的奥秘，从它的核心概念、组成部件，到其优势与挑战，并结合数学视角分析其成本效益，最终展望其未来。 引言：云计算的“终极抽象”之旅 回望软件开发的历史，我们经历了从物理机到虚拟机，再到容器化的演进。每一次变革都旨在提高资源利用率、简化部署和管理。  物理机时代：你拥有并维护自己的硬件，一切从零开始。 IaaS (Infrastructure as a Service)：云服务商提供虚拟机，你依然需要管理操作系统和运行时。 PaaS (Platform as a Service)：云服务商提供完整的运行时环境，你只需部署代码，但仍需关心平台配置和伸缩。 容器化 (Containerization)：如Docker和Kubernetes，提供了标准化的部署单元和强大的编排能力，但集群管理依然复杂。  而无...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/07/17/2025-07-17-120958/" title="量子计算基础：从比特到量子比特的跃迁"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-17</div><div class="info-item-2">量子计算基础：从比特到量子比特的跃迁</div></div><div class="info-2"><div class="info-item-1"> 引言：超越经典极限 自计算机诞生以来，我们见证了信息技术的飞速发展。摩尔定律一度预示着处理器性能的指数级增长，但随着晶体管尺寸逼近物理极限，经典计算的进步正面临瓶颈。我们生活在一个数据爆炸的时代，许多复杂问题，如药物发现、材料科学、金融建模以及密码学，其计算量之大，即使是当今最强大的超级计算机也束手无策。 正是在这样的背景下，量子计算 (Quantum Computing) 闪亮登场。它不是对经典计算的简单升级，而是一种全新的计算范式，利用量子力学的奇特现象来处理信息。本文将带您踏上量子计算的探索之旅，从最基础的概念开始，理解它为何拥有颠覆性的潜力。  1. 经典比特的局限与量子比特的诞生 在深入量子世界之前，我们先回顾一下熟悉的概念。 1.1 经典比特：0或1的确定性 在经典计算机中，信息的基本单位是比特 (Bit)。一个比特只能表示两种状态中的一种：0 或 1。这就像一个电灯开关，要么是开，要么是关，绝不可能同时处于两种状态。无论多么复杂的计算，都是由无数个 0 和 1 的组合、存储和逻辑运算实现的。 1.2 量子比特 (Qubit)：叠加态的奇妙世界 量子计算的核心概念是...</div></div></div></a><a class="pagination-related" href="/2025/07/17/2025-07-17-121638/" title="机器学习算法概述：从原理到实践"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-17</div><div class="info-item-2">机器学习算法概述：从原理到实践</div></div><div class="info-2"><div class="info-item-1"> 引言 在当今数据驱动的世界中，机器学习 (Machine Learning, ML) 无疑是最具颠覆性的技术之一。从个性化推荐系统到自动驾驶汽车，从疾病诊断到金融风险评估，机器学习算法正在悄然改变我们生活的方方面面。它赋予了计算机从数据中学习、识别模式并做出决策或预测的能力，而无需被明确编程。 作为一名技术爱好者，你可能已经对机器学习的大名有所耳闻，但其背后究竟是怎样一番天地？本文旨在为你揭开机器学习算法的神秘面纱，提供一个全面而深入的概述。我们将探索机器学习的主要范式，剖析各类经典算法的核心思想、应用场景以及它们背后的数学直觉。无论你是刚踏入ML领域的新手，还是希望系统性梳理知识的技术人员，本文都将为你提供一份宝贵的指南。 机器学习的核心范式 机器学习算法通常根据其学习方式和处理的数据类型被分为几个核心范式：监督学习、无监督学习、强化学习，以及一些交叉或进阶范式如半监督学习和深度学习。 1. 监督学习 (Supervised Learning) 监督学习是最常见、也是最容易理解的机器学习范式。它的核心思想是“从带标签的数据中学习”。这意味着我们拥有大量的输入数据（特征）和对应...</div></div></div></a><a class="pagination-related" href="/2025/07/17/2025-07-17-133634/" title="探索斐波那契数列：自然界、数学与计算机科学的奇妙交织"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-17</div><div class="info-item-2">探索斐波那契数列：自然界、数学与计算机科学的奇妙交织</div></div><div class="info-2"><div class="info-item-1">引言 在数学的广袤天地中，有些概念以其简洁而深邃的美感，跨越学科界限，无处不在。斐波那契数列（Fibonacci Sequence）无疑是其中最耀眼的一颗明星。从向日葵种子的螺旋排列到古代建筑的黄金比例，从算法设计的精妙策略到金融市场的波动分析，斐波那契数列以其独特的魅力，连接着自然、艺术、数学和计算机科学。 今天，我们将深入探索这个看似简单却蕴含无限奥秘的数列，揭示它的数学特性、在计算机科学中的应用，以及它在自然界中令人惊叹的显现。准备好，我们将一起踏上这场跨越学科的奇妙旅程。 一、斐波那契数列的定义与基础 斐波那契数列，得名于13世纪意大利数学家莱昂纳多·斐波那契（Leonardo Fibonacci），他在其著作《算盘书》（Liber Abaci）中首次提出了这个数列，用以解决一个理想化的兔子繁殖问题。 数列的定义极其简单：从0和1开始（或者1和1），后续的每一个数字都是前两个数字之和。 数学定义： 对于 ( n \ge 2 )，斐波那契数列 ( F_n ) 定义为： [ F_n = F_{n-1} + F_{n-2} ] 初始条件： [ F_0 = 0 ] [ F_1 =...</div></div></div></a><a class="pagination-related" href="/2025/07/17/2025-07-17-171904/" title="深入理解区块链技术：从零到一的硬核解析"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-17</div><div class="info-item-2">深入理解区块链技术：从零到一的硬核解析</div></div><div class="info-2"><div class="info-item-1">在数字化浪潮席卷全球的今天，区块链技术无疑是其中最引人注目且最具颠覆潜力的创新之一。它不仅仅是比特币的底层支撑，更被誉为构建未来数字经济基础设施的基石。然而，对于许多人来说，“区块链”这个词汇依旧带着一层神秘的面纱，它究竟是如何运作的？其背后的数学和计算机科学原理又是什么？ 作为一名热衷于技术与数学的博主，我将在这篇文章中，以深入浅出的方式，带你揭开区块链的神秘面纱，从核心组件到运作机制，再到实际应用，进行一场全面的硬核解析。无论你是编程新手、数据科学家，还是对未来技术充满好奇的普通读者，这篇文章都将为你提供理解区块链的坚实基础。 什么是区块链？核心概念速览 简单来说，区块链（Blockchain）是一种去中心化的、分布式账本技术（Distributed Ledger Technology, DLT）。它将数据以“块”（Block）的形式进行打包，并以密码学方式链接起来，形成一个不可篡改的“链”（Chain）。 想象一下，你不再需要一个银行或中央服务器来记录所有交易，而是每个人都有一个账本副本，并且这些账本会自动同步和验证。这就是区块链的核心思想：去中心化、不可篡改、公开透明和安...</div></div></div></a><a class="pagination-related" href="/2025/07/17/2025-07-17-202210/" title="探索斐波那契数列：自然界、数学与算法的永恒旋律"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-17</div><div class="info-item-2">探索斐波那契数列：自然界、数学与算法的永恒旋律</div></div><div class="info-2"><div class="info-item-1"> 引言：宇宙间无处不在的神秘数字序列 你是否曾仰望向日葵的螺旋花盘，惊叹于松果鳞片的排列，或是凝视鹦鹉螺的完美螺线？在这些看似随机却又充满秩序的自然现象背后，隐藏着一个简单却又异常深刻的数学序列——斐波那契数列。它不仅是数学家们探索不尽的宝藏，也是计算机科学家们优化算法的灵感来源，更是艺术家们追求和谐与美的秘密武器。 今天，我们将一起踏上探索斐波那契数列的旅程。从它的基本定义出发，深入剖析其令人着迷的数学性质，探讨高效的计算方法，并最终领略它在自然、科学乃至艺术领域中的广泛应用。准备好了吗？让我们一起揭开这个古老数列的神秘面纱！ 斐波那契数列的定义与基础 斐波那契数列（Fibonacci Sequence），以意大利数学家列奥纳多·斐波那契（Leonardo Fibonacci）命名，最早出现在他1202年出版的《算盘书》（Liber Abaci）中，用来解决一个理想化的兔子繁殖问题。 其定义非常简洁：数列中的每一个数字都是前两个数字的和。我们通常从 ( F_0 = 0 ) 和 ( F_1 = 1 ) 开始。 数学定义： 对于 ( n \ge 2 )，斐波那契数列 ( F_n )...</div></div></div></a><a class="pagination-related" href="/2025/07/17/2025-07-18-052537/" title="P vs NP：计算机科学的千年之问与未解之谜"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-18</div><div class="info-item-2">P vs NP：计算机科学的千年之问与未解之谜</div></div><div class="info-2"><div class="info-item-1">计算，是现代文明的基石。从智能手机到全球网络，从金融交易到基因测序，一切都离不开强大的计算能力。然而，并非所有问题都能被计算机“轻易”解决。有些问题，我们能很快找到答案；有些问题，我们虽然能快速验证一个给定的答案是否正确，但要找到这个答案本身却似乎难如登天。这种“易于验证，难以解决”的现象，正是计算机科学中最深刻、最引人入胜的未解之谜之一：P vs NP 问题。 这个问题不仅是理论计算机科学的基石，更是数学界七大“千禧年大奖难题”之一，价值一百万美元。它的答案将深刻影响人工智能、密码学、药物发现、物流优化，甚至我们对宇宙基本运作方式的理解。 1. 计算复杂性理论入门：衡量问题的难度 在深入探讨 P vs NP 之前，我们首先需要理解什么是“计算复杂性”。计算复杂性理论是计算机科学的一个分支，它研究的是解决一个问题所需的计算资源（主要是时间和空间）的量。 我们通常使用大O表示法（Big O Notation）来描述算法的运行时间或空间消耗如何随着输入规模 ( n ) 的增长而变化。  ( O(n) ) (线性时间)：算法的运行时间与输入规模成正比。 ( O(n^2) ) (平方时间...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">qmwneb946</div><div class="author-info-description">一个专注于技术分享的个人博客，涵盖编程、算法、系统设计等内容</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">18</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/qmwneb946"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">代码与远方，技术与生活交织的篇章。</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%95%E8%A8%80%EF%BC%9A%E9%80%9A%E5%BE%80%E6%99%BA%E8%83%BD%E6%9C%AA%E6%9D%A5%E7%9A%84%E5%9F%BA%E7%9F%B3"><span class="toc-number">1.</span> <span class="toc-text">引言：通往智能未来的基石</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E7%9A%84%E5%AE%8F%E8%A7%82%E5%88%86%E7%B1%BB"><span class="toc-number">2.</span> <span class="toc-text">机器学习算法的宏观分类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%EF%BC%9A%E4%BB%8E%E5%B7%B2%E7%9F%A5%E4%B8%AD%E5%AD%A6%E4%B9%A0%E9%A2%84%E6%B5%8B"><span class="toc-number">3.</span> <span class="toc-text">一、监督学习：从已知中学习预测</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-%E5%9B%9E%E5%BD%92-Regression-%EF%BC%9A%E9%A2%84%E6%B5%8B%E8%BF%9E%E7%BB%AD%E5%80%BC"><span class="toc-number">3.1.</span> <span class="toc-text">1.1 回归 (Regression)：预测连续值</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-1-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92-Linear-Regression"><span class="toc-number">3.1.1.</span> <span class="toc-text">1.1.1 线性回归 (Linear Regression)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-2-%E5%85%B6%E4%BB%96%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95"><span class="toc-number">3.1.2.</span> <span class="toc-text">1.1.2 其他回归算法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-%E5%88%86%E7%B1%BB-Classification-%EF%BC%9A%E9%A2%84%E6%B5%8B%E7%A6%BB%E6%95%A3%E7%B1%BB%E5%88%AB"><span class="toc-number">3.2.</span> <span class="toc-text">1.2 分类 (Classification)：预测离散类别</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-1-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92-Logistic-Regression"><span class="toc-number">3.2.1.</span> <span class="toc-text">1.2.1 逻辑回归 (Logistic Regression)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-2-%E5%85%B6%E4%BB%96%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95"><span class="toc-number">3.2.2.</span> <span class="toc-text">1.2.2 其他分类算法</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%EF%BC%9A%E4%BB%8E%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%8F%91%E7%8E%B0%E6%A8%A1%E5%BC%8F"><span class="toc-number">4.</span> <span class="toc-text">二、无监督学习：从数据中发现模式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E8%81%9A%E7%B1%BB-Clustering-%EF%BC%9A%E7%89%A9%E4%BB%A5%E7%B1%BB%E8%81%9A"><span class="toc-number">4.1.</span> <span class="toc-text">2.1 聚类 (Clustering)：物以类聚</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-1-K-Means-%E8%81%9A%E7%B1%BB"><span class="toc-number">4.1.1.</span> <span class="toc-text">2.1.1 K-Means 聚类</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-2-%E5%85%B6%E4%BB%96%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95"><span class="toc-number">4.1.2.</span> <span class="toc-text">2.1.2 其他聚类算法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E9%99%8D%E7%BB%B4-Dimensionality-Reduction-%EF%BC%9A%E7%AE%80%E5%8C%96%E5%A4%8D%E6%9D%82%E6%80%A7"><span class="toc-number">4.2.</span> <span class="toc-text">2.2 降维 (Dimensionality Reduction)：简化复杂性</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-1-%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90-Principal-Component-Analysis-PCA"><span class="toc-number">4.2.1.</span> <span class="toc-text">2.2.1 主成分分析 (Principal Component Analysis, PCA)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-2-%E5%85%B6%E4%BB%96%E9%99%8D%E7%BB%B4%E7%AE%97%E6%B3%95"><span class="toc-number">4.2.2.</span> <span class="toc-text">2.2.2 其他降维算法</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%EF%BC%9A%E4%BB%8E%E4%BA%92%E5%8A%A8%E4%B8%AD%E5%AD%A6%E4%B9%A0%E7%AD%96%E7%95%A5"><span class="toc-number">5.</span> <span class="toc-text">三、强化学习：从互动中学习策略</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%B4%9B%E8%B5%B7"><span class="toc-number">6.</span> <span class="toc-text">四、半监督学习与深度学习的崛起</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-%E5%8D%8A%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-Semi-Supervised-Learning"><span class="toc-number">6.1.</span> <span class="toc-text">4.1 半监督学习 (Semi-Supervised Learning)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Deep-Learning"><span class="toc-number">6.2.</span> <span class="toc-text">4.2 深度学习 (Deep Learning)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E9%80%89%E6%8B%A9%E4%B8%8E%E5%AE%9E%E8%B7%B5%E8%80%83%E9%87%8F"><span class="toc-number">7.</span> <span class="toc-text">机器学习算法选择与实践考量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA%EF%BC%9A%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%97%A0%E9%99%90%E5%8F%AF%E8%83%BD"><span class="toc-number">8.</span> <span class="toc-text">结论：机器学习的无限可能</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/18/hello-world/" title="Hello World">Hello World</a><time datetime="2025-07-18T05:34:17.401Z" title="发表于 2025-07-18 13:34:17">2025-07-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/17/2025-07-18-052537/" title="P vs NP：计算机科学的千年之问与未解之谜">P vs NP：计算机科学的千年之问与未解之谜</a><time datetime="2025-07-17T21:25:37.000Z" title="发表于 2025-07-18 05:25:37">2025-07-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/17/2025-07-18-043836/" title="揭秘代码的炼金术：编译器是如何工作的？">揭秘代码的炼金术：编译器是如何工作的？</a><time datetime="2025-07-17T20:38:36.000Z" title="发表于 2025-07-18 04:38:36">2025-07-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/17/2025-07-18-032828/" title="赋能与变革：人工智能在软件开发中的深远作用">赋能与变革：人工智能在软件开发中的深远作用</a><time datetime="2025-07-17T19:28:28.000Z" title="发表于 2025-07-18 03:28:28">2025-07-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/17/2025-07-18-014322/" title="欧拉恒等式的优雅：数学与美的终极融合">欧拉恒等式的优雅：数学与美的终极融合</a><time datetime="2025-07-17T17:43:22.000Z" title="发表于 2025-07-18 01:43:22">2025-07-18</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;2025 By qmwneb946</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.2</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(async () => {
  const showKatex = () => {
    document.querySelectorAll('#article-container .katex').forEach(el => el.classList.add('katex-show'))
  }

  if (!window.katex_js_css) {
    window.katex_js_css = true
    await btf.getCSS('https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css')
    if (true) {
      await btf.getScript('https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js')
    }
  }

  showKatex()
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const getGiscusTheme = theme => theme === 'dark' ? 'dark' : 'light'

  const createScriptElement = config => {
    const ele = document.createElement('script')
    Object.entries(config).forEach(([key, value]) => {
      ele.setAttribute(key, value)
    })
    return ele
  }

  const loadGiscus = (el = document, key) => {
    const mappingConfig = isShuoshuo
      ? { 'data-mapping': 'specific', 'data-term': key }
      : { 'data-mapping': (option && option['data-mapping']) || 'pathname' }

    const giscusConfig = {
      src: 'https://giscus.app/client.js',
      'data-repo': 'qmwneb946/blog',
      'data-repo-id': 'R_kgDOPM6cWw',
      'data-category-id': 'DIC_kwDOPM6cW84CtEzo',
      'data-theme': getGiscusTheme(document.documentElement.getAttribute('data-theme')),
      'data-reactions-enabled': '1',
      crossorigin: 'anonymous',
      async: true,
      ...option,
      ...mappingConfig
    }

    const scriptElement = createScriptElement(giscusConfig)

    el.querySelector('#giscus-wrap').appendChild(scriptElement)

    if (isShuoshuo) {
      window.shuoshuoComment.destroyGiscus = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }
  }

  const changeGiscusTheme = theme => {
    const iframe = document.querySelector('#giscus-wrap iframe')
    if (iframe) {
      const message = {
        giscus: {
          setConfig: {
            theme: getGiscusTheme(theme)
          }
        }
      }
      iframe.contentWindow.postMessage(message, 'https://giscus.app')
    }
  }

  btf.addGlobalFn('themeChange', changeGiscusTheme, 'giscus')

  if (isShuoshuo) {
    'Giscus' === 'Giscus'
      ? window.shuoshuoComment = { loadComment: loadGiscus }
      : window.loadOtherComment = loadGiscus
    return
  }

  if ('Giscus' === 'Giscus' || !false) {
    if (false) btf.loadComment(document.getElementById('giscus-wrap'), loadGiscus)
    else loadGiscus()
  } else {
    window.loadOtherComment = loadGiscus
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>