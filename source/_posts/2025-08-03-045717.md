---
title: 动态规划：算法之魂与其在实践中的璀璨应用
date: 2025-08-03 04:57:17
tags:
  - 动态规划应用
  - 计算机科学
  - 2025
categories:
  - 计算机科学
---

你好，各位技术同好与数学爱好者！我是 qmwneb946，今天我们不聊别的，只聊一个在算法世界里如同星辰般闪耀、却又常常让人感到“只可意会不可言传”的范式——动态规划（Dynamic Programming，简称 DP）。

动态规划，这个名字初听起来似乎与“动态”和“规划”的字面含义有些偏差，它既不像是一种实时调整的策略，也非某种未来蓝图的规划。实际上，它更像是一种艺术，一种将复杂问题分解为简单子问题，并通过巧妙地存储和复用子问题解来避免重复计算，最终高效地解决原问题的方法论。它由美国数学家 Richard Bellman 在 20 世纪 50 年代提出，最初是为了描述一种决策过程，在计算机科学领域，它则成为了解决最优化问题、计数问题以及判断性问题的强大工具。

如果你曾为斐波那契数列的递归效率低下而苦恼，如果你曾惊叹于背包问题、最长公共子序列等问题的优雅解法，那么你一定已经与动态规划不期而遇。动态规划不仅仅是一种算法，更是一种思维模式，它要求我们深刻理解问题的结构，抽丝剥茧，找到问题的最优子结构和重叠子问题。一旦掌握了它，你将发现许多看似无从下手的难题，在它的框架下都变得清晰可解。

本文将带领你深入探索动态规划的奥秘，从其核心思想出发，逐步揭示它在各类问题中的广泛应用。我们将通过丰富的实例，剖析动态规划的状态定义、状态转移方程以及边界条件，并探讨一些高级的优化技巧。准备好了吗？让我们一同踏上这段充满挑战与启迪的算法之旅！

---

## 动态规划的核心思想

要真正理解动态规划，我们首先需要把握其赖以存在的两大基石：**最优子结构**和**重叠子问题**。

### 最优子结构

一个问题具有最优子结构性质，意味着其最优解可以由其子问题的最优解有效地构造出来。换句话说，如果一个问题的最优解中包含了其子问题的最优解，那么这个问题就具有最优子结构性质。

以“最短路径”问题为例，如果我们想找到从点 A 到点 B 的最短路径，那么这条最短路径上的任何一点 C，从 A 到 C 的路径以及从 C 到 B 的路径都必须是各自子问题的最短路径。如果不是，我们就可以通过替换子路径来得到一条更短的总路径，这与“最短路径”的假设相矛盾。

### 重叠子问题

重叠子问题是指在递归求解问题的过程中，我们可能会多次遇到并计算相同的子问题。如果没有某种机制来存储和重用这些子问题的解，那么每次遇到相同的子问题时都会重新计算，导致大量的重复工作，从而降低效率。

最典型的例子就是斐波那契数列的递归实现。要计算 $F(n)$，我们需要计算 $F(n-1)$ 和 $F(n-2)$。而计算 $F(n-1)$ 又需要 $F(n-2)$ 和 $F(n-3)$，可以看到 $F(n-2)$ 被重复计算了。当 $n$ 增大时，这种重复计算会呈指数级增长。

### 动态规划的两种实现方式

理解了最优子结构和重叠子问题后，我们来看动态规划的两种主要实现方式：

#### 记忆化搜索（Top-Down DP / Memoization）

记忆化搜索是从问题的“顶层”开始，向下递归地解决子问题。每当一个子问题的解被计算出来时，就将其存储起来。下次再遇到相同的子问题时，直接从存储中取出结果，而不是重新计算。这本质上是带有缓存的递归。

#### 递推（Bottom-Up DP / Tabulation）

递推是从问题的“底层”开始，逐步向上解决更大规模的子问题，直到最终解决原问题。通常，我们会维护一个数组（或表格）来存储所有已解决子问题的解，并根据这些解来计算更大子问题的解。这种方法通常不需要递归，因此可以避免递归深度过大的问题，并且通常具有更好的性能。

在实际应用中，选择哪种方式取决于个人习惯和问题的特点。对于某些问题，递归的思维方式更自然；而对于另一些问题，递推的循环结构则更清晰。

## 动态规划的应用实例

现在，让我们通过具体的例子来深入探讨动态规划在不同类型问题中的应用。

### 斐波那契数列：DP的入门经典

斐波那契数列定义为：$F(0)=0, F(1)=1, F(n) = F(n-1) + F(n-2)$，其中 $n > 1$。

#### 递归实现 (低效)

```python
def fib_recursive(n):
    if n <= 1:
        return n
    return fib_recursive(n - 1) + fib_recursive(n - 2)
```
这种递归方式，由于存在大量的重叠子问题，其时间复杂度是指数级的 $O(2^n)$。

#### 记忆化搜索 (Top-Down DP)

```python
memo = {} # 用于存储已计算结果的字典

def fib_memo(n):
    if n in memo: # 如果已经计算过，直接返回
        return memo[n]
    
    if n <= 1:
        result = n
    else:
        result = fib_memo(n - 1) + fib_memo(n - 2)
    
    memo[n] = result # 存储结果
    return result

# print(fib_memo(10))
```
通过记忆化，我们将时间复杂度降低到了 $O(n)$，因为每个子问题只会被计算一次。

#### 递推 (Bottom-Up DP)

```python
def fib_dp_tabulation(n):
    if n <= 1:
        return n
    
    dp = [0] * (n + 1) # dp[i] 表示 F(i) 的值
    dp[0] = 0
    dp[1] = 1
    
    for i in range(2, n + 1):
        dp[i] = dp[i - 1] + dp[i - 2]
        
    return dp[n]

# print(fib_dp_tabulation(10))
```
递推方式同样达到了 $O(n)$ 的时间复杂度，并且由于避免了递归调用栈的开销，通常具有更好的常数因子性能。

### 背包问题：最优化决策的典范

背包问题是一类经典的组合优化问题，它有很多变种，其中最常见的是 0/1 背包和完全背包。

#### 0/1 背包问题

问题描述：给定 $N$ 个物品，每个物品有自己的重量 $w_i$ 和价值 $v_i$。现有一个容量为 $W$ 的背包，问如何选择物品放入背包，使得放入背包的物品总重量不超过 $W$ 的前提下，总价值最大？每个物品只能选择一次（0或1次）。

**状态定义：**
$dp[i][j]$ 表示考虑前 $i$ 个物品，背包容量为 $j$ 时所能获得的最大价值。

**状态转移方程：**
对于第 $i$ 个物品，我们有两种选择：
1.  **不放入第 $i$ 个物品：** 此时的最大价值与考虑前 $i-1$ 个物品、容量仍为 $j$ 时的最大价值相同，即 $dp[i-1][j]$。
2.  **放入第 $i$ 个物品：** 前提是背包容量 $j$ 足够放下第 $i$ 个物品（即 $j \ge w_i$）。此时的最大价值是考虑前 $i-1$ 个物品、背包容量为 $j - w_i$ 时的最大价值，再加上第 $i$ 个物品的价值 $v_i$，即 $dp[i-1][j-w_i] + v_i$。

因此，
$dp[i][j] = \max(dp[i-1][j], \quad dp[i-1][j-w_i] + v_i) \quad \text{当 } j \ge w_i$
$dp[i][j] = dp[i-1][j] \quad \text{当 } j < w_i$

**边界条件：**
$dp[0][j] = 0$ (没有物品时，价值为0)
$dp[i][0] = 0$ (背包容量为0时，价值为0)

**示例代码 (Python)：**

```python
def knapsack_01(weights, values, W):
    N = len(weights)
    # dp[i][j] 考虑前i个物品，容量为j的最大价值
    # dp 数组初始化为0
    dp = [[0] * (W + 1) for _ in range(N + 1)]

    for i in range(1, N + 1): # 遍历物品
        w_i = weights[i - 1] # 当前物品重量
        v_i = values[i - 1] # 当前物品价值
        for j in range(1, W + 1): # 遍历背包容量
            if j >= w_i: # 如果当前背包容量可以放下第i个物品
                # 比较：不放第i个物品 vs 放第i个物品
                dp[i][j] = max(dp[i-1][j], dp[i-1][j - w_i] + v_i)
            else: # 如果放不下
                dp[i][j] = dp[i-1][j] # 只能选择不放

    return dp[N][W]

# 示例
# weights = [2, 1, 3] # 物品重量
# values = [4, 2, 3] # 物品价值
# W = 4 # 背包容量
# print(knapsack_01(weights, values, W)) # 输出 6 (选择物品1和2，重量2+1=3，价值4+2=6)
```

#### 空间优化 (滚动数组)

注意到 $dp[i][j]$ 的计算只依赖于 $dp[i-1][\dots]$ 的值。这允许我们使用滚动数组将空间复杂度从 $O(NW)$ 优化到 $O(W)$。关键在于，在计算 $dp[j]$ (当前行)时，我们必须使用上一行的 $dp[j - w_i]$。因此，内层循环必须**从大到小**遍历 $j$。

```python
def knapsack_01_optimized(weights, values, W):
    N = len(weights)
    # dp[j] 表示当前容量为 j 的最大价值
    dp = [0] * (W + 1)

    for i in range(N): # 遍历物品
        w_i = weights[i]
        v_i = values[i]
        # 注意：这里 j 必须从大到小遍历，以确保 dp[j - w_i] 是上一轮（即未考虑当前物品）的值
        for j in range(W, w_i - 1, -1): 
            dp[j] = max(dp[j], dp[j - w_i] + v_i)
            
    return dp[W]

# 示例
# weights = [2, 1, 3]
# values = [4, 2, 3]
# W = 4
# print(knapsack_01_optimized(weights, values, W)) # 输出 6
```

#### 完全背包问题

问题描述：与 0/1 背包类似，但每个物品可以无限次选择。

**状态转移方程：**
关键区别在于，当选择放入第 $i$ 个物品时，背包容量变为 $j - w_i$，此时仍然可以继续放入第 $i$ 个物品。所以，$dp[j-w_i]$ 应该使用**当前轮次**（即已经考虑了第 $i$ 个物品的）结果。

$dp[i][j] = \max(dp[i-1][j], \quad dp[i][j-w_i] + v_i) \quad \text{当 } j \ge w_i$
如果使用空间优化，则内层循环需**从小到大**遍历 $j$。

```python
def knapsack_unbounded(weights, values, W):
    N = len(weights)
    dp = [0] * (W + 1)

    for i in range(N): # 遍历物品
        w_i = weights[i]
        v_i = values[i]
        # 注意：这里 j 从小到大遍历，因为 dp[j - w_i] 可能是由当前物品计算出来的
        for j in range(w_i, W + 1): 
            dp[j] = max(dp[j], dp[j - w_i] + v_i)
            
    return dp[W]

# 示例
# weights = [2, 1, 3] # 物品重量
# values = [4, 2, 3] # 物品价值
# W = 4 # 背包容量
# print(knapsack_unbounded(weights, values, W)) # 输出 8 (选择2个物品1，价值 4+4=8)
```

### 最长公共子序列 (LCS)：字符串匹配的核心

问题描述：给定两个字符串 $X$ 和 $Y$，找出它们最长的公共子序列的长度。子序列不要求连续，但保持相对顺序。

**状态定义：**
$dp[i][j]$ 表示字符串 $X$ 的前 $i$ 个字符与字符串 $Y$ 的前 $j$ 个字符的最长公共子序列的长度。

**状态转移方程：**
1.  如果 $X[i-1]$ (第 $i$ 个字符) 等于 $Y[j-1]$ (第 $j$ 个字符)：
    那么这两个字符可以作为公共子序列的一部分，所以 $dp[i][j]$ 就是 $X$ 的前 $i-1$ 个字符和 $Y$ 的前 $j-1$ 个字符的 LCS 长度加 1。
    $dp[i][j] = dp[i-1][j-1] + 1$
2.  如果 $X[i-1]$ 不等于 $Y[j-1]$：
    此时，这两个字符不能同时作为公共子序列的最后一个字符。我们需要考虑两种情况：
    *   不考虑 $X[i-1]$，即 $X$ 的前 $i-1$ 个字符和 $Y$ 的前 $j$ 个字符的 LCS 长度 ($dp[i-1][j]$)。
    *   不考虑 $Y[j-1]$，即 $X$ 的前 $i$ 个字符和 $Y$ 的前 $j-1$ 个字符的 LCS 长度 ($dp[i][j-1]$)。
    取这两种情况的最大值。
    $dp[i][j] = \max(dp[i-1][j], dp[i][j-1])$

**边界条件：**
$dp[0][j] = 0$ (空字符串与任何字符串的 LCS 长度为0)
$dp[i][0] = 0$ (空字符串与任何字符串的 LCS 长度为0)

**示例代码 (Python)：**

```python
def longest_common_subsequence(text1, text2):
    m, n = len(text1), len(text2)
    # dp[i][j] 存储 text1[:i] 和 text2[:j] 的 LCS 长度
    dp = [[0] * (n + 1) for _ in range(m + 1)]

    for i in range(1, m + 1):
        for j in range(1, n + 1):
            if text1[i - 1] == text2[j - 1]:
                dp[i][j] = dp[i - 1][j - 1] + 1
            else:
                dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])

    return dp[m][n]

# 示例
# text1 = "abcde"
# text2 = "ace"
# print(longest_common_subsequence(text1, text2)) # 输出 3 ("ace")
```

### 最长递增子序列 (LIS)：序列问题的基石

问题描述：给定一个无序的整数数组，找到其中最长递增子序列的长度。子序列不要求连续。

**状态定义 (O(N^2) 解法)：**
$dp[i]$ 表示以 $nums[i]$ 结尾的最长递增子序列的长度。

**状态转移方程 (O(N^2) 解法)：**
要计算 $dp[i]$，我们需要遍历 $nums[0 \dots i-1]$。如果 $nums[j] < nums[i]$，那么 $nums[i]$ 可以接在以 $nums[j]$ 结尾的递增子序列后面。所以，我们取所有符合条件的 $dp[j]$ 中的最大值，然后加 1。

$dp[i] = 1 + \max(\{dp[j] \mid j < i, nums[j] < nums[i]\} \cup \{0\})$
这里的 $\{0\}$ 表示当没有符合条件的 $j$ 时，以 $nums[i]$ 结尾的 LIS 长度至少为 1 (自身)。

**最终结果：** 整个数组的最长递增子序列长度是所有 $dp[i]$ 中的最大值。

**示例代码 (Python - O(N^2))：**

```python
def longest_increasing_subsequence_n_square(nums):
    if not nums:
        return 0
    
    n = len(nums)
    dp = [1] * n # dp[i] 初始化为 1，因为每个元素本身就是长度为 1 的递增子序列

    for i in range(n):
        for j in range(i):
            if nums[i] > nums[j]:
                dp[i] = max(dp[i], dp[j] + 1)
                
    return max(dp)

# 示例
# nums = [10, 9, 2, 5, 3, 7, 101, 18]
# print(longest_increasing_subsequence_n_square(nums)) # 输出 4 (例如 [2, 3, 7, 18] 或 [2, 5, 7, 18])
```

**优化 (O(N log N) 解法)：**
这个优化方法不直接使用 DP 数组存储子序列长度，而是维护一个 `tails` 数组，其中 `tails[k]` 存储所有长度为 `k+1` 的递增子序列中，最小的结尾元素。

当遍历到新数字 `num` 时：
*   如果 `num` 大于 `tails` 中所有元素，则它能延长最长的递增子序列，将 `num` 添加到 `tails` 末尾。
*   否则，找到 `tails` 中第一个大于等于 `num` 的元素，将其替换为 `num`。这样做的目的是为了让相同长度的递增子序列，其结尾元素尽可能小，为后续的数字提供更大的接续可能性。

最终 `tails` 数组的长度就是 LIS 的长度。

```python
import bisect # 用于二分查找

def longest_increasing_subsequence_n_log_n(nums):
    tails = [] # tails[k] 存储所有长度为 k+1 的递增子序列的最小尾部元素

    for num in nums:
        # 查找 num 在 tails 中可以插入的位置
        # bisect_left 返回插入点，使得序列依然保持有序
        idx = bisect.bisect_left(tails, num)
        
        if idx == len(tails): # 如果 num 大于 tails 中所有元素，则延长 LIS
            tails.append(num)
        else: # 否则，替换掉第一个大于等于 num 的元素
            tails[idx] = num
            
    return len(tails)

# 示例
# nums = [10, 9, 2, 5, 3, 7, 101, 18]
# print(longest_increasing_subsequence_n_log_n(nums)) # 输出 4
```

### 路径规划与网格DP

这类问题通常涉及到在一个网格中寻找路径，计数路径或找到最小/最大成本路径。

#### 最小路径和

问题描述：给定一个包含非负整数的 $m \times n$ 网格，从左上角到右下角，每次只能向下或向右移动一步，找到一条路径使得路径上的数字总和最小。

**状态定义：**
$dp[i][j]$ 表示从网格左上角 $(0,0)$ 到达 $(i,j)$ 的最小路径和。

**状态转移方程：**
要到达 $(i,j)$，只能从 $(i-1,j)$ 向下移动，或者从 $(i,j-1)$ 向右移动。所以，到达 $(i,j)$ 的最小路径和就是其上方和左方单元格的最小路径和的较小值，再加上当前单元格的值。

$dp[i][j] = \min(dp[i-1][j], dp[i][j-1]) + grid[i][j]$

**边界条件：**
*   $dp[0][0] = grid[0][0]$
*   第一行：$dp[0][j] = dp[0][j-1] + grid[0][j]$ (只能从左边来)
*   第一列：$dp[i][0] = dp[i-1][0] + grid[i][0]$ (只能从上面来)

**示例代码 (Python)：**

```python
def min_path_sum(grid):
    m = len(grid)
    n = len(grid[0])
    
    dp = [[0] * n for _ in range(m)]
    
    # 填充边界条件
    dp[0][0] = grid[0][0]
    for j in range(1, n): # 第一行
        dp[0][j] = dp[0][j - 1] + grid[0][j]
    for i in range(1, m): # 第一列
        dp[i][0] = dp[i - 1][0] + grid[i][0]
        
    # 填充其他单元格
    for i in range(1, m):
        for j in range(1, n):
            dp[i][j] = min(dp[i - 1][j], dp[i][j - 1]) + grid[i][j]
            
    return dp[m - 1][n - 1]

# 示例
# grid = [[1,3,1],[1,5,1],[4,2,1]]
# print(min_path_sum(grid)) # 输出 7 (1->1->2->1->1)
```

### 区间DP：处理序列或链条问题

区间 DP 主要用于解决那些与序列或链条的连续子区间相关的问题。其特点是状态通常定义为 $dp[i][j]$ 表示从 $i$ 到 $j$ 的区间的某个最优解，并且状态转移时通常会枚举区间内的某个分割点 $k$。

#### 石子合并 (或矩阵链乘法)

问题描述：有一排 $N$ 堆石子，每堆石子有一个重量。现在要将这些石子堆合并成一堆，每次只能合并相邻的两堆石子，合并的费用是这两堆石子的总重量。求合并所有石子的最小总费用。

**状态定义：**
$dp[i][j]$ 表示将从第 $i$ 堆到第 $j$ 堆石子合并成一堆的最小费用。

**状态转移方程：**
要将 $i$ 到 $j$ 的石子合并，我们需要在 $i$ 和 $j$ 之间选择一个分割点 $k$ ($i \le k < j$)，将石子分为两部分：$i$ 到 $k$ 和 $k+1$ 到 $j$。然后分别合并这两部分，最后将合并后的两堆再合并。总费用是两部分合并的费用之和加上最后一次合并的费用 (即 $i$ 到 $j$ 所有石子的总重量)。

$dp[i][j] = \min_{i \le k < j} (dp[i][k] + dp[k+1][j] + \sum_{p=i}^{j} \text{stones}[p])$

其中 $\sum_{p=i}^{j} \text{stones}[p]$ 可以通过前缀和预处理快速得到。设 $S[x] = \sum_{p=0}^{x-1} \text{stones}[p]$ (即前 $x$ 堆石子的总和)，那么 $\sum_{p=i}^{j} \text{stones}[p] = S[j+1] - S[i]$。

**边界条件：**
$dp[i][i] = 0$ (单堆石子不需要合并，费用为0)。

**计算顺序：** 通常按区间长度 $len = 2, 3, \dots, N$ 递增的方式进行计算。对于每个长度 $len$，遍历所有可能的起始点 $i$，计算 $j = i + len - 1$。

**示例代码 (Python)：**

```python
def stone_merging(stones):
    n = len(stones)
    if n <= 1:
        return 0

    # 计算前缀和，方便快速得到区间和
    prefix_sum = [0] * (n + 1)
    for i in range(n):
        prefix_sum[i+1] = prefix_sum[i] + stones[i]

    # dp[i][j] 表示合并从索引 i 到 j 的石子的最小代价
    dp = [[0] * n for _ in range(n)]

    # len 表示当前合并的石子堆的长度 (从2开始，因为长度为1的代价是0)
    for length in range(2, n + 1):
        for i in range(n - length + 1): # 区间起始点 i
            j = i + length - 1 # 区间结束点 j
            
            dp[i][j] = float('inf') # 初始化为无穷大
            current_sum = prefix_sum[j+1] - prefix_sum[i] # 当前区间的总和
            
            # 枚举分割点 k
            for k in range(i, j):
                dp[i][j] = min(dp[i][j], dp[i][k] + dp[k+1][j] + current_sum)
                
    return dp[0][n-1]

# 示例
# stones = [3, 4, 5, 6]
# print(stone_merging(stones)) # 输出 48
# (合并顺序示例: (3+4)=7, (5+6)=11, 7+11=18. 总和: (3+4) + (5+6) + (7+11) = 7+11+18 = 36。 
# 哎，这里算错了，是最后一次合并的费用，不是整个过程的费用。
# (3,4,5,6) -> (7,5,6) 费用 7
# (7,5,6) -> (7,11) 费用 11
# (7,11) -> (18) 费用 18
# 总费用 = 7 + 11 + 18 = 36. 
# 19 是哪里来的？ 3,4,5,6
# dp[0][1]=7, dp[1][2]=9, dp[2][3]=11
# dp[0][2]=min(dp[0][0]+dp[1][2]+sum(0,2), dp[0][1]+dp[2][2]+sum(0,2))
#          =min(0+9+(3+4+5), 7+0+(3+4+5)) = min(9+12, 7+12) = min(21, 19) = 19
# dp[1][3]=min(dp[1][1]+dp[2][3]+sum(1,3), dp[1][2]+dp[3][3]+sum(1,3))
#          =min(0+11+(4+5+6), 9+0+(4+5+6)) = min(11+15, 9+15) = min(26, 24) = 24
# dp[0][3]=min(dp[0][0]+dp[1][3]+sum(0,3), dp[0][1]+dp[2][3]+sum(0,3), dp[0][2]+dp[3][3]+sum(0,3))
#          =min(0+24+18, 7+11+18, 19+0+18) = min(42, 36, 37) = 36
# 答案是 36
```

### 树形DP：在树结构上进行决策

树形 DP 通常用于解决与树结构相关的最优化问题。状态通常定义为 $dp[u][\dots]$，其中 $u$ 是树中的一个节点，而 $\dots$ 代表与节点 $u$ 相关的其他状态（例如，选择 $u$ 或不选择 $u$，或 $u$ 的子树的某个属性）。

#### 树的最大独立集

问题描述：给定一棵树，在树中选择一个最大的节点集合，使得集合中任意两个节点之间都没有边相连（即它们不是相邻的）。

**状态定义：**
对于每个节点 $u$：
*   $dp[u][0]$：表示在以 $u$ 为根的子树中，不选择节点 $u$ 的情况下，所能获得的最大独立集大小。
*   $dp[u][1]$：表示在以 $u$ 为根的子树中，选择节点 $u$ 的情况下，所能获得的最大独立集大小。

**状态转移方程：**
通过 DFS 或 BFS 从叶子节点向上计算。
1.  **$dp[u][0]$ (不选择 $u$)：** 如果不选择 $u$，那么它的所有子节点 $v$ 都可以选择或不选择。为了使独立集最大，我们应该选择子节点 $v$ 的两种情况中的较大值。
    $dp[u][0] = \sum_{v \in \text{children}(u)} \max(dp[v][0], dp[v][1])$

2.  **$dp[u][1]$ (选择 $u$)：** 如果选择 $u$，那么它的所有子节点 $v$ 都不能被选择（因为是相邻的）。
    $dp[u][1] = 1 + \sum_{v \in \text{children}(u)} dp[v][0]$

**边界条件：**
对于叶子节点 $u$ (没有子节点)：
$dp[u][0] = 0$
$dp[u][1] = 1$

**示例代码 (Python - 伪代码或结构)：**

```python
# 假设 tree 是一个邻接列表表示的树
# tree = {node_id: [child1, child2, ...]}
# dp = {} # 存储结果

def dfs_tree_dp(u, parent, tree, dp):
    # 初始化叶子节点情况
    dp[u] = [0, 1] # [不选u, 选u]

    for v in tree.get(u, []):
        if v == parent: # 避免回到父节点
            continue
        
        dfs_tree_dp(v, u, tree, dp) # 递归计算子节点
        
        # 更新当前节点 u 的 dp 值
        dp[u][0] += max(dp[v][0], dp[v][1]) # 不选u，子节点v可以选或不选
        dp[u][1] += dp[v][0] # 选u，子节点v不能选

# 调用示例：
# 假设树的根节点是 0
# dfs_tree_dp(0, -1, tree_adj_list, dp)
# result = max(dp[0][0], dp[0][1]) # 最终结果是根节点两种情况的最大值
```

### 状态压缩DP (Bitmask DP)：小规模集合问题的利器

当问题的状态可以用一个整数（特别是二进制位掩码）来表示时，状态压缩 DP 变得非常有用。这通常适用于元素数量较少（例如 $N \le 20$）的问题。

#### 旅行商问题 (TSP - 简版)

问题描述：给定 $N$ 个城市和任意两城市之间的旅行费用，从某个城市出发，遍历所有城市恰好一次，并回到出发城市，求最小总费用。

**状态定义：**
$dp[mask][last\_node]$ 表示已经访问过的城市集合由 `mask` 表示，当前停留在 `last_node` 的最小费用。
`mask` 是一个二进制数，如果 `mask` 的第 $i$ 位为 1，表示第 $i$ 个城市已经被访问过。

**状态转移方程：**
要计算 $dp[mask][last\_node]$，我们需要考虑上一个访问的城市 $prev\_node$。
$dp[mask][last\_node] = \min_{prev\_node \in mask \setminus \{last\_node\}} (dp[mask \text{ XOR } (1 \ll last\_node)][prev\_node] + \text{cost}[prev\_node][last\_node])$

**边界条件：**
$dp[1 \ll start\_node][start\_node] = 0$ (从起点出发，只访问了起点，费用为0)

**计算顺序：** 通常按照 `mask` 中置位（1的个数）的数量从小到大进行计算。

**示例伪代码：**

```python
# 假设 N 是城市数量，cost[i][j] 是从城市 i 到城市 j 的费用
# start_node 是出发城市
# dp[mask][last_node]

# 初始化 dp 表为无穷大
dp = [[float('inf')] * N for _ in range(1 << N)]

# 边界条件：从起点出发，只访问了起点，费用为0
dp[1 << start_node][start_node] = 0

# 遍历所有可能的 mask (从只包含起点的 mask 开始)
for mask in range(1, 1 << N):
    for last_node in range(N):
        # 如果 last_node 不在当前 mask 中，或者 dp[mask][last_node] 仍为无穷大，则跳过
        if not (mask & (1 << last_node)) or dp[mask][last_node] == float('inf'):
            continue
        
        # 尝试从 last_node 走到下一个城市 next_node
        for next_node in range(N):
            # 如果 next_node 还没被访问过，且 next_node 不是 last_node
            if not (mask & (1 << next_node)): # and next_node != last_node (实际上不会相等)
                new_mask = mask | (1 << next_node) # 标记 next_node 已访问
                dp[new_mask][next_node] = min(dp[new_mask][next_node], 
                                              dp[mask][last_node] + cost[last_node][next_node])

# 最终结果：从每个城市回到起点的最小费用
min_total_cost = float('inf')
final_mask = (1 << N) - 1 # 所有城市都被访问过的 mask
for last_node in range(N):
    min_total_cost = min(min_total_cost, dp[final_mask][last_node] + cost[last_node][start_node])

# return min_total_cost
```

### 数位DP：统计满足特定条件的数字

数位 DP 是一种用于计算在给定区间 $[A, B]$ 内，满足某种特定性质的数字个数的方法。它通常将问题转化为计算 $[0, X]$ 内满足条件的数字个数，然后通过 $count(B) - count(A-1)$ 得到结果。

核心思想是按位（从高位到低位）构建数字，并使用 DP 状态来记录当前位、是否受上限限制（`tight`）、是否有前导零（`leading_zero`）以及其他与问题相关的状态。

**常见状态参数：**
*   `pos`: 当前正在构建的数字的位索引（从高位到低位）。
*   `tight`: 布尔值，表示当前位是否受到原始数字的上限限制。如果为真，当前位能取的最大值是原始数字对应位的值；如果为假，则可以取 0-9。
*   `leading_zero`: 布尔值，表示当前正在构建的数字是否全是前导零。用于处理像“不包含数字 0 的数”这类问题，或者在计算位数时避免前导零。
*   `other_states`: 任何其他需要传递的状态，例如当前数字的和、是否包含某个特定数字、是否满足某种递增/递减性质等。

**状态转移：**
递归函数通常会尝试当前位能取的所有数字 $d$，然后递归调用自身来构建下一位。根据 `tight` 和 `leading_zero` 更新下一层的参数。

**示例：统计 $1$ 到 $N$ 中数字 $1$ 出现的次数**

这是一个经典的数位 DP 问题，但其 DP 状态定义和转移逻辑相对复杂。简而言之，就是拆解成计算每一位贡献了多少个 1。

这里我们给一个更通用、更易于理解的数位 DP 框架：统计 $[A, B]$ 之间有多少个不含数字 `4` 的数字。

```python
# 例如，计算 [1, N] 范围内不含 4 的数字数量
# dp 数组用于记忆化搜索：dp[pos][tight][has_leading_zero][state_related_to_4_seen]

s = "" # 将 N 转换为字符串，方便按位处理
memo = {} # 记忆化字典

def dfs_digit_dp(pos, tight, leading_zero):
    # pos: 当前处理到数字的哪一位 (从左到右，0-indexed)
    # tight: 布尔值，当前位是否受到上限限制
    # leading_zero: 布尔值，当前是否还在处理前导零

    if pos == len(s): # 所有位都已处理完
        return 1 # 找到一个符合条件的数字

    state_key = (pos, tight, leading_zero)
    if state_key in memo:
        return memo[state_key]

    ans = 0
    upper_bound = int(s[pos]) if tight else 9 # 当前位能取的上限

    for digit in range(upper_bound + 1):
        if digit == 4: # 如果是4，跳过
            continue

        # 如果当前是前导零，并且当前位也取0，则下一位仍然是前导零
        new_leading_zero = leading_zero and (digit == 0)
        # 如果当前位取到上限，并且之前也是tight，则下一位仍然是tight
        new_tight = tight and (digit == upper_bound)
        
        # 递归调用
        ans += dfs_digit_dp(pos + 1, new_tight, new_leading_zero)
    
    memo[state_key] = ans
    return ans

# count_non_four(N) 的主函数
def count_non_four(n):
    global s, memo
    s = str(n)
    memo = {}
    # 注意：dfs_digit_dp 的调用，如果第一位是 0，可能会导致一些计数问题，需要额外处理或调整逻辑
    # 对于统计 [A,B] 范围内的数字，通常需要调整为 `count(B) - count(A-1)`
    # 且对于 `count(X)`，需要特别处理 X 本身是否包含 4。
    # 更严谨的数位DP通常会处理 leading_zero 和 tight 的组合情况。
    # 这里是一个简化版，仅作示意。
    # 一个更标准的处理方法是：
    # 比如 dfs(idx, sum, is_limit, is_num)
    # is_num: 表示当前位置前面是否已经填过数字了（用于处理前导0）。
    # 这个简化的例子，需要调整为 `(res = dfs(0, True, True))`，初始时是最高位，受限，有前导零。
    # 并且在最终返回时，如果 `is_num` 是 False (说明是纯前导零，没形成有效数字)，应该返回 0。
    # 对于本例，不包含4的数，前导零不影响，只要数字本身不包含4。
    # 一个更简单的理解，计算 `count(N)` 的函数:
    s = str(n)
    memo = {}
    return calculate_count_up_to_N(s, 0, True, True)

def calculate_count_up_to_N(num_str, pos, is_tight, is_leading_zero):
    if pos == len(num_str):
        # 如果is_leading_zero是True，说明到最后一位都是前导零，没有形成有效数字，返回0
        # 否则，形成了一个有效数字，返回1
        return 0 if is_leading_zero else 1

    state_key = (pos, is_tight, is_leading_zero)
    if state_key in memo:
        return memo[state_key]

    count = 0
    upper_bound = int(num_str[pos]) if is_tight else 9

    for digit in range(upper_bound + 1):
        if digit == 4:
            continue
        
        # 如果当前是前导零，且当前位取0，则下一位仍是前导零
        # 否则，已经开始形成有效数字，is_leading_zero = False
        next_is_leading_zero = is_leading_zero and (digit == 0)
        
        # 如果当前位取到上限，且之前也是is_tight，则下一位仍是is_tight
        next_is_tight = is_tight and (digit == upper_bound)
        
        # 递归计算下一位
        # 如果是前导零，且当前位也取0，则不计入结果（因为还没形成有效数字）
        # 只有当 next_is_leading_zero 为 False 时，才表示从这开始填的数字是有效的。
        # 另一种理解：如果 !is_leading_zero || digit != 0，表示当前位已经是非0数字或后续会是非0。
        # 但是对于“不含4”这类问题，我们关心的是所有位的组合，前导零的“数”本身不包含4。
        # 最简单的处理是：在最终判断 `if pos == len(num_str): return 1` 之前，如果 `is_leading_zero` 为真，则返回0。
        # 而这里递归进去的条件就直接是：
        count += calculate_count_up_to_N(num_str, pos + 1, next_is_tight, next_is_leading_zero)
        
        # 特别处理：当 `is_leading_zero` 为 True 且 `digit` 为 0 时，表示只是单纯填了前导零，
        # 这种情况下，递归函数本身只应该计算后续形成的“非零”数字。
        # 而对于本问题，如果数字是 007，我们只关心 7。
        # 实际上，我们需要在 `if pos == len(num_str):` 中返回 `1` 表示一个合法数字，
        # 然后在调用 `dfs(pos, is_tight, is_leading_zero)` 时，如果 `is_leading_zero` 为 `True` 且 `digit` 为 `0`，
        # 意味着当前填的还是前导 `0`，那么这个分支本身不代表一个独立的数，它只是为后续的数作准备。
        # 整个数位DP最常见的方式是：
        # dfs(pos, limit, is_zero, ...)
        # return (res = count(B)) - (res = count(A-1))
        # 这里的 `count_non_four` 就是 `count(N)` 的功能。
        # 最终的 `ans` 需要包含00, 01...09 等，但通常问题定义是正整数。
        # 如果问题是“统计0到N中不含4的数字”，那么0算一个。
        # 这里逻辑有点绕，直接给一个常见的简洁模板：
        
    memo[state_key] = count
    return count

# 实际应用中，通常会有一个入口函数来处理 N 本身。
# count(N):
#   res = 0
#   num_str = list(map(int, str(N)))
#   memo = {}
#   res = dfs(0, True, True) # dfs(index, is_limit, is_zero)
#   return res

# 考虑更通用和简洁的数位DP模板
def digit_dp_template(s_num_str):
    memo = {}

    def dfs(idx, is_limit, is_zero):
        # idx: 当前处理的位索引
        # is_limit: 是否受原数字对应位的限制 (True 表示当前位最大值是 s_num_str[idx])
        # is_zero: 是否当前位之前全是前导零 (True 表示是)
        
        if idx == len(s_num_str):
            # 所有位都已处理完。如果 is_zero 仍为 True，表示这个数是 0，根据题目要求可能需要计数或跳过
            # 如果是统计符合条件的数字个数，且 0 算作一个，则返回 1，否则返回 0
            # 对于“不含4的数”，0 是不含4的。
            return 1 if not is_zero else 0 # 如果没填过数字(is_zero)，则当前组合无效

        state_key = (idx, is_limit, is_zero)
        if state_key in memo: # and not is_limit: # 只有在不限位时，记忆化才有效
            # 这里需要注意，记忆化通常只在 is_limit 为 False 时有效，
            # 因为 is_limit 为 True 时，上限是动态的。
            # 但如果状态里包含了 is_limit，则记忆化是没问题的。
            return memo[state_key]

        count = 0
        up = int(s_num_str[idx]) if is_limit else 9

        for d in range(up + 1):
            if d == 4: # 特定条件：不能包含数字 4
                continue
            
            # 如果是前导零，且当前位也取0，则下一位仍是前导零
            next_is_zero = is_zero and (d == 0)
            
            # 如果当前位是0，且前缀都是0（即当前正在填前导零），那么它不构成一个“数”，不需要处理后续状态
            # 但对于“不含4的数字”这类问题，0045 和 45 视为一个数，前导零是不影响的。
            # 通常需要 is_zero 这个状态来处理 0 自身以及前导零的问题。
            
            # 这里的递归调用应该根据 `next_is_zero` 来调整
            # 如果 `next_is_zero` 为 True，表示目前还是前导0状态，当前填的数字不算一个有效数字的组成部分
            # 但在计数问题中，需要考虑所有可能的组合。
            # dfs(idx+1, is_limit and d == up, is_zero and d == 0)
            
            count += dfs(idx + 1, is_limit and (d == up), is_zero and (d == 0))
            
        memo[state_key] = count
        return count

    # 调用示例：计算 [0, N] 范围内不含 4 的数字数量
    # 示例计算 count(20) 不含4的数
    # s_num_str = "20"
    # memo.clear() # 清空缓存
    # return dfs(0, True, True)
    # 对于 0 本身，如果dfs(0, True, True)返回的是1，那么它会计算在内。
    # 很多数位DP问题要求统计正整数，此时需要减去1 (代表数字0)。
    # 比如 count(20) 会返回 18 (0-9: 10个，10-19: 10个。共20个。去掉4, 14, 共2个。所以18个。)
    # 实际测试： 1,2,3,5,6,7,8,9,10,11,12,13,15,16,17,18,19,20. 共18个。
    # 注意这里dfs(0,True,True)会把0也算进去，所以如果是求 [1, N] 区间内的，则需要减 1。
```
数位 DP 的实现细节往往是最复杂和最容易出错的，因为对 `is_limit` 和 `is_zero` 的处理需要非常精细。

---

## 动态规划的优化技巧

在实际问题中，DP 的时间和空间复杂度可能很高。因此，掌握一些优化技巧至关重要。

### 滚动数组优化 (Space Optimization)

前面在 0/1 背包和完全背包中已经演示过。当 $dp[i][\dots]$ 只依赖于 $dp[i-1][\dots]$ 时，可以将二维数组降维到一维，将 $O(N \cdot M)$ 的空间复杂度降低到 $O(M)$。

### 单调队列优化 (Monotonic Queue Optimization)

当 DP 转移方程的形式是 $dp[i] = \min_{j \in [i-k, i-1]} (dp[j] + cost(j, i))$，且 $cost(j,i)$ 具有某种性质时（例如，与 $j$ 或 $i$ 线性相关），我们可以使用单调队列来在 $O(1)$ 时间内找到滑动窗口内的最值，从而将内层循环从 $O(k)$ 优化到 $O(1)$，总时间复杂度从 $O(N \cdot k)$ 优化到 $O(N)$。

例如，滑动窗口最大值/最小值问题，或者一些带有窗口限制的 DP 问题，都可以考虑使用单调队列。

### 斜率优化 (Convex Hull Trick / Slope Optimization)

斜率优化是一种更高级的 DP 优化技术，适用于形如 $dp[i] = \min_{j < i} (dp[j] + a_i \cdot b_j + c_i)$ 的 DP 转移方程，其中 $a_i$ 和 $b_j$ 具有单调性。通过将转移方程变形为 $dp[j] + b_j \cdot a_i = dp[i] - c_i$，可以将其看作是关于 $a_i$ 的一次函数 $y = kx + b$ ($y = dp[j]$, $k = -b_j$, $x = a_i$, $b = dp[i] - c_i$)。
我们要求最小值，即在给定 $x$ 值时找到最低的点。如果点集和查询的斜率都具有单调性，我们可以维护一个下凸壳（或上凸壳）并使用单调队列或双端队列来维护凸壳，以 $O(1)$ 或 $O(\log N)$ 的时间复杂度进行查询和插入，将总复杂度从 $O(N^2)$ 优化到 $O(N)$ 或 $O(N \log N)$。

**经典应用：**
*   生产线问题（将一批货物分组，每组有固定启动成本和处理成本）
*   多边形分割问题
*   运输问题

斜率优化通常需要较强的数学推导和几何直观，是 DP 优化的难点之一。

### 四边形不等式优化 (Knuth's Optimization)

四边形不等式优化主要用于优化区间 DP 问题，当 $dp[i][j] = \min_{i \le k < j} (dp[i][k] + dp[k+1][j] + W(i,j))$ 形式的转移方程中，费用函数 $W(i,j)$ 满足四边形不等式（$W(a,c)+W(b,d) \le W(a,d)+W(b,c)$ 对于 $a \le b \le c \le d$ 成立）以及单调性时，可以证明最优分割点 $K[i][j]$ 也具有单调性：$K[i][j-1] \le K[i][j] \le K[i+1][j]$。
利用这种单调性，可以将枚举 $k$ 的范围从 $O(N)$ 缩小到 $O(K[i][j+1] - K[i-1][j])$，从而将区间 DP 的 $O(N^3)$ 复杂度优化到 $O(N^2)$。

**经典应用：**
*   石子合并问题（如果费用函数满足四边形不等式）
*   最优二叉搜索树（如果概率函数满足）
*   矩阵链乘法（如果矩阵维度满足）

---

## 总结与展望

走到这里，我们已经深入探讨了动态规划的核心概念、其两种实现方式以及它在斐波那契数列、背包问题、LCS、LIS、网格路径、区间合并、树形 DP、状态压缩以及数位 DP 等多种经典问题中的应用。我们还简要介绍了滚动数组、单调队列、斜率优化和四边形不等式优化等高级技巧。

动态规划之所以强大，因为它提供了一个系统化的方法来解决那些具有“最优子结构”和“重叠子问题”特征的难题。它强迫我们以一种分解和组合的思维方式去思考问题，这本身就是一种宝贵的思维训练。

掌握动态规划并非一蹴而就。它需要大量的练习和经验积累。当你面对一个新的问题时，尝试从以下几个方面入手：

1.  **明确目标：** 问题是要求最大值/最小值，还是计数，还是判断能否达到？
2.  **定义状态：** 这是 DP 最关键的一步。如何定义 $dp[\dots]$ 才能包含足够的信息来计算更大的子问题，且状态之间无后效性？
3.  **推导状态转移方程：** 找到当前状态与更小子问题状态之间的关系。
4.  **确定边界条件：** 最小规模子问题的解是什么？
5.  **确定计算顺序：** 是自底向上 (递推) 还是自顶向下 (记忆化搜索)？哪种更方便？
6.  **考虑优化：** 是否存在空间或时间上的优化机会？

动态规划是算法领域的一颗璀璨明珠，它不仅是面试和竞赛中的常客，更是我们在日常编程和解决实际问题时，优化代码性能、提升解决方案效率的利器。当你能熟练运用动态规划解决问题时，你会发现编程的世界又打开了一扇新的大门。

继续学习，继续探索，愿动态规划的算法之魂，常伴你的编程之路！我是 qmwneb946，下次再见！